<!doctype html>
<html><head><meta charset="utf-8"><meta name="viewport" content="width=device-width,initial-scale=1">
<title>arXiv 论文速递</title><style>
:root {
  --bg:#f8fafc; --card:#ffffff; --text:#0f172a; --muted:#667085; --border:#e5e7eb; --acc:#2563eb;
}
:root[data-theme="dark"] {
  --bg:#0b0f17; --card:#111827; --text:#e5e7eb; --muted:#9ca3af; --border:#1f2937; --acc:#2563eb;
}
*{box-sizing:border-box} body{margin:0;background:var(--bg);color:var(--text);
  font-family:ui-sans-serif,system-ui,-apple-system,Segoe UI,Roboto,Helvetica,Arial;line-height:1.6;}
.container{max-width:900px;margin:0 auto;padding:18px;}
.header{display:flex;gap:10px;justify-content:space-between;align-items:center;margin:8px 0 16px;flex-wrap:wrap}
h1{font-size:22px;margin:0}
.badge{font-size:12px;color:#111827;background:var(--acc);padding:2px 8px;border-radius:999px}
.card{background:var(--card);border:1px solid var(--border);border-radius:16px;padding:16px 18px;margin:14px 0;box-shadow:0 1px 2px rgba(0,0,0,.04)}
.title{font-weight:700;margin:0 0 6px 0;font-size:18px}
.meta-line{color:var(--muted);font-size:13px;margin:2px 0}
.links a{color:var(--acc);text-decoration:none;margin-right:12px}
.detail{margin-top:10px;background:rgba(2,6,23,.03);border:1px solid var(--border);border-radius:10px;padding:8px 10px}
summary{cursor:pointer;color:var(--acc)}
.mono{white-space:pre-wrap;background:rgba(2,6,23,.03);border:1px solid var(--border);padding:10px;border-radius:10px}
.row{display:grid;grid-template-columns:1fr;gap:12px}
@media (min-width: 860px) {
  .row-2{grid-template-columns:1fr 1fr}
}
.footer{color:var(--muted);font-size:13px;margin:20px 0 10px}
.hr{height:1px;background:var(--border);margin:14px 0}
.history-list a{display:block;color:var(--acc);text-decoration:none;margin:4px 0}
.controls{display:flex;gap:8px;align-items:center}
.btn{border:1px solid var(--border);background:var(--card);padding:6px 10px;border-radius:10px;cursor:pointer;color:var(--text)}
.btn:hover{border-color:var(--acc)}
</style>
<script>
(function() {
  const root = document.documentElement;
  function apply(t) {
    if (t==='dark') root.setAttribute('data-theme','dark');
    else if (t==='light') root.removeAttribute('data-theme');
    else {
      if (window.matchMedia && window.matchMedia('(prefers-color-scheme: dark)').matches)
        root.setAttribute('data-theme','dark');
      else root.removeAttribute('data-theme');
    }
  }
  let t = localStorage.getItem('theme') || 'light';
  if (!['light','dark','auto'].includes(t)) t='light';
  apply(t);
  window.__toggleTheme = function() {
    let cur = localStorage.getItem('theme') || 'light';
    if (cur==='light') cur='dark';
    else if (cur==='dark') cur='auto';
    else cur='light';
    localStorage.setItem('theme', cur);
    apply(cur);
    const el=document.getElementById('theme-label');
    if(el) el.textContent = cur.toUpperCase();
  }
  window.__expandAll = function(open) {
    document.querySelectorAll('details').forEach(d => d.open = !!open);
  }
})();
</script>
</head>
<body>
  <div class="container">
    <div class="header">
      <h1>arXiv 论文速递</h1>
      <div style="display:flex;gap:10px;align-items:center">
        
<div class="controls">
  <button class="btn" onclick="__toggleTheme()">Theme: <span id="theme-label" style="margin-left:6px">AUTO</span></button>
  <button class="btn" onclick="__expandAll(true)">Expand All</button>
  <button class="btn" onclick="__expandAll(false)">Collapse All</button>
</div>

        <span class="badge">2026-02-06 03:45</span>
      </div>
    </div>
    <div class="hr"></div>
    <div>Snapshot: 20260206_0345</div>
    <div class="row"><div class="card">
<div class="title">Protein Autoregressive Modeling via Multiscale Structure Generation</div>
<div class="meta-line">Authors: Yanru Qu, Cheng-Yen Hsieh, Zaixiang Zheng, Ge Liu, Quanquan Gu</div>
<div class="meta-line">First: 2026-02-04T18:59:49+00:00 · Latest: 2026-02-04T18:59:49+00:00</div>
<div class="meta-line">Comments: ByteDance Seed Tech Report; Page: https://par-protein.github.io/</div>
<div class="links" style="margin-top:8px"><a href="https://arxiv.org/abs/2602.04883v1">Abs</a> · <a href="https://arxiv.org/pdf/2602.04883v1">PDF</a> · <a href="https://huggingface.co/huggingface">Code1</a> · <a href="https://huggingface.co/docs/hub/spaces">Code2</a> · <a href="https://par-protein.github.io/">Project1</a></div>
<details class="detail"><summary>Abstract</summary>
<div class="mono">We present protein autoregressive modeling (PAR), the first multi-scale autoregressive framework for protein backbone generation via coarse-to-fine next-scale prediction. Using the hierarchical nature of proteins, PAR generates structures that mimic sculpting a statue, forming a coarse topology and refining structural details over scales. To achieve this, PAR consists of three key components: (i) multi-scale downsampling operations that represent protein structures across multiple scales during training; (ii) an autoregressive transformer that encodes multi-scale information and produces conditional embeddings to guide structure generation; (iii) a flow-based backbone decoder that generates backbone atoms conditioned on these embeddings. Moreover, autoregressive models suffer from exposure bias, caused by the training and the generation procedure mismatch, and substantially degrades structure generation quality. We effectively alleviate this issue by adopting noisy context learning and scheduled sampling, enabling robust backbone generation. Notably, PAR exhibits strong zero-shot generalization, supporting flexible human-prompted conditional generation and motif scaffolding without requiring fine-tuning. On the unconditional generation benchmark, PAR effectively learns protein distributions and produces backbones of high design quality, and exhibits favorable scaling behavior. Together, these properties establish PAR as a promising framework for protein structure generation.</div></details>
<details class="detail"><summary>中文标题/摘要</summary>
<div class="mono"><b>标题：</b>蛋白质自回归建模：通过多尺度结构生成</div>
<div class="mono" style="margin-top:8px">我们提出了蛋白质自回归建模（PAR），这是首个通过从粗到细的下一尺度预测实现蛋白质骨架生成的多尺度自回归框架。利用蛋白质的层次化特性，PAR生成结构的过程类似于雕刻雕像，先形成粗略拓扑，再逐尺度细化结构细节。为实现这一目标，PAR包含三个关键组件：（i）多尺度下采样操作，在训练中表示跨多个尺度的蛋白质结构；（ii）自回归Transformer，编码多尺度信息并生成条件嵌入以指导结构生成；（iii）基于流的骨架解码器，根据这些嵌入生成骨架原子。此外，自回归模型存在暴露偏差问题，由训练与生成过程不匹配引起，会显著降低结构生成质量。我们通过采用噪声上下文学习和计划采样有效缓解了这一问题，实现了稳健的骨架生成。值得注意的是，PAR展现出强大的零样本泛化能力，支持灵活的人工提示条件生成和基序支架构建，无需微调。在无条件生成基准测试中，PAR有效学习了蛋白质分布，生成了具有高设计质量的骨架，并表现出良好的扩展性。这些特性共同确立了PAR作为蛋白质结构生成的有前景框架。</div>
</details>
<details class="detail"><summary>Summary / 总结</summary>
<div class="mono">Motivated by the hierarchical nature of proteins, this work introduces Protein Autoregressive Modeling (PAR), a multi-scale autoregressive framework for generating protein backbones through coarse-to-fine next-scale prediction. The method employs multi-scale downsampling, an autoregressive transformer for encoding multi-scale information, and a flow-based backbone decoder to generate atomic coordinates, while mitigating exposure bias via noisy context learning and scheduled sampling. Key experimental results demonstrate that PAR learns protein distributions effectively, produces high-quality backbones in unconditional generation benchmarks, exhibits favorable scaling behavior, and shows strong zero-shot generalization for conditional tasks like motif scaffolding without requiring fine-tuning.</div>
<div class="mono" style="margin-top:8px">该研究针对蛋白质骨架结构生成的挑战，提出了蛋白质自回归建模（PAR），这是一个多尺度自回归框架，通过先生成粗粒度拓扑再细化细节来模拟雕刻过程。该方法采用多尺度下采样在不同分辨率上表示结构，使用自回归变换器编码多尺度信息并产生条件嵌入，以及基于流的骨架解码器生成原子。为缓解暴露偏差，它结合了噪声上下文学习和计划采样。实验表明，PAR在无需微调的情况下实现了强大的零样本泛化能力，支持条件生成和基序支架设计，在无条件生成基准上有效学习蛋白质分布，产生高质量骨架，并展现出良好的扩展性。</div>
</details>
</div>
<div class="card">
<div class="title">Contrastive Continual Learning for Model Adaptability in Internet of Things</div>
<div class="meta-line">Authors: Ajesh Koyatan Chathoth</div>
<div class="meta-line">First: 2026-02-04T18:59:14+00:00 · Latest: 2026-02-04T18:59:14+00:00</div>
<div class="links" style="margin-top:8px"><a href="https://arxiv.org/abs/2602.04881v1">Abs</a> · <a href="https://arxiv.org/pdf/2602.04881v1">PDF</a> · <a href="https://huggingface.co/huggingface">Code1</a> · <a href="https://huggingface.co/docs/hub/spaces">Code2</a></div>
<details class="detail"><summary>Abstract</summary>
<div class="mono">Internet of Things (IoT) deployments operate in nonstationary, dynamic environments where factors such as sensor drift, evolving user behavior, and heterogeneous user privacy requirements can affect application utility. Continual learning (CL) addresses this by adapting models over time without catastrophic forgetting. Meanwhile, contrastive learning has emerged as a powerful representation-learning paradigm that improves robustness and sample efficiency in a self-supervised manner. This paper reviews the usage of \emph{contrastive continual learning} (CCL) for IoT, connecting algorithmic design (replay, regularization, distillation, prompts) with IoT system realities (TinyML constraints, intermittent connectivity, privacy). We present a unifying problem formulation, derive common objectives that blend contrastive and distillation losses, propose an IoT-oriented reference architecture for on-device, edge, and cloud-based CCL, and provide guidance on evaluation protocols and metrics. Finally, we highlight open unique challenges with respect to the IoT domain, such as spanning tabular and streaming IoT data, concept drift, federated settings, and energy-aware training.</div></details>
<details class="detail"><summary>中文标题/摘要</summary>
<div class="mono"><b>标题：</b>对比持续学习在物联网中的模型适应性研究</div>
<div class="mono" style="margin-top:8px">物联网部署运行于非平稳的动态环境中，传感器漂移、用户行为演变及异构隐私需求等因素可能影响应用效能。持续学习通过随时间调整模型以避免灾难性遗忘来应对此问题。同时，对比学习作为一种强大的表示学习范式，以自监督方式提升了鲁棒性与样本效率。本文综述了对比持续学习在物联网中的应用，将算法设计（回放、正则化、蒸馏、提示）与物联网系统现实（TinyML限制、间歇连接、隐私）相结合。我们提出了统一的问题框架，推导了融合对比与蒸馏损失的共同目标，设计了面向物联网的端侧、边缘与云端对比持续学习参考架构，并提供了评估协议与指标的指导。最后，重点探讨了物联网领域特有的开放挑战，如跨表格与流式数据、概念漂移、联邦学习场景及能耗感知训练。</div>
</details>
<details class="detail"><summary>Summary / 总结</summary>
<div class="mono">This paper addresses the need for adaptable machine learning models in IoT environments, which are characterized by nonstationary conditions like sensor drift and evolving user behaviors. It proposes a framework for contrastive continual learning (CCL) that integrates contrastive learning&#x27;s self-supervised representation benefits with continual learning techniques such as replay and distillation to mitigate catastrophic forgetting. The study formulates a unified problem, designs an IoT-specific architecture for on-device, edge, and cloud deployment, and identifies key challenges including handling tabular and streaming data, concept drift, and energy constraints in federated settings.</div>
<div class="mono" style="margin-top:8px">本文针对物联网环境中因传感器漂移和用户行为变化等非平稳条件而需要自适应机器学习模型的问题，提出了一种将对比学习与持续学习技术（如回放和蒸馏）相结合的框架，以提高模型的鲁棒性和样本效率，同时避免灾难性遗忘。研究提出了统一的问题表述，设计了适用于物联网的参考架构，支持设备端、边缘和云端部署，并指出了处理表格与流数据、概念漂移以及在联邦设置中进行能量感知训练等关键挑战。</div>
</details>
</div>
<div class="card">
<div class="title">Rethinking the Trust Region in LLM Reinforcement Learning</div>
<div class="meta-line">Authors: Penghui Qi, Xiangxin Zhou, Zichen Liu, Tianyu Pang, Chao Du, Min Lin, Wee Sun Lee</div>
<div class="meta-line">First: 2026-02-04T18:59:04+00:00 · Latest: 2026-02-04T18:59:04+00:00</div>
<div class="links" style="margin-top:8px"><a href="https://arxiv.org/abs/2602.04879v1">Abs</a> · <a href="https://arxiv.org/pdf/2602.04879v1">PDF</a> · <a href="https://huggingface.co/huggingface">Code1</a> · <a href="https://huggingface.co/docs/hub/spaces">Code2</a></div>
<details class="detail"><summary>Abstract</summary>
<div class="mono">Reinforcement learning (RL) has become a cornerstone for fine-tuning Large Language Models (LLMs), with Proximal Policy Optimization (PPO) serving as the de facto standard algorithm. Despite its ubiquity, we argue that the core ratio clipping mechanism in PPO is structurally ill-suited for the large vocabularies inherent to LLMs. PPO constrains policy updates based on the probability ratio of sampled tokens, which serves as a noisy single-sample Monte Carlo estimate of the true policy divergence. This creates a sub-optimal learning dynamic: updates to low-probability tokens are aggressively over-penalized, while potentially catastrophic shifts in high-probability tokens are under-constrained, leading to training inefficiency and instability. To address this, we propose Divergence Proximal Policy Optimization (DPPO), which substitutes heuristic clipping with a more principled constraint based on a direct estimate of policy divergence (e.g., Total Variation or KL). To avoid huge memory footprint, we introduce the efficient Binary and Top-K approximations to capture the essential divergence with negligible overhead. Extensive empirical evaluations demonstrate that DPPO achieves superior training stability and efficiency compared to existing methods, offering a more robust foundation for RL-based LLM fine-tuning.</div></details>
<details class="detail"><summary>中文标题/摘要</summary>
<div class="mono"><b>标题：</b>重新思考大语言模型强化学习中的信任区域</div>
<div class="mono" style="margin-top:8px">强化学习已成为微调大语言模型的核心技术，其中近端策略优化算法是实际采用的标准方法。尽管应用广泛，我们认为PPO核心的概率比截断机制在结构上并不适合大语言模型固有的巨大词汇量。PPO基于采样词元的概率比约束策略更新，该比值是对真实策略散度的噪声单样本蒙特卡洛估计。这导致了次优的学习动态：对低概率词元的更新被过度惩罚，而高概率词元可能出现的灾难性偏移却约束不足，从而造成训练效率低下和稳定性问题。为此，我们提出散度近端策略优化算法，用基于策略散度直接估计（如总变差或KL散度）的原则性约束替代启发式截断。为避免巨大内存开销，我们引入高效的二元与Top-K近似方法，以可忽略的开销捕捉核心散度。大量实验评估表明，DPPO相比现有方法实现了更优的训练稳定性和效率，为基于强化学习的大语言模型微调提供了更稳健的基础。</div>
</details>
<details class="detail"><summary>Summary / 总结</summary>
<div class="mono">This work identifies a structural limitation in Proximal Policy Optimization (PPO) for fine-tuning Large Language Models, where its token-level ratio clipping creates noisy, sub-optimal constraints that over-penalize low-probability tokens and under-constrain high-probability ones, leading to instability. The proposed Divergence Proximal Policy Optimization (DPPO) replaces heuristic clipping with a direct constraint on policy divergence (e.g., Total Variation or KL) and introduces efficient Binary and Top-K approximations to manage computational cost. Experiments show DPPO achieves superior training stability and efficiency compared to existing methods for RL-based LLM fine-tuning.</div>
<div class="mono" style="margin-top:8px">该研究的动机在于，针对大语言模型微调，近端策略优化（PPO）的核心比率裁剪机制在结构上存在局限：它基于采样词元的概率比进行约束，这是一种对真实策略散度的噪声单样本蒙特卡洛估计，导致对低概率词元的更新被过度惩罚，而对高概率词元的潜在灾难性偏移约束不足，从而造成训练效率低下和不稳定。为此，研究者提出了散度近端策略优化（DPPO），用基于直接估计策略散度（如总变差或KL散度）的原则性约束替代启发式裁剪，并引入了高效的二值化和Top-K近似以控制计算开销。大量实验评估表明，与现有方法相比，DPPO实现了更优的训练稳定性和效率，为基于强化学习的大语言模型微调提供了更稳健的基础。</div>
</details>
</div>
<div class="card">
<div class="title">Multi-layer Cross-Attention is Provably Optimal for Multi-modal In-context Learning</div>
<div class="meta-line">Authors: Nicholas Barnfield, Subhabrata Sen, Pragya Sur</div>
<div class="meta-line">First: 2026-02-04T18:57:30+00:00 · Latest: 2026-02-04T18:57:30+00:00</div>
<div class="links" style="margin-top:8px"><a href="https://arxiv.org/abs/2602.04872v1">Abs</a> · <a href="https://arxiv.org/pdf/2602.04872v1">PDF</a> · <a href="https://huggingface.co/huggingface">Code1</a> · <a href="https://huggingface.co/docs/hub/spaces">Code2</a></div>
<details class="detail"><summary>Abstract</summary>
<div class="mono">Recent progress has rapidly advanced our understanding of the mechanisms underlying in-context learning in modern attention-based neural networks. However, existing results focus exclusively on unimodal data; in contrast, the theoretical underpinnings of in-context learning for multi-modal data remain poorly understood. We introduce a mathematically tractable framework for studying multi-modal learning and explore when transformer-like architectures can recover Bayes-optimal performance in-context. To model multi-modal problems, we assume the observed data arises from a latent factor model. Our first result comprises a negative take on expressibility: we prove that single-layer, linear self-attention fails to recover the Bayes-optimal predictor uniformly over the task distribution. To address this limitation, we introduce a novel, linearized cross-attention mechanism, which we study in the regime where both the number of cross-attention layers and the context length are large. We show that this cross-attention mechanism is provably Bayes optimal when optimized using gradient flow. Our results underscore the benefits of depth for in-context learning and establish the provable utility of cross-attention for multi-modal distributions.</div></details>
<details class="detail"><summary>中文标题/摘要</summary>
<div class="mono"><b>标题：</b>多层交叉注意力被证明是多模态上下文学习的最优方案</div>
<div class="mono" style="margin-top:8px">近期研究快速推进了我们对现代基于注意力的神经网络中上下文学习机制的理解。然而，现有成果仅聚焦于单模态数据；相比之下，多模态数据上下文学习的理论基础仍知之甚少。我们引入一个数学上可处理的框架来研究多模态学习，并探究类Transformer架构何时能在上下文中恢复贝叶斯最优性能。为建模多模态问题，我们假设观测数据源自潜在因子模型。首个结果呈现了表达能力的负面结论：我们证明单层线性自注意力无法在任务分布上一致地恢复贝叶斯最优预测器。为突破此局限，我们提出一种新颖的线性化交叉注意力机制，并在交叉注意力层数与上下文长度均较大的场景下进行研究。结果表明，该交叉注意力机制在使用梯度流优化时可被严格证明达到贝叶斯最优。我们的研究凸显了深度对上下文学习的益处，并确立了交叉注意力机制对多模态分布的可证明效用。</div>
</details>
<details class="detail"><summary>Summary / 总结</summary>
<div class="mono">The research is motivated by the lack of theoretical understanding of in-context learning for multi-modal data, despite recent progress in unimodal settings. The method introduces a mathematically tractable framework based on a latent factor model for multi-modal data and analyzes transformer-like architectures, proving that single-layer linear self-attention is insufficient for Bayes-optimal prediction. To overcome this, a novel linearized cross-attention mechanism is proposed and studied in the regime of many layers and long context lengths. Key experimental findings show that this cross-attention mechanism, when optimized via gradient flow, provably achieves Bayes-optimal performance, highlighting the necessity of depth and the utility of cross-attention for multi-modal in-context learning.</div>
<div class="mono" style="margin-top:8px">本研究针对多模态上下文学习中理论理解的缺乏，引入了一个基于潜在因子模型的可处理框架，以分析Transformer架构何时能实现贝叶斯最优性能。方法上，首先证明了单层线性自注意力机制的不足，进而提出了一种新颖的线性化交叉注意力机制，并在多层和长上下文长度的条件下进行分析。关键实验结果表明，通过梯度流优化后，该交叉注意力机制被证明是贝叶斯最优的，这强调了深度对于上下文学习的必要性以及交叉注意力在多模态分布中的可证明效用。</div>
</details>
</div>
<div class="card">
<div class="title">CRoSS: A Continual Robotic Simulation Suite for Scalable Reinforcement Learning with High Task Diversity and Realistic Physics Simulation</div>
<div class="meta-line">Authors: Yannick Denker, Alexander Gepperth</div>
<div class="meta-line">First: 2026-02-04T18:54:26+00:00 · Latest: 2026-02-04T18:54:26+00:00</div>
<div class="links" style="margin-top:8px"><a href="https://arxiv.org/abs/2602.04868v1">Abs</a> · <a href="https://arxiv.org/pdf/2602.04868v1">PDF</a> · <a href="https://huggingface.co/huggingface">Code1</a> · <a href="https://huggingface.co/docs/hub/spaces">Code2</a></div>
<details class="detail"><summary>Abstract</summary>
<div class="mono">Continual reinforcement learning (CRL) requires agents to learn from a sequence of tasks without forgetting previously acquired policies. In this work, we introduce a novel benchmark suite for CRL based on realistically simulated robots in the Gazebo simulator. Our Continual Robotic Simulation Suite (CRoSS) benchmarks rely on two robotic platforms: a two-wheeled differential-drive robot with lidar, camera and bumper sensor, and a robotic arm with seven joints. The former represent an agent in line-following and object-pushing scenarios, where variation of visual and structural parameters yields a large number of distinct tasks, whereas the latter is used in two goal-reaching scenarios with high-level cartesian hand position control (modeled after the Continual World benchmark), and low-level control based on joint angles. For the robotic arm benchmarks, we provide additional kinematics-only variants that bypass the need for physical simulation (as long as no sensor readings are required), and which can be run two orders of magnitude faster. CRoSS is designed to be easily extensible and enables controlled studies of continual reinforcement learning in robotic settings with high physical realism, and in particular allow the use of almost arbitrary simulated sensors. To ensure reproducibility and ease of use, we provide a containerized setup (Apptainer) that runs out-of-the-box, and report performances of standard RL algorithms, including Deep Q-Networks (DQN) and policy gradient methods. This highlights the suitability as a scalable and reproducible benchmark for CRL research.</div></details>
<details class="detail"><summary>中文标题/摘要</summary>
<div class="mono"><b>标题：</b>CRoSS：面向高任务多样性与真实物理仿真的可扩展强化学习持续机器人仿真套件</div>
<div class="mono" style="margin-top:8px">持续强化学习要求智能体在任务序列中学习且不遗忘已习得的策略。本研究基于Gazebo仿真器中的高拟真机器人，提出一种新颖的持续强化学习基准套件。该持续机器人仿真套件采用两种机器人平台：配备激光雷达、摄像头和碰撞传感器的两轮差速驱动机器人，以及七关节机械臂。前者用于线跟随和物体推动场景，通过视觉与结构参数变化生成大量差异化任务；后者应用于两种目标抵达场景：基于笛卡尔手部位置的高层控制（延续Continual World基准设计）和基于关节角度的底层控制。针对机械臂基准，我们额外提供仅需运动学计算的变体方案（无需传感器读数时可跳过物理仿真），其运行速度可提升两个数量级。本套件具备易扩展性，支持在高度物理真实的机器人环境中进行受控的持续强化学习研究，尤其支持近乎任意的仿真传感器配置。为确保可复现性与易用性，我们提供开箱即用的容器化部署方案（Apptainer），并报告了深度Q网络、策略梯度等标准强化学习算法的性能表现，验证了其作为可扩展、可复现的持续强化学习研究基准的适用性。</div>
</details>
<details class="detail"><summary>Summary / 总结</summary>
<div class="mono">This work introduces CRoSS, a benchmark suite for continual reinforcement learning (CRL) that addresses the need for scalable evaluation in robotic settings with high task diversity and realistic physics. The method is based on two simulated robotic platforms in Gazebo: a differential-drive robot for line-following and object-pushing tasks with varied visual and structural parameters, and a 7-joint robotic arm for goal-reaching tasks under both high-level Cartesian and low-level joint control, with kinematics-only variants provided for faster computation. Key experimental findings demonstrate the suite&#x27;s extensibility and controlled study capabilities, with containerized setups ensuring reproducibility, and initial performance reports of standard RL algorithms like DQN and policy gradient methods confirming its suitability as a scalable benchmark.</div>
<div class="mono" style="margin-top:8px">本研究提出了CRoSS，一个用于持续强化学习的基准测试套件，旨在解决机器人场景中需要高任务多样性和逼真物理仿真的可扩展评估需求。该方法基于Gazebo仿真器，使用两个机器人平台构建基准：一个用于具有可变视觉和结构参数的循线和物体推动任务的差速驱动机器人，以及一个用于具有高级笛卡尔控制和低级关节控制的目标到达任务的七关节机械臂，其中包含可快速运行的仅运动学变体。主要实验结果表明，CRoSS支持高物理真实性的受控研究，兼容几乎任意的仿真传感器，并提供可复现的容器化设置，能够评估DQN和策略梯度等标准强化学习算法，从而确立了其作为可扩展基准的适用性。</div>
</details>
</div>
<div class="card">
<div class="title">Subliminal Effects in Your Data: A General Mechanism via Log-Linearity</div>
<div class="meta-line">Authors: Ishaq Aden-Ali, Noah Golowich, Allen Liu, Abhishek Shetty, Ankur Moitra, Nika Haghtalab</div>
<div class="meta-line">First: 2026-02-04T18:50:46+00:00 · Latest: 2026-02-04T18:50:46+00:00</div>
<div class="meta-line">Comments: Code available at https://github.com/ishaqadenali/logit-linear-selection</div>
<div class="links" style="margin-top:8px"><a href="https://arxiv.org/abs/2602.04863v1">Abs</a> · <a href="https://arxiv.org/pdf/2602.04863v1">PDF</a> · <a href="https://github.com/ishaqadenali/logit-linear-selection">Code1</a> · <a href="https://huggingface.co/huggingface">Code2</a> · <a href="https://huggingface.co/docs/hub/spaces">Code3</a></div>
<details class="detail"><summary>Abstract</summary>
<div class="mono">Training modern large language models (LLMs) has become a veritable smorgasbord of algorithms and datasets designed to elicit particular behaviors, making it critical to develop techniques to understand the effects of datasets on the model&#x27;s properties. This is exacerbated by recent experiments that show datasets can transmit signals that are not directly observable from individual datapoints, posing a conceptual challenge for dataset-centric understandings of LLM training and suggesting a missing fundamental account of such phenomena. Towards understanding such effects, inspired by recent work on the linear structure of LLMs, we uncover a general mechanism through which hidden subtexts can arise in generic datasets.
  We introduce Logit-Linear-Selection (LLS), a method that prescribes how to select subsets of a generic preference dataset to elicit a wide range of hidden effects. We apply LLS to discover subsets of real-world datasets so that models trained on them exhibit behaviors ranging from having specific preferences, to responding to prompts in a different language not present in the dataset, to taking on a different persona. Crucially, the effect persists for the selected subset, across models with varying architectures, supporting its generality and universality.</div></details>
<details class="detail"><summary>中文标题/摘要</summary>
<div class="mono"><b>标题：</b>数据中的潜意识效应：基于对数线性的通用机制</div>
<div class="mono" style="margin-top:8px">训练现代大语言模型已成为融合多种算法与数据集的复杂过程，这些设计旨在激发特定行为，因此开发理解数据集对模型特性影响的技术至关重要。近期实验进一步表明，数据集可能传递无法从单个数据点直接观测的信号，这对以数据集为中心的大语言模型训练理解提出了概念性挑战，并暗示此类现象缺乏根本性理论解释。为探究此类效应，受大语言模型线性结构研究的启发，我们揭示了一种通用机制，可解释隐藏潜文本在通用数据集中的形成原理。
我们提出对数线性选择法——一种通过筛选通用偏好数据集的子集来激发多种隐藏效应的方法。应用该方法从现实数据集中发现的子集，能使训练出的模型展现出从特定偏好、响应数据集中不存在的异语言提示到呈现不同人格特征等一系列行为。关键的是，这种效应在不同架构的模型中均对选定子集保持稳定，印证了其普适性与通用性。</div>
</details>
<details class="detail"><summary>Summary / 总结</summary>
<div class="mono">The research is motivated by the need to understand how datasets influence large language models (LLMs), especially given evidence that datasets can transmit signals not apparent in individual data points, challenging dataset-centric explanations. The method introduces Logit-Linear-Selection (LLS), a technique for selecting subsets from generic preference datasets to elicit hidden effects, such as specific preferences, responses in unseen languages, or altered personas. Key experimental findings show that models trained on these subsets consistently exhibit the targeted behaviors across different architectures, demonstrating the generality and persistence of the effect.</div>
<div class="mono" style="margin-top:8px">本研究旨在理解数据集如何影响大语言模型（LLM）的行为，特别是考虑到数据集可能传递单条数据中无法观察到的信号。为此，我们提出了一种通用机制来解释隐藏的潜文本，并引入了Logit-Linear-Selection（LLS）方法，该方法规定了如何从通用偏好数据集中选择子集以引发特定的隐藏效应。关键实验结果表明，将LLS应用于真实世界数据集后，训练出的模型能够表现出特定偏好、以数据集中未出现的语言进行回复以及呈现不同人格等行为，且这些效应在选定的子集和不同架构的模型中均能持续存在，证明了其普遍性。</div>
</details>
</div>
<div class="card">
<div class="title">From Evaluation to Design: Using Potential Energy Surface Smoothness Metrics to Guide Machine Learning Interatomic Potential Architectures</div>
<div class="meta-line">Authors: Ryan Liu, Eric Qu, Tobias Kreiman, Samuel M. Blau, Aditi S. Krishnapriyan</div>
<div class="meta-line">First: 2026-02-04T18:50:10+00:00 · Latest: 2026-02-04T18:50:10+00:00</div>
<div class="meta-line">Comments: 13 pages main text, 10 pages reference &amp; appendix, 8 figures</div>
<div class="links" style="margin-top:8px"><a href="https://arxiv.org/abs/2602.04861v1">Abs</a> · <a href="https://arxiv.org/pdf/2602.04861v1">PDF</a> · <a href="https://huggingface.co/huggingface">Code1</a> · <a href="https://huggingface.co/docs/hub/spaces">Code2</a></div>
<details class="detail"><summary>Abstract</summary>
<div class="mono">Machine Learning Interatomic Potentials (MLIPs) sometimes fail to reproduce the physical smoothness of the quantum potential energy surface (PES), leading to erroneous behavior in downstream simulations that standard energy and force regression evaluations can miss. Existing evaluations, such as microcanonical molecular dynamics (MD), are computationally expensive and primarily probe near-equilibrium states. To improve evaluation metrics for MLIPs, we introduce the Bond Smoothness Characterization Test (BSCT). This efficient benchmark probes the PES via controlled bond deformations and detects non-smoothness, including discontinuities, artificial minima, and spurious forces, both near and far from equilibrium. We show that BSCT correlates strongly with MD stability while requiring a fraction of the cost of MD. To demonstrate how BSCT can guide iterative model design, we utilize an unconstrained Transformer backbone as a testbed, illustrating how refinements such as a new differentiable $k$-nearest neighbors algorithm and temperature-controlled attention reduce artifacts identified by our metric. By optimizing model design systematically based on BSCT, the resulting MLIP simultaneously achieves a low conventional E/F regression error, stable MD simulations, and robust atomistic property predictions. Our results establish BSCT as both a validation metric and as an &quot;in-the-loop&quot; model design proxy that alerts MLIP developers to physical challenges that cannot be efficiently evaluated by current MLIP benchmarks.</div></details>
<details class="detail"><summary>中文标题/摘要</summary>
<div class="mono"><b>标题：</b>从评估到设计：利用势能面平滑度指标指导机器学习原子间势能函数架构</div>
<div class="mono" style="margin-top:8px">机器学习原子间势能函数有时无法再现量子势能面的物理平滑性，导致下游模拟出现标准能量和力回归评估可能遗漏的错误行为。现有评估方法（如微正则分子动力学）计算成本高昂且主要探测近平衡态。为改进MLIP的评估指标，我们提出键平滑性表征测试。该高效基准通过受控键变形探测势能面，检测平衡态附近及远离平衡态的非平滑现象，包括不连续性、人工极小值和伪力。研究表明BSCT与MD稳定性强相关，而计算成本仅为MD的极小部分。为展示BSCT如何指导迭代模型设计，我们采用无约束Transformer主干作为测试平台，阐明新型可微分k近邻算法和温控注意力机制等改进如何减少该指标识别的伪影。基于BSCT系统优化模型设计后，所得MLIP同时实现了较低的传统能量/力回归误差、稳定的MD模拟和稳健的原子性质预测。本研究确立BSCT既可作为验证指标，也可作为“循环内”模型设计代理，向MLIP开发者警示当前基准测试无法高效评估的物理挑战。</div>
</details>
<details class="detail"><summary>Summary / 总结</summary>
<div class="mono">Machine Learning Interatomic Potentials (MLIPs) can fail to capture the physical smoothness of quantum potential energy surfaces, leading to simulation errors that standard regression evaluations miss, while existing tests like microcanonical molecular dynamics are computationally costly and limited to near-equilibrium states. To address this, the authors introduce the Bond Smoothness Characterization Test (BSCT), an efficient benchmark that probes the potential energy surface via controlled bond deformations to detect non-smoothness, including discontinuities and artificial minima, both near and far from equilibrium. Experimental results show that BSCT strongly correlates with molecular dynamics stability at a fraction of the cost, and when used to iteratively guide model design—such as by incorporating a differentiable k-nearest neighbors algorithm and temperature-controlled attention in a Transformer backbone—it helps produce an MLIP that achieves low regression error, stable simulations, and robust property predictions, establishing BSCT as both a validation metric and a design proxy for identifying physical challenges overlooked by current benchmarks.</div>
<div class="mono" style="margin-top:8px">机器学习原子间势能（MLIPs）有时无法再现量子势能面的物理平滑性，导致下游模拟出现错误，而标准的能量和力回归评估可能忽略这些问题，且现有评估如微正则分子动力学计算成本高且主要探测近平衡态。为此，研究者提出了键平滑性表征测试（BSCT），这是一种通过受控键变形探测势能面的高效基准测试，可检测非平滑性，包括不连续性、人工极小值和虚假力，适用于平衡态附近及远离平衡态的情况。实验结果表明，BSCT与分子动力学稳定性强相关，且计算成本大幅降低；当将其用于迭代指导模型设计时（例如在Transformer骨干网络中引入可微k近邻算法和温度控制注意力机制），BSCT有助于减少由该指标识别的伪影，最终得到的MLIP同时实现了较低的常规回归误差、稳定的分子动力学模拟和可靠的原子性质预测。</div>
</details>
</div>
<div class="card">
<div class="title">Beyond Fixed Frames: Dynamic Character-Aligned Speech Tokenization</div>
<div class="meta-line">Authors: Luca Della Libera, Cem Subakan, Mirco Ravanelli</div>
<div class="meta-line">First: 2026-01-30T16:58:40+00:00 · Latest: 2026-02-04T18:42:12+00:00</div>
<div class="meta-line">Comments: 18 pages, 3 figures</div>
<div class="links" style="margin-top:8px"><a href="https://arxiv.org/abs/2601.23174v2">Abs</a> · <a href="https://arxiv.org/pdf/2601.23174v2">PDF</a> · <a href="https://github.com/lucadellalib/dycast">Code1</a> · <a href="https://huggingface.co/huggingface">Code2</a> · <a href="https://huggingface.co/docs/hub/spaces">Code3</a></div>
<details class="detail"><summary>Abstract</summary>
<div class="mono">Neural audio codecs are at the core of modern conversational speech technologies, converting continuous speech into sequences of discrete tokens that can be processed by LLMs. However, existing codecs typically operate at fixed frame rates, allocating tokens uniformly in time and producing unnecessarily long sequences. In this work, we introduce DyCAST, a Dynamic Character-Aligned Speech Tokenizer that enables variable-frame-rate tokenization through soft character-level alignment and explicit duration modeling. DyCAST learns to associate tokens with character-level linguistic units during training and supports alignment-free inference with direct control over token durations at decoding time. To improve speech resynthesis quality at low frame rates, we further introduce a retrieval-augmented decoding mechanism that enhances reconstruction fidelity without increasing bitrate. Experiments show that DyCAST achieves competitive speech resynthesis quality and downstream performance while using significantly fewer tokens than fixed-frame-rate codecs. Code and checkpoints will be released publicly at https://github.com/lucadellalib/dycast.</div></details>
<details class="detail"><summary>中文标题/摘要</summary>
<div class="mono"><b>标题：</b>超越固定帧率：动态字符对齐的语音分词方法</div>
<div class="mono" style="margin-top:8px">神经音频编解码器是现代对话语音技术的核心，它将连续语音转换为可由大语言模型处理的离散标记序列。然而，现有编解码器通常以固定帧率运行，在时间上均匀分配标记并产生不必要的长序列。本研究提出DyCAST（动态字符对齐语音分词器），通过软字符级对齐和显式时长建模实现可变帧率分词。DyCAST在训练过程中学习将标记与字符级语言单元关联，并在解码时支持无需对齐的推理，直接控制标记时长。为提升低帧率下的语音重合成质量，我们进一步引入检索增强解码机制，在不增加比特率的情况下提高重建保真度。实验表明，DyCAST在使用显著少于固定帧率编解码器的标记数量时，仍能实现具有竞争力的语音重合成质量与下游任务性能。代码与模型检查点将通过 https://github.com/lucadellalib/dycast 公开。</div>
</details>
<details class="detail"><summary>Summary / 总结</summary>
<div class="mono">This work addresses the inefficiency of fixed-frame-rate neural audio codecs, which produce unnecessarily long token sequences by uniformly allocating tokens over time. The authors propose DyCAST, a dynamic character-aligned speech tokenizer that enables variable-frame-rate tokenization through soft character-level alignment and explicit duration modeling during training, and supports alignment-free inference with direct duration control. Experimental results demonstrate that DyCAST achieves competitive speech resynthesis quality and downstream performance while using significantly fewer tokens than fixed-frame-rate codecs, with a retrieval-augmented decoding mechanism further improving fidelity at low frame rates.</div>
<div class="mono" style="margin-top:8px">针对固定帧率神经音频编解码器效率低下、产生不必要长序列的问题，本研究提出了DyCAST，一种动态字符对齐的语音分词器。该方法通过训练时学习软字符级对齐和显式时长建模，实现了可变帧率分词，支持无需对齐的推理并可直接控制解码时的令牌时长；此外，还引入了检索增强的解码机制，在不增加比特率的情况下提升了低帧率下的重建保真度。实验结果表明，DyCAST在使用显著更少令牌的同时，实现了与固定帧率编解码器相竞争的语音重合成质量和下游任务性能。</div>
</details>
</div>
<div class="card">
<div class="title">El Agente Quntur: A research collaborator agent for quantum chemistry</div>
<div class="meta-line">Authors: Juan B. Pérez-Sánchez, Yunheng Zou, Jorge A. Campos-Gonzalez-Angulo, Marcel Müller, Ignacio Gustin, Andrew Wang, Han Hao, Tsz Wai Ko, Changhyeok Choi, Eric S. Isbrandt, Mohammad Ghazi Vakili, Hanyong Xu, Chris Crebolder, Varinia Bernales, Alán Aspuru-Guzik</div>
<div class="meta-line">First: 2026-02-04T18:38:50+00:00 · Latest: 2026-02-04T18:38:50+00:00</div>
<div class="links" style="margin-top:8px"><a href="https://arxiv.org/abs/2602.04850v1">Abs</a> · <a href="https://arxiv.org/pdf/2602.04850v1">PDF</a> · <a href="https://huggingface.co/huggingface">Code1</a> · <a href="https://huggingface.co/docs/hub/spaces">Code2</a></div>
<details class="detail"><summary>Abstract</summary>
<div class="mono">Quantum chemistry is a foundational enabling tool for the fields of chemistry, materials science, computational biology and others. Despite of its power, the practical application of quantum chemistry simulations remains in the hands of qualified experts due to methodological complexity, software heterogeneity, and the need for informed interpretation of results. To bridge the accessibility gap for these tools and expand their reach to chemists with broader backgrounds, we introduce El Agente Quntur, a hierarchical, multi-agent AI system designed to operate not merely as an automation tool but as a research collaborator for computational quantum chemistry. Quntur was designed following three main strategies: i) elimination of hard-coded procedural policies in favour of reasoning-driven decisions, ii) construction of general and composable actions that facilitate generalization and efficiency, and iii) implementation of guided deep research to integrate abstract quantum-chemical reasoning across subdisciplines and a detailed understanding of the software&#x27;s internal logic and syntax. Although instantiated in ORCA, these design principles are applicable to research agents more generally and easily expandable to additional quantum chemistry packages and beyond. Quntur supports the full range of calculations available in ORCA 6.0 and reasons over software documentation and scientific literature to plan, execute, adapt, and analyze in silico chemistry experiments following best practices. We discuss the advances and current bottlenecks in agentic systems operating at the research level in computational chemistry, and outline a roadmap toward a fully autonomous end-to-end computational chemistry research agent.</div></details>
<details class="detail"><summary>中文标题/摘要</summary>
<div class="mono"><b>标题：</b>Quntur智能体：面向量子化学研究的协作型智能代理系统</div>
<div class="mono" style="margin-top:8px">量子化学是化学、材料科学、计算生物学等领域的基础性支撑工具。尽管功能强大，但由于方法复杂性、软件异构性以及对结果需专业解读的要求，量子化学模拟的实际应用仍局限于合格专家。为降低工具使用门槛、拓展其面向更广泛化学背景的研究者，我们推出Quntur智能体——一个分层多智能体AI系统，其设计目标不仅是自动化工具，更是计算量子化学领域的研究协作伙伴。Quntur遵循三大核心策略：1) 摒弃硬编码流程策略，采用推理驱动决策；2) 构建通用可组合操作以提升泛化能力与效率；3) 实施引导式深度研究，整合跨子领域的抽象量子化学推理与软件内部逻辑语法的精细理解。虽基于ORCA平台实现，该设计原则可泛化至更广泛的研究智能体，并能便捷扩展至其他量子化学软件乃至更广领域。Quntur支持ORCA 6.0全部计算功能，通过解析软件文档与科学文献，遵循最佳实践对计算化学实验进行规划、执行、调整与分析。本文探讨了计算化学研究级智能体系统的进展与现存瓶颈，并勾勒了实现端到端全自主计算化学研究智能体的发展路径。</div>
</details>
<details class="detail"><summary>Summary / 总结</summary>
<div class="mono">The motivation for this work is to make quantum chemistry simulations more accessible to chemists with diverse backgrounds by overcoming the barriers of methodological complexity, software heterogeneity, and the need for expert interpretation. The method introduces El Agente Quntur, a hierarchical multi-agent AI system designed as a research collaborator, which employs reasoning-driven decisions instead of hard-coded policies, uses general and composable actions for efficiency, and integrates abstract quantum-chemical reasoning with detailed software knowledge, specifically instantiated in ORCA. Key experimental findings demonstrate that Quntur supports the full range of calculations in ORCA 6.0, can plan, execute, adapt, and analyze in silico experiments by reasoning over documentation and literature, and its design principles are generalizable to other quantum chemistry packages and research agents, though bottlenecks in achieving full autonomy are identified.</div>
<div class="mono" style="margin-top:8px">该研究旨在通过克服当前量子化学模拟中方法复杂、软件异构且需要专家解读的障碍，使具有不同背景的化学家更容易使用这些工具。为此，作者引入了El Agente Quntur，这是一个分层多智能体AI系统，被设计为研究协作者，采用推理驱动的决策、通用可组合操作以及结合抽象量子化学推理与软件特定逻辑的引导深度研究，具体在ORCA 6.0中实现。实验结果表明，Quntur能够遵循最佳实践，利用文档和文献来规划、执行、调整和分析全面的量子化学计算，其设计原则可推广到其他软件包，但完全自主的端到端研究智能体仍存在瓶颈。</div>
</details>
</div>
<div class="card">
<div class="title">El Agente Estructural: An Artificially Intelligent Molecular Editor</div>
<div class="meta-line">Authors: Changhyeok Choi, Yunheng Zou, Marcel Müller, Han Hao, Yeonghun Kang, Juan B. Pérez-Sánchez, Ignacio Gustin, Hanyong Xu, Mohammad Ghazi Vakili, Chris Crebolder, Alán Aspuru-Guzik, Varinia Bernales</div>
<div class="meta-line">First: 2026-02-04T18:38:48+00:00 · Latest: 2026-02-04T18:38:48+00:00</div>
<div class="links" style="margin-top:8px"><a href="https://arxiv.org/abs/2602.04849v1">Abs</a> · <a href="https://arxiv.org/pdf/2602.04849v1">PDF</a> · <a href="https://huggingface.co/huggingface">Code1</a> · <a href="https://huggingface.co/docs/hub/spaces">Code2</a></div>
<details class="detail"><summary>Abstract</summary>
<div class="mono">We present El Agente Estructural, a multimodal, natural-language-driven geometry-generation and manipulation agent for autonomous chemistry and molecular modelling. Unlike molecular generation or editing via generative models, Estructural mimics how human experts directly manipulate molecular systems in three dimensions by integrating a comprehensive set of domain-informed tools and vision-language models. This design enables precise control over atomic or functional group replacements, atomic connectivity, and stereochemistry without the need to rebuild extensive core molecular frameworks. Through a series of representative case studies, we demonstrate that Estructural enables chemically meaningful geometry manipulation across a wide range of real-world scenarios. These include site-selective functionalization, ligand binding, ligand exchange, stereochemically controlled structure construction, isomer interconversion, fragment-level structural analysis, image-guided generation of structures from schematic reaction mechanisms, and mechanism-driven geometry generation and modification. These examples illustrate how multimodal reasoning, when combined with specialized geometry-aware tools, supports interactive and context-aware molecular modelling beyond structure generation. Looking forward, the integration of Estructural into El Agente Quntur, an autonomous multi-agent quantum chemistry platform, enhances its capabilities by adding sophisticated tools for the generation and editing of three-dimensional structures.</div></details>
<details class="detail"><summary>中文标题/摘要</summary>
<div class="mono"><b>标题：</b>结构智能体：人工智能驱动的分子编辑器</div>
<div class="mono" style="margin-top:8px">我们提出&#x27;结构智能体&#x27;——一种多模态、自然语言驱动的几何生成与操控智能体，用于自主化学与分子建模。与基于生成模型的分子生成或编辑不同，该智能体通过整合领域知识工具集和视觉语言模型，模拟人类专家在三维空间中直接操控分子系统的方式。这种设计能精确控制原子或官能团替换、原子连接性及立体化学，无需重建庞大的核心分子骨架。通过系列代表性案例研究，我们证明该智能体能在广泛的实际场景中实现具有化学意义的几何操控，包括：位点选择性功能化、配体结合、配体交换、立体化学控制的结构构建、异构体互变、片段级结构分析、基于反应机理示意图的图像引导结构生成，以及机理驱动的几何生成与修饰。这些案例展示了多模态推理与专业几何感知工具结合后，如何支持超越结构生成的交互式情境感知分子建模。展望未来，将该智能体集成至自主多智能体量子化学平台&#x27;量子智能体&#x27;中，可通过添加复杂的三维结构生成与编辑工具进一步增强其能力。</div>
</details>
<details class="detail"><summary>Summary / 总结</summary>
<div class="mono">The research aims to develop a more intuitive and precise approach to molecular modeling by mimicking how human experts directly manipulate 3D molecular structures, moving beyond generative models that often lack fine control. The method introduces El Agente Estructural, a multimodal agent that integrates natural language processing, vision-language models, and a comprehensive suite of domain-specific geometry-aware tools to enable direct editing of atomic connectivity, stereochemistry, and functional groups without rebuilding core frameworks. Experimental case studies demonstrate its effectiveness in diverse real-world tasks, including site-selective functionalization, ligand binding and exchange, stereochemical control, isomer interconversion, and image-guided structure generation from reaction mechanisms, showcasing its capability for interactive and context-aware molecular modeling.</div>
<div class="mono" style="margin-top:8px">本研究旨在开发一种更直观、更精确的分子建模方法，以模拟人类专家直接操纵三维结构的方式，超越生成模型。该方法引入了El Agente Estructural，这是一个多模态智能体，它整合了自然语言处理、视觉语言模型以及一套全面的领域专用几何感知工具，以实现对原子替换、连接性和立体化学的直接控制。实验案例研究表明，该工具在多种实际任务中表现有效，包括位点选择性功能化、配体结合/交换、立体化学构建、异构体互变、片段分析，以及基于图像或反应机理引导的结构生成与修饰。</div>
</details>
</div>
<div class="card">
<div class="title">Fluid Representations in Reasoning Models</div>
<div class="meta-line">Authors: Dmitrii Kharlapenko, Alessandro Stolfo, Arthur Conmy, Mrinmaya Sachan, Zhijing Jin</div>
<div class="meta-line">First: 2026-02-04T18:34:50+00:00 · Latest: 2026-02-04T18:34:50+00:00</div>
<div class="links" style="margin-top:8px"><a href="https://arxiv.org/abs/2602.04843v1">Abs</a> · <a href="https://arxiv.org/pdf/2602.04843v1">PDF</a> · <a href="https://huggingface.co/huggingface">Code1</a> · <a href="https://huggingface.co/docs/hub/spaces">Code2</a></div>
<details class="detail"><summary>Abstract</summary>
<div class="mono">Reasoning language models, which generate long chains of thought, dramatically outperform non-reasoning language models on abstract problems. However, the internal model mechanisms that allow this superior performance remain poorly understood. We present a mechanistic analysis of how QwQ-32B - a model specifically trained to produce extensive reasoning traces - process abstract structural information. On Mystery Blocksworld - a semantically obfuscated planning domain - we find that QwQ-32B gradually improves its internal representation of actions and concepts during reasoning. The model develops abstract encodings that focus on structure rather than specific action names. Through steering experiments, we establish causal evidence that these adaptations improve problem solving: injecting refined representations from successful traces boosts accuracy, while symbolic representations can replace many obfuscated encodings with minimal performance loss. We find that one of the factors driving reasoning model performance is in-context refinement of token representations, which we dub Fluid Reasoning Representations.</div></details>
<details class="detail"><summary>中文标题/摘要</summary>
<div class="mono"><b>标题：</b>推理模型中的流体表征</div>
<div class="mono" style="margin-top:8px">能够生成长链思维过程的推理语言模型在抽象问题上显著优于非推理语言模型，但其实现优异性能的内部机制仍不明确。本研究对QwQ-32B模型（专门训练用于生成扩展推理轨迹）处理抽象结构信息的机制进行分析。在语义模糊的规划领域Mystery Blocksworld中，我们发现QwQ-32B在推理过程中会逐步优化其对动作和概念的内部表征。该模型发展出聚焦结构而非具体动作名称的抽象编码机制。通过导向实验，我们获得了这些适应性改进提升问题解决能力的因果证据：注入成功轨迹中的精炼表征可提升准确率，而符号表征能以最小性能损失替代多数模糊编码。研究表明，驱动推理模型性能的关键因素之一是表征在上下文中的动态精炼过程，我们将其命名为流体推理表征。</div>
</details>
<details class="detail"><summary>Summary / 总结</summary>
<div class="mono">This research investigates the internal mechanisms that enable reasoning language models to outperform standard models on abstract problems, focusing on understanding how these models process structural information during chain-of-thought reasoning. The study conducts a mechanistic analysis of QwQ-32B, a model trained for extensive reasoning, using the semantically obfuscated Mystery Blocksworld planning domain. Experimental results show that the model gradually refines its internal representations of actions and concepts during reasoning, developing abstract encodings focused on structure rather than specific names. Causal evidence from steering experiments demonstrates that injecting refined representations from successful traces boosts accuracy, while symbolic representations can replace many obfuscated encodings with minimal performance loss, identifying in-context refinement of token representations as a key performance factor.</div>
<div class="mono" style="margin-top:8px">本研究旨在揭示推理语言模型在抽象任务上优于标准模型的内部机制，因为其卓越性能仍未被充分理解。方法包括对经过专门训练以产生广泛推理痕迹的QwQ-32B模型进行机制分析，使用语义混淆的Mystery Blocksworld领域来检验其如何处理结构信息。主要实验结果表明，QwQ-32B在推理过程中逐步改进其对动作和概念的内部表示，形成专注于结构而非具体名称的抽象编码；通过引导实验提供了因果证据，表明这些精炼的表示能提升问题解决准确率，且符号表示可以替代许多混淆编码而性能损失最小，从而强调了上下文中的令牌表示精炼是推理模型性能的关键驱动因素。</div>
</details>
</div>
<div class="card">
<div class="title">Group-Evolving Agents: Open-Ended Self-Improvement via Experience Sharing</div>
<div class="meta-line">Authors: Zhaotian Weng, Antonis Antoniades, Deepak Nathani, Zhen Zhang, Xiao Pu, Xin Eric Wang</div>
<div class="meta-line">First: 2026-02-04T18:29:36+00:00 · Latest: 2026-02-04T18:29:36+00:00</div>
<div class="meta-line">Comments: 18 pages</div>
<div class="links" style="margin-top:8px"><a href="https://arxiv.org/abs/2602.04837v1">Abs</a> · <a href="https://arxiv.org/pdf/2602.04837v1">PDF</a> · <a href="https://huggingface.co/huggingface">Code1</a> · <a href="https://huggingface.co/docs/hub/spaces">Code2</a></div>
<details class="detail"><summary>Abstract</summary>
<div class="mono">Open-ended self-improving agents can autonomously modify their own structural designs to advance their capabilities and overcome the limits of pre-defined architectures, thus reducing reliance on human intervention. We introduce Group-Evolving Agents (GEA), a new paradigm for open-ended self-improvements, which treats a group of agents as the fundamental evolutionary unit, enabling explicit experience sharing and reuse within the group throughout evolution. Unlike existing open-ended self-evolving paradigms that adopt tree-structured evolution, GEA overcomes the limitation of inefficient utilization of exploratory diversity caused by isolated evolutionary branches. We evaluate GEA on challenging coding benchmarks, where it significantly outperforms state-of-the-art self-evolving methods (71.0% vs. 56.7% on SWE-bench Verified, 88.3% vs. 68.3% on Polyglot) and matches or exceeds top human-designed agent frameworks (71.8% and 52.0% on two benchmarks, respectively). Analysis reveals that GEA more effectively converts early-stage exploratory diversity into sustained, long-term progress, achieving stronger performance under the same number of evolved agents. Furthermore, GEA exhibits consistent transferability across different coding models and greater robustness, fixing framework-level bugs in 1.4 iterations on average, versus 5 for self-evolving methods.</div></details>
<details class="detail"><summary>中文标题/摘要</summary>
<div class="mono"><b>标题：</b>群体演化智能体：通过经验共享实现开放式自我改进</div>
<div class="mono" style="margin-top:8px">开放式自我改进智能体能够自主修改其结构设计以提升能力，突破预定义架构的限制，从而减少对人类干预的依赖。本文提出群体演化智能体（GEA）这一开放式自我改进新范式，将智能体群体作为基本演化单元，实现演化过程中群体内显式的经验共享与复用。与现有采用树状结构演化的开放式自演化范式不同，GEA克服了因孤立演化分支导致探索多样性利用效率低下的局限。在具有挑战性的代码生成基准测试中，GEA显著优于当前最先进的自演化方法（SWE-bench Verified数据集71.0%对56.7%，Polyglot数据集88.3%对68.3%），并与顶尖人工设计智能体框架性能相当或更优（两项基准测试分别达71.8%和52.0%）。分析表明，GEA能更有效地将早期探索多样性转化为持续的长期进展，在相同演化智能体数量下实现更强性能。此外，GEA在不同编码模型间具有稳定的可迁移性和更强的鲁棒性，平均仅需1.4次迭代即可修复框架级错误，而自演化方法需要5次迭代。</div>
</details>
<details class="detail"><summary>Summary / 总结</summary>
<div class="mono">To reduce reliance on human intervention and overcome the limitations of pre-defined agent architectures, this research introduces Group-Evolving Agents (GEA), a paradigm for open-ended self-improvement that treats a group of agents as the fundamental evolutionary unit to enable explicit experience sharing and reuse. The method moves beyond isolated, tree-structured evolution by fostering collective learning within the group, aiming to convert exploratory diversity more efficiently into sustained progress. Experimental evaluation on coding benchmarks shows GEA significantly outperforms state-of-the-art self-evolving methods (e.g., 71.0% vs. 56.7% on SWE-bench Verified) and matches or exceeds top human-designed frameworks, while analysis confirms it more effectively utilizes diversity for long-term gains and demonstrates greater robustness, fixing framework bugs in far fewer iterations.</div>
<div class="mono" style="margin-top:8px">为推进能够自主增强能力、超越固定架构的开放式自改进智能体，本文提出了群体演化智能体（GEA）范式，将智能体群体作为基本演化单元，在整个演化过程中实现显式的经验共享与重用，克服了孤立树状演化结构中探索多样性利用低效的问题。该方法在具有挑战性的代码基准测试中进行了评估，结果显著优于最先进的自演化方法（在SWE-bench Verified上为71.0%对56.7%，在Polyglot上为88.3%对68.3%），并达到或超过了顶级人工设计智能体框架的性能。分析表明，GEA能更有效地将早期探索多样性转化为持续的长期进展，在相同演化智能体数量下实现更强性能，在不同代码模型间展现出一致的可迁移性，并具有更高的鲁棒性，平均仅需1.4次迭代即可修复框架级错误，而自演化方法需要5次。</div>
</details>
</div>
<div class="card">
<div class="title">Group-Adaptive Adversarial Learning for Robust Fake News Detection Against Malicious Comments</div>
<div class="meta-line">Authors: Zhao Tong, Chunlin Gong, Yimeng Gu, Haichao Shi, Qiang Liu, Shu Wu, Xiao-Yu Zhang</div>
<div class="meta-line">First: 2025-10-10T04:39:57+00:00 · Latest: 2026-02-04T18:29:24+00:00</div>
<div class="meta-line">Comments: 10 pages, 12 figures</div>
<div class="links" style="margin-top:8px"><a href="https://arxiv.org/abs/2510.09712v2">Abs</a> · <a href="https://arxiv.org/pdf/2510.09712v2">PDF</a> · <a href="https://huggingface.co/huggingface">Code1</a> · <a href="https://huggingface.co/docs/hub/spaces">Code2</a></div>
<details class="detail"><summary>Abstract</summary>
<div class="mono">Online fake news profoundly distorts public judgment and erodes trust in social platforms. While existing detectors achieve competitive performance on benchmark datasets, they remain notably vulnerable to malicious comments designed specifically to induce misclassification. This evolving threat landscape necessitates detection systems that simultaneously prioritize predictive accuracy and structural robustness. However, current detectors often fail to generalize across diverse and novel comment attack patterns. To bridge this gap, we propose AdComment, an adaptive adversarial training framework for robustness enhancement against diverse malicious comments. Based on cognitive psychology, we categorize adversarial comments into Fact Distortion, Logical Confusion, and Emotional Manipulation, and leverage LLMs to synthesize diverse, category-specific perturbations. Central to our framework is an InfoDirichlet Resampling (IDR) mechanism that dynamically adjusts malicious comment proportions during training, thereby steering optimization toward the model&#x27;s most susceptible regions. Experimental results demonstrate that our approach achieves state-of-the-art performance on three benchmark datasets, improving the F1 scores by 17.9%, 14.5% and 9.0%, respectively.</div></details>
<details class="detail"><summary>中文标题/摘要</summary>
<div class="mono"><b>标题：</b>面向恶意评论的鲁棒虚假新闻检测：群体自适应对抗学习</div>
<div class="mono" style="margin-top:8px">网络虚假新闻严重扭曲公众判断并侵蚀对社交平台的信任。现有检测器在基准数据集上虽具竞争力，但面对专门诱导误判的恶意评论仍存在显著脆弱性。这一不断演变的威胁态势要求检测系统必须同时兼顾预测准确性与结构鲁棒性。然而当前检测器往往难以泛化至多样化的新型评论攻击模式。为填补这一空白，我们提出AdComment——一种针对多样化恶意评论的鲁棒性增强自适应对抗训练框架。基于认知心理学，我们将对抗性评论划分为事实扭曲、逻辑混淆和情感操纵三类，并利用大语言模型合成多样化的类别特异性扰动。该框架的核心是信息狄利克雷重采样机制，可在训练过程中动态调整恶意评论比例，从而将优化导向模型最敏感区域。实验结果表明，我们的方法在三个基准数据集上均取得最先进性能，F1分数分别提升17.9%、14.5%和9.0%。</div>
</details>
<details class="detail"><summary>Summary / 总结</summary>
<div class="mono">The research is motivated by the vulnerability of existing fake news detectors to malicious comments designed to induce misclassification, necessitating systems that balance predictive accuracy with structural robustness. The proposed method, AdComment, is an adaptive adversarial training framework that first categorizes adversarial comments into Fact Distortion, Logical Confusion, and Emotional Manipulation based on cognitive psychology, then uses LLMs to synthesize diverse, category-specific perturbations, and employs an InfoDirichlet Resampling mechanism to dynamically adjust malicious comment proportions during training. Key experimental findings show that this approach achieves state-of-the-art performance on three benchmark datasets, improving F1 scores by 17.9%, 14.5%, and 9.0%, respectively.</div>
<div class="mono" style="margin-top:8px">本研究动机在于现有虚假新闻检测器易受诱导错误分类的恶意评论攻击，需要构建兼顾预测准确性和结构鲁棒性的系统。所提出的方法AdComment是一种自适应对抗训练框架，基于认知心理学将对抗性评论分为事实扭曲、逻辑混淆和情感操纵三类，利用大语言模型合成特定类别的扰动，并采用信息狄利克雷重采样机制在训练中动态调整恶意评论比例。实验结果表明，该方法在三个基准数据集上取得了最先进的性能，F1分数分别提高了17.9%、14.5%和9.0%。</div>
</details>
</div>
<div class="card">
<div class="title">Are AI Capabilities Increasing Exponentially? A Competing Hypothesis</div>
<div class="meta-line">Authors: Haosen Ge, Hamsa Bastani, Osbert Bastani</div>
<div class="meta-line">First: 2026-02-04T18:28:49+00:00 · Latest: 2026-02-04T18:28:49+00:00</div>
<div class="links" style="margin-top:8px"><a href="https://arxiv.org/abs/2602.04836v1">Abs</a> · <a href="https://arxiv.org/pdf/2602.04836v1">PDF</a> · <a href="https://huggingface.co/huggingface">Code1</a> · <a href="https://huggingface.co/docs/hub/spaces">Code2</a></div>
<details class="detail"><summary>Abstract</summary>
<div class="mono">Rapidly increasing AI capabilities have substantial real-world consequences, ranging from AI safety concerns to labor market consequences. The Model Evaluation &amp; Threat Research (METR) report argues that AI capabilities have exhibited exponential growth since 2019. In this note, we argue that the data does not support exponential growth, even in shorter-term horizons. Whereas the METR study claims that fitting sigmoid/logistic curves results in inflection points far in the future, we fit a sigmoid curve to their current data and find that the inflection point has already passed. In addition, we propose a more complex model that decomposes AI capabilities into base and reasoning capabilities, exhibiting individual rates of improvement. We prove that this model supports our hypothesis that AI capabilities will exhibit an inflection point in the near future. Our goal is not to establish a rigorous forecast of our own, but to highlight the fragility of existing forecasts of exponential growth.</div></details>
<details class="detail"><summary>中文标题/摘要</summary>
<div class="mono"><b>标题：</b>AI能力是否呈指数级增长？一个竞争性假说</div>
<div class="mono" style="margin-top:8px">AI能力的快速提升已带来显著的现实影响，涉及AI安全担忧与劳动力市场效应。模型评估与威胁研究（METR）报告认为，自2019年以来AI能力呈现指数增长。本文指出，数据并不支持这一指数增长趋势，即使在短期范围内亦然。METR研究声称拟合S型/逻辑曲线会得出远在未来的拐点，而我们对当前数据拟合S型曲线后发现拐点已过。此外，我们提出一个更复杂的模型，将AI能力分解为基础能力与推理能力，二者各自呈现不同的改进速率。该模型证实了我们的假说：AI能力将在近期出现拐点。本文目标并非建立严谨的独立预测，而是揭示现有指数增长预测的脆弱性。</div>
</details>
<details class="detail"><summary>Summary / 总结</summary>
<div class="mono">This study critically examines the claim that AI capabilities are growing exponentially, as proposed in a recent report, arguing that such forecasts are fragile and not supported by the data. The authors re-analyze the same dataset by fitting a sigmoid curve, finding that the inflection point for AI capability growth has already occurred, contrary to the report&#x27;s projection of a distant future inflection. They further introduce a decomposed model separating base and reasoning capabilities, each with distinct improvement rates, to substantiate the hypothesis of an imminent inflection point, thereby challenging the exponential growth narrative without asserting a definitive alternative forecast.</div>
<div class="mono" style="margin-top:8px">本研究对近期报告中关于人工智能能力呈指数级增长的说法提出批判性审视，认为数据并不支持这种趋势，即使在短期内也是如此。作者通过拟合S型曲线重新分析了报告中的数据，发现能力增长的拐点已经出现，并提出了一个更精细的模型，将能力分解为基础能力和推理能力，各自具有不同的改进速率。分析表明，人工智能能力很可能在不久的将来出现拐点，从而凸显出现有指数增长预测的脆弱性。</div>
</details>
</div>
<div class="card">
<div class="title">It&#x27;s not a Lottery, it&#x27;s a Race: Understanding How Gradient Descent Adapts the Network&#x27;s Capacity to the Task</div>
<div class="meta-line">Authors: Hannah Pinson</div>
<div class="meta-line">First: 2026-02-04T18:22:40+00:00 · Latest: 2026-02-04T18:22:40+00:00</div>
<div class="links" style="margin-top:8px"><a href="https://arxiv.org/abs/2602.04832v1">Abs</a> · <a href="https://arxiv.org/pdf/2602.04832v1">PDF</a> · <a href="https://huggingface.co/huggingface">Code1</a> · <a href="https://huggingface.co/docs/hub/spaces">Code2</a></div>
<details class="detail"><summary>Abstract</summary>
<div class="mono">Our theoretical understanding of neural networks is lagging behind their empirical success. One of the important unexplained phenomena is why and how, during the process of training with gradient descent, the theoretical capacity of neural networks is reduced to an effective capacity that fits the task. We here investigate the mechanism by which gradient descent achieves this through analyzing the learning dynamics at the level of individual neurons in single hidden layer ReLU networks. We identify three dynamical principles -- mutual alignment, unlocking and racing -- that together explain why we can often successfully reduce capacity after training through the merging of equivalent neurons or the pruning of low norm weights. We specifically explain the mechanism behind the lottery ticket conjecture, or why the specific, beneficial initial conditions of some neurons lead them to obtain higher weight norms.</div></details>
<details class="detail"><summary>中文标题/摘要</summary>
<div class="mono"><b>标题：</b>这不是彩票，而是竞赛：理解梯度下降如何使网络能力适应任务</div>
<div class="mono" style="margin-top:8px">我们对神经网络的理论理解滞后于其实际成功。一个重要未解现象是，在梯度下降训练过程中，神经网络的理论能力为何及如何被缩减为适应任务的有效能力。本文通过分析单隐藏层ReLU网络中单个神经元的学习动态，探究梯度下降实现这一点的机制。我们识别出三个动态原则——相互对齐、解锁与竞赛——共同解释了为何训练后常能通过合并等效神经元或修剪低范数权重来成功缩减能力。我们特别解释了彩票假设背后的机制，即为何某些神经元特定的有利初始条件使其获得更高的权重范数。</div>
</details>
<details class="detail"><summary>Summary / 总结</summary>
<div class="mono">This study aims to explain the gap between the high theoretical capacity of neural networks and their effective, task-appropriate capacity after training with gradient descent. By analyzing learning dynamics in single hidden-layer ReLU networks at the level of individual neurons, the authors identify three key mechanisms: mutual alignment, unlocking, and racing. These principles collectively explain why post-training capacity reduction techniques like neuron merging and weight pruning are effective, and specifically elucidate the mechanism behind the lottery ticket hypothesis, showing how beneficial initial conditions allow certain neurons to develop higher weight norms.</div>
<div class="mono" style="margin-top:8px">本研究旨在解释梯度下降如何将神经网络的理论容量降低至适合特定任务的有效容量，以弥补实证成功与理论理解之间的差距。方法包括在单隐藏层ReLU网络中分析单个神经元的学习动态，识别出三个关键动力学原理：相互对齐、解锁和竞争。主要实验结果表明，这些原理解释了为何通过合并等效神经元或修剪低范数权重来降低容量通常是成功的，并具体阐明了彩票假设背后的机制，揭示了有益的初始条件如何促使某些神经元获得更高的权重范数。</div>
</details>
</div>
<div class="card">
<div class="title">Attention Consistency Regularization for Interpretable Early-Exit Neural Networks</div>
<div class="meta-line">Authors: Yanhua Zhao</div>
<div class="meta-line">First: 2026-01-13T11:19:09+00:00 · Latest: 2026-02-04T18:16:12+00:00</div>
<div class="meta-line">Comments: 2 pages, 1 figure</div>
<div class="links" style="margin-top:8px"><a href="https://arxiv.org/abs/2601.08891v2">Abs</a> · <a href="https://arxiv.org/pdf/2601.08891v2">PDF</a> · <a href="https://huggingface.co/huggingface">Code1</a> · <a href="https://huggingface.co/docs/hub/spaces">Code2</a></div>
<details class="detail"><summary>Abstract</summary>
<div class="mono">Early-exit neural networks enable adaptive inference by allowing predictions at intermediate layers, reducing computational cost. However, early exits often lack interpretability and may focus on different features than deeper layers, limiting trust and explainability. This paper presents Explanation-Guided Training (EGT), a multi-objective framework that improves interpretability and consistency in early-exit networks through attention-based regularization. EGT introduces an attention consistency loss that aligns early-exit attention maps with the final exit. The framework jointly optimizes classification accuracy and attention consistency through a weighted combination of losses. Experiments on a real-world image classification dataset demonstrate that EGT achieves up to 98.97% overall accuracy (matching baseline performance) with a 1.97x inference speedup through early exits, while improving attention consistency by up to 18.5% compared to baseline models. The proposed method provides more interpretable and consistent explanations across all exit points, making early-exit networks more suitable for explainable AI applications in resource-constrained environments.</div></details>
<details class="detail"><summary>中文标题/摘要</summary>
<div class="mono"><b>标题：</b>面向可解释早退神经网络的注意力一致性正则化方法</div>
<div class="mono" style="margin-top:8px">早退神经网络通过在中间层进行预测实现自适应推理，从而降低计算成本。然而，早退出口通常缺乏可解释性，且可能关注与深层不同的特征，限制了可信度与可解释性。本文提出解释引导训练（EGT）——一种通过基于注意力的正则化提升早退网络可解释性与一致性的多目标框架。EGT引入注意力一致性损失函数，使早退注意力图与最终出口对齐。该框架通过加权组合损失函数，联合优化分类准确率与注意力一致性。在真实图像分类数据集上的实验表明，EGT通过早退机制实现1.97倍推理加速的同时，整体准确率达98.97%（与基线性能持平），且注意力一致性较基线模型提升最高达18.5%。所提方法在所有出口点提供更具可解释性与一致性的解释，使早退网络更适用于资源受限环境下的可解释AI应用。</div>
</details>
<details class="detail"><summary>Summary / 总结</summary>
<div class="mono">Early-exit neural networks reduce computational cost but often lack interpretability and feature consistency across exits, limiting trust. To address this, the paper proposes Explanation-Guided Training (EGT), a multi-objective framework that introduces an attention consistency loss to align early-exit attention maps with the final exit, jointly optimizing classification and consistency. Experiments on an image classification dataset show EGT achieves 98.97% overall accuracy with a 1.97x inference speedup, while improving attention consistency by up to 18.5% compared to baselines, yielding more interpretable explanations across exits.</div>
<div class="mono" style="margin-top:8px">早期退出神经网络虽能降低计算成本，但其可解释性不足且不同退出层的关注特征不一致，这限制了预测的可信度。为此，本文提出解释引导训练（EGT）这一多目标框架，通过引入注意力一致性损失，使早期退出层的注意力图与最终退出层对齐，从而联合优化分类准确性和可解释性。在真实图像分类数据集上的实验表明，EGT在保持98.97%基线准确率的同时，实现了1.97倍的推理加速，并将注意力一致性提升了高达18.5%，从而在所有退出点提供了更可解释且一致的解释。</div>
</details>
</div>
<div class="card">
<div class="title">TRACE: Transparent Web Reliability Assessment with Contextual Explanations</div>
<div class="meta-line">Authors: Joydeep Chandra, Aleksandr Algazinov, Satyam Kumar Navneet, Rim El Filali, Matt Laing, Andrew Hanna, Yong Zhang</div>
<div class="meta-line">First: 2025-06-05T01:48:09+00:00 · Latest: 2026-02-04T18:13:53+00:00</div>
<div class="links" style="margin-top:8px"><a href="https://arxiv.org/abs/2506.12072v3">Abs</a> · <a href="https://arxiv.org/pdf/2506.12072v3">PDF</a> · <a href="http://github.com/zade90/TrueGL">Code1</a> · <a href="https://huggingface.co/huggingface">Code2</a> · <a href="https://huggingface.co/docs/hub/spaces">Code3</a></div>
<details class="detail"><summary>Abstract</summary>
<div class="mono">In an era of AI-generated misinformation flooding the web, existing tools struggle to empower users with nuanced, transparent assessments of content credibility. They often default to binary (true/false) classifications without contextual justifications, leaving users vulnerable to disinformation. We address this gap by introducing TRACE: Transparent Reliability Assessment with Contextual Explanations, a unified framework that performs two key tasks: (1) it assigns a fine-grained, continuous reliability score (from 0.1 to 1.0) to web content, and (2) it generates a contextual explanation for its assessment. The core of TRACE is the TrueGL-1B model, fine-tuned on a novel, large-scale dataset of over 140,000 articles. This dataset&#x27;s primary contribution is its annotation with 35 distinct continuous reliability scores, created using a Human-LLM co-creation and data poisoning paradigm. This method overcomes the limitations of binary-labeled datasets by populating the mid-ranges of reliability. In our evaluation, TrueGL-1B consistently outperforms other small-scale LLM baselines and rule-based approaches on key regression metrics, including MAE, RMSE, and R2. The model&#x27;s high accuracy and interpretable justifications make trustworthy information more accessible. To foster future research, our code and model are made publicly available here: github.com/zade90/TrueGL.</div></details>
<details class="detail"><summary>中文标题/摘要</summary>
<div class="mono"><b>标题：</b>TRACE：基于上下文解释的透明网络可靠性评估框架</div>
<div class="mono" style="margin-top:8px">在人工智能生成虚假信息充斥网络的时代，现有工具难以向用户提供细致透明的内容可信度评估。这些工具通常采用缺乏上下文依据的二元（真/假）分类模式，导致用户易受虚假信息影响。为填补这一空白，我们提出TRACE框架——基于上下文解释的透明可靠性评估系统，该统一框架执行两项核心任务：（1）为网络内容分配细粒度连续可靠性评分（0.1至1.0）；（2）生成评估结果的上下文解释。TRACE的核心是TrueGL-1B模型，该模型基于包含14万篇文章的新型大规模数据集进行微调。该数据集的核心贡献在于采用人机协同创建与数据污染范式，为每篇文章标注了35种不同的连续可靠性评分，有效解决了二元标注数据集在可靠性中段分布不足的缺陷。评估结果显示，TrueGL-1B在MAE、RMSE和R2等关键回归指标上持续优于其他小型LLM基线及基于规则的方法。模型的高精度与可解释性论证显著提升了可信信息的可及性。为促进后续研究，代码与模型已在github.com/zade90/TrueGL开源。</div>
</details>
<details class="detail"><summary>Summary / 总结</summary>
<div class="mono">To combat AI-generated misinformation and overcome the limitations of binary credibility classifiers that lack contextual justification, this research introduces TRACE, a framework for transparent web reliability assessment. The method centers on fine-tuning the TrueGL-1B model on a novel, large-scale dataset of over 140,000 articles annotated with 35 distinct continuous reliability scores, generated via a Human-LLM co-creation and data poisoning paradigm to populate the mid-ranges of reliability. Experimental results show that TrueGL-1B consistently outperforms other small-scale LLM baselines and rule-based approaches on key regression metrics (MAE, RMSE, R2), demonstrating high accuracy in generating both fine-grained reliability scores and interpretable contextual explanations.</div>
<div class="mono" style="margin-top:8px">为应对人工智能生成错误信息的挑战，本研究针对现有工具仅提供二元可信度分类且缺乏上下文解释的局限性。作者提出了TRACE框架，该框架为网络内容分配细粒度的连续可靠性分数并生成上下文解释，其核心是基于人类-大语言模型协同创建范式标注的、包含超过14万篇文章和35个不同可靠性分数的新数据集进行微调的TrueGL-1B模型。实验结果表明，TrueGL-1B在MAE、RMSE和R2等关键回归指标上持续优于其他小规模大语言模型基线和基于规则的方法，展现出高准确性并提供可解释的论证。</div>
</details>
</div>
<div class="card">
<div class="title">Safe Urban Traffic Control via Uncertainty-Aware Conformal Prediction and World-Model Reinforcement Learning</div>
<div class="meta-line">Authors: Joydeep Chandra, Satyam Kumar Navneet, Aleksandr Algazinov, Yong Zhang</div>
<div class="meta-line">First: 2026-02-04T18:10:59+00:00 · Latest: 2026-02-04T18:10:59+00:00</div>
<div class="links" style="margin-top:8px"><a href="https://arxiv.org/abs/2602.04821v1">Abs</a> · <a href="https://arxiv.org/pdf/2602.04821v1">PDF</a> · <a href="https://huggingface.co/huggingface">Code1</a> · <a href="https://huggingface.co/docs/hub/spaces">Code2</a></div>
<details class="detail"><summary>Abstract</summary>
<div class="mono">Urban traffic management demands systems that simultaneously predict future conditions, detect anomalies, and take safe corrective actions -- all while providing reliability guarantees. We present STREAM-RL, a unified framework that introduces three novel algorithmic contributions: (1) PU-GAT+, an Uncertainty-Guided Adaptive Conformal Forecaster that uses prediction uncertainty to dynamically reweight graph attention via confidence-monotonic attention, achieving distribution-free coverage guarantees; (2) CRFN-BY, a Conformal Residual Flow Network that models uncertainty-normalized residuals via normalizing flows with Benjamini-Yekutieli FDR control under arbitrary dependence; and (3) LyCon-WRL+, an Uncertainty-Guided Safe World-Model RL agent with Lyapunov stability certificates, certified Lipschitz bounds, and uncertainty-propagated imagination rollouts. To our knowledge, this is the first framework to propagate calibrated uncertainty from forecasting through anomaly detection to safe policy learning with end-to-end theoretical guarantees. Experiments on multiple real-world traffic trajectory data demonstrate that STREAM-RL achieves 91.4\% coverage efficiency, controls FDR at 4.1\% under verified dependence, and improves safety rate to 95.2\% compared to 69\% for standard PPO while achieving higher reward, with 23ms end-to-end inference latency.</div></details>
<details class="detail"><summary>中文标题/摘要</summary>
<div class="mono"><b>标题：</b>基于不确定性感知共形预测与世界模型强化学习的城市交通安全控制</div>
<div class="mono" style="margin-top:8px">城市交通管理系统需同时预测未来路况、检测异常并采取安全纠正措施，同时提供可靠性保证。本文提出STREAM-RL统一框架，包含三项创新算法贡献：(1) PU-GAT+：不确定性引导的自适应共形预测器，通过置信度单调注意力动态调整图注意力权重，实现无分布覆盖保证；(2) CRFN-BY：共形残差流网络，通过标准化流建模不确定性归一化残差，在任意依赖关系下实现Benjamini-Yekutieli错误发现率控制；(3) LyCon-WRL+：具备李雅普诺夫稳定性证明、经认证的利普希茨边界及不确定性传播想象推演的引导式安全世界模型强化学习智能体。据我们所知，这是首个将校准不确定性从预测端传播至异常检测再到安全策略学习，并具备端到端理论保证的框架。在多个真实交通轨迹数据上的实验表明：STREAM-RL实现91.4%的覆盖效率，在已验证依赖关系下将错误发现率控制在4.1%，安全率提升至95.2%（标准PPO为69%），同时获得更高奖励，端到端推理延迟为23毫秒。</div>
</details>
<details class="detail"><summary>Summary / 总结</summary>
<div class="mono">Urban traffic management requires systems that can predict, detect anomalies, and act safely with reliability guarantees. The proposed STREAM-RL framework integrates three novel methods: PU-GAT+ for uncertainty-guided conformal forecasting with coverage guarantees, CRFN-BY for anomaly detection using normalizing flows with FDR control, and LyCon-WRL+ for safe reinforcement learning with stability certificates and uncertainty-propagated rollouts. Experiments on real-world traffic data show the framework achieves 91.4% coverage efficiency, controls FDR at 4.1%, improves safety rate to 95.2% from 69% for standard PPO, and maintains 23ms inference latency.</div>
<div class="mono" style="margin-top:8px">城市交通控制需要能够可靠预测、检测异常并安全行动的保障系统。为此，研究者提出了STREAM-RL统一框架，其包含用于动态预测加权的引导不确定性共形预测器、具有错误发现率控制的共形残差流网络异常检测器，以及带有稳定性证明的安全世界模型强化学习智能体。在真实交通轨迹数据上的实验表明，该框架实现了91.4%的覆盖效率，将错误发现率控制在4.1%，安全率从基准方法的69%提升至95.2%，并保持了较低的端到端推理延迟。</div>
</details>
</div>
<div class="card">
<div class="title">Toward Reliable and Explainable Nail Disease Classification: Leveraging Adversarial Training and Grad-CAM Visualization</div>
<div class="meta-line">Authors: Farzia Hossain, Samanta Ghosh, Shahida Begum, B. M. Shahria Alam, Mohammad Tahmid Noor, Md Parvez Mia, Nishat Tasnim Niloy</div>
<div class="meta-line">First: 2026-02-04T18:08:13+00:00 · Latest: 2026-02-04T18:08:13+00:00</div>
<div class="meta-line">Comments: 6 pages, 12 figures. This is the author&#x27;s accepted manuscript of a paper accepted for publication in the Proceedings of the 16th International IEEE Conference on Computing, Communication and Networking Technologies (ICCCNT 2025). The final published version will be available via IEEE Xplore</div>
<div class="links" style="margin-top:8px"><a href="https://arxiv.org/abs/2602.04820v1">Abs</a> · <a href="https://arxiv.org/pdf/2602.04820v1">PDF</a> · <a href="https://huggingface.co/huggingface">Code1</a> · <a href="https://huggingface.co/docs/hub/spaces">Code2</a></div>
<details class="detail"><summary>Abstract</summary>
<div class="mono">Human nail diseases are gradually observed over all age groups, especially among older individuals, often going ignored until they become severe. Early detection and accurate diagnosis of such conditions are important because they sometimes reveal our body&#x27;s health problems. But it is challenging due to the inferred visual differences between disease types. This paper presents a machine learning-based model for automated classification of nail diseases based on a publicly available dataset, which contains 3,835 images scaling six categories. In 224x224 pixels, all images were resized to ensure consistency. To evaluate performance, four well-known CNN models-InceptionV3, DenseNet201, EfficientNetV2, and ResNet50 were trained and analyzed. Among these, InceptionV3 outperformed the others with an accuracy of 95.57%, while DenseNet201 came next with 94.79%. To make the model stronger and less likely to make mistakes on tricky or noisy images, we used adversarial training. To help understand how the model makes decisions, we used SHAP to highlight important features in the predictions. This system could be a helpful support for doctors, making nail disease diagnosis more accurate and faster.</div></details>
<details class="detail"><summary>中文标题/摘要</summary>
<div class="mono"><b>标题：</b>迈向可靠且可解释的指甲疾病分类：利用对抗训练与Grad-CAM可视化</div>
<div class="mono" style="margin-top:8px">人类指甲疾病在各年龄段逐渐显现，尤其在老年群体中常被忽视直至病情加重。早期检测与准确诊断至关重要，因其可能揭示身体健康问题。但由于疾病类型间视觉差异细微，诊断面临挑战。本文基于包含3,835张图像、涵盖六类疾病的公开数据集，提出一种机器学习驱动的自动化指甲疾病分类模型。所有图像统一调整为224×224像素以确保一致性。为评估性能，对InceptionV3、DenseNet201、EfficientNetV2和ResNet50四种经典CNN模型进行训练分析，其中InceptionV3以95.57%准确率表现最优，DenseNet201以94.79%次之。通过对抗训练增强模型对复杂或噪声图像的鲁棒性，并采用SHAP方法可视化预测关键特征以提升决策可解释性。该系统有望辅助医生实现更精准、快速的指甲疾病诊断。</div>
</details>
<details class="detail"><summary>Summary / 总结</summary>
<div class="mono">Motivated by the need for early detection of nail diseases, which can indicate underlying health issues but are challenging to diagnose due to subtle visual differences, this study develops an automated classification system using a public dataset of 3,835 images across six categories. The method involves training and comparing four CNN architectures (InceptionV3, DenseNet201, EfficientNetV2, ResNet50) on resized 224x224 pixel images, with adversarial training employed to enhance robustness against noisy inputs and SHAP used for explainability via feature visualization. Experimentally, InceptionV3 achieved the highest accuracy of 95.57%, followed by DenseNet201 at 94.79%, demonstrating the model&#x27;s potential as a decision-support tool to improve diagnostic accuracy and speed.</div>
<div class="mono" style="margin-top:8px">本研究旨在实现指甲疾病的早期检测，这类疾病常反映潜在健康问题，但因视觉差异细微而诊断困难。方法基于包含六类共3,835张图像的公开数据集，通过训练和比较InceptionV3、DenseNet201、EfficientNetV2和ResNet50四种CNN模型，并采用对抗训练增强模型对噪声图像的鲁棒性，同时利用SHAP进行特征可视化以提高可解释性。实验结果表明，InceptionV3取得了95.57%的最高准确率，DenseNet201次之为94.79%，验证了该系统作为辅助工具可提升诊断准确性和效率的潜力。</div>
</details>
</div>
<div class="card">
<div class="title">Agentic AI in Healthcare &amp; Medicine: A Seven-Dimensional Taxonomy for Empirical Evaluation of LLM-based Agents</div>
<div class="meta-line">Authors: Shubham Vatsal, Harsh Dubey, Aditi Singh</div>
<div class="meta-line">Venue: IEEE Access, vol. 14, pp. 4840-4863, 2026</div>
<div class="meta-line">First: 2026-02-04T17:59:14+00:00 · Latest: 2026-02-04T17:59:14+00:00</div>
<div class="links" style="margin-top:8px"><a href="https://arxiv.org/abs/2602.04813v1">Abs</a> · <a href="https://arxiv.org/pdf/2602.04813v1">PDF</a> · <a href="https://huggingface.co/huggingface">Code1</a> · <a href="https://huggingface.co/docs/hub/spaces">Code2</a></div>
<details class="detail"><summary>Abstract</summary>
<div class="mono">Large Language Model (LLM)-based agents that plan, use tools and act has begun to shape healthcare and medicine. Reported studies demonstrate competence on various tasks ranging from EHR analysis and differential diagnosis to treatment planning and research workflows. Yet the literature largely consists of overviews which are either broad surveys or narrow dives into a single capability (e.g., memory, planning, reasoning), leaving healthcare work without a common frame. We address this by reviewing 49 studies using a seven-dimensional taxonomy: Cognitive Capabilities, Knowledge Management, Interaction Patterns, Adaptation &amp; Learning, Safety &amp; Ethics, Framework Typology and Core Tasks &amp; Subtasks with 29 operational sub-dimensions. Using explicit inclusion and exclusion criteria and a labeling rubric (Fully Implemented, Partially Implemented, Not Implemented), we map each study to the taxonomy and report quantitative summaries of capability prevalence and co-occurrence patterns. Our empirical analysis surfaces clear asymmetries. For instance, the External Knowledge Integration sub-dimension under Knowledge Management is commonly realized (~76% Fully Implemented) whereas Event-Triggered Activation sub-dimenison under Interaction Patterns is largely absent (~92% Not Implemented) and Drift Detection &amp; Mitigation sub-dimension under Adaptation &amp; Learning is rare (~98% Not Implemented). Architecturally, Multi-Agent Design sub-dimension under Framework Typology is the dominant pattern (~82% Fully Implemented) while orchestration layers remain mostly partial. Across Core Tasks &amp; Subtasks, information centric capabilities lead e.g., Medical Question Answering &amp; Decision Support and Benchmarking &amp; Simulation, while action and discovery oriented areas such as Treatment Planning &amp; Prescription still show substantial gaps (~59% Not Implemented).</div></details>
<details class="detail"><summary>中文标题/摘要</summary>
<div class="mono"><b>标题：</b>医疗健康领域具身智能体：基于大语言模型的智能体实证评估七维分类体系</div>
<div class="mono" style="margin-top:8px">基于大语言模型（LLM）的智能体通过规划、工具调用与自主执行，正逐步重塑医疗健康领域。现有研究展示了其在电子健康记录分析、鉴别诊断、治疗规划及科研工作流等多样化任务中的能力。然而当前文献多为概览性研究——或为宽泛综述，或聚焦单一能力维度（如记忆、规划、推理），缺乏统一的评估框架。本研究通过系统回顾49项实证研究，构建包含七大维度（认知能力、知识管理、交互模式、适应与学习、安全与伦理、框架类型学、核心任务与子任务）及29个可操作子维度的分类体系。采用明确的纳入排除标准与三级标注规则（完全实现/部分实现/未实现），我们将每项研究映射至该分类体系，并量化呈现能力分布与共现模式。实证分析揭示显著的不对称性：知识管理维度下的外部知识整合子维度普及率较高（约76%完全实现），而交互模式维度下的事件触发激活子维度普遍缺失（约92%未实现），适应与学习维度下的漂移检测与缓解子维度则极为罕见（约98%未实现）。在架构层面，框架类型学下的多智能体设计子维度占据主导（约82%完全实现），而协调层实现程度普遍有限。在核心任务维度，信息中心型能力（如医疗问答与决策支持、基准测试与模拟）发展领先，而面向行动与探索的领域（如治疗规划与处方）仍存在显著缺口（约59%未实现）。</div>
</details>
<details class="detail"><summary>Summary / 总结</summary>
<div class="mono">The rapid emergence of LLM-based agents in healthcare necessitates a structured framework for empirical evaluation, as existing literature lacks a common taxonomy to assess their diverse capabilities. To address this, the authors propose a seven-dimensional taxonomy with 29 sub-dimensions and systematically review 49 studies, mapping each to the taxonomy using a rubric of Fully, Partially, or Not Implemented. Quantitative analysis reveals significant asymmetries: capabilities like External Knowledge Integration are common (76% Fully Implemented), while Event-Triggered Activation (92% Not Implemented) and Drift Detection &amp; Mitigation (98% Not Implemented) are largely absent; Multi-Agent Design is dominant (82% Fully Implemented), but action-oriented tasks like Treatment Planning show substantial gaps (59% Not Implemented).</div>
<div class="mono" style="margin-top:8px">医疗领域基于大语言模型的智能体迅速涌现，但现有文献缺乏评估其多样化能力的统一框架。为此，本研究提出了一个包含七个维度、29个子维度的分类法，并依据明确标准对49项现有研究进行了系统性映射和量化标注。分析结果揭示了显著的能力不对称性：外部知识整合等能力已普遍实现，而事件触发激活、漂移检测与缓解等维度，以及治疗规划等面向行动的任务则大多缺失或发展不足。</div>
</details>
</div>
<div class="card">
<div class="title">SE-Bench: Benchmarking Self-Evolution with Knowledge Internalization</div>
<div class="meta-line">Authors: Jiarui Yuan, Tailin Jin, Weize Chen, Zeyuan Liu, Zhiyuan Liu, Maosong Sun</div>
<div class="meta-line">First: 2026-02-04T17:58:32+00:00 · Latest: 2026-02-04T17:58:32+00:00</div>
<div class="meta-line">Comments: Under review</div>
<div class="links" style="margin-top:8px"><a href="https://arxiv.org/abs/2602.04811v1">Abs</a> · <a href="https://arxiv.org/pdf/2602.04811v1">PDF</a> · <a href="https://github.com/thunlp/SE-Bench">Code1</a> · <a href="https://huggingface.co/huggingface">Code2</a> · <a href="https://huggingface.co/docs/hub/spaces">Code3</a></div>
<details class="detail"><summary>Abstract</summary>
<div class="mono">True self-evolution requires agents to act as lifelong learners that internalize novel experiences to solve future problems. However, rigorously measuring this foundational capability is hindered by two obstacles: the entanglement of prior knowledge, where ``new&#x27;&#x27; knowledge may appear in pre-training data, and the entanglement of reasoning complexity, where failures may stem from problem difficulty rather than an inability to recall learned knowledge. We introduce SE-Bench, a diagnostic environment that obfuscates the NumPy library and its API doc into a pseudo-novel package with randomized identifiers. Agents are trained to internalize this package and evaluated on simple coding tasks without access to documentation, yielding a clean setting where tasks are trivial with the new API doc but impossible for base models without it. Our investigation reveals three insights: (1) the Open-Book Paradox, where training with reference documentation inhibits retention, requiring &quot;Closed-Book Training&quot; to force knowledge compression into weights; (2) the RL Gap, where standard RL fails to internalize new knowledge completely due to PPO clipping and negative gradients; and (3) the viability of Self-Play for internalization, proving models can learn from self-generated, noisy tasks when coupled with SFT, but not RL. Overall, SE-Bench establishes a rigorous diagnostic platform for self-evolution with knowledge internalization. Our code and dataset can be found at https://github.com/thunlp/SE-Bench.</div></details>
<details class="detail"><summary>中文标题/摘要</summary>
<div class="mono"><b>标题：</b>SE-Bench：基于知识内化的自我进化基准测试</div>
<div class="mono" style="margin-top:8px">真正的自我进化要求智能体作为终身学习者，内化新经验以解决未来问题。然而，严谨衡量这一基础能力面临两大障碍：先验知识纠缠（“新”知识可能已出现在预训练数据中）与推理复杂度纠缠（失败可能源于问题难度而非知识召回能力缺失）。我们提出SE-Bench——通过将NumPy库及其API文档混淆为随机标识符的伪新包，构建诊断环境。智能体需内化该包，并在无文档访问权限下完成简单编码任务，形成纯净测试场景：使用新API文档时任务极易完成，而基础模型无法处理。研究揭示三大发现：（1）开卷悖论：参考文档训练会抑制知识留存，需采用“闭卷训练”强制知识压缩至权重；（2）强化学习鸿沟：标准RL因PPO裁剪与负梯度无法完全内化新知识；（3）自我博弈可行性：模型可通过监督微调从自生成的噪声任务中学习，但强化学习无效。SE-Bench为知识内化的自我进化建立了严谨诊断平台。代码与数据集详见https://github.com/thunlp/SE-Bench。</div>
</details>
<details class="detail"><summary>Summary / 总结</summary>
<div class="mono">The research aims to benchmark self-evolution in AI agents, specifically their ability to internalize novel knowledge for lifelong learning, addressing challenges posed by the entanglement of prior knowledge in pre-training data and reasoning complexity in evaluation. The method introduces SE-Bench, a diagnostic environment that obfuscates the NumPy library into a pseudo-novel package with randomized identifiers; agents are trained to internalize this package and then tested on simple coding tasks without documentation, isolating the effect of knowledge retention. Key findings include the Open-Book Paradox, where training with reference docs hinders retention, necessitating closed-book training for compression; the RL Gap, where standard reinforcement learning fails due to PPO clipping and negative gradients; and the viability of self-play with supervised fine-tuning for internalization, though not with RL.</div>
<div class="mono" style="margin-top:8px">本研究旨在为AI智能体的自我进化能力建立基准，重点关注其内化新知识以实现终身学习的能力，这一目标受到预训练数据中先验知识纠缠和评估任务中推理复杂性干扰的阻碍。方法上提出了SE-Bench，这是一个诊断环境，通过随机化标识符将NumPy库混淆为伪新包；智能体被训练内化该包，然后在无文档访问的情况下测试简单编码任务，从而隔离知识保留效应。主要实验结果包括：开卷训练悖论，即使用参考文档训练会抑制知识保留，需要闭卷训练进行压缩；强化学习差距，标准强化学习因PPO裁剪和负梯度而失败；以及自博弈与监督微调结合可实现内化，但强化学习无效。</div>
</details>
</div>
<div class="card">
<div class="title">Beyond Rewards in Reinforcement Learning for Cyber Defence</div>
<div class="meta-line">Authors: Elizabeth Bates, Chris Hicks, Vasilios Mavroudis</div>
<div class="meta-line">First: 2026-02-04T17:55:23+00:00 · Latest: 2026-02-04T17:55:23+00:00</div>
<div class="links" style="margin-top:8px"><a href="https://arxiv.org/abs/2602.04809v1">Abs</a> · <a href="https://arxiv.org/pdf/2602.04809v1">PDF</a> · <a href="https://huggingface.co/huggingface">Code1</a> · <a href="https://huggingface.co/docs/hub/spaces">Code2</a></div>
<details class="detail"><summary>Abstract</summary>
<div class="mono">Recent years have seen an explosion of interest in autonomous cyber defence agents trained to defend computer networks using deep reinforcement learning. These agents are typically trained in cyber gym environments using dense, highly engineered reward functions which combine many penalties and incentives for a range of (un)desirable states and costly actions. Dense rewards help alleviate the challenge of exploring complex environments but risk biasing agents towards suboptimal and potentially riskier solutions, a critical issue in complex cyber environments. We thoroughly evaluate the impact of reward function structure on learning and policy behavioural characteristics using a variety of sparse and dense reward functions, two well-established cyber gyms, a range of network sizes, and both policy gradient and value-based RL algorithms. Our evaluation is enabled by a novel ground truth evaluation approach which allows directly comparing between different reward functions, illuminating the nuanced inter-relationships between rewards, action space and the risks of suboptimal policies in cyber environments. Our results show that sparse rewards, provided they are goal aligned and can be encountered frequently, uniquely offer both enhanced training reliability and more effective cyber defence agents with lower-risk policies. Surprisingly, sparse rewards can also yield policies that are better aligned with cyber defender goals and make sparing use of costly defensive actions without explicit reward-based numerical penalties.</div></details>
<details class="detail"><summary>中文标题/摘要</summary>
<div class="mono"><b>标题：</b>超越奖励：强化学习在网络安全防御中的应用</div>
<div class="mono" style="margin-top:8px">近年来，利用深度强化学习训练自主网络防御代理以保护计算机网络的研究兴趣激增。这些代理通常在网络训练环境中通过密集且高度工程化的奖励函数进行训练，这些函数结合了对多种（非）理想状态和代价高昂行动的惩罚与激励。密集奖励有助于缓解复杂环境探索的挑战，但可能导致代理偏向次优且风险更高的解决方案，这在复杂网络环境中尤为关键。我们通过多种稀疏与密集奖励函数、两个成熟的网络训练环境、不同网络规模以及策略梯度和基于价值的强化学习算法，全面评估了奖励函数结构对学习过程及策略行为特征的影响。本研究采用一种新颖的基准评估方法，可直接比较不同奖励函数的效果，揭示网络环境中奖励机制、行动空间与次优策略风险之间微妙的相互作用。结果表明，只要目标一致且能频繁触发，稀疏奖励不仅能提升训练可靠性，还能产生具有更低风险策略的更有效网络防御代理。令人惊讶的是，稀疏奖励还能生成更符合网络防御目标、且无需显式数值惩罚即可节制使用高成本防御行动的优化策略。</div>
</details>
<details class="detail"><summary>Summary / 总结</summary>
<div class="mono">Motivated by the risk that dense reward functions may bias reinforcement learning agents toward suboptimal and risky policies in autonomous cyber defense, this study systematically evaluates the impact of reward structure. The method employs a novel ground truth evaluation approach to compare sparse and dense reward functions across two established cyber gym environments, various network sizes, and both policy gradient and value-based RL algorithms. Key experimental findings reveal that sparse, goal-aligned rewards, when encountered frequently, lead to more reliable training, produce more effective defense agents with lower-risk policies, and can yield behaviors better aligned with defender goals—including sparing use of costly actions—even without explicit numerical penalties.</div>
<div class="mono" style="margin-top:8px">针对自主网络防御中密集设计的奖励函数可能导致强化学习智能体偏向次优和风险策略的问题，本研究系统评估了奖励结构的影响。方法采用一种新颖的基准评估方法，在两个成熟的网络训练环境、不同网络规模以及策略梯度和基于价值的RL算法中，比较稀疏与密集奖励函数。主要实验结果表明，只要稀疏奖励与目标对齐且能频繁遇到，就能独特地提高训练可靠性，并产生更有效的防御智能体，其策略风险更低、更符合防御者目标，且能在没有显式惩罚的情况下节约使用代价高昂的防御动作。</div>
</details>
</div>
<div class="card">
<div class="title">Skin Tokens: A Learned Compact Representation for Unified Autoregressive Rigging</div>
<div class="meta-line">Authors: Jia-peng Zhang, Cheng-Feng Pu, Meng-Hao Guo, Yan-Pei Cao, Shi-Min Hu</div>
<div class="meta-line">First: 2026-02-04T17:52:17+00:00 · Latest: 2026-02-04T17:52:17+00:00</div>
<div class="meta-line">Comments: 14 pages, 10 figures</div>
<div class="links" style="margin-top:8px"><a href="https://arxiv.org/abs/2602.04805v1">Abs</a> · <a href="https://arxiv.org/pdf/2602.04805v1">PDF</a> · <a href="https://huggingface.co/huggingface">Code1</a> · <a href="https://huggingface.co/docs/hub/spaces">Code2</a></div>
<details class="detail"><summary>Abstract</summary>
<div class="mono">The rapid proliferation of generative 3D models has created a critical bottleneck in animation pipelines: rigging. Existing automated methods are fundamentally limited by their approach to skinning, treating it as an ill-posed, high-dimensional regression task that is inefficient to optimize and is typically decoupled from skeleton generation. We posit this is a representation problem and introduce SkinTokens: a learned, compact, and discrete representation for skinning weights. By leveraging an FSQ-CVAE to capture the intrinsic sparsity of skinning, we reframe the task from continuous regression to a more tractable token sequence prediction problem. This representation enables TokenRig, a unified autoregressive framework that models the entire rig as a single sequence of skeletal parameters and SkinTokens, learning the complicated dependencies between skeletons and skin deformations. The unified model is then amenable to a reinforcement learning stage, where tailored geometric and semantic rewards improve generalization to complex, out-of-distribution assets. Quantitatively, the SkinTokens representation leads to a 98%-133% percents improvement in skinning accuracy over state-of-the-art methods, while the full TokenRig framework, refined with RL, enhances bone prediction by 17%-22%. Our work presents a unified, generative approach to rigging that yields higher fidelity and robustness, offering a scalable solution to a long-standing challenge in 3D content creation.</div></details>
<details class="detail"><summary>中文标题/摘要</summary>
<div class="mono"><b>标题：</b>皮肤令牌：一种用于统一自回归绑定系统的学习型紧凑表示</div>
<div class="mono" style="margin-top:8px">生成式3D模型的快速扩散在动画流程中造成了关键瓶颈：绑定。现有自动化方法从根本上受限于其蒙皮处理方式，将其视为一个不适定的高维回归任务，优化效率低下且通常与骨骼生成解耦。我们认为这是一个表示问题，并提出了皮肤令牌：一种学习得到的、紧凑的、离散的蒙皮权重表示。通过利用FSQ-CVAE捕捉蒙皮固有的稀疏性，我们将任务从连续回归重构为更易处理的令牌序列预测问题。该表示支持TokenRig——一个统一的自回归框架，将整个绑定系统建模为骨骼参数与皮肤令牌的单一序列，从而学习骨骼与皮肤变形间的复杂依赖关系。该统一模型随后适用于强化学习阶段，其中定制的几何与语义奖励提升了模型对复杂、分布外资产的泛化能力。量化结果显示，皮肤令牌表示在蒙皮精度上比现有最优方法提升了98%-133%，而经过RL优化的完整TokenRig框架将骨骼预测精度提高了17%-22%。本研究提出了一种统一的生成式绑定方法，实现了更高的保真度与鲁棒性，为3D内容创作中长期存在的挑战提供了可扩展的解决方案。</div>
</details>
<details class="detail"><summary>Summary / 总结</summary>
<div class="mono">The rapid growth of generative 3D models has made manual rigging a bottleneck, as existing automated methods treat skinning as a high-dimensional, ill-posed regression task decoupled from skeleton generation. To address this, the authors introduce SkinTokens, a learned compact and discrete representation for skinning weights using an FSQ-CVAE to capture sparsity, reframing the problem as token sequence prediction. This enables TokenRig, a unified autoregressive framework that models the entire rig as a single sequence of skeletal parameters and SkinTokens, learning dependencies between skeletons and skin deformations, with a reinforcement learning stage applying geometric and semantic rewards for generalization. Experiments show the SkinTokens representation improves skinning accuracy by 98%-133% over state-of-the-art methods, and the full TokenRig framework enhances bone prediction by 17%-22%, offering a scalable, high-fidelity solution for 3D content creation.</div>
<div class="mono" style="margin-top:8px">生成式3D模型的快速增长使得手动绑定成为流程瓶颈，现有自动化方法将蒙皮权重视为低效的高维回归任务，且与骨骼生成分离。为此，研究者提出了SkinTokens，这是一种通过FSQ-CVAE学习到的离散表示，能够捕捉蒙皮的稀疏性，从而将问题转化为令牌序列预测。基于此，他们构建了TokenRig，一个统一的自回归框架，可联合预测骨骼参数和SkinTokens，并利用强化学习结合几何与语义奖励进行优化以提升泛化能力。实验表明，SkinTokens表示将蒙皮精度较现有方法提高了98%-133%，而完整的TokenRig框架则将骨骼预测性能提升了17%-22%，为3D内容创作提供了更高保真度和鲁棒性的可扩展解决方案。</div>
</details>
</div>
<div class="card">
<div class="title">Y-Shaped Generative Flows</div>
<div class="meta-line">Authors: Arip Asadulaev, Semyon Semenov, Abduragim Shtanchaev, Eric Moulines, Fakhri Karray, Martin Takac</div>
<div class="meta-line">First: 2025-10-13T21:33:37+00:00 · Latest: 2026-02-04T17:51:14+00:00</div>
<div class="links" style="margin-top:8px"><a href="https://arxiv.org/abs/2510.11955v3">Abs</a> · <a href="https://arxiv.org/pdf/2510.11955v3">PDF</a> · <a href="https://huggingface.co/huggingface">Code1</a> · <a href="https://huggingface.co/docs/hub/spaces">Code2</a></div>
<details class="detail"><summary>Abstract</summary>
<div class="mono">Modern continuous-time generative models typically induce \emph{V-shaped} flows: each sample travels independently along a nearly straight trajectory from the prior to the data. Although effective, this independent movement overlooks the hierarchical structures that exist in real-world data. To address this, we introduce \emph{Y-shaped generative flows}, a framework in which samples travel together along shared pathways before branching off to target-specific endpoints. Our formulation is theoretically justified, yet remains practical, requiring only minimal modifications to standard velocity-driven models. We implement this through a scalable, neural network-based training objective. Experiments on synthetic, image, and biological datasets demonstrate that our method recovers hierarchy-aware structures, improves distributional metrics over strong flow-based baselines, and reaches targets in fewer steps.</div></details>
<details class="detail"><summary>中文标题/摘要</summary>
<div class="mono"><b>标题：</b>Y形生成流</div>
<div class="mono" style="margin-top:8px">现代连续时间生成模型通常产生\emph{V形流}：每个样本沿着从先验分布到数据的近似直线轨迹独立运动。尽管有效，这种独立运动忽略了现实数据中存在的层次结构。为此，我们提出\emph{Y形生成流}框架，在该框架中样本先沿共享路径共同运动，再分岔至特定目标端点。我们的理论推导具有严谨性，同时保持实用性，仅需对标准速度驱动模型进行最小改动。我们通过可扩展的神经网络训练目标实现该方法。在合成数据、图像和生物数据集上的实验表明，本方法能恢复层次感知结构，在基于流的强基线模型上提升分布度量指标，并以更少步骤抵达目标。</div>
</details>
<details class="detail"><summary>Summary / 总结</summary>
<div class="mono">The research addresses the limitation of conventional continuous-time generative models, which employ V-shaped flows that treat samples independently and overlook hierarchical data structures. The proposed Y-shaped generative flows introduce a framework where samples initially travel along shared pathways before branching to specific endpoints, implemented via a scalable neural network training objective with minimal modifications to standard velocity-driven models. Experimental results on synthetic, image, and biological datasets show that the method recovers hierarchy-aware structures, improves distributional metrics over strong flow-based baselines, and achieves targets in fewer steps.</div>
<div class="mono" style="margin-top:8px">本研究针对标准连续时间生成模型产生V形流（样本从先验到数据独立移动）而忽略真实数据层次结构的局限性，提出了Y形生成流框架，使样本先沿共享路径共同移动再分支到个体端点，该方法通过基于神经网络的训练目标实现，仅需对现有速度驱动模型进行最小修改。在合成、图像和生物数据集上的实验表明，该方法能恢复层次感知结构，相比基于流的基线模型改进了分布度量指标，并以更少步骤达到目标。</div>
</details>
</div>
<div class="card">
<div class="title">Accurate and scalable exchange-correlation with deep learning</div>
<div class="meta-line">Authors: Giulia Luise, Chin-Wei Huang, Thijs Vogels, Derk P. Kooi, Sebastian Ehlert, Stephanie Lanius, Klaas J. H. Giesbertz, Amir Karton, Deniz Gunceler, Megan Stanley, Wessel P. Bruinsma, Lin Huang, Xinran Wei, José Garrido Torres, Abylay Katbashev, Rodrigo Chavez Zavaleta, Bálint Máté, Sékou-Oumar Kaba, Roberto Sordillo, Yingrong Chen, David B. Williams-Young, Christopher M. Bishop, Jan Hermann, Rianne van den Berg, Paola Gori-Giorgi</div>
<div class="meta-line">First: 2025-06-17T15:56:56+00:00 · Latest: 2026-02-04T17:40:00+00:00</div>
<div class="meta-line">Comments: Main: 13 pages plus references, 11 figures and tables. Supplementary information: 19 pages, 12 figures and tables. v2 update: fix rendering of figure 1 and part of figure 5 in Safari PDF viewer. v3 update: update author information and fix typo. v4 update: The Skala model and inference code are available under MIT license at https://github.com/microsoft/skala</div>
<div class="links" style="margin-top:8px"><a href="https://arxiv.org/abs/2506.14665v4">Abs</a> · <a href="https://arxiv.org/pdf/2506.14665v4">PDF</a> · <a href="https://github.com/microsoft/skala">Code1</a> · <a href="https://huggingface.co/huggingface">Code2</a> · <a href="https://huggingface.co/docs/hub/spaces">Code3</a></div>
<details class="detail"><summary>Abstract</summary>
<div class="mono">Density Functional Theory (DFT) is the most widely used electronic structure method for predicting the properties of molecules and materials. Although DFT is, in principle, an exact reformulation of the Schrödinger equation, practical applications rely on approximations to the unknown exchange-correlation (XC) functional. Most existing XC functionals are constructed using a limited set of increasingly complex, hand-crafted features that improve accuracy at the expense of computational efficiency. Yet, no current approximation achieves the accuracy and generality for predictive modeling of laboratory experiments at chemical accuracy -- typically defined as errors below 1 kcal/mol. In this work, we present Skala, a modern deep learning-based XC functional that bypasses expensive hand-designed features by learning representations directly from data. Skala achieves chemical accuracy for atomization energies of small molecules while retaining the computational efficiency typical of semi-local DFT. This performance is enabled by training on an unprecedented volume of high-accuracy reference data generated using computationally intensive wavefunction-based methods. Notably, Skala systematically improves with additional training data covering diverse chemistry. By incorporating a modest amount of additional high-accuracy data tailored to chemistry beyond atomization energies, Skala achieves accuracy competitive with the best-performing hybrid functionals across general main group chemistry, at the cost of semi-local DFT. As the training dataset continues to expand, Skala is poised to further enhance the predictive power of first-principles simulations.</div></details>
<details class="detail"><summary>中文标题/摘要</summary>
<div class="mono"><b>标题：</b>基于深度学习的精确可扩展交换关联泛函</div>
<div class="mono" style="margin-top:8px">密度泛函理论（DFT）是预测分子与材料性质最广泛使用的电子结构方法。虽然DFT在原理上是薛定谔方程的精确重构，实际应用仍需对未知的交换关联（XC）泛函进行近似。现有XC泛函大多通过有限的手工设计特征构建，这些特征以计算效率为代价提升精度，且复杂度递增。然而，当前尚无任何近似方法能达到实验室实验预测建模所需的化学精度（通常定义为误差低于1 kcal/mol）与普适性。本研究提出Skala——一种基于现代深度学习的XC泛函，通过直接从数据中学习表征，绕过了昂贵的手工设计特征。Skala在小分子原子化能计算中达到化学精度，同时保持了半局域DFT典型的计算效率。这一性能得益于使用计算密集的波函数方法生成的前所未有的大规模高精度参考数据训练。值得注意的是，Skala能通过覆盖多样化化学领域的额外训练数据实现系统性提升。通过融入少量针对原子化能之外化学特性的定制化高精度数据，Skala以半局域DFT的计算成本，在通用主族化学领域达到与最优杂化泛函相当的精度。随着训练数据集的持续扩展，Skala有望进一步增强第一性原理模拟的预测能力。</div>
</details>
<details class="detail"><summary>Summary / 总结</summary>
<div class="mono">Density Functional Theory (DFT) is widely used but relies on approximate exchange-correlation (XC) functionals, which often trade accuracy for computational efficiency and fail to achieve chemical accuracy (errors below 1 kcal/mol) for predictive modeling. This work introduces Skala, a deep learning-based XC functional that learns representations directly from data, bypassing hand-crafted features, and is trained on a large volume of high-accuracy reference data from wavefunction-based methods. Skala achieves chemical accuracy for small molecule atomization energies while maintaining the computational efficiency of semi-local DFT, and its performance systematically improves with additional training data, becoming competitive with the best hybrid functionals across general main group chemistry at semi-local DFT cost.</div>
<div class="mono" style="margin-top:8px">密度泛函理论（DFT）需要精确近似未知的交换关联（XC）泛函，但现有手工构建的泛函难以在保持计算效率的同时达到化学精度（误差低于1 kcal/mol）。本研究提出了Skala，一种基于深度学习的XC泛函，它通过从基于波函数方法生成的大量高精度参考数据中直接学习表示，绕过了人工特征工程。实验表明，Skala以半局域DFT的计算成本实现了对小分子原子化能的化学精度，且其性能随更多样化的训练数据而系统提升；当用额外数据扩展后，它在半局域DFT成本下对主族化学的精度可与最佳杂化泛函相媲美。</div>
</details>
</div>
<div class="card">
<div class="title">UniReason 1.0: A Unified Reasoning Framework for World Knowledge Aligned Image Generation and Editing</div>
<div class="meta-line">Authors: Dianyi Wang, Chaofan Ma, Feng Han, Size Wu, Wei Song, Yibin Wang, Zhixiong Zhang, Tianhang Wang, Siyuan Wang, Zhongyu Wei, Jiaqi Wang</div>
<div class="meta-line">First: 2026-02-02T18:34:35+00:00 · Latest: 2026-02-04T17:38:12+00:00</div>
<div class="links" style="margin-top:8px"><a href="https://arxiv.org/abs/2602.02437v2">Abs</a> · <a href="https://arxiv.org/pdf/2602.02437v2">PDF</a> · <a href="https://huggingface.co/huggingface">Code1</a> · <a href="https://huggingface.co/docs/hub/spaces">Code2</a></div>
<details class="detail"><summary>Abstract</summary>
<div class="mono">Unified multimodal models often struggle with complex synthesis tasks that demand deep reasoning, and typically treat text-to-image generation and image editing as isolated capabilities rather than interconnected reasoning steps. To address this, we propose UniReason, a unified framework that harmonizes these two tasks through two complementary reasoning paradigms. We incorporate world knowledge-enhanced textual reasoning into generation to infer implicit knowledge, and leverage editing capabilities for fine-grained editing-like visual refinement to further correct visual errors via self-reflection. This approach unifies generation and editing within a shared architecture, mirroring the human cognitive process of planning followed by refinement. We support this framework by systematically constructing a large-scale reasoning-centric dataset (~300k samples) covering five major knowledge domains (e.g., cultural commonsense, physics, etc.) for textual reasoning, alongside an agent-generated corpus for visual refinement. Extensive experiments demonstrate that UniReason achieves advanced performance on reasoning-intensive benchmarks such as WISE, KrisBench and UniREditBench, while maintaining superior general synthesis capabilities.</div></details>
<details class="detail"><summary>中文标题/摘要</summary>
<div class="mono"><b>标题：</b>UniReason 1.0：面向世界知识对齐图像生成与编辑的统一推理框架</div>
<div class="mono" style="margin-top:8px">统一多模态模型在处理需要深度推理的复杂合成任务时常面临困难，且通常将文本到图像生成与图像编辑视为孤立能力而非相互关联的推理步骤。为此，我们提出UniReason框架，通过两种互补的推理范式协调这两项任务：在生成阶段引入世界知识增强的文本推理以推断隐含知识，并利用编辑能力进行细粒度视觉优化，通过自反思机制修正视觉误差。该方法将生成与编辑统一于共享架构，模拟人类“规划-优化”的认知过程。我们系统构建了大规模以推理为中心的数据集（约30万样本），涵盖文化常识、物理等五大知识领域用于文本推理，同时构建智能体生成的视觉优化语料库支持该框架。大量实验表明，UniReason在WISE、KrisBench和UniREditBench等推理密集型基准测试中取得先进性能，同时保持卓越的通用合成能力。</div>
</details>
<details class="detail"><summary>Summary / 总结</summary>
<div class="mono">To address the limitations of unified multimodal models in complex synthesis tasks requiring deep reasoning and the isolated treatment of text-to-image generation and image editing, this work proposes UniReason, a unified framework that integrates these tasks through complementary reasoning paradigms. The method incorporates world knowledge-enhanced textual reasoning to infer implicit knowledge during generation and employs editing-like visual refinement to correct errors via self-reflection, unifying both processes within a shared architecture that mimics human cognitive planning and refinement. Experimental results show that UniReason achieves advanced performance on reasoning-intensive benchmarks like WISE, KrisBench, and UniREditBench while maintaining superior general synthesis capabilities, supported by a systematically constructed large-scale reasoning-centric dataset covering five major knowledge domains.</div>
<div class="mono" style="margin-top:8px">本研究针对统一多模态模型在处理需要深度推理的复杂合成任务时的局限性，这些模型通常将文本到图像生成和图像编辑视为孤立能力而非相互关联的步骤。提出的UniReason框架通过两种互补的推理范式协调这些任务：在生成过程中融入世界知识增强的文本推理以推断隐含知识，以及利用编辑式视觉细化通过自我反思纠正错误，从而在共享架构中统一生成和编辑，模拟人类先规划后细化的认知过程。实验结果表明，UniReason在WISE、KrisBench和UniREditBench等推理密集型基准测试中取得了先进性能，同时保持了卓越的通用合成能力，该框架得到了一个系统构建的大规模数据集的支持，覆盖了五个主要知识领域。</div>
</details>
</div>
<div class="card">
<div class="title">GPU-Accelerated ANNS: Quantized for Speed, Built for Change</div>
<div class="meta-line">Authors: Hunter McCoy, Zikun Wang, Prashant Pandey</div>
<div class="meta-line">First: 2026-01-11T19:51:54+00:00 · Latest: 2026-02-04T17:37:50+00:00</div>
<div class="links" style="margin-top:8px"><a href="https://arxiv.org/abs/2601.07048v3">Abs</a> · <a href="https://arxiv.org/pdf/2601.07048v3">PDF</a> · <a href="https://huggingface.co/huggingface">Code1</a> · <a href="https://huggingface.co/docs/hub/spaces">Code2</a></div>
<details class="detail"><summary>Abstract</summary>
<div class="mono">Approximate nearest neighbor search (ANNS) is a core problem in machine learning and information retrieval applications. GPUs offer a promising path to high-performance ANNS: they provide massive parallelism for distance computations, are readily available, and can co-locate with downstream applications.
  Despite these advantages, current GPU-accelerated ANNS systems face three key limitations. First, real-world applications operate on evolving datasets that require fast batch updates, yet most GPU indices must be rebuilt from scratch when new data arrives. Second, high-dimensional vectors strain memory bandwidth, but current GPU systems lack efficient quantization techniques that reduce data movement without introducing costly random memory accesses. Third, the data-dependent memory accesses inherent to greedy search make overlapping compute and memory difficult, leading to reduced performance.
  We present Jasper, a GPU-native ANNS system with both high query throughput and updatability. Jasper builds on the Vamana graph index and overcomes existing bottlenecks via three contributions: (1) a CUDA batch-parallel construction algorithm that enables lock-free streaming insertions, (2) a GPU-efficient implementation of RaBitQ quantization that reduces memory footprint up to 8x without the random access penalties, and (3) an optimized greedy search kernel that increases compute utilization, resulting in better latency hiding and higher throughput.
  Our evaluation across five datasets shows that Jasper achieves up to 1.93x higher query throughput than CAGRA and achieves up to 80% peak utilization as measured by the roofline model. Jasper&#x27;s construction scales efficiently and constructs indices an average of 2.4x faster than CAGRA while providing updatability that CAGRA lacks. Compared to BANG, the previous fastest GPU Vamana implementation, Jasper delivers 19-131x faster queries.</div></details>
<details class="detail"><summary>中文标题/摘要</summary>
<div class="mono"><b>标题：</b>GPU加速的近似最近邻搜索：量化提速，适应动态数据</div>
<div class="mono" style="margin-top:8px">近似最近邻搜索（ANNS）是机器学习和信息检索应用中的核心问题。GPU为实现高性能ANNS提供了可行路径：它们为距离计算提供大规模并行能力，易于获取，并能与下游应用协同部署。然而，现有GPU加速ANNS系统面临三个关键局限：一是实际应用中的动态数据集需要快速批量更新，而多数GPU索引在新数据到达时需完全重建；二是高维向量对内存带宽造成压力，但当前GPU系统缺乏能在减少数据移动的同时避免昂贵随机内存访问的高效量化技术；三是贪婪搜索固有的数据依赖性内存访问使得计算与内存难以重叠，导致性能下降。
我们提出Jasper——一个兼具高查询吞吐量与可更新性的GPU原生ANNS系统。Jasper基于Vamana图索引，通过三项创新突破现有瓶颈：（1）支持无锁流式插入的CUDA批量并行构建算法；（2）实现RaBitQ量化的GPU高效方案，将内存占用降低至1/8且避免随机访问开销；（3）优化的贪婪搜索内核，提升计算利用率以实现更好的延迟隐藏与更高吞吐。
在五个数据集上的评估表明：Jasper的查询吞吐量最高达CAGRA的1.93倍，屋顶线模型测得峰值利用率达80%；其构建效率平均比CAGRA快2.4倍，且具备CAGRA缺乏的可更新性；与此前最快的GPU Vamana实现BANG相比，Jasper的查询速度快19-131倍。</div>
</details>
<details class="detail"><summary>Summary / 总结</summary>
<div class="mono">This research addresses key limitations in GPU-accelerated approximate nearest neighbor search (ANNS) systems, which struggle with evolving datasets, memory bandwidth constraints from high-dimensional vectors, and inefficient compute-memory overlap during search. The authors present Jasper, a GPU-native ANNS system built on the Vamana graph index, featuring three core innovations: a CUDA batch-parallel construction algorithm enabling lock-free streaming insertions, a GPU-efficient RaBitQ quantization implementation reducing memory footprint up to 8x without random access penalties, and an optimized greedy search kernel improving compute utilization. Experimental evaluation across five datasets demonstrates Jasper achieves up to 1.93x higher query throughput than CAGRA, reaches up to 80% peak roofline utilization, constructs indices 2.4x faster on average, and delivers 19-131x faster queries than the prior fastest GPU Vamana implementation, BANG, while providing updatability that CAGRA lacks.</div>
<div class="mono" style="margin-top:8px">本研究旨在解决GPU加速近似最近邻搜索（ANNS）系统的三个关键局限：无法高效处理动态更新的数据集、高维向量导致的内存带宽压力，以及搜索过程中数据依赖的内存访问导致的计算利用率低下。作者提出了Jasper，一个基于Vamana图索引的GPU原生系统，其核心方法包括：支持无锁流式插入的CUDA批量并行构建算法、集成RaBitQ量化以减少内存占用且避免随机访问开销，以及优化的贪婪搜索内核以更好地隐藏延迟。在五个数据集上的实验结果表明，Jasper相比CAGRA实现了最高1.93倍的查询吞吐量提升和平均2.4倍的索引构建加速，并提供了CAGRA所不具备的数据更新能力；相比之前最快的GPU Vamana实现BANG，其查询速度提升了19至131倍。</div>
</details>
</div>
<div class="card">
<div class="title">MixGRPO: Unlocking Flow-based GRPO Efficiency with Mixed ODE-SDE</div>
<div class="meta-line">Authors: Junzhe Li, Yutao Cui, Tao Huang, Yinping Ma, Chun Fan, Miles Yang, Zhao Zhong, Liefeng Bo</div>
<div class="meta-line">First: 2025-07-29T13:40:09+00:00 · Latest: 2026-02-04T17:35:17+00:00</div>
<div class="links" style="margin-top:8px"><a href="https://arxiv.org/abs/2507.21802v5">Abs</a> · <a href="https://arxiv.org/pdf/2507.21802v5">PDF</a> · <a href="https://huggingface.co/huggingface">Code1</a> · <a href="https://huggingface.co/docs/hub/spaces">Code2</a></div>
<details class="detail"><summary>Abstract</summary>
<div class="mono">Although GRPO substantially enhances flow matching models in human preference alignment of image generation, methods such as FlowGRPO and DanceGRPO still exhibit inefficiency due to the necessity of sampling and optimizing over all denoising steps specified by the Markov Decision Process (MDP). In this paper, we propose $\textbf{MixGRPO}$, a novel framework that leverages the flexibility of mixed sampling strategies through the integration of stochastic differential equations (SDE) and ordinary differential equations (ODE). This streamlines the optimization process within the MDP to improve efficiency and boost performance. Specifically, MixGRPO introduces a sliding window mechanism, using SDE sampling and GRPO-guided optimization only within the window, while applying ODE sampling outside. This design confines sampling randomness to the time-steps within the window, thereby reducing the optimization overhead, and allowing for more focused gradient updates to accelerate convergence. Additionally, as time-steps beyond the sliding window are not involved in optimization, higher-order solvers are supported for faster sampling. So we present a faster variant, termed $\textbf{MixGRPO-Flash}$, which further improves training efficiency while achieving comparable performance. MixGRPO exhibits substantial gains across multiple dimensions of human preference alignment, outperforming DanceGRPO in both effectiveness and efficiency, with nearly 50% lower training time. Notably, MixGRPO-Flash further reduces training time by 71%.</div></details>
<details class="detail"><summary>中文标题/摘要</summary>
<div class="mono"><b>标题：</b>MixGRPO：通过混合ODE-SDE解锁基于流的GRPO效率</div>
<div class="mono" style="margin-top:8px">尽管GRPO在图像生成的人类偏好对齐中显著提升了流匹配模型的性能，但FlowGRPO和DanceGRPO等方法仍因需对马尔可夫决策过程（MDP）指定的所有去噪步骤进行采样和优化而存在效率瓶颈。本文提出$\textbf{MixGRPO}$，一种通过整合随机微分方程（SDE）和常微分方程（ODE）来利用混合采样策略灵活性的新框架。该框架简化了MDP内的优化过程，从而提升效率并增强性能。具体而言，MixGRPO引入滑动窗口机制：仅在窗口内使用SDE采样和GRPO引导的优化，而在窗口外应用ODE采样。这一设计将采样随机性限制在窗口内的时间步，从而降低优化开销，并通过更聚焦的梯度更新加速收敛。此外，由于滑动窗口外的时间步不参与优化，可支持高阶求解器以实现更快采样。为此我们提出一个更快的变体$\textbf{MixGRPO-Flash}$，在保持相当性能的同时进一步提升训练效率。MixGRPO在人类偏好对齐的多个维度上取得显著提升，在效果和效率上均优于DanceGRPO，训练时间降低近50%。值得注意的是，MixGRPO-Flash进一步将训练时间缩减了71%。</div>
</details>
<details class="detail"><summary>Summary / 总结</summary>
<div class="mono">The research addresses the inefficiency of existing flow-based GRPO methods like FlowGRPO and DanceGRPO, which require sampling and optimizing over all denoising steps in a Markov Decision Process, leading to high computational cost. To improve efficiency, the proposed MixGRPO framework integrates stochastic and ordinary differential equations (SDE and ODE) with a sliding window mechanism: SDE sampling and GRPO-guided optimization are applied only within the window, while ODE sampling is used outside, thereby confining randomness and reducing optimization overhead. Experimental results show that MixGRPO outperforms DanceGRPO in human preference alignment with nearly 50% lower training time, and its faster variant, MixGRPO-Flash, further reduces training time by 71% while maintaining comparable performance.</div>
<div class="mono" style="margin-top:8px">本研究针对现有GRPO方法（如FlowGRPO和DanceGRPO）效率低下的问题，这些方法需要在马尔可夫决策过程的所有去噪步骤上进行采样和优化，导致计算成本高昂。提出的MixGRPO框架引入了一种混合采样策略，整合了随机微分方程（SDE）和常微分方程（ODE），采用滑动窗口机制，将SDE采样和GRPO引导的优化限制在窗口内，而在窗口外使用ODE采样。实验结果表明，MixGRPO在人类偏好对齐的多个维度上显著提升性能，在效果和效率上均优于DanceGRPO，训练时间降低近50%，其快速变体MixGRPO-Flash进一步将训练时间减少71%的同时保持了可比性能。</div>
</details>
</div>
<div class="card">
<div class="title">Multi-Excitation Projective Simulation with a Many-Body Physics Inspired Inductive Bias</div>
<div class="meta-line">Authors: Philip A. LeMaitre, Marius Krumm, Hans J. Briegel</div>
<div class="meta-line">Venue: Artificial Intelligence 352, 104489 (2026)</div>
<div class="meta-line">First: 2024-02-15T18:48:32+00:00 · Latest: 2026-02-04T17:34:48+00:00</div>
<div class="meta-line">Comments: 41 pages, 9 figures; Code repository at https://github.com/MariusKrumm/ManyBodyMEPS. Updated to be consistent with AIJ version</div>
<div class="links" style="margin-top:8px"><a href="https://arxiv.org/abs/2402.10192v4">Abs</a> · <a href="https://arxiv.org/pdf/2402.10192v4">PDF</a> · <a href="https://github.com/MariusKrumm/ManyBodyMEPS">Code1</a> · <a href="https://huggingface.co/huggingface">Code2</a> · <a href="https://huggingface.co/docs/hub/spaces">Code3</a></div>
<details class="detail"><summary>Abstract</summary>
<div class="mono">With the impressive progress of deep learning, applications relying on machine learning are increasingly being integrated into daily life. However, most deep learning models have an opaque, oracle-like nature making it difficult to interpret and understand their decisions. This problem led to the development of the field known as eXplainable Artificial Intelligence (XAI). One method in this field known as Projective Simulation (PS) models a chain-of-thought as a random walk of a particle on a graph with vertices that have concepts attached to them. While this description has various benefits, including the possibility of quantization, it cannot be naturally used to model thoughts that combine several concepts simultaneously. To overcome this limitation, we introduce Multi-Excitation Projective Simulation (mePS), a generalization that considers a chain-of-thought to be a random walk of several particles on a hypergraph. A definition for a dynamic hypergraph is put forward to describe the agent&#x27;s training history along with applications to AI and hypergraph visualization. An inductive bias inspired by the remarkably successful few-body interaction models used in quantum many-body physics is formalized for our classical mePS framework and employed to tackle the exponential complexity associated with naive implementations of hypergraphs. We prove that our inductive bias reduces the complexity from exponential to polynomial, with the exponent representing the cutoff on how many particles can interact. We numerically apply our method to two toy environments and a more complex scenario modelling the diagnosis of a broken computer. These environments demonstrate the resource savings provided by an appropriate choice of inductive bias, as well as showcasing aspects of interpretability. A quantum model for mePS is also briefly outlined and some future directions for it are discussed.</div></details>
<details class="detail"><summary>中文标题/摘要</summary>
<div class="mono"><b>标题：</b>多激发投影模拟：一种受多体物理启发的归纳偏置</div>
<div class="mono" style="margin-top:8px">随着深度学习的显著进步，依赖机器学习的应用日益融入日常生活。然而，大多数深度学习模型具有不透明、类神谕的特性，使其决策难以解释和理解。这一问题催生了可解释人工智能领域的发展。该领域中的一种方法称为投影模拟，它将思维链建模为粒子在带有概念顶点的图上的随机游走。尽管这种描述具有多种优势（包括量子化的可能性），但无法自然地用于模拟同时结合多个概念的思维。为克服此限制，我们引入了多激发投影模拟，这是一种将思维链视为多个粒子在超图上随机游走的推广方法。我们提出了动态超图的定义，以描述智能体的训练历史，并应用于人工智能和超图可视化。受量子多体物理中极为成功的少体相互作用模型启发，我们为经典多激发投影模拟框架形式化了一种归纳偏置，用于应对朴素超图实现带来的指数级复杂度。我们证明该归纳偏置将复杂度从指数级降至多项式级，其中指数代表可相互作用粒子数量的截断。我们在两个玩具环境和一个模拟计算机故障诊断的更复杂场景中数值应用了该方法。这些环境展示了适当选择归纳偏置所带来的资源节约，并体现了可解释性的多个方面。本文还简要概述了多激发投影模拟的量子模型，并讨论了其未来研究方向。</div>
</details>
<details class="detail"><summary>Summary / 总结</summary>
<div class="mono">To address the interpretability limitations of opaque deep learning models, this work introduces Multi-Excitation Projective Simulation (mePS), a generalization of Projective Simulation that models a chain-of-thought as a random walk of multiple particles on a hypergraph, enabling the representation of simultaneous concepts. The method formalizes an inductive bias inspired by few-body interaction models from quantum many-body physics to manage the exponential complexity of naive hypergraph implementations, proving a reduction to polynomial complexity dependent on an interaction cutoff. Numerical experiments on toy environments and a computer diagnosis scenario demonstrate the resource efficiency gained from this inductive bias and highlight the model&#x27;s interpretability features, with a quantum model for mePS also outlined for future exploration.</div>
<div class="mono" style="margin-top:8px">为解决深度学习模型不透明、难以解释的问题，本研究提出了多激发投影模拟（mePS），该方法将投影模拟推广为多个粒子在超图上的随机游走，从而能够表示同时出现的多个概念。该方法引入了受量子多体物理中少体相互作用模型启发的归纳偏置，以应对朴素超图实现带来的指数级复杂度。在玩具环境和计算机故障诊断场景中的实验结果表明，该偏置将复杂度从指数级降低至多项式级，实现了资源节约并保持了模型的可解释性。</div>
</details>
</div>
<div class="card">
<div class="title">Team, Then Trim: An Assembly-Line LLM Framework for High-Quality Tabular Data Generation</div>
<div class="meta-line">Authors: Congjing Zhang, Ryan Feng Lin, Ruoxuan Bao, Shuai Huang</div>
<div class="meta-line">First: 2026-02-04T17:34:41+00:00 · Latest: 2026-02-04T17:34:41+00:00</div>
<div class="links" style="margin-top:8px"><a href="https://arxiv.org/abs/2602.04785v1">Abs</a> · <a href="https://arxiv.org/pdf/2602.04785v1">PDF</a> · <a href="https://huggingface.co/huggingface">Code1</a> · <a href="https://huggingface.co/docs/hub/spaces">Code2</a></div>
<details class="detail"><summary>Abstract</summary>
<div class="mono">While tabular data is fundamental to many real-world machine learning (ML) applications, acquiring high-quality tabular data is usually labor-intensive and expensive. Limited by the scarcity of observations, tabular datasets often exhibit critical deficiencies, such as class imbalance, selection bias, and low fidelity. To address these challenges, building on recent advances in Large Language Models (LLMs), this paper introduces Team-then-Trim (T$^2$), a framework that synthesizes high-quality tabular data through a collaborative team of LLMs, followed by a rigorous three-stage plug-in data quality control (QC) pipeline. In T$^2$, tabular data generation is conceptualized as a manufacturing process: specialized LLMs, guided by domain knowledge, are tasked with generating different data components sequentially, and the resulting products, i.e., the synthetic data, are systematically evaluated across multiple dimensions of QC. Empirical results on both simulated and real-world datasets demonstrate that T$^2$ outperforms state-of-the-art methods in producing high-quality tabular data, highlighting its potential to support downstream models when direct data collection is practically infeasible.</div></details>
<details class="detail"><summary>中文标题/摘要</summary>
<div class="mono"><b>标题：</b>团队协作，精准修剪：面向高质量表格数据生成的流水线式大语言模型框架</div>
<div class="mono" style="margin-top:8px">表格数据是众多现实世界机器学习应用的基础，但获取高质量表格数据通常需要耗费大量人力且成本高昂。受限于观测数据的稀缺性，表格数据集常存在类别不平衡、选择偏差和保真度低等关键缺陷。为应对这些挑战，本文基于大语言模型的最新进展，提出了Team-then-Trim（T$^2$）框架。该框架通过LLM协作团队合成高质量表格数据，并配备严格的三阶段插件式数据质量控制流程。在T$^2$中，表格数据生成被概念化为制造流程：由领域知识指导的专用LLM按序生成不同数据组件，生成的合成数据将通过多维度QC进行系统评估。在模拟和真实数据集上的实证结果表明，T$^2$在生成高质量表格数据方面优于现有先进方法，凸显了其在直接数据收集不可行时支持下游模型的潜力。</div>
</details>
<details class="detail"><summary>Summary / 总结</summary>
<div class="mono">The research addresses the challenge of acquiring high-quality tabular data, which is often labor-intensive and suffers from deficiencies like class imbalance and low fidelity. The proposed Team-then-Trim (T²) framework conceptualizes data generation as a manufacturing process, employing a collaborative team of specialized Large Language Models guided by domain knowledge to generate data components sequentially, followed by a three-stage plug-in quality control pipeline. Experimental results on simulated and real-world datasets show that T² outperforms state-of-the-art methods in generating high-quality synthetic tabular data, demonstrating its utility for supporting downstream models when direct data collection is infeasible.</div>
<div class="mono" style="margin-top:8px">获取高质量表格数据通常成本高昂且困难，现有数据集常存在类别不平衡、选择偏差和保真度低等缺陷。为此，本研究基于大语言模型的最新进展，提出了Team-then-Trim（T²）框架，该方法将表格数据生成视为一个制造流程：首先由具备领域知识的专业化大语言模型团队协作、顺序生成数据组件，随后通过一个严格的三阶段插件式质量控制管道进行筛选。在模拟和真实数据集上的实验结果表明，T²在生成高质量表格数据方面优于现有最先进方法，凸显了其在直接数据收集不可行时对下游模型的支持潜力。</div>
</details>
</div></div>
    <details style="margin-top:16px" class="detail"><summary>History</summary>
      <div class="history-list"><a href="archive/20260205_0628.html">20260205_0628</a>
<a href="archive/20260205_0537.html">20260205_0537</a>
<a href="archive/20260205_0450.html">20260205_0450</a>
<a href="archive/20260205_0346.html">20260205_0346</a>
<a href="archive/20260204_0633.html">20260204_0633</a>
<a href="archive/20260204_0541.html">20260204_0541</a>
<a href="archive/20260204_0456.html">20260204_0456</a>
<a href="archive/20260204_0354.html">20260204_0354</a>
<a href="archive/20260202_0623.html">20260202_0623</a>
<a href="archive/20260202_0525.html">20260202_0525</a>
<a href="archive/20260202_0441.html">20260202_0441</a>
<a href="archive/20260202_0331.html">20260202_0331</a>
<a href="archive/20260201_0625.html">20260201_0625</a>
<a href="archive/20260201_0527.html">20260201_0527</a>
<a href="archive/20260201_0443.html">20260201_0443</a>
<a href="archive/20260201_0331.html">20260201_0331</a>
<a href="archive/20260131_0628.html">20260131_0628</a>
<a href="archive/20260131_0535.html">20260131_0535</a>
<a href="archive/20260131_0449.html">20260131_0449</a>
<a href="archive/20260131_0342.html">20260131_0342</a>
<a href="archive/20260130_0631.html">20260130_0631</a>
<a href="archive/20260130_0533.html">20260130_0533</a>
<a href="archive/20260130_0449.html">20260130_0449</a>
<a href="archive/20260130_0341.html">20260130_0341</a>
<a href="archive/20260129_0630.html">20260129_0630</a>
<a href="archive/20260129_0536.html">20260129_0536</a>
<a href="archive/20260129_0450.html">20260129_0450</a>
<a href="archive/20260129_0336.html">20260129_0336</a>
<a href="archive/20260128_0625.html">20260128_0625</a>
<a href="archive/20260128_0439.html">20260128_0439</a>
<a href="archive/20260128_0334.html">20260128_0334</a>
<a href="archive/20260127_0627.html">20260127_0627</a>
<a href="archive/20260127_0529.html">20260127_0529</a>
<a href="archive/20260127_0439.html">20260127_0439</a>
<a href="archive/20260127_0333.html">20260127_0333</a>
<a href="archive/20260126_0626.html">20260126_0626</a>
<a href="archive/20260126_0526.html">20260126_0526</a>
<a href="archive/20260126_0327.html">20260126_0327</a>
<a href="archive/20260125_0624.html">20260125_0624</a>
<a href="archive/20260125_0524.html">20260125_0524</a>
<a href="archive/20260125_0440.html">20260125_0440</a>
<a href="archive/20260125_0325.html">20260125_0325</a>
<a href="archive/20260124_0627.html">20260124_0627</a>
<a href="archive/20260124_0526.html">20260124_0526</a>
<a href="archive/20260124_0444.html">20260124_0444</a>
<a href="archive/20260124_0334.html">20260124_0334</a>
<a href="archive/20260123_0627.html">20260123_0627</a>
<a href="archive/20260123_0529.html">20260123_0529</a>
<a href="archive/20260123_0446.html">20260123_0446</a>
<a href="archive/20260123_0334.html">20260123_0334</a>
<a href="archive/20260122_2019.html">20260122_2019</a>
<a href="archive/20260122_2013.html">20260122_2013</a>
<a href="archive/20260122_2008.html">20260122_2008</a>
<a href="archive/20260122_2001.html">20260122_2001</a>
<a href="archive/20260122_0629.html">20260122_0629</a>
<a href="archive/20260122_0535.html">20260122_0535</a>
<a href="archive/20260122_0449.html">20260122_0449</a>
<a href="archive/20260122_0336.html">20260122_0336</a>
<a href="archive/20260121_0625.html">20260121_0625</a>
<a href="archive/20260121_0529.html">20260121_0529</a>
<a href="archive/20260121_0450.html">20260121_0450</a>
<a href="archive/20260121_0423.html">20260121_0423</a>
<a href="archive/20260120_0626.html">20260120_0626</a>
<a href="archive/20260120_0528.html">20260120_0528</a>
<a href="archive/20260120_0443.html">20260120_0443</a>
<a href="archive/20260120_0330.html">20260120_0330</a>
<a href="archive/20260119_0624.html">20260119_0624</a>
<a href="archive/20260119_0525.html">20260119_0525</a>
<a href="archive/20260119_0440.html">20260119_0440</a>
<a href="archive/20260119_0325.html">20260119_0325</a>
<a href="archive/20260118_2225.html">20260118_2225</a>
<a href="archive/20260118_2159.html">20260118_2159</a>
<a href="archive/20260118_2135.html">20260118_2135</a>
<a href="archive/20260118_2040.html">20260118_2040</a>
<a href="archive/20260118_1953.html">20260118_1953</a>
<a href="archive/20260118_1907.html">20260118_1907</a>
<a href="archive/20260118_0327.html">20260118_0327</a>
<a href="archive/20260117_0332.html">20260117_0332</a>
<a href="archive/20260116_0339.html">20260116_0339</a>
<a href="archive/20260115_0334.html">20260115_0334</a>
<a href="archive/20260114_0333.html">20260114_0333</a>
<a href="archive/20260113_0334.html">20260113_0334</a>
<a href="archive/20260112_0331.html">20260112_0331</a>
<a href="archive/20260111_0329.html">20260111_0329</a>
<a href="archive/20260110_0333.html">20260110_0333</a>
<a href="archive/20260109_0334.html">20260109_0334</a>
<a href="archive/20260108_0335.html">20260108_0335</a>
<a href="archive/20260107_0330.html">20260107_0330</a>
<a href="archive/20260106_0336.html">20260106_0336</a>
<a href="archive/20260105_0328.html">20260105_0328</a>
<a href="archive/20260104_0328.html">20260104_0328</a>
<a href="archive/20260103_0325.html">20260103_0325</a>
<a href="archive/20260102_0339.html">20260102_0339</a>
<a href="archive/20260101_0329.html">20260101_0329</a>
<a href="archive/20251231_0333.html">20251231_0333</a>
<a href="archive/20251230_0332.html">20251230_0332</a>
<a href="archive/20251229_0329.html">20251229_0329</a>
<a href="archive/20251228_0332.html">20251228_0332</a>
<a href="archive/20251227_0329.html">20251227_0329</a>
<a href="archive/20251226_0330.html">20251226_0330</a></div>
    </details>
    <div class="footer">Generated by arxiv-tracker</div>
  </div>
</body></html>
