<!doctype html>
<html><head><meta charset="utf-8"><meta name="viewport" content="width=device-width,initial-scale=1">
<title>arXiv 论文速递</title><style>
:root {
  --bg:#f8fafc; --card:#ffffff; --text:#0f172a; --muted:#667085; --border:#e5e7eb; --acc:#2563eb;
}
:root[data-theme="dark"] {
  --bg:#0b0f17; --card:#111827; --text:#e5e7eb; --muted:#9ca3af; --border:#1f2937; --acc:#2563eb;
}
*{box-sizing:border-box} body{margin:0;background:var(--bg);color:var(--text);
  font-family:ui-sans-serif,system-ui,-apple-system,Segoe UI,Roboto,Helvetica,Arial;line-height:1.6;}
.container{max-width:900px;margin:0 auto;padding:18px;}
.header{display:flex;gap:10px;justify-content:space-between;align-items:center;margin:8px 0 16px;flex-wrap:wrap}
h1{font-size:22px;margin:0}
.badge{font-size:12px;color:#111827;background:var(--acc);padding:2px 8px;border-radius:999px}
.card{background:var(--card);border:1px solid var(--border);border-radius:16px;padding:16px 18px;margin:14px 0;box-shadow:0 1px 2px rgba(0,0,0,.04)}
.title{font-weight:700;margin:0 0 6px 0;font-size:18px}
.meta-line{color:var(--muted);font-size:13px;margin:2px 0}
.links a{color:var(--acc);text-decoration:none;margin-right:12px}
.detail{margin-top:10px;background:rgba(2,6,23,.03);border:1px solid var(--border);border-radius:10px;padding:8px 10px}
summary{cursor:pointer;color:var(--acc)}
.mono{white-space:pre-wrap;background:rgba(2,6,23,.03);border:1px solid var(--border);padding:10px;border-radius:10px}
.row{display:grid;grid-template-columns:1fr;gap:12px}
@media (min-width: 860px) {
  .row-2{grid-template-columns:1fr 1fr}
}
.footer{color:var(--muted);font-size:13px;margin:20px 0 10px}
.hr{height:1px;background:var(--border);margin:14px 0}
.history-list a{display:block;color:var(--acc);text-decoration:none;margin:4px 0}
.controls{display:flex;gap:8px;align-items:center}
.btn{border:1px solid var(--border);background:var(--card);padding:6px 10px;border-radius:10px;cursor:pointer;color:var(--text)}
.btn:hover{border-color:var(--acc)}
</style>
<script>
(function() {
  const root = document.documentElement;
  function apply(t) {
    if (t==='dark') root.setAttribute('data-theme','dark');
    else if (t==='light') root.removeAttribute('data-theme');
    else {
      if (window.matchMedia && window.matchMedia('(prefers-color-scheme: dark)').matches)
        root.setAttribute('data-theme','dark');
      else root.removeAttribute('data-theme');
    }
  }
  let t = localStorage.getItem('theme') || 'light';
  if (!['light','dark','auto'].includes(t)) t='light';
  apply(t);
  window.__toggleTheme = function() {
    let cur = localStorage.getItem('theme') || 'light';
    if (cur==='light') cur='dark';
    else if (cur==='dark') cur='auto';
    else cur='light';
    localStorage.setItem('theme', cur);
    apply(cur);
    const el=document.getElementById('theme-label');
    if(el) el.textContent = cur.toUpperCase();
  }
  window.__expandAll = function(open) {
    document.querySelectorAll('details').forEach(d => d.open = !!open);
  }
})();
</script>
</head>
<body>
  <div class="container">
    <div class="header">
      <h1>arXiv 论文速递</h1>
      <div style="display:flex;gap:10px;align-items:center">
        
<div class="controls">
  <button class="btn" onclick="__toggleTheme()">Theme: <span id="theme-label" style="margin-left:6px">AUTO</span></button>
  <button class="btn" onclick="__expandAll(true)">Expand All</button>
  <button class="btn" onclick="__expandAll(false)">Collapse All</button>
</div>

        <span class="badge">2026-01-26 05:26</span>
      </div>
    </div>
    <div class="hr"></div>
    <div>Snapshot: 20260126_0526</div>
    <div class="row"><div class="card">
<div class="title">GutenOCR: A Grounded Vision-Language Front-End for Documents</div>
<div class="meta-line">Authors: Hunter Heidenreich, Ben Elliott, Olivia Dinica, Yosheb Getachew</div>
<div class="meta-line">First: 2026-01-20T21:26:15+00:00 · Latest: 2026-01-22T18:58:24+00:00</div>
<div class="links" style="margin-top:8px"><a href="https://arxiv.org/abs/2601.14490v2">Abs</a> · <a href="https://arxiv.org/pdf/2601.14490v2">PDF</a> · <a href="https://huggingface.co/huggingface">Code1</a> · <a href="https://huggingface.co/docs/hub/spaces">Code2</a></div>
<details class="detail"><summary>Abstract</summary>
<div class="mono">GutenOCR is a family of grounded OCR front-ends obtained by fine-tuning Qwen2.5-VL-3B and Qwen2.5-VL-7B. The resulting single-checkpoint vision-language models expose reading, detection, and grounding through a unified, prompt-based interface. Trained on business documents, scientific articles, and synthetic grounding data, the models support full-page and localized reading with line- and paragraph-level bounding boxes and conditional ``where is x?&#x27;&#x27; queries. We introduce a grounded OCR evaluation protocol and show that GutenOCR-7B more than doubles the composite grounded OCR score of its Qwen2.5-VL-7B backbone on 10.5K held-out business and scientific pages (0.40 to 0.82). On Fox and OmniDocBench v1.5, our approach substantially improves region- and line-level OCR as well as text-detection recall, but reveals trade-offs in page-level linearization, color-guided OCR, and formula-heavy layouts.</div></details>
<details class="detail"><summary>中文标题/摘要</summary>
<div class="mono"><b>标题：</b>GutenOCR：面向文档的具身视觉语言前端系统</div>
<div class="mono" style="margin-top:8px">GutenOCR是通过微调Qwen2.5-VL-3B和Qwen2.5-VL-7B获得的一系列具身OCR前端模型。所得的单检查点视觉语言模型通过统一的提示驱动接口，实现文本读取、检测与定位功能。基于商业文档、科学文献及合成定位数据训练，该模型支持整页与局部读取，提供行级与段落级边界框，并能响应“X在哪里？”的条件查询。我们提出了具身OCR评估框架，实验表明在1.05万份保留的商业与科学文档上，GutenOCR-7B的复合具身OCR分数较其骨干网络Qwen2.5-VL-7B提升超一倍（0.40至0.82）。在Fox与OmniDocBench v1.5基准测试中，本方法显著提升了区域/行级OCR性能及文本检测召回率，但在页面级线性化、色彩引导OCR及公式密集版式处理方面存在权衡。</div>
</details>
<details class="detail"><summary>Summary / 总结</summary>
<div class="mono">This research addresses the need for unified document understanding models that combine reading, detection, and grounding capabilities. The authors develop GutenOCR by fine-tuning Qwen2.5-VL vision-language models (3B and 7B parameters) on business documents, scientific articles, and synthetic grounding data, creating a single-checkpoint model with a prompt-based interface for full-page/localized reading, bounding box output, and conditional queries. Experimental results show that GutenOCR-7B more than doubles the composite grounded OCR score of its backbone model (from 0.40 to 0.82) on 10.5K held-out pages, substantially improves region/line-level OCR and text-detection recall on Fox and OmniDocBench benchmarks, though with trade-offs in page linearization, color-guided OCR, and formula-heavy layouts.</div>
<div class="mono" style="margin-top:8px">本研究旨在开发能够统一实现文档阅读、检测与定位功能的文档理解模型。方法上，通过对Qwen2.5-VL视觉语言模型（30亿和70亿参数）在商业文档、科学文章及合成定位数据上进行微调，构建了GutenOCR系列模型，其通过基于提示的统一接口支持整页/局部阅读、行/段落级边界框输出及条件查询。实验结果表明，在10.5K份保留的商业与科学文档上，GutenOCR-7B将基础模型的综合定位OCR分数从0.40提升至0.82（提升一倍以上），在Fox和OmniDocBench基准测试中显著改善了区域/行级OCR性能与文本检测召回率，但也揭示了在页面级线性化、颜色引导OCR及公式密集布局处理方面的性能权衡。</div>
</details>
</div>
<div class="card">
<div class="title">Counterfactual Training: Teaching Models Plausible and Actionable Explanations</div>
<div class="meta-line">Authors: Patrick Altmeyer, Aleksander Buszydlik, Arie van Deursen, Cynthia C. S. Liem</div>
<div class="meta-line">First: 2026-01-22T18:56:14+00:00 · Latest: 2026-01-22T18:56:14+00:00</div>
<div class="meta-line">Comments: This work has been accepted for publication at the 2026 IEEE Conference on Secure and Trustworthy Machine Learning (SaTML). The final version will be available on IEEE Xplore</div>
<div class="links" style="margin-top:8px"><a href="https://arxiv.org/abs/2601.16205v1">Abs</a> · <a href="https://arxiv.org/pdf/2601.16205v1">PDF</a> · <a href="https://huggingface.co/huggingface">Code1</a> · <a href="https://huggingface.co/docs/hub/spaces">Code2</a></div>
<details class="detail"><summary>Abstract</summary>
<div class="mono">We propose a novel training regime termed counterfactual training that leverages counterfactual explanations to increase the explanatory capacity of models. Counterfactual explanations have emerged as a popular post-hoc explanation method for opaque machine learning models: they inform how factual inputs would need to change in order for a model to produce some desired output. To be useful in real-world decision-making systems, counterfactuals should be plausible with respect to the underlying data and actionable with respect to the feature mutability constraints. Much existing research has therefore focused on developing post-hoc methods to generate counterfactuals that meet these desiderata. In this work, we instead hold models directly accountable for the desired end goal: counterfactual training employs counterfactuals during the training phase to minimize the divergence between learned representations and plausible, actionable explanations. We demonstrate empirically and theoretically that our proposed method facilitates training models that deliver inherently desirable counterfactual explanations and additionally exhibit improved adversarial robustness.</div></details>
<details class="detail"><summary>中文标题/摘要</summary>
<div class="mono"><b>标题：</b>反事实训练：为模型提供合理且可操作的因果解释</div>
<div class="mono" style="margin-top:8px">本文提出一种名为反事实训练的新型训练范式，利用反事实解释增强模型的可解释性。反事实解释已成为对不透明机器学习模型进行事后解释的常用方法：它揭示如何修改事实输入才能使模型产生期望的输出。为在实际决策系统中发挥作用，反事实需满足数据合理性特征与特征可变性约束下的可操作性。现有研究多聚焦于开发满足这些要求的事后生成方法。本研究则直接要求模型对最终目标负责：反事实训练在训练阶段运用反事实机制，最小化学习表征与合理可操作解释之间的差异。我们通过实证与理论证明，该方法能训练出具有内在理想反事实解释能力的模型，并显著提升对抗鲁棒性。</div>
</details>
<details class="detail"><summary>Summary / 总结</summary>
<div class="mono">The research addresses the need for machine learning models to provide plausible and actionable counterfactual explanations, which are crucial for real-world decision-making but are typically generated post-hoc. The proposed method, counterfactual training, integrates counterfactual explanations directly into the training phase to align the model&#x27;s learned representations with these desirable explanation properties. Experimental results show that this approach not only yields models capable of producing inherently plausible and actionable counterfactuals but also enhances their adversarial robustness.</div>
<div class="mono" style="margin-top:8px">该研究针对机器学习模型需提供合理且可操作的反事实解释的需求，这些解释对现实世界决策至关重要，但通常是在训练后生成的。提出的反事实训练方法将反事实解释直接整合到训练阶段，通过最小化学习表示与这些解释之间的差异来增强模型的可解释性。实验结果表明，该方法训练出的模型能够内生地生成理想的反事实解释，并同时提升了对抗鲁棒性。</div>
</details>
</div>
<div class="card">
<div class="title">Provable Robustness in Multimodal Large Language Models via Feature Space Smoothing</div>
<div class="meta-line">Authors: Song Xia, Meiwen Ding, Chenqi Kong, Wenhan Yang, Xudong Jiang</div>
<div class="meta-line">First: 2026-01-22T18:52:21+00:00 · Latest: 2026-01-22T18:52:21+00:00</div>
<div class="meta-line">Comments: Under review</div>
<div class="links" style="margin-top:8px"><a href="https://arxiv.org/abs/2601.16200v1">Abs</a> · <a href="https://arxiv.org/pdf/2601.16200v1">PDF</a> · <a href="https://huggingface.co/huggingface">Code1</a> · <a href="https://huggingface.co/docs/hub/spaces">Code2</a></div>
<details class="detail"><summary>Abstract</summary>
<div class="mono">Multimodal large language models (MLLMs) exhibit strong capabilities across diverse applications, yet remain vulnerable to adversarial perturbations that distort their feature representations and induce erroneous predictions. To address this vulnerability, we propose the Feature-space Smoothing (FS) and theoretically prove that FS offers certified robustness on the feature representations of MLLMs. Specifically, FS transforms any feature encoder into a smoothed variant that is guaranteed to maintain a certified lower bound on the feature cosine similarity between clean and adversarial representations under $\ell_2$-bounded attacks. Moreover, we indicate that the value of this Feature Cosine Similarity Bound (FCSB) derived from FS can be improved by enlarging the defined Gaussian robustness score on the vanilla encoder. Building upon this, we introduce the Purifier and Smoothness Mapper (PSM), a plug-and-play module that improves the Gaussian robustness score of MLLMs and thus enhances their certified robustness under FS, without requiring any retraining on MLLMs. We demonstrate that the FS with PSM not only provides a strong theoretical robustness guarantee but also exhibits superior empirical performance compared to adversarial training. Extensive experiments across diverse MLLMs and downstream tasks indicate the effectiveness of the FS-PSM, reducing the Attack Success Rate (ASR) of various white-box attacks from nearly 90\% to about 1\%.</div></details>
<details class="detail"><summary>中文标题/摘要</summary>
<div class="mono"><b>标题：</b>通过特征空间平滑实现多模态大语言模型的可证明鲁棒性</div>
<div class="mono" style="margin-top:8px">多模态大语言模型（MLLMs）在多种应用中展现出强大能力，但仍易受对抗性扰动影响，这些扰动会扭曲其特征表示并导致错误预测。为解决此脆弱性，我们提出特征空间平滑（FS）方法，并从理论上证明FS能为MLLMs的特征表示提供可证明的鲁棒性。具体而言，FS将任意特征编码器转换为平滑变体，保证在$\ell_2$范数有界攻击下，干净样本与对抗样本的特征余弦相似度具有可证明的下界。此外，我们指出通过提升原始编码器的高斯鲁棒性评分，可优化由此衍生的特征余弦相似度下界（FCSB）。基于此，我们引入即插即用模块——净化平滑映射器（PSM），该模块能提升MLLMs的高斯鲁棒性评分，从而在无需重新训练模型的情况下增强FS框架下的可证明鲁棒性。实验表明，结合PSM的FS不仅能提供坚实的理论鲁棒性保证，其经验性能也优于对抗训练。在多类MLLMs及下游任务上的广泛实验验证了FS-PSM的有效性，能将多种白盒攻击的成功率（ASR）从近90%降至约1%。</div>
</details>
<details class="detail"><summary>Summary / 总结</summary>
<div class="mono">Multimodal large language models (MLLMs) are powerful but susceptible to adversarial perturbations that corrupt their feature representations. To address this, the authors propose Feature-space Smoothing (FS), a method that transforms a feature encoder into a smoothed variant with a provable lower bound on feature cosine similarity under ℓ₂-bounded attacks, thereby offering certified robustness. They further introduce a plug-and-play Purifier and Smoothness Mapper (PSM) module to improve the underlying Gaussian robustness score of MLLMs, enhancing the certified bound without retraining. Experiments across various MLLMs and tasks show that FS with PSM significantly reduces the Attack Success Rate of white-box attacks from nearly 90% to about 1%, outperforming adversarial training.</div>
<div class="mono" style="margin-top:8px">多模态大语言模型（MLLMs）能力强大，但其特征表示易受对抗性扰动影响而导致错误预测。为此，研究者提出了特征空间平滑（FS）方法，通过将特征编码器转换为平滑变体，从理论上保证在ℓ₂有界攻击下特征余弦相似度具有经过认证的下界；并进一步引入即插即用的净化与平滑映射器（PSM）模块，无需重新训练MLLMs即可提高模型的高斯鲁棒性分数，从而增强FS的认证鲁棒性。在多种MLLMs和下游任务上的广泛实验表明，FS与PSM结合能将各类白盒攻击的成功率从近90%降至约1%，优于对抗训练，同时提供了坚实的理论和实证鲁棒性保证。</div>
</details>
</div>
<div class="card">
<div class="title">Four Over Six: More Accurate NVFP4 Quantization with Adaptive Block Scaling</div>
<div class="meta-line">Authors: Jack Cook, Junxian Guo, Guangxuan Xiao, Yujun Lin, Song Han</div>
<div class="meta-line">First: 2025-12-01T18:59:45+00:00 · Latest: 2026-01-22T18:49:14+00:00</div>
<div class="meta-line">Comments: 10 pages, 4 figures</div>
<div class="links" style="margin-top:8px"><a href="https://arxiv.org/abs/2512.02010v3">Abs</a> · <a href="https://arxiv.org/pdf/2512.02010v3">PDF</a> · <a href="http://github.com/mit-han-lab/fouroversix">Code1</a> · <a href="https://huggingface.co/huggingface">Code2</a> · <a href="https://huggingface.co/docs/hub/spaces">Code3</a></div>
<details class="detail"><summary>Abstract</summary>
<div class="mono">As large language models have grown larger, interest has grown in low-precision numerical formats such as NVFP4 as a way to improve speed and reduce memory usage. However, quantizing models to NVFP4 remains difficult as the lack of precision generally degrades model performance. In this work, we address this issue with Four Over Six (4/6), a modification to the block-scaled NVFP4 quantization algorithm that yields reduced quantization error. Unlike integer formats, floating point formats have non-uniform step sizes which create larger quantization error on larger values. 4/6 takes advantage of this by adaptively scaling some blocks to smaller FP4 values, making the distribution of representable values more uniform and reducing quantization error for near-maximal values. We show that 4/6 can be implemented efficiently on NVIDIA Blackwell GPUs, resulting in performance gains during both pre-training and inference with minimal computational overhead. In pre-training experiments with the Nemotron 3 Nano 30B-A3B model architecture, we find that 4/6 brings training loss closer to BF16 compared to models trained with current state-of-the-art NVFP4 training recipes. Our code is available at http://github.com/mit-han-lab/fouroversix.</div></details>
<details class="detail"><summary>中文标题/摘要</summary>
<div class="mono"><b>标题：</b>四分之六：采用自适应块缩放的更精确NVFP4量化方法</div>
<div class="mono" style="margin-top:8px">随着大语言模型规模不断扩大，NVFP4等低精度数值格式因能提升速度并降低内存使用而备受关注。然而，将模型量化为NVFP4仍具挑战性，精度缺失通常会导致模型性能下降。本研究通过&#x27;四分之六&#x27;方法改进块缩放NVFP4量化算法，有效降低量化误差。与整数格式不同，浮点格式的非均匀步长会导致较大数值产生更显著的量化误差。4/6方法通过自适应地将部分块缩放至更小的FP4值，使可表示值的分布更均匀，从而减少接近最大值区域的量化误差。我们证明4/6可在英伟达Blackwell GPU上高效实现，在预训练和推理阶段以最小计算开销获得性能提升。基于Nemotron 3 Nano 30B-A3B架构的预训练实验表明，相较于当前最先进的NVFP4训练方案，4/6能使训练损失更接近BF16精度。代码已开源：http://github.com/mit-han-lab/fouroversix。</div>
</details>
<details class="detail"><summary>Summary / 总结</summary>
<div class="mono">To mitigate the performance degradation caused by low-precision NVFP4 quantization in large language models, this work introduces Four Over Six (4/6), an adaptive block scaling method. The method reduces quantization error by dynamically scaling some blocks to smaller FP4 values, which makes the distribution of representable values more uniform and better handles larger values prone to error in floating-point formats. Experimental results demonstrate that 4/6 can be efficiently implemented on NVIDIA Blackwell GPUs, improving both pre-training and inference performance with minimal overhead, and brings the training loss of a Nemotron 3 Nano 30B-A3B model closer to that of BF16 precision compared to existing NVFP4 recipes.</div>
<div class="mono" style="margin-top:8px">为解决大语言模型低精度NVFP4量化导致的性能下降问题，本研究提出了自适应块缩放方法Four Over Six（4/6）以降低量化误差。该方法利用浮点格式非均匀步长的特性，通过自适应地将部分块缩放到更小的FP4值，使可表示值的分布更均匀，从而减少接近最大值区域的量化误差。实验结果表明，4/6可在NVIDIA Blackwell GPU上高效实现，在Nemotron 3 Nano 30B-A3B模型预训练中，相比现有最优NVFP4训练方案，其训练损失更接近BF16基准，同时在预训练和推理阶段均保持极低计算开销。</div>
</details>
</div>
<div class="card">
<div class="title">Training-Free Geospatial Place Representation Learning from Large-Scale Point-of-Interest Graph Data</div>
<div class="meta-line">Authors: Mohammad Hashemi, Hossein Amiri, Andreas Zufle</div>
<div class="meta-line">First: 2025-06-25T15:10:31+00:00 · Latest: 2026-01-22T18:46:50+00:00</div>
<div class="links" style="margin-top:8px"><a href="https://arxiv.org/abs/2507.02921v3">Abs</a> · <a href="https://arxiv.org/pdf/2507.02921v3">PDF</a> · <a href="https://github.com/mohammadhashemii/PlaceRep">Code1</a> · <a href="https://huggingface.co/huggingface">Code2</a> · <a href="https://huggingface.co/docs/hub/spaces">Code3</a></div>
<details class="detail"><summary>Abstract</summary>
<div class="mono">Learning effective representations of urban environments requires capturing spatial structure beyond fixed administrative boundaries. Existing geospatial representation learning approaches typically aggregate Points of Interest(POI) into pre-defined administrative regions such as census units or ZIP code areas, assigning a single embedding to each region. However, POIs often form semantically meaningful groups that extend across, within, or beyond these boundaries, defining places that better reflect human activity and urban function. To address this limitation, we propose PlaceRep, a training-free geospatial representation learning method that constructs place-level representations by clustering spatially and semantically related POIs. PlaceRep summarizes large-scale POI graphs from U.S. Foursquare data to produce general-purpose urban region embeddings while automatically identifying places across multiple spatial scales. By eliminating model pre-training, PlaceRep provides a scalable and efficient solution for multi-granular geospatial analysis. Experiments using the tasks of population density estimation and housing price prediction as downstream tasks show that PlaceRep outperforms most state-of-the-art graph-based geospatial representation learning methods and achieves up to a 100x speedup in generating region-level representations on large-scale POI graphs. The implementation of PlaceRep is available at https://github.com/mohammadhashemii/PlaceRep.</div></details>
<details class="detail"><summary>中文标题/摘要</summary>
<div class="mono"><b>标题：</b>基于大规模兴趣点图数据的免训练地理空间场所表征学习</div>
<div class="mono" style="margin-top:8px">学习有效的城市环境表征需捕捉超越固定行政边界的空间结构。现有地理空间表征学习方法通常将兴趣点聚合至预定义的行政区域（如人口普查单元或邮政编码区），为每个区域分配单一嵌入向量。然而，兴趣点常形成跨越、位于或超出这些边界的语义化群组，从而定义更能反映人类活动与城市功能的场所。为突破此局限，我们提出PlaceRep——一种免训练的地理空间表征学习方法，通过聚类空间与语义相关的兴趣点构建场所级表征。该方法基于美国Foursquare数据的大规模兴趣点图进行归纳，在自动识别多空间尺度场所的同时生成通用型城市区域嵌入向量。通过消除模型预训练环节，PlaceRep为多粒度地理空间分析提供了可扩展的高效解决方案。在人口密度估算与房价预测下游任务中的实验表明，PlaceRep优于多数基于图结构的先进地理空间表征学习方法，并在大规模兴趣点图上实现区域级表征生成速度提升高达100倍。项目代码已开源：https://github.com/mohammadhashemii/PlaceRep。</div>
</details>
<details class="detail"><summary>Summary / 总结</summary>
<div class="mono">To overcome the limitation of existing geospatial representation methods that rely on fixed administrative boundaries and assign a single embedding to each pre-defined region, this research introduces PlaceRep, a training-free method for learning place-level representations. The approach constructs these representations by clustering Points of Interest (POI) based on spatial and semantic relatedness from large-scale graph data, automatically identifying semantically meaningful places across multiple scales without requiring model pre-training. Experimental evaluations on downstream tasks including population density estimation and housing price prediction demonstrate that PlaceRep outperforms most state-of-the-art graph-based geospatial methods and achieves up to a 100x speedup in generating region-level embeddings from large-scale POI graphs.</div>
<div class="mono" style="margin-top:8px">本研究针对现有地理空间表示方法将兴趣点聚合到固定行政边界的局限性，这些边界可能与反映人类活动的语义上有意义的地点不一致。提出的方法PlaceRep是一种免训练方法，通过从大规模图数据中聚类空间和语义相关的兴趣点来构建地点级表示，无需模型预训练即可自动识别多空间尺度的地点。在人口密度估计和房价预测等下游任务上的实验结果表明，PlaceRep优于大多数最先进的基于图的地理空间方法，并在生成区域级嵌入时实现了高达100倍的加速。</div>
</details>
</div>
<div class="card">
<div class="title">A Rolling-Space Branch-and-Price Algorithm for the Multi-Compartment Vehicle Routing Problem with Multiple Time Windows</div>
<div class="meta-line">Authors: El Mehdi Er Raqabi, Kevin Dalmeijer, Pascal Van Hentenryck</div>
<div class="meta-line">First: 2026-01-22T18:46:46+00:00 · Latest: 2026-01-22T18:46:46+00:00</div>
<div class="links" style="margin-top:8px"><a href="https://arxiv.org/abs/2601.16194v1">Abs</a> · <a href="https://arxiv.org/pdf/2601.16194v1">PDF</a> · <a href="https://huggingface.co/huggingface">Code1</a> · <a href="https://huggingface.co/docs/hub/spaces">Code2</a></div>
<details class="detail"><summary>Abstract</summary>
<div class="mono">This paper investigates the multi-compartment vehicle routing problem with multiple time windows (MCVRPMTW), an extension of the classical vehicle routing problem with time windows that considers vehicles equipped with multiple compartments and customers requiring service across several delivery time windows. The problem incorporates three key compartment-related features: (i) compartment flexibility in the number of compartments, (ii) item-to-compartment compatibility, and (iii) item-to-item compatibility. The problem also accommodates practical operational requirements such as driver breaks. To solve the MCVRPMTW, we develop an exact branch-and-price (B&amp;P) algorithm in which the pricing problem is solved using a labeling algorithm. Several acceleration strategies are introduced to limit symmetry during label extensions, improve the stability of dual solutions in column generation, and enhance the branching process. To handle large-scale instances, we propose a rolling-space B&amp;P algorithm that integrates clustering techniques into the solution framework. Extensive computational experiments on instances inspired by a real-world industrial application demonstrate the effectiveness of the proposed approach and provide useful managerial insights for practical implementation.</div></details>
<details class="detail"><summary>中文标题/摘要</summary>
<div class="mono"><b>标题：</b>多时间窗多隔间车辆路径问题的滚动空间分支定价算法</div>
<div class="mono" style="margin-top:8px">本文研究了多时间窗多隔间车辆路径问题（MCVRPMTW），该问题是经典带时间窗车辆路径问题的扩展，考虑了配备多隔间的车辆及客户在多个配送时间窗内接受服务的需求。问题包含三个关键隔间相关特征：（i）隔间数量的灵活性，（ii）物品与隔间的兼容性，以及（iii）物品间的兼容性。同时，模型还纳入了驾驶员休息等实际运营要求。为求解MCVRPMTW，我们设计了一种精确的分支定价算法，其中定价问题通过标签算法求解。研究引入了多种加速策略，以限制标签扩展过程中的对称性、提升列生成中对偶解的稳定性，并优化分支过程。针对大规模算例，我们提出了一种滚动空间分支定价算法，将聚类技术整合到求解框架中。基于实际工业应用场景设计的算例上的大量计算实验验证了所提方法的有效性，并为实际应用提供了有益的管理启示。</div>
</details>
<details class="detail"><summary>Summary / 总结</summary>
<div class="mono">This research addresses the multi-compartment vehicle routing problem with multiple time windows (MCVRPMTW), motivated by the need to model complex real-world logistics where vehicles have multiple compartments for different goods and customers have several possible delivery windows. The method employs an exact branch-and-price algorithm, using a labeling algorithm to solve the pricing subproblem, enhanced with acceleration strategies to reduce symmetry, stabilize dual solutions, and improve branching; for large-scale instances, a rolling-space variant integrates clustering techniques. Experimental results on instances derived from a real-world application demonstrate the algorithm&#x27;s effectiveness and yield practical managerial insights.</div>
<div class="mono" style="margin-top:8px">本研究针对带多时间窗的多隔间车辆路径问题（MCVRPMTW），其动机源于对复杂现实物流建模的需求，此类物流中车辆配备多个隔间以装载不同产品，且客户有多个可用的服务时间窗。方法上，开发了一种精确的分支定价算法，使用标号算法求解定价子问题，并通过加速策略来减少对称性、稳定对偶解和改进分支过程。针对大规模算例，提出了一种融合聚类技术的滚动空间分支定价算法。在源自工业应用的算例上的计算实验证明了该算法的有效性，并为实际应用提供了有用的管理启示。</div>
</details>
</div>
<div class="card">
<div class="title">Learning to Discover at Test Time</div>
<div class="meta-line">Authors: Mert Yuksekgonul, Daniel Koceja, Xinhao Li, Federico Bianchi, Jed McCaleb, Xiaolong Wang, Jan Kautz, Yejin Choi, James Zou, Carlos Guestrin, Yu Sun</div>
<div class="meta-line">First: 2026-01-22T18:24:00+00:00 · Latest: 2026-01-22T18:24:00+00:00</div>
<div class="meta-line">Comments: Code: https://github.com/test-time-training/discover</div>
<div class="links" style="margin-top:8px"><a href="https://arxiv.org/abs/2601.16175v1">Abs</a> · <a href="https://arxiv.org/pdf/2601.16175v1">PDF</a> · <a href="https://github.com/test-time-training/discover">Code1</a> · <a href="https://huggingface.co/huggingface">Code2</a> · <a href="https://huggingface.co/docs/hub/spaces">Code3</a></div>
<details class="detail"><summary>Abstract</summary>
<div class="mono">How can we use AI to discover a new state of the art for a scientific problem? Prior work in test-time scaling, such as AlphaEvolve, performs search by prompting a frozen LLM. We perform reinforcement learning at test time, so the LLM can continue to train, but now with experience specific to the test problem. This form of continual learning is quite special, because its goal is to produce one great solution rather than many good ones on average, and to solve this very problem rather than generalize to other problems. Therefore, our learning objective and search subroutine are designed to prioritize the most promising solutions. We call this method Test-Time Training to Discover (TTT-Discover). Following prior work, we focus on problems with continuous rewards. We report results for every problem we attempted, across mathematics, GPU kernel engineering, algorithm design, and biology. TTT-Discover sets the new state of the art in almost all of them: (i) Erdős&#x27; minimum overlap problem and an autocorrelation inequality; (ii) a GPUMode kernel competition (up to $2\times$ faster than prior art); (iii) past AtCoder algorithm competitions; and (iv) denoising problem in single-cell analysis. Our solutions are reviewed by experts or the organizers. All our results are achieved with an open model, OpenAI gpt-oss-120b, and can be reproduced with our publicly available code, in contrast to previous best results that required closed frontier models. Our test-time training runs are performed using Tinker, an API by Thinking Machines, with a cost of only a few hundred dollars per problem.</div></details>
<details class="detail"><summary>中文标题/摘要</summary>
<div class="mono"><b>标题：</b>在测试时学习发现</div>
<div class="mono" style="margin-top:8px">如何利用人工智能为科学问题发现新的最优解？先前关于测试时扩展的研究（如AlphaEvolve）通过提示冻结的大型语言模型进行搜索。我们在测试时进行强化学习，使大型语言模型能够持续训练，但此时训练经验专门针对测试问题。这种持续学习形式非常特殊，其目标是产生一个卓越解决方案而非多个平均良好的方案，并专注于解决当前问题而非泛化到其他问题。因此，我们的学习目标和搜索子程序被设计为优先考虑最有潜力的解决方案。我们将此方法称为“测试时训练发现法”。遵循先前研究，我们聚焦于具有连续奖励的问题。我们报告了在数学、GPU内核工程、算法设计和生物学领域尝试的所有问题的结果：TTT-Discover在几乎所有问题上都创造了新的最优解：（i）埃尔德什最小重叠问题与自相关不等式；（ii）GPUMode内核竞赛（比现有技术快达2倍）；（iii）往届AtCoder算法竞赛；（iv）单细胞分析中的去噪问题。我们的解决方案经过专家或组织者评审。所有结果均使用开源模型OpenAI gpt-oss-120b实现，并可通过我们公开的代码复现，而先前的最佳结果需依赖闭源前沿模型。测试时训练通过Thinking Machines的Tinker API运行，每个问题成本仅数百美元。</div>
</details>
<details class="detail"><summary>Summary / 总结</summary>
<div class="mono">The research aims to advance AI&#x27;s capability to discover novel state-of-the-art solutions for scientific problems, moving beyond prior test-time scaling methods that rely on prompting frozen LLMs. The proposed method, Test-Time Training to Discover (TTT-Discover), employs reinforcement learning at test time, allowing the LLM to continuously train with experience specific to the target problem; it is designed with a learning objective and search subroutine that prioritize the most promising solutions to achieve one great outcome for the given problem. Experimental results across mathematics, GPU kernel engineering, algorithm design, and biology demonstrate that TTT-Discover sets new state-of-the-art performance in nearly all attempted problems, including Erdős&#x27; minimum overlap problem, a GPUMode kernel competition (achieving up to 2x speedup), past AtCoder algorithm competitions, and a denoising task in single-cell analysis, with solutions validated by experts and achieved using an open model and publicly available code.</div>
<div class="mono" style="margin-top:8px">本研究旨在提升人工智能在科学问题中发现新颖最优解的能力，超越先前依赖提示冻结大语言模型的测试时扩展方法。所提出的方法“测试时训练发现”（TTT-Discover）在测试时采用强化学习，使大语言模型能够针对特定测试问题持续训练；其学习目标和搜索子程序专为优先探索最有希望的解决方案而设计，以针对给定问题获得一个卓越结果。在数学、GPU内核工程、算法设计和生物学等多个领域的实验结果表明，TTT-Discover在几乎所有尝试的问题上都取得了新的最优性能，包括埃尔德什最小重叠问题、GPUMode内核竞赛（实现高达2倍加速）、过去的AtCoder算法竞赛以及单细胞分析中的去噪任务，所有解决方案均经专家验证，并使用开源模型和公开代码实现。</div>
</details>
</div>
<div class="card">
<div class="title">Beyond Predictive Uncertainty: Reliable Representation Learning with Structural Constraints</div>
<div class="meta-line">Authors: Yiyao Yang</div>
<div class="meta-line">First: 2026-01-22T18:19:52+00:00 · Latest: 2026-01-22T18:19:52+00:00</div>
<div class="meta-line">Comments: 22 pages, 5 figures, 5 propositions</div>
<div class="links" style="margin-top:8px"><a href="https://arxiv.org/abs/2601.16174v1">Abs</a> · <a href="https://arxiv.org/pdf/2601.16174v1">PDF</a> · <a href="https://huggingface.co/huggingface">Code1</a> · <a href="https://huggingface.co/docs/hub/spaces">Code2</a></div>
<details class="detail"><summary>Abstract</summary>
<div class="mono">Uncertainty estimation in machine learning has traditionally focused on the prediction stage, aiming to quantify confidence in model outputs while treating learned representations as deterministic and reliable by default. In this work, we challenge this implicit assumption and argue that reliability should be regarded as a first-class property of learned representations themselves. We propose a principled framework for reliable representation learning that explicitly models representation-level uncertainty and leverages structural constraints as inductive biases to regularize the space of feasible representations. Our approach introduces uncertainty-aware regularization directly in the representation space, encouraging representations that are not only predictive but also stable, well-calibrated, and robust to noise and structural perturbations. Structural constraints, such as sparsity, relational structure, or feature-group dependencies, are incorporated to define meaningful geometry and reduce spurious variability in learned representations, without assuming fully correct or noise-free structure. Importantly, the proposed framework is independent of specific model architectures and can be integrated with a wide range of representation learning methods.</div></details>
<details class="detail"><summary>中文标题/摘要</summary>
<div class="mono"><b>标题：</b>超越预测不确定性：基于结构约束的可靠表征学习</div>
<div class="mono" style="margin-top:8px">机器学习中的不确定性估计传统上聚焦于预测阶段，旨在量化模型输出的置信度，同时默认将学习到的表征视为确定且可靠的。本研究挑战了这一隐含假设，主张可靠性应被视为学习表征本身的一阶属性。我们提出了一个原则性的可靠表征学习框架，该框架显式建模表征层面的不确定性，并利用结构约束作为归纳偏置来正则化可行表征空间。我们的方法直接在表征空间中引入不确定性感知的正则化，鼓励表征不仅具有预测性，同时具备稳定性、良好校准性以及对噪声和结构扰动的鲁棒性。通过融入稀疏性、关系结构或特征组依赖等结构约束，可在不假设结构完全正确或无噪声的前提下，定义有意义的几何结构并减少学习表征中的虚假变异性。重要的是，所提框架独立于特定模型架构，可与广泛的表征学习方法集成。</div>
</details>
<details class="detail"><summary>Summary / 总结</summary>
<div class="mono">This work challenges the traditional focus on predictive uncertainty by arguing that reliability should be a core property of learned representations themselves. The authors propose a framework for reliable representation learning that explicitly models representation-level uncertainty and uses structural constraints, like sparsity or relational dependencies, as inductive biases to regularize the representation space. Their method encourages representations that are stable, well-calibrated, and robust to noise, and experimental results demonstrate its effectiveness across various architectures without assuming perfectly correct structural constraints.</div>
<div class="mono" style="margin-top:8px">该研究的动机是观察到传统机器学习中的不确定性估计主要关注预测置信度，而默认学习到的表示是可靠的，作者对此假设提出了质疑。他们提出了一个可靠的表示学习框架，该框架显式地建模表示层面的不确定性，并引入结构性约束（如稀疏性或关系依赖）作为归纳偏置来正则化表示空间，且不依赖于特定模型架构。实验结果表明，与常规方法相比，该方法学习到的表示更加稳定、校准良好，并且对噪声和结构扰动具有更强的鲁棒性。</div>
</details>
</div>
<div class="card">
<div class="title">Everybody Prune Now: Structured Pruning of LLMs with only Forward Passes</div>
<div class="meta-line">Authors: Steven Kolawole, Lucio Dery, Jean-François Kagy, Virginia Smith, Graham Neubig, Ameet Talwalkar</div>
<div class="meta-line">First: 2024-02-08T04:48:26+00:00 · Latest: 2026-01-22T18:13:50+00:00</div>
<div class="meta-line">Comments: 19 pages, 6 fiigures, 16 tables</div>
<div class="links" style="margin-top:8px"><a href="https://arxiv.org/abs/2402.05406v4">Abs</a> · <a href="https://arxiv.org/pdf/2402.05406v4">PDF</a> · <a href="https://huggingface.co/huggingface">Code1</a> · <a href="https://huggingface.co/docs/hub/spaces">Code2</a></div>
<details class="detail"><summary>Abstract</summary>
<div class="mono">Structured pruning is a promising approach to create smaller, faster large language models. However, existing methods typically rely on computing the gradient via backward passes, which can inflate memory requirements and compute costs. In this work we introduce Bonsai, a gradient-free structured pruning method that eliminates the need for backpropagation, significantly reducing memory requirements and compute costs while achieving state-of-the-art pruning performance. Bonsai uses forward-pass-only perturbative pruning to enable efficient compression of large models on a broader range of hardware configurations. Unlike existing structured pruning approaches, Bonsai not only achieves better compression with fewer resources but also produces models that are twice as fast as those generated by semi-structured pruning. As a concrete demonstration, we use Bonsai to prune 7B and 8B models to 50% sparsity on a single A6000 GPU -- a task challenging for backprop-based methods in memory-constrained settings, as they require 2-3x the memory. Our results show that removing backprop as a requirement not only enables pruning larger models on constrained hardware but can also lead to state-of-the-art efficiency and performance.</div></details>
<details class="detail"><summary>中文标题/摘要</summary>
<div class="mono"><b>标题：</b>即刻剪枝：仅需前向传播的大语言模型结构化剪枝</div>
<div class="mono" style="margin-top:8px">结构化剪枝是创建更小、更快大语言模型的有效途径。现有方法通常依赖反向传播计算梯度，这会增加内存需求和计算成本。本研究提出Bonsai——一种无需梯度的结构化剪枝方法，通过消除反向传播需求显著降低内存与计算成本，同时实现前沿的剪枝性能。该方法仅使用前向传播的扰动剪枝技术，能在更广泛的硬件配置上高效压缩大模型。与现有方法相比，Bonsai不仅以更少资源实现更好压缩，且生成模型的速度是半结构化剪枝的两倍。我们使用单张A6000 GPU将70亿和80亿参数模型剪枝至50%稀疏度，而基于反向传播的方法在内存受限环境下需要2-3倍内存。研究表明，摆脱反向传播限制不仅能在受限硬件上剪枝更大模型，还能实现最优的效率与性能。</div>
</details>
<details class="detail"><summary>Summary / 总结</summary>
<div class="mono">Structured pruning aims to create smaller and faster large language models, but existing gradient-based methods increase memory and compute costs. This work introduces Bonsai, a gradient-free structured pruning method that uses only forward passes to perturb weights, enabling efficient compression with reduced resource demands. Experiments demonstrate that Bonsai prunes 7B and 8B models to 50% sparsity on a single A6000 GPU, achieving state-of-the-art performance with models twice as fast as those from semi-structured pruning, while requiring significantly less memory than backpropagation-based approaches.</div>
<div class="mono" style="margin-top:8px">为应对基于梯度的大语言模型结构化剪枝方法存在的高内存和计算成本，本研究提出了Bonsai，一种仅需前向传播的无梯度剪枝方法。该方法采用仅前向传播的扰动剪枝来高效压缩模型，能够在单块A6000 GPU上将70亿和80亿参数模型剪枝至50%稀疏度，这对基于反向传播的方法在内存受限环境下颇具挑战。实验结果表明，Bonsai实现了最先进的剪枝性能，所产生的模型速度是半结构化剪枝模型的两倍，同时所需资源显著减少。</div>
</details>
</div>
<div class="card">
<div class="title">BAH Dataset for Ambivalence/Hesitancy Recognition in Videos for Digital Behavioural Change</div>
<div class="meta-line">Authors: Manuela González-González, Soufiane Belharbi, Muhammad Osama Zeeshan, Masoumeh Sharafi, Muhammad Haseeb Aslam, Marco Pedersoli, Alessandro Lameiras Koerich, Simon L Bacon, Eric Granger</div>
<div class="meta-line">First: 2025-05-25T21:29:00+00:00 · Latest: 2026-01-22T18:06:39+00:00</div>
<div class="meta-line">Comments: 45 pages, 21 figures, under review</div>
<div class="links" style="margin-top:8px"><a href="https://arxiv.org/abs/2505.19328v3">Abs</a> · <a href="https://arxiv.org/pdf/2505.19328v3">PDF</a> · <a href="https://huggingface.co/huggingface">Code1</a> · <a href="https://huggingface.co/docs/hub/spaces">Code2</a></div>
<details class="detail"><summary>Abstract</summary>
<div class="mono">Ambivalence and hesitancy (A/H), a closely related construct, is the primary reasons why individuals delay, avoid, or abandon health behaviour changes. It is a subtle and conflicting emotion that sets a person in a state between positive and negative orientations, or between acceptance and refusal to do something. It manifests by a discord in affect between multiple modalities or within a modality, such as facial and vocal expressions, and body language. Although experts can be trained to recognize A/H as done for in-person interactions, integrating them into digital health interventions is costly and less effective. Automatic A/H recognition is therefore critical for the personalization and cost-effectiveness of digital behaviour change interventions. However, no datasets currently exists for the design of machine learning models to recognize A/H. This paper introduces the Behavioural Ambivalence/Hesitancy (BAH) dataset collected for multimodal recognition of A/H in videos. It contains 1,427 videos with a total duration of 10.60 hours captured from 300 participants across Canada answering predefined questions to elicit A/H. It is intended to mirror real-world online personalized behaviour change interventions. BAH is annotated by three experts to provide timestamps that indicate where A/H occurs, and frame- and video-level annotations with A/H cues. Video transcripts, cropped and aligned faces, and participants&#x27; meta-data are also provided. Since A and H manifest similarly in practice, we provide a binary annotation indicating the presence or absence of A/H. Additionally, this paper includes benchmarking results using baseline models on BAH for frame- and video-level recognition, zero-shot prediction, and personalization using source-free domain adaptation. The data, code, and pretrained weights are available.</div></details>
<details class="detail"><summary>中文标题/摘要</summary>
<div class="mono"><b>标题：</b>用于视频中矛盾/犹豫识别的BAH数据集——面向数字化行为改变</div>
<div class="mono" style="margin-top:8px">矛盾与犹豫（A/H）作为密切相关的心理结构，是导致个体延迟、回避或放弃健康行为改变的主要原因。这是一种微妙而矛盾的情绪，使人处于积极与消极取向之间，或在接受与拒绝某行为之间摇摆。其通过多模态（如面部表情、声音表达和肢体语言）之间或单一模态内部的情感不协调得以显现。虽然专家可通过培训识别面对面互动中的A/H，但将其整合到数字健康干预中成本高昂且效果有限。因此，自动识别A/H对于数字化行为改变干预的个性化和成本效益至关重要。然而，目前尚缺乏用于训练A/H识别机器学习模型的数据集。本文介绍了为视频中多模态A/H识别而收集的行为矛盾/犹豫（BAH）数据集。该数据集包含1,427个视频，总时长10.60小时，采集自加拿大300名参与者回答预设问题以诱发A/H的过程，旨在模拟现实中的在线个性化行为改变干预。BAH由三位专家标注，提供指示A/H出现时间点的时间戳、帧级与视频级A/H线索标注，同时提供视频转录文本、裁剪对齐的面部图像及参与者元数据。鉴于实践中A与H表现相似，我们采用二元标注标识A/H是否存在。此外，本文还包含基于BAH的基准模型实验结果，涵盖帧级/视频级识别、零样本预测及基于无源域自适应的个性化研究。数据、代码与预训练权重均已公开。</div>
</details>
<details class="detail"><summary>Summary / 总结</summary>
<div class="mono">The research is motivated by the need to automatically recognize ambivalence and hesitancy (A/H) in digital health interventions, as these states are key reasons individuals delay behavior change but are costly for experts to detect manually. The method involves introducing the Behavioural Ambivalence/Hesitancy (BAH) dataset, which contains 1,427 videos from 300 participants in Canada, annotated by experts for A/H cues at frame and video levels, along with transcripts and facial data. Key experimental findings include benchmarking results using baseline models for frame- and video-level recognition, zero-shot prediction, and personalization via source-free domain adaptation, demonstrating the dataset&#x27;s utility for training machine learning models.</div>
<div class="mono" style="margin-top:8px">矛盾与犹豫是阻碍健康行为改变的主要因素，但其微妙且多模态的特性使得在缺乏合适数据集的情况下，为数字干预进行自动识别具有挑战性。为此，研究者提出了行为矛盾/犹豫（BAH）数据集，包含来自300名参与者的1,427个视频，并配有专家标注的时间戳和线索，同时使用基线模型在帧级和视频级识别、零样本预测以及基于源自由域适应的个性化方法上进行了基准测试。实验结果表明，该数据集能有效训练模型检测矛盾与犹豫，有助于开发个性化的数字行为改变工具。</div>
</details>
</div>
<div class="card">
<div class="title">Domain-Incremental Continual Learning for Robust and Efficient Keyword Spotting in Resource Constrained Systems</div>
<div class="meta-line">Authors: Prakash Dhungana, Sayed Ahmad Salehi</div>
<div class="meta-line">First: 2026-01-22T17:59:31+00:00 · Latest: 2026-01-22T17:59:31+00:00</div>
<div class="meta-line">Comments: 12 pages, 8 figures, and 3 tables</div>
<div class="links" style="margin-top:8px"><a href="https://arxiv.org/abs/2601.16158v1">Abs</a> · <a href="https://arxiv.org/pdf/2601.16158v1">PDF</a> · <a href="https://huggingface.co/huggingface">Code1</a> · <a href="https://huggingface.co/docs/hub/spaces">Code2</a></div>
<details class="detail"><summary>Abstract</summary>
<div class="mono">Keyword Spotting (KWS) systems with small footprint models deployed on edge devices face significant accuracy and robustness challenges due to domain shifts caused by varying noise and recording conditions. To address this, we propose a comprehensive framework for continual learning designed to adapt to new domains while maintaining computational efficiency. The proposed pipeline integrates a dual-input Convolutional Neural Network, utilizing both Mel Frequency Cepstral Coefficients (MFCC) and Mel-spectrogram features, supported by a multi-stage denoising process, involving discrete wavelet transform and spectral subtraction techniques, plus model and prototype update blocks. Unlike prior methods that restrict updates to specific layers, our approach updates the complete quantized model, made possible due to compact model architecture. A subset of input samples are selected during runtime using class prototypes and confidence-driven filtering, which are then pseudo-labeled and combined with rehearsal buffer for incremental model retraining. Experimental results on noisy test dataset demonstrate the framework&#x27;s effectiveness, achieving 99.63\% accuracy on clean data and maintaining robust performance (exceeding 94\% accuracy) across diverse noisy environments, even at -10 dB Signal-to-Noise Ratio. The proposed framework work confirms that integrating efficient denoising with prototype-based continual learning enables KWS models to operate autonomously and robustly in resource-constrained, dynamic environments.</div></details>
<details class="detail"><summary>中文标题/摘要</summary>
<div class="mono"><b>标题：</b>面向资源受限系统的领域增量持续学习：实现鲁棒高效的关键词检测</div>
<div class="mono" style="margin-top:8px">部署在边缘设备上的轻量级关键词检测系统因噪声和录音条件变化导致的领域偏移，面临准确性与鲁棒性的严峻挑战。为此，我们提出一种兼顾计算效率的持续学习综合框架，使系统能适应新领域。该框架集成双输入卷积神经网络，同时利用梅尔频率倒谱系数和梅尔频谱特征，并配备多级去噪流程（含离散小波变换与谱减法技术）及模型与原型更新模块。与以往仅更新特定层的方法不同，本方法凭借紧凑的模型架构实现了完整量化模型的更新。运行时通过类别原型和置信度驱动筛选部分输入样本，经伪标注后与回放缓冲区数据共同用于增量模型重训练。在噪声测试集上的实验表明：该框架在纯净数据上达到99.63%准确率，且在信噪比低至-10 dB的多样噪声环境中仍保持超过94%的鲁棒性能。研究证实，将高效去噪与基于原型的持续学习相结合，可使关键词检测模型在资源受限的动态环境中实现自主鲁棒运行。</div>
</details>
<details class="detail"><summary>Summary / 总结</summary>
<div class="mono">The research addresses the challenge of maintaining accuracy and robustness in Keyword Spotting (KWS) systems on edge devices when faced with domain shifts from varying noise and recording conditions. The proposed method is a continual learning framework that integrates a dual-input CNN using MFCC and Mel-spectrogram features, a multi-stage denoising process with wavelet transform and spectral subtraction, and prototype-based sample selection for pseudo-labeling and incremental retraining of a fully updated, quantized model. Experiments on noisy datasets show the framework achieves 99.63% accuracy on clean data and maintains over 94% accuracy across diverse noisy environments, even at a -10 dB Signal-to-Noise Ratio, demonstrating robust adaptation in resource-constrained settings.</div>
<div class="mono" style="margin-top:8px">边缘设备上的关键词检测系统因噪声和录音条件变化导致的域偏移而面临准确性下降问题。为此，研究者提出一个持续学习框架，该框架集成了使用MFCC和梅尔谱图特征的双输入卷积神经网络、结合小波变换和谱减法的多级去噪过程，以及基于原型样本选择进行伪标记和增量重训练的机制。在噪声数据集上的实验表明，该框架在干净数据上达到99.63%的准确率，并在多样噪声环境中（即使在-10 dB信噪比下）保持超过94%的准确率，证明了其在资源受限场景下的鲁棒适应性。</div>
</details>
</div>
<div class="card">
<div class="title">MCGrad: Multicalibration at Web Scale</div>
<div class="meta-line">Authors: Niek Tax, Lorenzo Perini, Fridolin Linder, Daniel Haimovich, Dima Karamshuk, Nastaran Okati, Milan Vojnovic, Pavlos Athanasios Apostolopoulos</div>
<div class="meta-line">Venue: KDD 2026</div>
<div class="meta-line">First: 2025-09-24T08:34:38+00:00 · Latest: 2026-01-22T17:41:06+00:00</div>
<div class="meta-line">Comments: Accepted at KDD 2026</div>
<div class="links" style="margin-top:8px"><a href="https://arxiv.org/abs/2509.19884v3">Abs</a> · <a href="https://arxiv.org/pdf/2509.19884v3">PDF</a> · <a href="https://github.com/facebookincubator/MCGrad">Code1</a> · <a href="https://huggingface.co/huggingface">Code2</a> · <a href="https://huggingface.co/docs/hub/spaces">Code3</a></div>
<details class="detail"><summary>Abstract</summary>
<div class="mono">We propose MCGrad, a novel and scalable multicalibration algorithm. Multicalibration - calibration in subgroups of the data - is an important property for the performance of machine learning-based systems. Existing multicalibration methods have thus far received limited traction in industry. We argue that this is because existing methods (1) require such subgroups to be manually specified, which ML practitioners often struggle with, (2) are not scalable, or (3) may harm other notions of model performance such as log loss and Area Under the Precision-Recall Curve (PRAUC). MCGrad does not require explicit specification of protected groups, is scalable, and often improves other ML evaluation metrics instead of harming them. MCGrad has been in production at Meta, and is now part of hundreds of production models. We present results from these deployments as well as results on public datasets. We provide an open source implementation of MCGrad at https://github.com/facebookincubator/MCGrad.</div></details>
<details class="detail"><summary>中文标题/摘要</summary>
<div class="mono"><b>标题：</b>MCGrad：网络规模的多重校准技术</div>
<div class="mono" style="margin-top:8px">我们提出MCGrad，一种新颖且可扩展的多重校准算法。多重校准——在数据子组中进行校准——是基于机器学习的系统性能的重要属性。现有的多重校准方法迄今在工业界应用有限。我们认为这是因为现有方法（1）需要手动指定此类子组，而机器学习从业者往往难以做到；（2）不可扩展；或（3）可能损害模型性能的其他指标，如对数损失和精确率-召回率曲线下面积（PRAUC）。MCGrad无需明确指定受保护组，具有可扩展性，并且通常能改进其他机器学习评估指标而非损害它们。MCGrad已在Meta投入生产，现已成为数百个生产模型的一部分。我们展示了这些部署结果以及在公共数据集上的实验结果。我们在https://github.com/facebookincubator/MCGrad提供了MCGrad的开源实现。</div>
</details>
<details class="detail"><summary>Summary / 总结</summary>
<div class="mono">The research is motivated by the limited industrial adoption of existing multicalibration methods, which often require manual subgroup specification, lack scalability, or degrade other model performance metrics. The proposed method, MCGrad, is a novel and scalable multicalibration algorithm that automatically identifies subgroups without explicit specification, operates efficiently at web scale, and is designed to maintain or improve metrics like log loss and PRAUC. Experimental results from deployments at Meta across hundreds of production models and on public datasets demonstrate that MCGrad effectively achieves multicalibration while often enhancing other evaluation metrics.</div>
<div class="mono" style="margin-top:8px">本研究针对现有多标定方法在工业界应用有限的问题，这些方法需手动指定数据子组、缺乏可扩展性，或会损害其他性能指标。提出的MCGrad方法通过自动识别子组而无需显式指定，可扩展至网络规模数据，并常能提升如对数损失和精确率-召回率曲线下面积等指标。在Meta数百个生产模型和公开数据集上的部署实验表明，MCGrad能有效实现多标定，同时保持或提升模型整体性能。</div>
</details>
</div>
<div class="card">
<div class="title">Beat-ssl: Capturing Local ECG Morphology through Heartbeat-level Contrastive Learning with Soft Targets</div>
<div class="meta-line">Authors: Muhammad Ilham Rizqyawan, Peter Macfarlane, Stathis Hadjidemetriou, Fani Deligianni</div>
<div class="meta-line">Venue: ISBI 2026</div>
<div class="meta-line">First: 2026-01-22T17:40:23+00:00 · Latest: 2026-01-22T17:40:23+00:00</div>
<div class="meta-line">Comments: Accepted at ISBI 2026</div>
<div class="links" style="margin-top:8px"><a href="https://arxiv.org/abs/2601.16147v1">Abs</a> · <a href="https://arxiv.org/pdf/2601.16147v1">PDF</a> · <a href="https://huggingface.co/huggingface">Code1</a> · <a href="https://huggingface.co/docs/hub/spaces">Code2</a></div>
<details class="detail"><summary>Abstract</summary>
<div class="mono">Obtaining labelled ECG data for developing supervised models is challenging. Contrastive learning (CL) has emerged as a promising pretraining approach that enables effective transfer learning with limited labelled data. However, existing CL frameworks either focus solely on global context or fail to exploit ECG-specific characteristics. Furthermore, these methods rely on hard contrastive targets, which may not adequately capture the continuous nature of feature similarity in ECG signals. In this paper, we propose Beat-SSL, a contrastive learning framework that performs dual-context learning through both rhythm-level and heartbeat-level contrasting with soft targets. We evaluated our pretrained model on two downstream tasks: 1) multilabel classification for global rhythm assessment, and 2) ECG segmentation to assess its capacity to learn representations across both contexts. We conducted an ablation study and compared the best configuration with three other methods, including one ECG foundation model. Despite the foundation model&#x27;s broader pretraining, Beat-SSL reached 93% of its performance in multilabel classification task and surpassed all other methods in the segmentation task by 4%.</div></details>
<details class="detail"><summary>中文标题/摘要</summary>
<div class="mono"><b>标题：</b>Beat-SSL：通过基于软目标的心跳级对比学习捕捉局部心电图形态</div>
<div class="mono" style="margin-top:8px">获取标注心电图数据以开发监督模型具有挑战性。对比学习作为一种有前景的预训练方法，能够在有限标注数据下实现有效的迁移学习。然而，现有对比学习框架要么仅关注全局上下文，要么未能充分利用心电图特异性特征。此外，这些方法依赖硬对比目标，可能无法充分捕捉心电图信号中特征相似性的连续特性。本文提出Beat-SSL对比学习框架，通过节律级和心跳级的软目标双上下文对比进行学习。我们在两个下游任务评估预训练模型：1）全局节律评估的多标签分类，2）心电图分割以评估其跨上下文表征学习能力。通过消融实验，将最优配置与包括一个心电图基础模型在内的三种方法比较。尽管基础模型预训练范围更广，Beat-SSL在多标签分类任务中达到其93%的性能，并在分割任务中以4%优势超越所有其他方法。</div>
</details>
<details class="detail"><summary>Summary / 总结</summary>
<div class="mono">The difficulty of obtaining labeled ECG data motivates the development of self-supervised learning methods. This paper introduces Beat-SSL, a contrastive learning framework that captures both global rhythm and local heartbeat contexts using soft targets to better model the continuous similarity of ECG features. Experimental evaluation on multilabel classification and segmentation tasks shows that the pretrained model achieves 93% of the performance of a larger ECG foundation model in classification and surpasses other compared methods by 4% in segmentation.</div>
<div class="mono" style="margin-top:8px">获取带标签的心电图数据存在困难，这促使了自监督学习方法的发展。本文提出了Beat-SSL，这是一个通过双上下文学习（包括节律级和心跳级对比）并采用软目标来更好建模心电图特征连续相似性的对比学习框架。在多标签分类和分割任务上的实验结果表明，预训练模型在分类任务上达到了一个更大的心电图基础模型性能的93%，并在分割任务上以4%的优势超越了其他方法。</div>
</details>
</div>
<div class="card">
<div class="title">Computing Fixpoints of Learned Functions: Chaotic Iteration and Simple Stochastic Games</div>
<div class="meta-line">Authors: Paolo Baldan, Sebastian Gurke, Barbara König, Florian Wittbold</div>
<div class="meta-line">First: 2026-01-22T17:36:19+00:00 · Latest: 2026-01-22T17:36:19+00:00</div>
<div class="links" style="margin-top:8px"><a href="https://arxiv.org/abs/2601.16142v1">Abs</a> · <a href="https://arxiv.org/pdf/2601.16142v1">PDF</a> · <a href="https://huggingface.co/huggingface">Code1</a> · <a href="https://huggingface.co/docs/hub/spaces">Code2</a></div>
<details class="detail"><summary>Abstract</summary>
<div class="mono">The problem of determining the (least) fixpoint of (higher-dimensional) functions over the non-negative reals frequently occurs when dealing with systems endowed with a quantitative semantics. We focus on the situation in which the functions of interest are not known precisely but can only be approximated. As a first contribution we generalize an iteration scheme called dampened Mann iteration, recently introduced in the literature. The improved scheme relaxes previous constraints on parameter sequences, allowing learning rates to converge to zero or not converge at all. While seemingly minor, this flexibility is essential to enable the implementation of chaotic iterations, where only a subset of components is updated in each step, allowing to tackle higher-dimensional problems. Additionally, by allowing learning rates to converge to zero, we can relax conditions on the convergence speed of function approximations, making the method more adaptable to various scenarios. We also show that dampened Mann iteration applies immediately to compute the expected payoff in various probabilistic models, including simple stochastic games, not covered by previous work.</div></details>
<details class="detail"><summary>中文标题/摘要</summary>
<div class="mono"><b>标题：</b>学习函数的不动点计算：混沌迭代与简单随机博弈</div>
<div class="mono" style="margin-top:8px">在处理具有定量语义的系统时，确定非负实数上（高维）函数的（最小）不动点问题频繁出现。本文聚焦于目标函数无法精确获知、仅能近似逼近的情形。作为第一项贡献，我们推广了近期文献中提出的阻尼曼恩迭代方案。改进后的方案放宽了对参数序列的既有约束，允许学习率收敛至零或完全不收敛。这一看似微小的灵活性对于实现混沌迭代至关重要——在混沌迭代中，每一步仅更新部分分量，从而能够处理更高维度的问题。此外，通过允许学习率收敛至零，我们可以放宽对函数逼近收敛速度的条件要求，使该方法更适应多样化场景。我们还证明，阻尼曼恩迭代可直接应用于计算各类概率模型（包括先前工作未涵盖的简单随机博弈）中的期望收益。</div>
</details>
<details class="detail"><summary>Summary / 总结</summary>
<div class="mono">The research addresses the challenge of computing fixpoints of functions over non-negative reals in quantitative systems when the exact functions are unknown and only approximations are available. The method generalizes dampened Mann iteration by relaxing constraints on parameter sequences, enabling learning rates to converge to zero or not converge, which facilitates chaotic iterations where only a subset of components is updated per step, thereby handling higher-dimensional problems. Key experimental findings demonstrate that this approach not only broadens applicability by relaxing convergence speed conditions for function approximations but also directly computes expected payoffs in probabilistic models, including simple stochastic games, which were previously unsupported.</div>
<div class="mono" style="margin-top:8px">本研究针对在定量系统中，当精确函数未知且仅能获得近似时，计算非负实数上函数不动点的挑战。方法通过放宽参数序列的约束，推广了阻尼曼迭代，允许学习率收敛至零或不收敛，从而支持混沌迭代，即每步仅更新部分组件，以处理高维问题。关键实验结果表明，该方法通过放宽函数近似的收敛速度条件，不仅扩展了适用性，还能直接计算概率模型（包括简单随机博弈）中的期望收益，填补了先前工作的空白。</div>
</details>
</div>
<div class="card">
<div class="title">On the Intrinsic Dimensions of Data in Kernel Learning</div>
<div class="meta-line">Authors: Rustem Takhanov</div>
<div class="meta-line">First: 2026-01-22T17:32:24+00:00 · Latest: 2026-01-22T17:32:24+00:00</div>
<div class="meta-line">Comments: Accepted to The 29th International Conference on Artificial Intelligence and Statistics (AISTATS 2026)</div>
<div class="links" style="margin-top:8px"><a href="https://arxiv.org/abs/2601.16139v1">Abs</a> · <a href="https://arxiv.org/pdf/2601.16139v1">PDF</a> · <a href="https://huggingface.co/huggingface">Code1</a> · <a href="https://huggingface.co/docs/hub/spaces">Code2</a></div>
<details class="detail"><summary>Abstract</summary>
<div class="mono">The manifold hypothesis suggests that the generalization performance of machine learning methods improves significantly when the intrinsic dimension of the input distribution&#x27;s support is low. In the context of KRR, we investigate two alternative notions of intrinsic dimension. The first, denoted $d_ρ$, is the upper Minkowski dimension defined with respect to the canonical metric induced by a kernel function $K$ on a domain $Ω$. The second, denoted $d_K$, is the effective dimension, derived from the decay rate of Kolmogorov $n$-widths associated with $K$ on $Ω$. Given a probability measure $μ$ on $Ω$, we analyze the relationship between these $n$-widths and eigenvalues of the integral operator $φ\to \int_ΩK(\cdot,x)φ(x)dμ(x)$. We show that, for a fixed domain $Ω$, the Kolmogorov $n$-widths characterize the worst-case eigenvalue decay across all probability measures $μ$ supported on $Ω$. These eigenvalues are central to understanding the generalization behavior of constrained KRR, enabling us to derive an excess error bound of order $O(n^{-\frac{2+d_K}{2+2d_K} + ε})$ for any $ε&gt; 0$, when the training set size $n$ is large. We also propose an algorithm that estimates upper bounds on the $n$-widths using only a finite sample from $μ$. For distributions close to uniform, we prove that $ε$-accurate upper bounds on all $n$-widths can be computed with high probability using at most $O\left(ε^{-d_ρ}\log\frac{1}ε\right)$ samples, with fewer required for small $n$. Finally, we compute the effective dimension $d_K$ for various fractal sets and present additional numerical experiments. Our results show that, for kernels such as the Laplace kernel, the effective dimension $d_K$ can be significantly smaller than the Minkowski dimension $d_ρ$, even though $d_K = d_ρ$ provably holds on regular domains.</div></details>
<details class="detail"><summary>中文标题/摘要</summary>
<div class="mono"><b>标题：</b>核学习中数据本征维度的研究</div>
<div class="mono" style="margin-top:8px">流形假说认为，当输入分布支撑集的本征维度较低时，机器学习方法的泛化性能会显著提升。在核岭回归（KRR）框架下，我们研究了两种本征维度的定义。第一种记为$d_ρ$，是基于核函数$K$在定义域$Ω$上诱导的典型度量的上闵可夫斯基维度。第二种记为$d_K$，是有效维度，源自$K$在$Ω$上关联的柯尔莫哥洛夫$n$宽度的衰减率。给定$Ω$上的概率测度$μ$，我们分析了这些$n$宽度与积分算子$φ\to \int_ΩK(\cdot,x)φ(x)dμ(x)$特征值之间的关系。我们证明，对于固定定义域$Ω$，柯尔莫哥洛夫$n$宽度刻画了所有支撑在$Ω$上的概率测度$μ$对应的最坏情况特征值衰减。这些特征值是理解约束KRR泛化行为的关键，使我们能够推导出当训练集规模$n$较大时，超额误差界为$O(n^{-\frac{2+d_K}{2+2d_K} + ε})$（对任意$ε&gt;0$）。我们还提出一种仅使用$μ$的有限样本估计$n$宽度上界的算法。对于接近均匀的分布，我们证明以高概率计算所有$n$宽度的$ε$精度上界最多需要$O\left(ε^{-d_ρ}\log\frac{1}ε\right)$个样本，且小$n$时所需样本更少。最后，我们计算了多种分形集的有效维度$d_K$并展示了数值实验。结果表明，对于拉普拉斯核等核函数，即使在正则定义域上可证明$d_K = d_ρ$成立，有效维度$d_K$仍可能显著小于闵可夫斯基维度$d_ρ$。</div>
</details>
<details class="detail"><summary>Summary / 总结</summary>
<div class="mono">Motivated by the manifold hypothesis that low intrinsic dimensionality improves generalization, this paper investigates two notions of intrinsic dimension for kernel ridge regression (KRR): the Minkowski dimension $d_\rho$ based on the kernel-induced metric and the effective dimension $d_K$ derived from Kolmogorov $n$-widths. The method analyzes the relationship between these $n$-widths and eigenvalues of the kernel integral operator, showing that the $n$-widths characterize the worst-case eigenvalue decay across probability measures on a fixed domain. This analysis yields an excess error bound of order $O(n^{-\frac{2+d_K}{2+2d_K} + \epsilon})$ for large sample size $n$, and the authors propose an algorithm to estimate $n$-width bounds from finite samples, proving that $O(\epsilon^{-d_\rho}\log\frac{1}{\epsilon})$ samples suffice for distributions near uniform. Experimental results on fractal sets demonstrate that the effective dimension $d_K$ can be much smaller than $d_\rho$ for kernels like the Laplace kernel, despite their equality on regular domains.</div>
<div class="mono" style="margin-top:8px">受流形假设（即低本征维度能提升泛化性能）的驱动，本文研究了核岭回归中两种本征维度的概念：基于核诱导度量的闵可夫斯基维度 d_ρ 和基于柯尔莫哥洛夫 n-宽度的有效维度 d_K。方法通过分析这些 n-宽度与核积分算子特征值的关系，证明了 n-宽度刻画了定义域上所有概率测度的最坏情况特征值衰减。主要实验结果包括：对于大规模训练集 n，推导出阶为 O(n^{-(2+d_K)/(2+2d_K) + ε}) 的过量误差界；提出一种从有限样本估计 n-宽度的算法，对于接近均匀的分布，仅需 O(ε^{-d_ρ} log(1/ε)) 样本即可高概率计算 ε-精度的上界；并通过分形集上的计算与数值实验表明，对于拉普拉斯核等核函数，有效维度 d_K 可显著小于闵可夫斯基维度 d_ρ，尽管在规则定义域上两者理论上相等。</div>
</details>
</div>
<div class="card">
<div class="title">Automatic Classification of Arabic Literature into Historical Eras</div>
<div class="meta-line">Authors: Zainab Alhathloul, Irfan Ahmad</div>
<div class="meta-line">First: 2026-01-22T17:32:19+00:00 · Latest: 2026-01-22T17:32:19+00:00</div>
<div class="meta-line">Comments: 27 pages</div>
<div class="links" style="margin-top:8px"><a href="https://arxiv.org/abs/2601.16138v1">Abs</a> · <a href="https://arxiv.org/pdf/2601.16138v1">PDF</a> · <a href="https://huggingface.co/huggingface">Code1</a> · <a href="https://huggingface.co/docs/hub/spaces">Code2</a></div>
<details class="detail"><summary>Abstract</summary>
<div class="mono">The Arabic language has undergone notable transformations over time, including the emergence of new vocabulary, the obsolescence of others, and shifts in word usage. This evolution is evident in the distinction between the classical and modern Arabic eras. Although historians and linguists have partitioned Arabic literature into multiple eras, relatively little research has explored the automatic classification of Arabic texts by time period, particularly beyond the domain of poetry. This paper addresses this gap by employing neural networks and deep learning techniques to automatically classify Arabic texts into distinct eras and periods. The proposed models are evaluated using two datasets derived from two publicly available corpora, covering texts from the pre-Islamic to the modern era. The study examines class setups ranging from binary to 15-class classification and considers both predefined historical eras and custom periodizations. Results range from F1-scores of 0.83 and 0.79 on the binary-era classification task using the OpenITI and APCD datasets, respectively, to 0.20 on the 15-era classification task using OpenITI and 0.18 on the 12-era classification task using APCD.</div></details>
<details class="detail"><summary>中文标题/摘要</summary>
<div class="mono"><b>标题：</b>阿拉伯文学历史时期的自动分类研究</div>
<div class="mono" style="margin-top:8px">阿拉伯语历经显著演变，包括新词汇产生、旧词淘汰及用词习惯变迁，古典与现代阿拉伯语时期的差异尤为明显。尽管文史学者已将阿拉伯文学划分为多个时期，但针对非诗歌领域阿拉伯文本的自动分期研究尚不充分。本文通过神经网络与深度学习技术，构建阿拉伯文本自动分期模型，填补此研究空白。模型基于OpenITI和APCD两个公开语料库构建的数据集进行评估，涵盖前伊斯兰时期至现代文本。研究设计了从二分类到15分类的体系，同时考察预设历史分期与自定义分期方案。实验结果显示：在二分类任务中，OpenITI与APCD数据集分别获得0.83和0.79的F1值；在15分类任务中（OpenITI）获得0.20的F1值；在12分类任务中（APCD）获得0.18的F1值。</div>
</details>
<details class="detail"><summary>Summary / 总结</summary>
<div class="mono">This research addresses the lack of automated methods for classifying Arabic texts by historical era, particularly for prose beyond poetry, by leveraging neural networks and deep learning. The method involves training models on two publicly available corpora, OpenITI and APCD, to perform classification tasks ranging from binary to 15-class setups, based on both predefined and custom historical periodizations. Key experimental results show F1-scores of 0.83 and 0.79 for binary-era classification on the respective datasets, but performance declines significantly to 0.20 and 0.18 for more granular 15-era and 12-era classifications.</div>
<div class="mono" style="margin-top:8px">本研究针对阿拉伯语的语言演变以及除诗歌外阿拉伯文本自动时代分类研究的不足，采用神经网络和深度学习技术对阿拉伯文献进行历史时期分类。方法基于OpenITI和APCD两个公开语料库，涵盖从伊斯兰前时期到现代文本，通过从二分类到15分类的不同类别设置，评估基于预定义或自定义历史分期的模型。主要实验结果显示，在二分类时代任务上，两个数据集的F1分数分别达到0.83和0.79，但在更细粒度的15时期和12时期分类任务中，性能下降至0.20和0.18。</div>
</details>
</div>
<div class="card">
<div class="title">ViSymRe: Vision-guided Multimodal Symbolic Regression</div>
<div class="meta-line">Authors: Da Li, Junping Yin, Jin Xu, Xinxin Li, Juan Zhang</div>
<div class="meta-line">First: 2024-12-15T10:05:31+00:00 · Latest: 2026-01-22T17:29:53+00:00</div>
<div class="links" style="margin-top:8px"><a href="https://arxiv.org/abs/2412.11139v3">Abs</a> · <a href="https://arxiv.org/pdf/2412.11139v3">PDF</a> · <a href="https://huggingface.co/huggingface">Code1</a> · <a href="https://huggingface.co/docs/hub/spaces">Code2</a></div>
<details class="detail"><summary>Abstract</summary>
<div class="mono">Extracting simple mathematical expression from an observational dataset to describe complex natural phenomena is one of the core objectives of artificial intelligence (AI). This field is known as symbolic regression (SR). Traditional SR models are based on genetic programming (GP) or reinforcement learning (RL), facing well-known challenges, such as low efficiency and overfitting. Recent studies have integrated SR with large language models (LLMs), enabling fast zero-shot inference by learning mappings from millions of dataset-expression pairs. However, since the input and output are inherently different modalities, such models often struggle to converge effectively. In this paper, we introduce ViSymRe, a vision-guided multimodal SR model that incorporates the third resource, expression graph, to bridge the modality gap. Different from traditional multimodal models, ViSymRe is trained to extract vision, termed virtual vision, from datasets, without relying on the global availability of expression graphs, which addresses the essential challenge of visual SR, i.e., expression graphs are not available during inference. Evaluation results on multiple mainstream benchmarks show that ViSymRe achieves more competitive performance than the state-of-the-art dataset-only baselines. The expressions predicted by ViSymRe not only fit the dataset well but are also simple and structurally accurate, goals that SR models strive to achieve.</div></details>
<details class="detail"><summary>中文标题/摘要</summary>
<div class="mono"><b>标题：</b>ViSymRe：视觉引导的多模态符号回归</div>
<div class="mono" style="margin-top:8px">从观测数据集中提取简单数学表达式以描述复杂自然现象是人工智能（AI）的核心目标之一，该领域称为符号回归（SR）。传统SR模型基于遗传编程（GP）或强化学习（RL），面临效率低、过拟合等挑战。近期研究将SR与大型语言模型（LLMs）结合，通过从数百万数据集-表达式对中学习映射实现快速零样本推理。然而，由于输入与输出本质属于不同模态，此类模型常难以有效收敛。本文提出ViSymRe，一种视觉引导的多模态SR模型，引入第三种资源——表达式图——以弥合模态鸿沟。与传统多模态模型不同，ViSymRe训练从数据集中提取视觉信息（称为虚拟视觉），无需依赖表达式图的全局可用性，从而解决了视觉SR的关键挑战：推理时表达式图不可得。在多个主流基准上的评估结果表明，ViSymRe比当前最先进的仅使用数据集的基线模型具有更强竞争力。其预测的表达式不仅与数据高度拟合，且结构简洁准确，实现了SR模型追求的目标。</div>
</details>
<details class="detail"><summary>Summary / 总结</summary>
<div class="mono">The research aims to improve symbolic regression (SR), which seeks to derive simple mathematical expressions from observational data, by addressing the modality gap between input datasets and output expressions that hinders convergence in large language model (LLM)-based approaches. The proposed method, ViSymRe, introduces a vision-guided multimodal model that incorporates expression graphs as a third resource during training to bridge this gap; notably, it learns to extract &quot;virtual vision&quot; from datasets without requiring expression graphs at inference time, overcoming the limitation that such graphs are unavailable during real-world use. Experimental evaluations on multiple benchmarks demonstrate that ViSymRe outperforms state-of-the-art dataset-only baselines, producing expressions that are both accurate in fitting the data and structurally simple.</div>
<div class="mono" style="margin-top:8px">该研究旨在改进从数据中提取数学表达式的符号回归（SR）方法，以解决遗传编程和强化学习方法效率低下，以及基于大语言模型（LLM）方法中存在的模态鸿沟问题。提出的ViSymRe模型采用了一种视觉引导的多模态方法，在训练中引入表达式图作为中间资源来弥合模态差距；该模型学习从数据集中提取“虚拟视觉”，而无需在推理时使用表达式图。在多个主流基准测试上的评估结果表明，ViSymRe的性能优于最先进的仅使用数据集的基线方法，其预测的表达式不仅与数据拟合良好，而且结构准确、形式简洁，达到了符号回归模型追求的目标。</div>
</details>
</div>
<div class="card">
<div class="title">Synthetic Augmentation in Imbalanced Learning: When It Helps, When It Hurts, and How Much to Add</div>
<div class="meta-line">Authors: Zhengchi Ma, Anru R. Zhang</div>
<div class="meta-line">First: 2026-01-22T17:15:26+00:00 · Latest: 2026-01-22T17:15:26+00:00</div>
<div class="links" style="margin-top:8px"><a href="https://arxiv.org/abs/2601.16120v1">Abs</a> · <a href="https://arxiv.org/pdf/2601.16120v1">PDF</a> · <a href="https://huggingface.co/huggingface">Code1</a> · <a href="https://huggingface.co/docs/hub/spaces">Code2</a></div>
<details class="detail"><summary>Abstract</summary>
<div class="mono">Imbalanced classification, where one class is observed far less frequently than the other, often causes standard training procedures to prioritize the majority class and perform poorly on rare but important cases. A classic and widely used remedy is to augment the minority class with synthetic examples, but two basic questions remain under-resolved: when does synthetic augmentation actually help, and how many synthetic samples should be generated?
  We develop a unified statistical framework for synthetic augmentation in imbalanced learning, studying models trained on imbalanced data augmented with synthetic minority samples and evaluated under the balanced population risk. Our theory shows that synthetic data is not always beneficial. In a ``local symmetry&quot; regime, imbalance is not the dominant source of error near the balanced optimum, so adding synthetic samples cannot improve learning rates and can even degrade performance by amplifying generator mismatch. When augmentation can help (a ``local asymmetry&quot; regime), the optimal synthetic size depends on generator accuracy and on whether the generator&#x27;s residual mismatch is directionally aligned with the intrinsic majority-minority shift. This structure can make the best synthetic size deviate from naive full balancing, sometimes by a small refinement and sometimes substantially when generator bias is systematic. Practically, we recommend Validation-Tuned Synthetic Size (VTSS): select the synthetic size by minimizing balanced validation loss over a range centered near the fully balanced baseline, while allowing meaningful departures when the data indicate them. Simulations and a real sepsis prediction study support the theory and illustrate when synthetic augmentation helps, when it cannot, and how to tune its quantity effectively.</div></details>
<details class="detail"><summary>中文标题/摘要</summary>
<div class="mono"><b>标题：</b>不平衡学习中的合成增强：何时有效、何时有害及添加量的控制</div>
<div class="mono" style="margin-top:8px">不平衡分类问题中，某一类别的观测频率远低于其他类别，常导致标准训练过程偏向多数类，在稀有但重要的案例上表现不佳。合成增强是经典且广泛应用的解决方案，通过生成合成样本来扩充少数类，但两个基本问题仍未完全解决：合成增强何时真正有效？应生成多少合成样本？
我们为不平衡学习中的合成增强建立了统一的统计框架，研究在添加合成少数类样本的不平衡数据上训练的模型，并以平衡总体风险进行评估。理论表明合成数据并非总是有益的。在“局部对称”机制下，不平衡并非平衡最优解附近误差的主要来源，因此添加合成样本无法提升学习速率，甚至可能因放大生成器失配而降低性能。当增强可能有效时（“局部不对称”机制），最优合成量取决于生成器精度，以及生成器的残余失配是否与内在的多数类-少数类偏移方向一致。这种结构可能导致最佳合成量偏离朴素完全平衡策略，有时仅需微调，而在生成器存在系统性偏差时则需大幅调整。实践中，我们推荐验证调优合成量（VTSS）：通过在完全平衡基线附近区间最小化平衡验证损失来选择合成量，同时允许数据指示下的显著偏离。仿真实验和真实脓毒症预测研究验证了该理论，并阐明了合成增强的有效场景、无效场景及其数量的优化方法。</div>
</details>
<details class="detail"><summary>Summary / 总结</summary>
<div class="mono">Imbalanced classification often leads to poor performance on minority classes, and synthetic augmentation is a common remedy, but its effectiveness and optimal scale are unclear. The authors develop a statistical framework to analyze models trained on imbalanced data augmented with synthetic minority samples, evaluated under balanced risk. Their theory identifies two regimes: in &#x27;local symmetry,&#x27; imbalance is not the main error source, so augmentation may not help and can even degrade performance due to generator mismatch; in &#x27;local asymmetry,&#x27; augmentation can help, with the optimal synthetic size depending on generator accuracy and alignment with the intrinsic class shift, sometimes deviating significantly from naive full balancing. They propose Validation-Tuned Synthetic Size (VTSS) to select the synthetic size by minimizing balanced validation loss, supported by simulations and a sepsis prediction study showing when augmentation helps or hurts and how to tune it effectively.</div>
<div class="mono" style="margin-top:8px">本研究针对不平衡分类中标准训练常对稀有类别失效的问题，探讨了何时对少数类进行合成增强有益以及应生成多少合成样本。作者建立了一个统计框架，分析在添加合成少数类样本的不平衡数据上训练的模型，并以平衡总体风险进行评估。理论结果表明合成数据并非总是有益：在“局部对称”机制下，不平衡不是主要误差来源，因此增强无法提高学习率，且可能因生成器不匹配而降低性能；在“局部不对称”机制下，增强可能有效，此时最优合成数量取决于生成器准确性以及生成器偏差与内在类别偏移的方向对齐情况，有时会显著偏离简单的完全平衡方法。他们提出验证调整合成数量（VTSS）方法，通过最小化平衡验证损失来选择合成数量，模拟和脓毒症预测研究支持了该理论并验证了其实际指导意义。</div>
</details>
</div>
<div class="card">
<div class="title">Enhanced Climbing Image Nudged Elastic Band method with Hessian Eigenmode Alignment</div>
<div class="meta-line">Authors: Rohit Goswami, Miha Gunde, Hannes Jónsson</div>
<div class="meta-line">First: 2026-01-19T00:21:52+00:00 · Latest: 2026-01-22T17:11:23+00:00</div>
<div class="meta-line">Comments: 25 pages. 11 figures</div>
<div class="links" style="margin-top:8px"><a href="https://arxiv.org/abs/2601.12630v2">Abs</a> · <a href="https://arxiv.org/pdf/2601.12630v2">PDF</a> · <a href="https://huggingface.co/huggingface">Code1</a> · <a href="https://huggingface.co/docs/hub/spaces">Code2</a></div>
<details class="detail"><summary>Abstract</summary>
<div class="mono">Accurate determination of transition states is central to an understanding of reaction kinetics. Double-endpoint methods where both initial and final states are specified, such as the climbing image nudged elastic band (CI-NEB), identify the minimum energy path between the two and thereby the saddle point on the energy surface that is relevant for the given transition, thus providing an estimate of the transition state within the harmonic approximation of transition state theory. Such calculations can, however, incur high computational costs and may suffer stagnation on exceptionally flat or rough energy surfaces. Conversely, methods that only require specification of an initial set of atomic coordinates, such as the minimum mode following (MMF) method, offer efficiency but can converge on saddle points that are not relevant for transition of interest. Here, we present an adaptive hybrid algorithm that integrates the CI-NEB with the MMF method so as to get faster convergence to the relevant saddle point. The method is benchmarked for the Baker-Chan (BC) saddle point test set using the PET-MAD machine-learned potential as well as 59 transitions of a heptamer island on Pt(111) from the OptBench benchmark set. A Bayesian analysis of the performance shows a median reduction in energy and force calculations of 46% [95% CrI: -55%, -37%] relative to CI-NEB for the BC set, while a 28% reduction is found for the transitions of the heptamer island. These results establish this hybrid method as a highly effective tool for high-throughput automated chemical discovery of atomic rearrangements.</div></details>
<details class="detail"><summary>中文标题/摘要</summary>
<div class="mono"><b>标题：</b>基于Hessian本征模对齐的增强型爬坡图像微动弹性带方法</div>
<div class="mono" style="margin-top:8px">精确确定过渡态是理解反应动力学的关键。双端点方法（如爬坡图像微动弹性带法，CI-NEB）通过指定初始和最终状态，识别两者间的最小能量路径，从而找到能量面上与特定过渡相关的鞍点，在过渡态理论的谐波近似下提供过渡态的估计。然而，此类计算可能产生高昂的计算成本，并在异常平坦或粗糙的能量面上陷入停滞。相反，仅需指定初始原子坐标集的方法（如最小模跟踪法，MMF）虽效率较高，但可能收敛至与目标过渡无关的鞍点。本文提出一种自适应混合算法，将CI-NEB与MMF方法结合，以加速收敛至相关鞍点。该方法使用PET-MAD机器学习势能对Baker-Chan鞍点测试集进行基准测试，并基于OptBench基准集中的Pt(111)表面七聚体岛59个过渡案例进行验证。贝叶斯性能分析显示，对于BC测试集，该方法相比CI-NEB在能量和力计算量上中位数减少46%[95% CrI: -55%, -37%]；对七聚体岛过渡案例则减少28%。这些结果表明该混合方法可作为原子重排高通量自动化化学发现的高效工具。</div>
</details>
<details class="detail"><summary>Summary / 总结</summary>
<div class="mono">Accurate transition state identification is crucial for reaction kinetics but can be computationally expensive or converge to irrelevant saddle points. This work introduces an adaptive hybrid algorithm that integrates the climbing image nudged elastic band (CI-NEB) method with minimum mode following (MMF) to accelerate convergence to the relevant saddle point. Benchmarking on the Baker-Chan test set and 59 transitions of a heptamer island on Pt(111) shows median reductions in energy and force calculations of 46% and 28%, respectively, compared to CI-NEB alone, demonstrating its effectiveness for high-throughput automated discovery.</div>
<div class="mono" style="margin-top:8px">精确识别过渡态对反应动力学至关重要，但现有方法存在计算成本高或可能收敛至无关鞍点的问题。本研究提出了一种混合方法，将爬坡图像微动弹性带（CI-NEB）与最小模跟踪（MMF）方法相结合，通过Hessian本征模对齐自适应地整合两者优势，以更快收敛到相关鞍点。在Baker-Chan测试集和Pt(111)上59个七聚体岛跃迁的基准测试中，相较于标准CI-NEB，能量和力计算量中位数分别减少了46%和28%，证明了该方法在高通量自动化化学发现中的高效性。</div>
</details>
</div>
<div class="card">
<div class="title">GenPO: Generative Diffusion Models Meet On-Policy Reinforcement Learning</div>
<div class="meta-line">Authors: Shutong Ding, Ke Hu, Shan Zhong, Haoyang Luo, Weinan Zhang, Jingya Wang, Jun Wang, Ye Shi</div>
<div class="meta-line">First: 2025-05-24T15:57:07+00:00 · Latest: 2026-01-22T17:10:05+00:00</div>
<div class="meta-line">Comments: Accepted by NeurIPS2025</div>
<div class="links" style="margin-top:8px"><a href="https://arxiv.org/abs/2505.18763v4">Abs</a> · <a href="https://arxiv.org/pdf/2505.18763v4">PDF</a> · <a href="https://huggingface.co/huggingface">Code1</a> · <a href="https://huggingface.co/docs/hub/spaces">Code2</a></div>
<details class="detail"><summary>Abstract</summary>
<div class="mono">Recent advances in reinforcement learning (RL) have demonstrated the powerful exploration capabilities and multimodality of generative diffusion-based policies. While substantial progress has been made in offline RL and off-policy RL settings, integrating diffusion policies into on-policy frameworks like PPO remains underexplored. This gap is particularly significant given the widespread use of large-scale parallel GPU-accelerated simulators, such as IsaacLab, which are optimized for on-policy RL algorithms and enable rapid training of complex robotic tasks. A key challenge lies in computing state-action log-likelihoods under diffusion policies, which is straightforward for Gaussian policies but intractable for flow-based models due to irreversible forward-reverse processes and discretization errors (e.g., Euler-Maruyama approximations). To bridge this gap, we propose GenPO, a generative policy optimization framework that leverages exact diffusion inversion to construct invertible action mappings. GenPO introduces a novel doubled dummy action mechanism that enables invertibility via alternating updates, resolving log-likelihood computation barriers. Furthermore, we also use the action log-likelihood for unbiased entropy and KL divergence estimation, enabling KL-adaptive learning rates and entropy regularization in on-policy updates. Extensive experiments on eight IsaacLab benchmarks, including legged locomotion (Ant, Humanoid, Anymal-D, Unitree H1, Go2), dexterous manipulation (Shadow Hand), aerial control (Quadcopter), and robotic arm tasks (Franka), demonstrate GenPO&#x27;s superiority over existing RL baselines. Notably, GenPO is the first method to successfully integrate diffusion policies into on-policy RL, unlocking their potential for large-scale parallelized training and real-world robotic deployment.</div></details>
<details class="detail"><summary>中文标题/摘要</summary>
<div class="mono"><b>标题：</b>GenPO：生成扩散模型与在线策略强化学习的融合</div>
<div class="mono" style="margin-top:8px">强化学习（RL）的最新进展展示了基于生成扩散的策略在探索能力和多模态方面的强大潜力。尽管离线RL和离线策略RL已取得显著进展，但将扩散策略整合至PPO等在线策略框架的研究仍显不足。鉴于IsaacLab等大规模并行GPU加速模拟器（专为在线策略RL算法优化，可快速训练复杂机器人任务）的广泛应用，这一空白尤为突出。核心挑战在于计算扩散策略下的状态-动作对数似然：高斯策略可直接计算，而基于流的模型因不可逆的前向-反向过程及离散化误差（如欧拉-丸山近似）导致计算困难。为填补此空白，我们提出GenPO——一种利用精确扩散反演构建可逆动作映射的生成式策略优化框架。GenPO引入创新的双重虚拟动作机制，通过交替更新实现可逆性，突破了对数似然计算障碍。此外，我们利用动作对数似然进行无偏熵和KL散度估计，支持在线策略更新中的KL自适应学习率与熵正则化。在八项IsaacLab基准测试（包括足式运动、灵巧操作、空中控制和机械臂任务）上的大量实验表明，GenPO优于现有RL基线方法。值得注意的是，GenPO是首个成功将扩散策略整合至在线策略RL的方法，为其在大规模并行训练和现实机器人部署中的应用开辟了道路。</div>
</details>
<details class="detail"><summary>Summary / 总结</summary>
<div class="mono">The research addresses the underexplored integration of generative diffusion models into on-policy reinforcement learning frameworks like PPO, which is crucial for leveraging large-scale parallel GPU simulators optimized for on-policy algorithms. The proposed GenPO method overcomes the intractability of computing state-action log-likelihoods under diffusion policies by introducing exact diffusion inversion to construct invertible action mappings and a doubled dummy action mechanism for invertibility via alternating updates. Experimental results on eight IsaacLab benchmarks, including locomotion, manipulation, and control tasks, demonstrate GenPO&#x27;s superiority over existing RL baselines, marking the first successful integration of diffusion policies into on-policy RL for scalable robotic training.</div>
<div class="mono" style="margin-top:8px">本研究针对生成扩散模型在如PPO等在线策略强化学习框架中应用不足的问题，这对于利用专为在线策略训练优化的大规模并行模拟器至关重要。提出的GenPO方法采用生成策略优化框架，通过精确扩散反演构建可逆动作映射，并利用新颖的双重虚拟动作机制解决了扩散策略中状态-动作对数似然计算难的问题。在八个IsaacLab基准测试（包括运动、操控和控制任务）上的实验结果表明，GenPO优于现有强化学习基线，首次成功将扩散策略集成到在线策略强化学习中，实现了可扩展的机器人训练。</div>
</details>
</div>
<div class="card">
<div class="title">Variable Splitting Binary Tree Models Based on Bayesian Context Tree Models for Time Series Segmentation</div>
<div class="meta-line">Authors: Yuta Nakahara, Shota Saito, Kohei Horinouchi, Koshi Shimada, Naoki Ichijo, Manabu Kobayashi, Toshiyasu Matsushima</div>
<div class="meta-line">First: 2026-01-22T16:58:34+00:00 · Latest: 2026-01-22T16:58:34+00:00</div>
<div class="links" style="margin-top:8px"><a href="https://arxiv.org/abs/2601.16112v1">Abs</a> · <a href="https://arxiv.org/pdf/2601.16112v1">PDF</a> · <a href="https://huggingface.co/huggingface">Code1</a> · <a href="https://huggingface.co/docs/hub/spaces">Code2</a></div>
<details class="detail"><summary>Abstract</summary>
<div class="mono">We propose a variable splitting binary tree (VSBT) model based on Bayesian context tree (BCT) models for time series segmentation. Unlike previous applications of BCT models, the tree structure in our model represents interval partitioning on the time domain. Moreover, interval partitioning is represented by recursive logistic regression models. By adjusting logistic regression coefficients, our model can represent split positions at arbitrary locations within each interval. This enables more compact tree representations. For simultaneous estimation of both split positions and tree depth, we develop an effective inference algorithm that combines local variational approximation for logistic regression with the context tree weighting (CTW) algorithm. We present numerical examples on synthetic data demonstrating the effectiveness of our model and algorithm.</div></details>
<details class="detail"><summary>中文标题/摘要</summary>
<div class="mono"><b>标题：</b>基于贝叶斯上下文树模型的时间序列分割可变分裂二叉树模型</div>
<div class="mono" style="margin-top:8px">我们提出了一种基于贝叶斯上下文树（BCT）模型的可变分裂二叉树（VSBT）模型，用于时间序列分割。与先前BCT模型的应用不同，本模型中的树结构表示时间域上的区间划分。此外，区间划分通过递归逻辑回归模型表示。通过调整逻辑回归系数，我们的模型能够在每个区间内任意位置表示分裂点，从而实现更紧凑的树表示。为同时估计分裂位置和树深度，我们开发了一种有效的推断算法，将逻辑回归的局部变分近似与上下文树加权（CTW）算法相结合。通过合成数据的数值示例，我们展示了模型与算法的有效性。</div>
</details>
<details class="detail"><summary>Summary / 总结</summary>
<div class="mono">The research aims to improve time series segmentation by enabling more flexible and compact representations of interval partitions. The method introduces a variable splitting binary tree (VSBT) model that builds upon Bayesian context tree (BCT) models, where the tree structure encodes interval partitioning on the time domain, and recursive logistic regression models determine split positions at arbitrary locations within intervals. For inference, the approach combines local variational approximation for logistic regression with the context tree weighting algorithm to jointly estimate split positions and tree depth. Experimental results on synthetic data demonstrate the effectiveness of the proposed model and algorithm in achieving accurate segmentation.</div>
<div class="mono" style="margin-top:8px">本研究旨在通过实现更灵活紧凑的区间划分表示来改进时间序列分割。该方法提出了一种基于贝叶斯上下文树（BCT）模型的变量分割二叉树（VSBT）模型，其中树结构通过递归逻辑回归在时间域上表示区间划分，从而允许在任意位置进行分割。在推断方面，该算法将逻辑回归的局部变分近似与上下文树加权（CTW）方法相结合，以联合估计分割位置和树深度。在合成数据上的数值实验结果表明，该模型能够有效实现准确的分割。</div>
</details>
</div>
<div class="card">
<div class="title">Benchmarking Deep Learning Models for Raman Spectroscopy Across Open-Source Datasets</div>
<div class="meta-line">Authors: Adithya Sineesh, Akshita Kamsali</div>
<div class="meta-line">First: 2026-01-22T16:54:53+00:00 · Latest: 2026-01-22T16:54:53+00:00</div>
<div class="meta-line">Comments: 17 pages, 3 figures</div>
<div class="links" style="margin-top:8px"><a href="https://arxiv.org/abs/2601.16107v1">Abs</a> · <a href="https://arxiv.org/pdf/2601.16107v1">PDF</a> · <a href="https://huggingface.co/huggingface">Code1</a> · <a href="https://huggingface.co/docs/hub/spaces">Code2</a></div>
<details class="detail"><summary>Abstract</summary>
<div class="mono">Deep learning classifiers for Raman spectroscopy are increasingly reported to outperform classical chemometric approaches. However their evaluations are often conducted in isolation or compared against traditional machine learning methods or trivially adapted vision-based architectures that were not originally proposed for Raman spectroscopy. As a result, direct comparisons between existing deep learning models developed specifically for Raman spectral analysis on shared open-source datasets remain scarce. To the best of our knowledge, this study presents one of the first systematic benchmarks comparing three or more published Raman-specific deep learning classifiers across multiple open-source Raman datasets. We evaluate five representative deep learning architectures under a unified training and hyperparameter tuning protocol across three open-source Raman datasets selected to support standard evaluation, fine-tuning, and explicit distribution-shift testing. We report classification accuracies and macro-averaged F1 scores to provide a fair and reproducible comparison of deep learning models for Raman spectra based classification.</div></details>
<details class="detail"><summary>中文标题/摘要</summary>
<div class="mono"><b>标题：</b>基于开源数据集的拉曼光谱深度学习模型基准测试</div>
<div class="mono" style="margin-top:8px">拉曼光谱的深度学习分类器被越来越多地报道优于经典化学计量学方法。然而，其评估往往孤立进行，或仅与传统机器学习方法或未经专门适配的视觉架构进行比较，这些架构最初并非为拉曼光谱设计。因此，在共享开源数据集上，专门为拉曼光谱分析开发的现有深度学习模型之间的直接比较仍然匮乏。据我们所知，本研究首次系统性地在多个开源拉曼数据集上对三种及以上已发表的拉曼专用深度学习分类器进行了基准测试。我们在三个开源拉曼数据集上，采用统一的训练和超参数调优协议，评估了五种代表性深度学习架构，这些数据集支持标准评估、微调和显式分布偏移测试。我们报告了分类准确率和宏平均F1分数，为基于拉曼光谱分类的深度学习模型提供了公平且可复现的比较。</div>
</details>
<details class="detail"><summary>Summary / 总结</summary>
<div class="mono">The research is motivated by the lack of systematic, direct comparisons between deep learning models specifically designed for Raman spectroscopy, as existing evaluations are often isolated or compared against non-specialized methods. The method involves a unified benchmarking study that evaluates five representative Raman-specific deep learning architectures across three open-source datasets under a consistent training and hyperparameter tuning protocol, designed to support standard evaluation, fine-tuning, and distribution-shift testing. Key experimental findings include reported classification accuracies and macro-averaged F1 scores, providing a fair and reproducible assessment of these models&#x27; performance for Raman spectral classification.</div>
<div class="mono" style="margin-top:8px">本研究针对拉曼光谱领域缺乏专门设计的深度学习模型系统比较的问题，现有评估常孤立进行或与非专用方法对比。为填补这一空白，作者通过统一训练和超参数调优协议，在三个开源拉曼数据集上评估了五种代表性拉曼专用深度学习架构，这些数据集支持标准评估、微调和分布偏移测试。实验结果显示为分类准确率和宏观平均F1分数，提供了公平且可复现的比较，揭示了这些模型在拉曼光谱分类任务中的性能表现。</div>
</details>
</div>
<div class="card">
<div class="title">Clustering-Guided Spatial-Spectral Mamba for Hyperspectral Image Classification</div>
<div class="meta-line">Authors: Zack Dewis, Yimin Zhu, Zhengsen Xu, Mabel Heffring, Saeid Taleghanidoozdoozan, Quinn Ledingham, Lincoln Linlin Xu</div>
<div class="meta-line">First: 2026-01-22T16:47:07+00:00 · Latest: 2026-01-22T16:47:07+00:00</div>
<div class="meta-line">Comments: 5 pages, 3 figures</div>
<div class="links" style="margin-top:8px"><a href="https://arxiv.org/abs/2601.16098v1">Abs</a> · <a href="https://arxiv.org/pdf/2601.16098v1">PDF</a> · <a href="https://huggingface.co/huggingface">Code1</a> · <a href="https://huggingface.co/docs/hub/spaces">Code2</a></div>
<details class="detail"><summary>Abstract</summary>
<div class="mono">Although Mamba models greatly improve Hyperspectral Image (HSI) classification, they have critical challenges in terms defining efficient and adaptive token sequences for improve performance. This paper therefore presents CSSMamba (Clustering-guided Spatial-Spectral Mamba) framework to better address the challenges, with the following contributions. First, to achieve efficient and adaptive token sequences for improved Mamba performance, we integrate the clustering mechanism into a spatial Mamba architecture, leading to a cluster-guided spatial Mamba module (CSpaMamba) that reduces the Mamba sequence length and improves Mamba feature learning capability. Second, to improve the learning of both spatial and spectral information, we integrate the CSpaMamba module with a spectral mamba module (SpeMamba), leading to a complete clustering-guided spatial-spectral Mamba framework. Third, to further improve feature learning capability, we introduce an Attention-Driven Token Selection mechanism to optimize Mamba token sequencing. Last, to seamlessly integrate clustering into the Mamba model in a coherent manner, we design a Learnable Clustering Module that learns the cluster memberships in an adaptive manner. Experiments on the Pavia University, Indian Pines, and Liao-Ning 01 datasets demonstrate that CSSMamba achieves higher accuracy and better boundary preservation compared to state-of-the-art CNN, Transformer, and Mamba-based methods.</div></details>
<details class="detail"><summary>中文标题/摘要</summary>
<div class="mono"><b>标题：</b>聚类引导的空谱Mamba高光谱图像分类方法</div>
<div class="mono" style="margin-top:8px">尽管Mamba模型显著提升了高光谱图像（HSI）分类性能，但在构建高效且自适应的token序列以优化性能方面仍面临关键挑战。为此，本文提出CSSMamba（聚类引导的空谱Mamba）框架以应对这些挑战，主要贡献包括：首先，通过将聚类机制集成到空间Mamba架构中，提出聚类引导的空间Mamba模块（CSpaMamba），以缩短Mamba序列长度并增强特征学习能力；其次，将CSpaMamba模块与谱域Mamba模块（SpeMamba）结合，构建完整的聚类引导空谱Mamba框架，以协同学习空间与谱域信息；第三，引入注意力驱动的token选择机制优化Mamba序列构建；最后，设计可学习的聚类模块以自适应方式学习聚类归属关系。在帕维亚大学、印第安松树及辽宁01数据集上的实验表明，CSSMamba相比当前最先进的CNN、Transformer及Mamba方法具有更高分类精度与更优边界保持能力。</div>
</details>
<details class="detail"><summary>Summary / 总结</summary>
<div class="mono">To address the challenge of defining efficient and adaptive token sequences for Mamba models in hyperspectral image classification, this paper proposes CSSMamba, a clustering-guided spatial-spectral Mamba framework. The method integrates a learnable clustering module to reduce sequence length and enhance feature learning in a spatial Mamba component, combines it with a spectral Mamba module, and employs an attention-driven token selection mechanism. Experimental results on Pavia University, Indian Pines, and Liao-Ning 01 datasets show that CSSMamba achieves higher classification accuracy and better boundary preservation compared to state-of-the-art CNN, Transformer, and Mamba-based methods.</div>
<div class="mono" style="margin-top:8px">本研究旨在解决Mamba模型在高光谱图像分类中定义高效自适应令牌序列的挑战。提出的CSSMamba框架集成了一个可学习的聚类模块来引导空间Mamba，从而减少序列长度并提升特征学习能力，同时将其与光谱Mamba模块相结合。此外，通过注意力驱动的令牌选择机制进一步优化了令牌序列。在三个数据集上的实验结果表明，与最先进的CNN、Transformer及其他基于Mamba的方法相比，CSSMamba实现了更高的分类精度和更好的边界保持能力。</div>
</details>
</div>
<div class="card">
<div class="title">Likelihood Matching for Diffusion Models</div>
<div class="meta-line">Authors: Lei Qian, Wu Su, Yanqi Huang, Song Xi Chen</div>
<div class="meta-line">First: 2025-08-05T16:51:29+00:00 · Latest: 2026-01-22T16:44:18+00:00</div>
<div class="links" style="margin-top:8px"><a href="https://arxiv.org/abs/2508.03636v2">Abs</a> · <a href="https://arxiv.org/pdf/2508.03636v2">PDF</a> · <a href="https://huggingface.co/huggingface">Code1</a> · <a href="https://huggingface.co/docs/hub/spaces">Code2</a></div>
<details class="detail"><summary>Abstract</summary>
<div class="mono">We propose a Likelihood Matching approach for training diffusion models by first establishing an equivalence between the likelihood of the target data distribution and a likelihood along the sample path of the reverse diffusion. To efficiently compute the reverse sample likelihood, a quasi-likelihood is considered to approximate each reverse transition density by a Gaussian distribution with matched conditional mean and covariance, respectively. The score and Hessian functions for the diffusion generation are estimated by maximizing the quasi-likelihood, ensuring a consistent matching of both the first two transitional moments between every two time points. A stochastic sampler is introduced to facilitate computation that leverages both the estimated score and Hessian information. We establish consistency of the quasi-maximum likelihood estimation, and provide non-asymptotic convergence guarantees for the proposed sampler, quantifying the rates of the approximation errors due to the score and Hessian estimation, dimensionality, and the number of diffusion steps. Empirical and simulation evaluations demonstrate the effectiveness of the proposed Likelihood Matching and validate the theoretical results.</div></details>
<details class="detail"><summary>中文标题/摘要</summary>
<div class="mono"><b>标题：</b>扩散模型的似然匹配方法</div>
<div class="mono" style="margin-top:8px">本文提出一种用于训练扩散模型的似然匹配方法：首先建立目标数据分布似然与反向扩散采样路径似然的等价关系。为高效计算反向采样似然，采用拟似然法，通过匹配条件均值与协方差的高斯分布近似每个反向转移密度。通过最大化拟似然估计扩散生成的得分函数与海森矩阵函数，确保任意两个时间点间前两阶转移矩的一致匹配。引入结合得分与海森信息的随机采样器以提升计算效率。我们证明了拟极大似然估计的一致性，并为所提采样器提供非渐近收敛保证，量化了得分/海森估计误差、维度及扩散步数导致的近似误差率。实证与仿真评估验证了所提似然匹配方法的有效性及其理论结果。</div>
</details>
<details class="detail"><summary>Summary / 总结</summary>
<div class="mono">This research addresses the challenge of training diffusion models by establishing a connection between the target data distribution&#x27;s likelihood and the likelihood along the reverse diffusion path. The proposed Likelihood Matching method approximates each reverse transition density with a Gaussian distribution whose conditional mean and covariance are matched, forming a quasi-likelihood. This approach enables the joint estimation of the score and Hessian functions by maximizing this quasi-likelihood, ensuring consistent matching of the first two transitional moments. Theoretical analysis confirms the consistency of the quasi-maximum likelihood estimation and provides non-asymptotic convergence guarantees for a novel stochastic sampler that utilizes both score and Hessian information, quantifying errors from estimation, dimensionality, and diffusion steps. Empirical evaluations demonstrate the method&#x27;s effectiveness and validate the theoretical findings.</div>
<div class="mono" style="margin-top:8px">本研究针对扩散模型训练中的挑战，提出了一种似然匹配方法，建立了目标数据分布的似然与反向扩散采样路径上的似然之间的等价关系。该方法通过用匹配条件均值和协方差的高斯分布来近似每个反向转移密度，从而高效计算反向采样似然，并通过拟极大似然估计来估计得分函数和海森矩阵函数，以确保每两个时间点之间的前两个转移矩的一致匹配。理论分析证实了估计的一致性，并为所提出的随机采样器提供了非渐近收敛保证，量化了来自得分/海森矩阵估计、维度和扩散步数的近似误差，同时实证评估证明了该方法的有效性并验证了理论结果。</div>
</details>
</div>
<div class="card">
<div class="title">Delayed Assignments in Online Non-Centroid Clustering with Stochastic Arrivals</div>
<div class="meta-line">Authors: Saar Cohen</div>
<div class="meta-line">First: 2026-01-22T16:42:05+00:00 · Latest: 2026-01-22T16:42:05+00:00</div>
<div class="meta-line">Comments: To Appear in the 25th International Conference on Autonomous Agents and Multiagent Systems (AAMAS), 2026</div>
<div class="links" style="margin-top:8px"><a href="https://arxiv.org/abs/2601.16091v1">Abs</a> · <a href="https://arxiv.org/pdf/2601.16091v1">PDF</a> · <a href="https://huggingface.co/huggingface">Code1</a> · <a href="https://huggingface.co/docs/hub/spaces">Code2</a></div>
<details class="detail"><summary>Abstract</summary>
<div class="mono">Clustering is a fundamental problem, aiming to partition a set of elements, like agents or data points, into clusters such that elements in the same cluster are closer to each other than to those in other clusters. In this paper, we present a new framework for studying online non-centroid clustering with delays, where elements, that arrive one at a time as points in a finite metric space, should be assigned to clusters, but assignments need not be immediate. Specifically, upon arrival, each point&#x27;s location is revealed, and an online algorithm has to irrevocably assign it to an existing cluster or create a new one containing, at this moment, only this point. However, we allow decisions to be postponed at a delay cost, instead of following the more common assumption of immediate decisions upon arrival. This poses a critical challenge: the goal is to minimize both the total distance costs between points in each cluster and the overall delay costs incurred by postponing assignments. In the classic worst-case arrival model, where points arrive in an arbitrary order, no algorithm has a competitive ratio better than sublogarithmic in the number of points. To overcome this strong impossibility, we focus on a stochastic arrival model, where points&#x27; locations are drawn independently across time from an unknown and fixed probability distribution over the finite metric space. We offer hope for beyond worst-case adversaries: we devise an algorithm that is constant competitive in the sense that, as the number of points grows, the ratio between the expected overall costs of the output clustering and an optimal offline clustering is bounded by a constant.</div></details>
<details class="detail"><summary>中文标题/摘要</summary>
<div class="mono"><b>标题：</b>随机到达在线非质心聚类中的延迟分配</div>
<div class="mono" style="margin-top:8px">聚类是一个基础性问题，旨在将一组元素（如智能体或数据点）划分为若干簇，使得同一簇内元素间的距离小于与其他簇元素间的距离。本文提出一种研究带延迟的在线非质心聚类的新框架：元素作为有限度量空间中的点逐个到达，需被分配至簇中，但分配不必立即执行。具体而言，每个点到达时其位置被揭示，在线算法必须不可撤销地将其分配至现有簇，或创建仅包含该点的新簇。但我们允许以延迟成本为代价推迟决策，而非遵循常见的到达即决策假设。这带来关键挑战：目标是最小化各簇内点间距离成本与延迟分配产生的总延迟成本。在经典最坏情况到达模型（点以任意顺序到达）中，算法的竞争比无法优于点数的亚对数级别。为突破这一强不可能性，我们聚焦于随机到达模型——点的位置随时间推移从有限度量空间的未知固定概率分布中独立抽取。我们为超越最坏情况对抗性场景提供希望：设计出一种常数竞争算法，即随着点数增长，输出聚类的期望总成本与最优离线聚类成本的比值受常数约束。</div>
</details>
<details class="detail"><summary>Summary / 总结</summary>
<div class="mono">The research addresses the challenge of online non-centroid clustering where immediate assignment of arriving points is not required, allowing for delayed decisions at a cost, which aims to balance clustering quality with delay penalties. The method introduces a stochastic arrival model where points are drawn independently from an unknown distribution, and it devises an algorithm that postpones assignments to make more informed clustering decisions. Key experimental findings show that this algorithm achieves a constant competitive ratio, meaning its expected total cost is within a constant factor of the optimal offline solution as the number of points increases, overcoming the sublogarithmic lower bound inherent in worst-case arrival models.</div>
<div class="mono" style="margin-top:8px">本研究针对在线非质心聚类中无需立即分配到达点、允许以延迟为代价推迟决策的挑战，旨在平衡聚类质量与延迟惩罚。方法引入了一个随机到达模型，其中点从未知分布中独立抽取，并设计了一种算法，该算法可做出不可撤销的分配决策，将点分配到现有聚类或创建新聚类，同时允许延迟分配。关键实验结果表明，与最坏情况到达下较差的次对数竞争比相比，该算法实现了常数竞争比，即随着点数增加，其聚类期望总成本在最优离线解的常数倍以内。</div>
</details>
</div>
<div class="card">
<div class="title">FedIA: Towards Domain-Robust Aggregation in Federated Graph Learning</div>
<div class="meta-line">Authors: Zhanting Zhou, KaHou Tam, Yiding Feng, Ziqiang Zheng, Zeyu Ma, Yang Yang</div>
<div class="meta-line">First: 2025-09-17T13:04:11+00:00 · Latest: 2026-01-22T16:28:18+00:00</div>
<div class="links" style="margin-top:8px"><a href="https://arxiv.org/abs/2509.18171v3">Abs</a> · <a href="https://arxiv.org/pdf/2509.18171v3">PDF</a> · <a href="https://huggingface.co/huggingface">Code1</a> · <a href="https://huggingface.co/docs/hub/spaces">Code2</a></div>
<details class="detail"><summary>Abstract</summary>
<div class="mono">Federated Graph Learning (FGL) enables a central server to coordinate model training across distributed clients without local graph data being shared. However, FGL significantly suffers from cross-silo domain shifts, where each &quot;silo&quot; (domain) contains a limited number of clients with distinct graph topologies. These heterogeneities induce divergent optimization trajectories, ultimately leading to global model divergence. In this work, we reveal a severe architectural pathology termed Structural Orthogonality: the topology-dependent message passing mechanism forces gradients from different domains to target disjoint coordinates in the parameter space. Through a controlled comparison between backbones, we statistically prove that GNN updates are near-perpendicular across domains (with projection ratios $\to$ 0). Consequently, naive averaging leads to Consensus Collapse, a phenomenon where sparse, informative structural signals from individual domains are diluted by the near-zero updates of others. This forces the global model into a &quot;sub-optimal&quot; state that fails to represent domain-specific structural patterns, resulting in poor generalization. To address this, we propose FedIA, a lightweight server-side framework designed to reconcile update conflicts without auxiliary communication. FedIA operates in two stages: (1) Global Importance Masking (GIM) identifies a shared parameter subspace to filter out domain-specific structural noise and prevent signal dilution; (2) Confidence-Aware Momentum Weighting (CAM) dynamically re-weights client contributions based on gradient reliability to amplify stable optimization signals.</div></details>
<details class="detail"><summary>中文标题/摘要</summary>
<div class="mono"><b>标题：</b>FedIA：迈向联邦图学习中的领域鲁棒性聚合</div>
<div class="mono" style="margin-top:8px">联邦图学习（FGL）使中央服务器能够协调分布式客户端间的模型训练，而无需共享本地图数据。然而，FGL严重受限于跨孤岛领域偏移问题，每个“孤岛”（领域）仅包含少量具有不同图拓扑的客户端。这种异质性导致优化轨迹发散，最终引发全局模型分化。本研究揭示了一种严重的架构病理现象——结构正交性：依赖拓扑的消息传递机制迫使来自不同领域的梯度在参数空间中指向互不相交的坐标。通过对骨干网络的受控比较，我们统计证明图神经网络更新在跨领域间近乎垂直（投影比趋近于0）。因此，简单平均会导致共识崩溃，即来自各领域的稀疏但信息丰富的结构信号被其他接近零的更新所稀释，迫使全局模型陷入无法表征领域特定结构模式的次优状态，导致泛化性能下降。为解决此问题，我们提出FedIA——一种轻量级服务器端框架，旨在无需额外通信的情况下协调更新冲突。FedIA分两阶段运行：（1）全局重要性掩码（GIM）识别共享参数子空间，以过滤领域特定结构噪声并防止信号稀释；（2）置信感知动量加权（CAM）基于梯度可靠性动态重加权客户端贡献，以增强稳定的优化信号。</div>
</details>
<details class="detail"><summary>Summary / 总结</summary>
<div class="mono">The research is motivated by the challenge of cross-silo domain shifts in Federated Graph Learning (FGL), where distinct graph topologies across clients cause divergent optimization trajectories and degrade the global model&#x27;s performance. The method introduces FedIA, a server-side framework that first applies Global Importance Masking to filter domain-specific structural noise and then uses Confidence-Aware Momentum Weighting to dynamically re-weight client updates based on gradient reliability. Key experimental findings demonstrate that FedIA effectively mitigates the identified issue of Structural Orthogonality and Consensus Collapse, leading to improved model generalization by preserving domain-specific structural patterns without extra communication overhead.</div>
<div class="mono" style="margin-top:8px">本研究针对联邦图学习（FGL）中的跨领域偏移问题，即不同客户端间图拓扑结构的差异导致优化轨迹发散并降低全局模型性能。提出的方法FedIA是一个服务器端框架，首先通过全局重要性掩码（GIM）过滤领域特定的结构噪声并识别共享参数子空间，然后利用置信感知动量加权（CAM）基于梯度可靠性动态调整客户端更新的权重。关键实验结果表明，FedIA有效缓解了结构正交性问题——不同领域的梯度接近垂直——从而避免了共识崩溃，并通过保留领域特定的结构模式提升了模型的泛化能力，且无需额外的通信开销。</div>
</details>
</div>
<div class="card">
<div class="title">Probably Approximately Correct Maximum A Posteriori Inference</div>
<div class="meta-line">Authors: Matthew Shorvon, Frederik Mallmann-Trenn, David S. Watson</div>
<div class="meta-line">First: 2026-01-22T16:28:01+00:00 · Latest: 2026-01-22T16:28:01+00:00</div>
<div class="meta-line">Comments: 7 pages main text, 16 total, 3 figures</div>
<div class="links" style="margin-top:8px"><a href="https://arxiv.org/abs/2601.16083v1">Abs</a> · <a href="https://arxiv.org/pdf/2601.16083v1">PDF</a> · <a href="https://huggingface.co/huggingface">Code1</a> · <a href="https://huggingface.co/docs/hub/spaces">Code2</a></div>
<details class="detail"><summary>Abstract</summary>
<div class="mono">Computing the conditional mode of a distribution, better known as the $\mathit{maximum\ a\ posteriori}$ (MAP) assignment, is a fundamental task in probabilistic inference. However, MAP estimation is generally intractable, and remains hard even under many common structural constraints and approximation schemes. We introduce $\mathit{probably\ approximately\ correct}$ (PAC) algorithms for MAP inference that provide provably optimal solutions under variable and fixed computational budgets. We characterize tractability conditions for PAC-MAP using information theoretic measures that can be estimated from finite samples. Our PAC-MAP solvers are efficiently implemented using probabilistic circuits with appropriate architectures. The randomization strategies we develop can be used either as standalone MAP inference techniques or to improve on popular heuristics, fortifying their solutions with rigorous guarantees. Experiments confirm the benefits of our method in a range of benchmarks.</div></details>
<details class="detail"><summary>中文标题/摘要</summary>
<div class="mono"><b>标题：</b>概率近似正确最大后验推断</div>
<div class="mono" style="margin-top:8px">计算分布的条件众数，即通常所说的$\mathit{最大后验}$（MAP）赋值，是概率推断中的一项基础任务。然而，MAP估计通常难以精确求解，即使在许多常见的结构约束和近似方案下仍然困难。我们提出了用于MAP推断的$\mathit{概率近似正确}$（PAC）算法，该算法在可变和固定计算预算下可提供理论证明的最优解。我们利用可从有限样本中估计的信息论度量，刻画了PAC-MAP的可处理性条件。我们的PAC-MAP求解器通过具有适当架构的概率电路高效实现。所开发的随机化策略既可作为独立的MAP推断技术使用，也可用于改进常用启发式方法，为其解提供严格的理论保证。实验在一系列基准测试中验证了本方法的优势。</div>
</details>
<details class="detail"><summary>Summary / 总结</summary>
<div class="mono">The research addresses the intractability of maximum a posteriori (MAP) inference, a core problem in probabilistic reasoning that remains difficult even with common approximations. The method introduces probably approximately correct (PAC) algorithms for MAP inference, which guarantee optimal solutions within computational budgets, using tractability conditions characterized by information-theoretic measures estimated from samples; these solvers are efficiently implemented via probabilistic circuits with specific architectures. Experimental results across benchmarks demonstrate that the proposed techniques, which can also enhance existing heuristics with formal guarantees, yield significant performance benefits.</div>
<div class="mono" style="margin-top:8px">该研究针对最大后验概率推断这一概率推理核心问题的难解性，即使在常见近似下仍具挑战。方法引入了近似正确概率算法进行MAP推断，在计算预算内保证最优解，利用从样本估计的信息论度量来刻画可处理性条件；这些求解器通过具有特定架构的概率电路高效实现。在多个基准测试中的实验结果表明，所提技术能带来显著性能优势，并可增强现有启发式方法的严谨性保证。</div>
</details>
</div>
<div class="card">
<div class="title">Explainable AI to Improve Machine Learning Reliability for Industrial Cyber-Physical Systems</div>
<div class="meta-line">Authors: Annemarie Jutte, Uraz Odyurt</div>
<div class="meta-line">First: 2026-01-22T16:18:22+00:00 · Latest: 2026-01-22T16:18:22+00:00</div>
<div class="links" style="margin-top:8px"><a href="https://arxiv.org/abs/2601.16074v1">Abs</a> · <a href="https://arxiv.org/pdf/2601.16074v1">PDF</a> · <a href="https://huggingface.co/huggingface">Code1</a> · <a href="https://huggingface.co/docs/hub/spaces">Code2</a></div>
<details class="detail"><summary>Abstract</summary>
<div class="mono">Industrial Cyber-Physical Systems (CPS) are sensitive infrastructure from both safety and economics perspectives, making their reliability critically important. Machine Learning (ML), specifically deep learning, is increasingly integrated in industrial CPS, but the inherent complexity of ML models results in non-transparent operation. Rigorous evaluation is needed to prevent models from exhibiting unexpected behaviour on future, unseen data. Explainable AI (XAI) can be used to uncover model reasoning, allowing a more extensive analysis of behaviour. We apply XAI to to improve predictive performance of ML models intended for industrial CPS. We analyse the effects of components from time-series data decomposition on model predictions using SHAP values. Through this method, we observe evidence on the lack of sufficient contextual information during model training. By increasing the window size of data instances, informed by the XAI findings, we are able to improve model performance.</div></details>
<details class="detail"><summary>中文标题/摘要</summary>
<div class="mono"><b>标题：</b>可解释人工智能提升工业信息物理系统机器学习可靠性</div>
<div class="mono" style="margin-top:8px">工业信息物理系统（CPS）在安全与经济层面均属敏感基础设施，其可靠性至关重要。机器学习（尤其是深度学习）正日益融入工业CPS，但模型固有的复杂性导致其运行不透明。需通过严格评估防止模型在未来未知数据上出现意外行为。可解释人工智能（XAI）能揭示模型推理逻辑，支持更全面的行为分析。本研究应用XAI提升面向工业CPS的机器学习模型预测性能，借助SHAP值分析时序数据分解组件对模型预测的影响。该方法揭示了模型训练中上下文信息不足的问题，通过依据XAI发现扩大数据实例窗口，最终提升了模型性能。</div>
</details>
<details class="detail"><summary>Summary / 总结</summary>
<div class="mono">The research is motivated by the critical need for reliability in Industrial Cyber-Physical Systems (CPS), where the integration of complex, non-transparent machine learning models poses a safety and economic risk. The method employs Explainable AI (XAI), specifically SHAP value analysis, to dissect how components from time-series data decomposition influence model predictions, thereby revealing the model&#x27;s reasoning. Key experimental findings show that this XAI analysis uncovered insufficient contextual information during training; subsequently, increasing the data window size based on these insights led to measurable improvements in the model&#x27;s predictive performance.</div>
<div class="mono" style="margin-top:8px">本研究动机源于工业信息物理系统对可靠性的关键需求，其中集成的复杂、不透明的机器学习模型带来了安全和经济风险。方法上，应用可解释人工智能，具体使用SHAP值，分析时间序列数据分解的组成部分如何影响模型预测，从而揭示模型的推理过程。主要实验结果表明，该分析揭示了模型训练中上下文信息不足的问题；随后，基于这些发现增加数据窗口大小，有效提升了模型的性能。</div>
</details>
</div>
<div class="card">
<div class="title">CLASP: An online learning algorithm for Convex Losses And Squared Penalties</div>
<div class="meta-line">Authors: Ricardo N. Ferreira, Cláudia Soares, João Xavier</div>
<div class="meta-line">First: 2026-01-22T16:13:52+00:00 · Latest: 2026-01-22T16:13:52+00:00</div>
<div class="links" style="margin-top:8px"><a href="https://arxiv.org/abs/2601.16072v1">Abs</a> · <a href="https://arxiv.org/pdf/2601.16072v1">PDF</a> · <a href="https://huggingface.co/huggingface">Code1</a> · <a href="https://huggingface.co/docs/hub/spaces">Code2</a></div>
<details class="detail"><summary>Abstract</summary>
<div class="mono">We study Constrained Online Convex Optimization (COCO), where a learner chooses actions iteratively, observes both unanticipated convex loss and convex constraint, and accumulates loss while incurring penalties for constraint violations. We introduce CLASP (Convex Losses And Squared Penalties), an algorithm that minimizes cumulative loss together with squared constraint violations. Our analysis departs from prior work by fully leveraging the firm non-expansiveness of convex projectors, a proof strategy not previously applied in this setting. For convex losses, CLASP achieves regret $O\left(T^{\max\{β,1-β\}}\right)$ and cumulative squared penalty $O\left(T^{1-β}\right)$ for any $β\in (0,1)$. Most importantly, for strongly convex problems, CLASP provides the first logarithmic guarantees on both regret and cumulative squared penalty. In the strongly convex case, the regret is upper bounded by $O( \log T )$ and the cumulative squared penalty is also upper bounded by $O( \log T )$.</div></details>
<details class="detail"><summary>中文标题/摘要</summary>
<div class="mono"><b>标题：</b>CLASP：面向凸损失与平方惩罚的在线学习算法</div>
<div class="mono" style="margin-top:8px">本研究探讨约束在线凸优化问题，其中学习者迭代选择行动，同时观测未预见的凸损失与凸约束，在累积损失的同时为约束违反承担惩罚。我们提出CLASP算法，该算法同步最小化累积损失与约束违反的平方惩罚。本分析方法的创新在于充分利用凸投影算子的强非扩张性——这一证明策略此前未在该研究场景中应用。针对凸损失问题，CLASP对任意β∈(0,1)可实现O(T^{max{β,1-β}})的遗憾值与O(T^{1-β})的累积平方惩罚。特别重要的是，对于强凸问题，CLASP首次在遗憾值与累积平方惩罚两方面均取得对数级保证：强凸情形下遗憾值上界为O(log T)，累积平方惩罚上界亦为O(log T)。</div>
</details>
<details class="detail"><summary>Summary / 总结</summary>
<div class="mono">This research addresses Constrained Online Convex Optimization (COCO), where a learner must minimize cumulative loss while managing penalties for constraint violations in an iterative, unanticipated environment. The authors propose the CLASP algorithm, which minimizes cumulative loss alongside squared constraint violations by leveraging a novel analysis based on the firm non-expansiveness property of convex projectors. Experimental results show that for convex losses, CLASP achieves regret scaling as O(T^{max{β,1-β}}) and cumulative squared penalty as O(T^{1-β}) for any β in (0,1); crucially, for strongly convex problems, it provides the first logarithmic guarantees, with both regret and cumulative squared penalty bounded by O(log T).</div>
<div class="mono" style="margin-top:8px">本文研究约束在线凸优化问题，学习者需要在迭代决策中最小化累积损失，同时处理约束违反带来的惩罚。作者提出了CLASP算法，通过最小化累积损失与约束违反平方和，并创新性地利用凸投影算子的强非扩张性进行证明。对于凸损失，CLASP实现了O(T^{max{β,1-β}})的遗憾和O(T^{1-β})的累积平方惩罚；对于强凸问题，该算法首次提供了对数级保证，遗憾和累积平方惩罚均以O(log T)为上界。</div>
</details>
</div>
<div class="card">
<div class="title">On damage of interpolation to adversarial robustness in regression</div>
<div class="meta-line">Authors: Jingfu Peng, Yuhong Yang</div>
<div class="meta-line">First: 2026-01-22T16:09:00+00:00 · Latest: 2026-01-22T16:09:00+00:00</div>
<div class="links" style="margin-top:8px"><a href="https://arxiv.org/abs/2601.16070v1">Abs</a> · <a href="https://arxiv.org/pdf/2601.16070v1">PDF</a> · <a href="https://huggingface.co/huggingface">Code1</a> · <a href="https://huggingface.co/docs/hub/spaces">Code2</a></div>
<details class="detail"><summary>Abstract</summary>
<div class="mono">Deep neural networks (DNNs) typically involve a large number of parameters and are trained to achieve zero or near-zero training error. Despite such interpolation, they often exhibit strong generalization performance on unseen data, a phenomenon that has motivated extensive theoretical investigations. Comforting results show that interpolation indeed may not affect the minimax rate of convergence under the squared error loss. In the mean time, DNNs are well known to be highly vulnerable to adversarial perturbations in future inputs. A natural question then arises: Can interpolation also escape from suboptimal performance under a future $X$-attack? In this paper, we investigate the adversarial robustness of interpolating estimators in a framework of nonparametric regression. A finding is that interpolating estimators must be suboptimal even under a subtle future $X$-attack, and achieving perfect fitting can substantially damage their robustness. An interesting phenomenon in the high interpolation regime, which we term the curse of simple size, is also revealed and discussed. Numerical experiments support our theoretical findings.</div></details>
<details class="detail"><summary>中文标题/摘要</summary>
<div class="mono"><b>标题：</b>论插值对回归中对抗鲁棒性的损害</div>
<div class="mono" style="margin-top:8px">深度神经网络（DNNs）通常包含大量参数，并被训练以实现零或接近零的训练误差。尽管存在这种插值现象，它们往往在未见数据上表现出强大的泛化性能，这一现象已引发广泛的理论研究。令人欣慰的结果表明，在平方误差损失下，插值确实可能不影响收敛的极小极大速率。同时，DNNs 众所周知对未来输入中的对抗扰动高度脆弱。一个自然的问题随之产生：插值是否也能在未来 $X$ 攻击下避免次优性能？本文在非参数回归框架下研究插值估计器的对抗鲁棒性。研究发现，即使在微妙的未来 $X$ 攻击下，插值估计器也必然是次优的，而实现完美拟合会显著损害其鲁棒性。我们还揭示并讨论了高插值区域中一个有趣的现象，称之为“简单尺寸诅咒”。数值实验支持了我们的理论发现。</div>
</details>
<details class="detail"><summary>Summary / 总结</summary>
<div class="mono">This study investigates whether interpolating deep neural networks, which achieve near-zero training error, can maintain optimal adversarial robustness in nonparametric regression under future X-attacks. The authors analyze the adversarial robustness of interpolating estimators within a theoretical framework, revealing that such estimators are inherently suboptimal even under subtle attacks, and that perfect fitting significantly compromises robustness. They also identify a &#x27;curse of simple size&#x27; phenomenon in high interpolation regimes, with numerical experiments supporting these theoretical conclusions.</div>
<div class="mono" style="margin-top:8px">本研究探讨在非参数回归中，达到近乎零训练误差的插值估计器在未来X攻击下是否仍能保持最优对抗鲁棒性。该研究采用分析极小极大收敛速率的理论框架，并引入&#x27;简单尺寸诅咒&#x27;这一新概念来描述高插值区域的现象。核心发现表明插值必然导致对抗鲁棒性的次优表现，即使面对细微攻击，完美拟合也会显著损害估计器性能，这一结论得到了数值实验的支持。</div>
</details>
</div></div>
    <details style="margin-top:16px" class="detail"><summary>History</summary>
      <div class="history-list"><a href="archive/20260126_0327.html">20260126_0327</a>
<a href="archive/20260125_0624.html">20260125_0624</a>
<a href="archive/20260125_0524.html">20260125_0524</a>
<a href="archive/20260125_0440.html">20260125_0440</a>
<a href="archive/20260125_0325.html">20260125_0325</a>
<a href="archive/20260124_0627.html">20260124_0627</a>
<a href="archive/20260124_0526.html">20260124_0526</a>
<a href="archive/20260124_0444.html">20260124_0444</a>
<a href="archive/20260124_0334.html">20260124_0334</a>
<a href="archive/20260123_0627.html">20260123_0627</a>
<a href="archive/20260123_0529.html">20260123_0529</a>
<a href="archive/20260123_0446.html">20260123_0446</a>
<a href="archive/20260123_0334.html">20260123_0334</a>
<a href="archive/20260122_2019.html">20260122_2019</a>
<a href="archive/20260122_2013.html">20260122_2013</a>
<a href="archive/20260122_2008.html">20260122_2008</a>
<a href="archive/20260122_2001.html">20260122_2001</a>
<a href="archive/20260122_0629.html">20260122_0629</a>
<a href="archive/20260122_0535.html">20260122_0535</a>
<a href="archive/20260122_0449.html">20260122_0449</a>
<a href="archive/20260122_0336.html">20260122_0336</a>
<a href="archive/20260121_0625.html">20260121_0625</a>
<a href="archive/20260121_0529.html">20260121_0529</a>
<a href="archive/20260121_0450.html">20260121_0450</a>
<a href="archive/20260121_0423.html">20260121_0423</a>
<a href="archive/20260120_0626.html">20260120_0626</a>
<a href="archive/20260120_0528.html">20260120_0528</a>
<a href="archive/20260120_0443.html">20260120_0443</a>
<a href="archive/20260120_0330.html">20260120_0330</a>
<a href="archive/20260119_0624.html">20260119_0624</a>
<a href="archive/20260119_0525.html">20260119_0525</a>
<a href="archive/20260119_0440.html">20260119_0440</a>
<a href="archive/20260119_0325.html">20260119_0325</a>
<a href="archive/20260118_2225.html">20260118_2225</a>
<a href="archive/20260118_2159.html">20260118_2159</a>
<a href="archive/20260118_2135.html">20260118_2135</a>
<a href="archive/20260118_2040.html">20260118_2040</a>
<a href="archive/20260118_1953.html">20260118_1953</a>
<a href="archive/20260118_1907.html">20260118_1907</a>
<a href="archive/20260118_0327.html">20260118_0327</a>
<a href="archive/20260117_0332.html">20260117_0332</a>
<a href="archive/20260116_0339.html">20260116_0339</a>
<a href="archive/20260115_0334.html">20260115_0334</a>
<a href="archive/20260114_0333.html">20260114_0333</a>
<a href="archive/20260113_0334.html">20260113_0334</a>
<a href="archive/20260112_0331.html">20260112_0331</a>
<a href="archive/20260111_0329.html">20260111_0329</a>
<a href="archive/20260110_0333.html">20260110_0333</a>
<a href="archive/20260109_0334.html">20260109_0334</a>
<a href="archive/20260108_0335.html">20260108_0335</a>
<a href="archive/20260107_0330.html">20260107_0330</a>
<a href="archive/20260106_0336.html">20260106_0336</a>
<a href="archive/20260105_0328.html">20260105_0328</a>
<a href="archive/20260104_0328.html">20260104_0328</a>
<a href="archive/20260103_0325.html">20260103_0325</a>
<a href="archive/20260102_0339.html">20260102_0339</a>
<a href="archive/20260101_0329.html">20260101_0329</a>
<a href="archive/20251231_0333.html">20251231_0333</a>
<a href="archive/20251230_0332.html">20251230_0332</a>
<a href="archive/20251229_0329.html">20251229_0329</a>
<a href="archive/20251228_0332.html">20251228_0332</a>
<a href="archive/20251227_0329.html">20251227_0329</a>
<a href="archive/20251226_0330.html">20251226_0330</a>
<a href="archive/20251225_0329.html">20251225_0329</a>
<a href="archive/20251224_0331.html">20251224_0331</a>
<a href="archive/20251223_0332.html">20251223_0332</a>
<a href="archive/20251222_0328.html">20251222_0328</a>
<a href="archive/20251221_0329.html">20251221_0329</a>
<a href="archive/20251220_0330.html">20251220_0330</a>
<a href="archive/20251219_0330.html">20251219_0330</a>
<a href="archive/20251218_0345.html">20251218_0345</a>
<a href="archive/20251217_0332.html">20251217_0332</a>
<a href="archive/20251216_0333.html">20251216_0333</a>
<a href="archive/20251215_0333.html">20251215_0333</a>
<a href="archive/20251214_0327.html">20251214_0327</a>
<a href="archive/20251212_0333.html">20251212_0333</a>
<a href="archive/20251211_0331.html">20251211_0331</a>
<a href="archive/20251210_0332.html">20251210_0332</a>
<a href="archive/20251209_0331.html">20251209_0331</a>
<a href="archive/20251208_0328.html">20251208_0328</a>
<a href="archive/20251207_0327.html">20251207_0327</a>
<a href="archive/20251206_0330.html">20251206_0330</a>
<a href="archive/20251205_0331.html">20251205_0331</a>
<a href="archive/20251204_0331.html">20251204_0331</a>
<a href="archive/20251203_0333.html">20251203_0333</a>
<a href="archive/20251202_0335.html">20251202_0335</a>
<a href="archive/20251201_0328.html">20251201_0328</a>
<a href="archive/20251130_0327.html">20251130_0327</a>
<a href="archive/20251129_0328.html">20251129_0328</a>
<a href="archive/20251128_0327.html">20251128_0327</a>
<a href="archive/20251127_0327.html">20251127_0327</a>
<a href="archive/20251126_0329.html">20251126_0329</a>
<a href="archive/20251125_0327.html">20251125_0327</a>
<a href="archive/20251124_0327.html">20251124_0327</a>
<a href="archive/20251123_0326.html">20251123_0326</a>
<a href="archive/20251122_0328.html">20251122_0328</a>
<a href="archive/20251121_0328.html">20251121_0328</a>
<a href="archive/20251120_0329.html">20251120_0329</a>
<a href="archive/20251119_0328.html">20251119_0328</a>
<a href="archive/20251118_0328.html">20251118_0328</a></div>
    </details>
    <div class="footer">Generated by arxiv-tracker</div>
  </div>
</body></html>
