<!doctype html>
<html><head><meta charset="utf-8"><meta name="viewport" content="width=device-width,initial-scale=1">
<title>arXiv 论文速递</title><style>
:root {
  --bg:#f8fafc; --card:#ffffff; --text:#0f172a; --muted:#667085; --border:#e5e7eb; --acc:#2563eb;
}
:root[data-theme="dark"] {
  --bg:#0b0f17; --card:#111827; --text:#e5e7eb; --muted:#9ca3af; --border:#1f2937; --acc:#2563eb;
}
*{box-sizing:border-box} body{margin:0;background:var(--bg);color:var(--text);
  font-family:ui-sans-serif,system-ui,-apple-system,Segoe UI,Roboto,Helvetica,Arial;line-height:1.6;}
.container{max-width:900px;margin:0 auto;padding:18px;}
.header{display:flex;gap:10px;justify-content:space-between;align-items:center;margin:8px 0 16px;flex-wrap:wrap}
h1{font-size:22px;margin:0}
.badge{font-size:12px;color:#111827;background:var(--acc);padding:2px 8px;border-radius:999px}
.card{background:var(--card);border:1px solid var(--border);border-radius:16px;padding:16px 18px;margin:14px 0;box-shadow:0 1px 2px rgba(0,0,0,.04)}
.title{font-weight:700;margin:0 0 6px 0;font-size:18px}
.meta-line{color:var(--muted);font-size:13px;margin:2px 0}
.links a{color:var(--acc);text-decoration:none;margin-right:12px}
.detail{margin-top:10px;background:rgba(2,6,23,.03);border:1px solid var(--border);border-radius:10px;padding:8px 10px}
summary{cursor:pointer;color:var(--acc)}
.mono{white-space:pre-wrap;background:rgba(2,6,23,.03);border:1px solid var(--border);padding:10px;border-radius:10px}
.row{display:grid;grid-template-columns:1fr;gap:12px}
@media (min-width: 860px) {
  .row-2{grid-template-columns:1fr 1fr}
}
.footer{color:var(--muted);font-size:13px;margin:20px 0 10px}
.hr{height:1px;background:var(--border);margin:14px 0}
.history-list a{display:block;color:var(--acc);text-decoration:none;margin:4px 0}
.controls{display:flex;gap:8px;align-items:center}
.btn{border:1px solid var(--border);background:var(--card);padding:6px 10px;border-radius:10px;cursor:pointer;color:var(--text)}
.btn:hover{border-color:var(--acc)}
</style>
<script>
(function() {
  const root = document.documentElement;
  function apply(t) {
    if (t==='dark') root.setAttribute('data-theme','dark');
    else if (t==='light') root.removeAttribute('data-theme');
    else {
      if (window.matchMedia && window.matchMedia('(prefers-color-scheme: dark)').matches)
        root.setAttribute('data-theme','dark');
      else root.removeAttribute('data-theme');
    }
  }
  let t = localStorage.getItem('theme') || 'light';
  if (!['light','dark','auto'].includes(t)) t='light';
  apply(t);
  window.__toggleTheme = function() {
    let cur = localStorage.getItem('theme') || 'light';
    if (cur==='light') cur='dark';
    else if (cur==='dark') cur='auto';
    else cur='light';
    localStorage.setItem('theme', cur);
    apply(cur);
    const el=document.getElementById('theme-label');
    if(el) el.textContent = cur.toUpperCase();
  }
  window.__expandAll = function(open) {
    document.querySelectorAll('details').forEach(d => d.open = !!open);
  }
})();
</script>
</head>
<body>
  <div class="container">
    <div class="header">
      <h1>arXiv 论文速递</h1>
      <div style="display:flex;gap:10px;align-items:center">
        
<div class="controls">
  <button class="btn" onclick="__toggleTheme()">Theme: <span id="theme-label" style="margin-left:6px">AUTO</span></button>
  <button class="btn" onclick="__expandAll(true)">Expand All</button>
  <button class="btn" onclick="__expandAll(false)">Collapse All</button>
</div>

        <span class="badge">2026-01-22 05:35</span>
      </div>
    </div>
    <div class="hr"></div>
    <div>Snapshot: 20260122_0535</div>
    <div class="row"><div class="card">
<div class="title">Jet-RL: Enabling On-Policy FP8 Reinforcement Learning with Unified Training and Rollout Precision Flow</div>
<div class="meta-line">Authors: Haocheng Xi, Charlie Ruan, Peiyuan Liao, Yujun Lin, Han Cai, Yilong Zhao, Shuo Yang, Kurt Keutzer, Song Han, Ligeng Zhu</div>
<div class="meta-line">First: 2026-01-20T18:54:31+00:00 · Latest: 2026-01-20T18:54:31+00:00</div>
<div class="meta-line">Comments: 11 pages, 6 figures, 4 tables</div>
<div class="links" style="margin-top:8px"><a href="https://arxiv.org/abs/2601.14243v1">Abs</a> · <a href="https://arxiv.org/pdf/2601.14243v1">PDF</a> · <a href="https://huggingface.co/huggingface">Code1</a> · <a href="https://huggingface.co/docs/hub/spaces">Code2</a></div>
<details class="detail"><summary>Abstract</summary>
<div class="mono">Reinforcement learning (RL) is essential for enhancing the complex reasoning capabilities of large language models (LLMs). However, existing RL training pipelines are computationally inefficient and resource-intensive, with the rollout phase accounting for over 70% of total training time. Quantized RL training, particularly using FP8 precision, offers a promising approach to mitigating this bottleneck. A commonly adopted strategy applies FP8 precision during rollout while retaining BF16 precision for training. In this work, we present the first comprehensive study of FP8 RL training and demonstrate that the widely used BF16-training + FP8-rollout strategy suffers from severe training instability and catastrophic accuracy collapse under long-horizon rollouts and challenging tasks. Our analysis shows that these failures stem from the off-policy nature of the approach, which introduces substantial numerical mismatch between training and inference. Motivated by these observations, we propose Jet-RL, an FP8 RL training framework that enables robust and stable RL optimization. The key idea is to adopt a unified FP8 precision flow for both training and rollout, thereby minimizing numerical discrepancies and eliminating the need for inefficient inter-step calibration. Extensive experiments validate the effectiveness of Jet-RL: our method achieves up to 33% speedup in the rollout phase, up to 41% speedup in the training phase, and a 16% end-to-end speedup over BF16 training, while maintaining stable convergence across all settings and incurring negligible accuracy degradation.</div></details>
<details class="detail"><summary>中文标题/摘要</summary>
<div class="mono"><b>标题：</b>Jet-RL：通过统一的训练与推演精度流实现基于策略的FP8强化学习</div>
<div class="mono" style="margin-top:8px">强化学习（RL）对于提升大语言模型（LLMs）的复杂推理能力至关重要。然而，现有RL训练流程计算效率低下且资源密集，其中推演阶段占总训练时间的70%以上。量化RL训练，特别是使用FP8精度，为解决这一瓶颈提供了可行方案。当前常用策略是在推演阶段采用FP8精度，同时在训练阶段保留BF16精度。本研究首次对FP8 RL训练进行了全面分析，并证明广泛采用的“BF16训练+FP8推演”策略在长序列推演和复杂任务中会出现严重的训练不稳定性和灾难性精度崩溃。分析表明，这些失效源于该方法的离策略特性，导致训练与推理之间存在显著数值失配。基于此，我们提出Jet-RL——一个能够实现稳健稳定RL优化的FP8训练框架。其核心思想是采用统一的FP8精度流同时处理训练与推演，从而最小化数值差异并消除低效的步间校准需求。大量实验验证了Jet-RL的有效性：相较于BF16训练，本方法在推演阶段最高加速33%，训练阶段最高加速41%，端到端整体加速16%，同时在所有设置下保持稳定收敛，且精度损失可忽略不计。</div>
</details>
<details class="detail"><summary>Summary / 总结</summary>
<div class="mono">Reinforcement learning (RL) is crucial for improving large language models but suffers from computational inefficiency, with the rollout phase consuming most of the training time. While using FP8 precision for rollout and BF16 for training is a common strategy to address this, this work identifies that this off-policy approach causes severe instability and accuracy collapse in long-horizon tasks due to numerical mismatches. To solve this, the authors propose Jet-RL, a framework that employs a unified FP8 precision flow for both training and rollout to minimize discrepancies and avoid calibration overhead. Experimental results show that Jet-RL achieves up to 33% rollout speedup, 41% training speedup, and a 16% end-to-end speedup over BF16 training while maintaining stable convergence with negligible accuracy loss.</div>
<div class="mono" style="margin-top:8px">本研究旨在解决强化学习（RL）在大语言模型训练中计算效率低下的问题，其中推演阶段占训练总时间的70%以上，而采用FP8精度的量化训练被视为潜在解决方案。方法上提出了Jet-RL框架，通过统一训练和推演的FP8精度流程，解决了常见混合精度策略（如BF16训练结合FP8推演）因离策略特性导致的数值不匹配、训练不稳定和精度崩溃问题。实验结果表明，Jet-RL在推演阶段实现了高达33%的加速，训练阶段加速达41%，整体端到端速度比BF16训练提升16%，同时在所有设置中保持稳定收敛且精度损失可忽略不计。</div>
</details>
</div>
<div class="card">
<div class="title">APEX-Agents</div>
<div class="meta-line">Authors: Bertie Vidgen, Austin Mann, Abby Fennelly, John Wright Stanly, Lucas Rothman, Marco Burstein, Julien Benchek, David Ostrofsky, Anirudh Ravichandran, Debnil Sur, Neel Venugopal, Alannah Hsia, Isaac Robinson, Calix Huang, Olivia Varones, Daniyal Khan, Michael Haines, Zach Richards, Chirag Mahapatra, Brendan Foody, Osvald Nitski</div>
<div class="meta-line">First: 2026-01-20T18:53:44+00:00 · Latest: 2026-01-20T18:53:44+00:00</div>
<div class="links" style="margin-top:8px"><a href="https://arxiv.org/abs/2601.14242v1">Abs</a> · <a href="https://arxiv.org/pdf/2601.14242v1">PDF</a> · <a href="https://huggingface.co/huggingface">Code1</a> · <a href="https://huggingface.co/docs/hub/spaces">Code2</a></div>
<details class="detail"><summary>Abstract</summary>
<div class="mono">We introduce the AI Productivity Index for Agents (APEX-Agents), a benchmark for assessing whether AI agents can execute long-horizon, cross-application tasks created by investment banking analysts, management consultants, and corporate lawyers. APEX-Agents requires agents to navigate realistic work environments with files and tools. We test eight agents for the leaderboard using Pass@1. Gemini 3 Flash (Thinking=High) achieves the highest score of 24.0%, followed by GPT-5.2 (Thinking=High), Claude Opus 4.5 (Thinking=High), and Gemini 3 Pro (Thinking=High). We open source the APEX-Agents benchmark (n=480) with all prompts, rubrics, gold outputs, files, and metadata. We also open-source Archipelago, our infrastructure for agent execution and evaluation.</div></details>
<details class="detail"><summary>中文标题/摘要</summary>
<div class="mono"><b>标题：</b>APEX-Agents</div>
<div class="mono" style="margin-top:8px">我们推出了AI智能体生产力指数（APEX-Agents），这是一个用于评估AI智能体能否执行由投行分析师、管理顾问和企业律师设计的跨应用长周期任务的基准测试。APEX-Agents要求智能体在包含文件与工具的真实工作环境中进行操作。我们采用Pass@1指标对八个智能体进行排行榜测试：Gemini 3 Flash（思考模式=高）以24.0%得分位居榜首，其后依次是GPT-5.2（思考模式=高）、Claude Opus 4.5（思考模式=高）和Gemini 3 Pro（思考模式=高）。我们开源了包含全部提示词、评分标准、标准答案、文件及元数据的APEX-Agents基准测试集（n=480），同时开源了用于智能体执行与评估的基础设施Archipelago。</div>
</details>
<details class="detail"><summary>Summary / 总结</summary>
<div class="mono">The research is motivated by the need to evaluate AI agents on complex, real-world professional tasks that span multiple applications and require long-term planning, as encountered in fields like investment banking and management consulting. The method introduces the APEX-Agents benchmark, which simulates realistic work environments with files and tools, and employs a Pass@1 metric to test agents on a set of 480 tasks. Key experimental results show that Gemini 3 Flash (Thinking=High) achieved the highest score of 24.0%, followed by GPT-5.2, Claude Opus 4.5, and Gemini 3 Pro, all with high thinking settings, while the benchmark and associated execution infrastructure, Archipelago, are open-sourced.</div>
<div class="mono" style="margin-top:8px">该研究的动机源于需要评估AI智能体在复杂、跨应用且需长期规划的真实专业任务上的能力，这些任务常见于投资银行和管理咨询等领域。方法上提出了APEX-Agents基准测试，它模拟了包含文件和工具的真实工作环境，并使用Pass@1指标在480个任务上测试智能体性能。主要实验结果表明，Gemini 3 Flash（Thinking=High）以24.0%的最高得分领先，优于GPT-5.2、Claude Opus 4.5和Gemini 3 Pro等其他领先模型，同时该基准及其执行基础设施Archipelago已开源。</div>
</details>
</div>
<div class="card">
<div class="title">Spatiotemporal Wildfire Prediction and Reinforcement Learning for Helitack Suppression</div>
<div class="meta-line">Authors: Shaurya Mathur, Shreyas Bellary Manjunath, Nitin Kulkarni, Alina Vereshchaka</div>
<div class="meta-line">Venue: www</div>
<div class="meta-line">First: 2026-01-20T18:50:12+00:00 · Latest: 2026-01-20T18:50:12+00:00</div>
<div class="meta-line">Comments: 6 pages, 5 figures (two of them in tables), Conference: IEEE International Conference on Machine Learning and Applications 2025 (ICMLA 2025): https://www.icmla-conference.org/icmla25/</div>
<div class="links" style="margin-top:8px"><a href="https://arxiv.org/abs/2601.14238v1">Abs</a> · <a href="https://arxiv.org/pdf/2601.14238v1">PDF</a> · <a href="https://huggingface.co/huggingface">Code1</a> · <a href="https://huggingface.co/docs/hub/spaces">Code2</a> · <a href="https://sites.google.com/view/firecastrl">Project1</a></div>
<details class="detail"><summary>Abstract</summary>
<div class="mono">Wildfires are growing in frequency and intensity, devastating ecosystems and communities while causing billions of dollars in suppression costs and economic damage annually in the U.S. Traditional wildfire management is mostly reactive, addressing fires only after they are detected. We introduce \textit{FireCastRL}, a proactive artificial intelligence (AI) framework that combines wildfire forecasting with intelligent suppression strategies. Our framework first uses a deep spatiotemporal model to predict wildfire ignition. For high-risk predictions, we deploy a pre-trained reinforcement learning (RL) agent to execute real-time suppression tactics with helitack units inside a physics-informed 3D simulation. The framework generates a threat assessment report to help emergency responders optimize resource allocation and planning. In addition, we are publicly releasing a large-scale, spatiotemporal dataset containing $\mathbf{9.5}$ million samples of environmental variables for wildfire prediction. Our work demonstrates how deep learning and RL can be combined to support both forecasting and tactical wildfire response. More details can be found at https://sites.google.com/view/firecastrl.</div></details>
<details class="detail"><summary>中文标题/摘要</summary>
<div class="mono"><b>标题：</b>时空野火预测与直升机灭火强化学习抑制策略</div>
<div class="mono" style="margin-top:8px">野火发生频率和强度日益增加，不仅破坏生态系统和社区，每年在美国还造成数十亿美元的灭火成本和经济损失。传统野火管理多为被动响应，仅在火灾被发现后才采取行动。本文提出《FireCastRL》——一种结合野火预测与智能抑制策略的主动式人工智能框架。该框架首先采用深度时空模型预测野火起火点，针对高风险预测，部署预训练的强化学习智能体在物理信息三维模拟中指挥直升机灭火单元执行实时抑制战术。框架生成威胁评估报告，协助应急响应人员优化资源调配与规划。此外，我们公开释放一个包含950万条环境变量样本的大规模时空数据集用于野火预测。本研究展示了深度学习与强化学习如何协同支持野火预测与战术响应。更多细节详见：https://sites.google.com/view/firecastrl。</div>
</details>
<details class="detail"><summary>Summary / 总结</summary>
<div class="mono">Motivated by the increasing frequency and intensity of wildfires and the limitations of reactive management, this research introduces FireCastRL, a proactive AI framework that integrates deep spatiotemporal modeling for wildfire ignition prediction with reinforcement learning for tactical suppression planning. The method employs a deep spatiotemporal model to forecast ignitions and, for high-risk cases, deploys a pre-trained RL agent within a physics-informed 3D simulation to plan helitack suppression strategies, also generating threat assessment reports. Key experimental findings include the creation and public release of a large-scale dataset with 9.5 million environmental samples and a demonstration that the combined deep learning and RL approach can effectively support both forecasting and real-time tactical response.</div>
<div class="mono" style="margin-top:8px">针对野火日益频发和传统被动管理的局限，本研究提出了FireCastRL这一主动式人工智能框架，将深度时空预测与强化学习战术抑制相结合。该方法首先使用深度时空模型预测野火起火点；对于高风险预测，一个预训练的强化学习代理在物理信息化的3D模拟中执行实时直升机灭火战术，并生成威胁评估报告以协助应急响应。主要实验成果包括构建了一个包含950万个环境样本的大规模数据集，并证明了深度学习和强化学习的结合能有效支持野火的预测和战术响应。</div>
</details>
</div>
<div class="card">
<div class="title">Opportunities in AI/ML for the Rubin LSST Dark Energy Science Collaboration</div>
<div class="meta-line">Authors: LSST Dark Energy Science Collaboration, Eric Aubourg, Camille Avestruz, Matthew R. Becker, Biswajit Biswas, Rahul Biswas, Boris Bolliet, Adam S. Bolton, Clecio R. Bom, Raphaël Bonnet-Guerrini, Alexandre Boucaud, Jean-Eric Campagne, Chihway Chang, Aleksandra Ćiprijanović, Johann Cohen-Tanugi, Michael W. Coughlin, John Franklin Crenshaw, Juan C. Cuevas-Tello, Juan de Vicente, Seth W. Digel, Steven Dillmann, Mariano Javier de León Dominguez Romero, Alex Drlica-Wagner, Sydney Erickson, Alexander T. Gagliano, Christos Georgiou, Aritra Ghosh, Matthew Grayling, Kirill A. Grishin, Alan Heavens, Lindsay R. House, Mustapha Ishak, Wassim Kabalan, Arun Kannawadi, François Lanusse, C. Danielle Leonard, Pierre-François Léget, Michelle Lochner, Yao-Yuan Mao, Peter Melchior, Grant Merz, Martin Millon, Anais Möller, Gautham Narayan, Yuuki Omori, Hiranya Peiris, Laurence Perreault-Levasseur, Andrés A. Plazas Malagón, Nesar Ramachandra, Benjamin Remy, Cécile Roucelle, Jaime Ruiz-Zapatero, Stefan Schuldt, Ignacio Sevilla-Noarbe, Ved G. Shah, Tjitske Starkenburg, Stephen Thorp, Laura Toribio San Cipriano, Tilman Tröster, Roberto Trotta, Padma Venkatraman, Amanda Wasserman, Tim White, Justine Zeghal, Tianqing Zhang, Yuanyuan Zhang</div>
<div class="meta-line">First: 2026-01-20T18:46:42+00:00 · Latest: 2026-01-20T18:46:42+00:00</div>
<div class="meta-line">Comments: 84 pages. This is v1.0 of the DESC&#x27;s white paper on AI/ML, a collaboration document that is being made public but which is not planned for submission to a journal</div>
<div class="links" style="margin-top:8px"><a href="https://arxiv.org/abs/2601.14235v1">Abs</a> · <a href="https://arxiv.org/pdf/2601.14235v1">PDF</a> · <a href="https://huggingface.co/huggingface">Code1</a> · <a href="https://huggingface.co/docs/hub/spaces">Code2</a></div>
<details class="detail"><summary>Abstract</summary>
<div class="mono">The Vera C. Rubin Observatory&#x27;s Legacy Survey of Space and Time (LSST) will produce unprecedented volumes of heterogeneous astronomical data (images, catalogs, and alerts) that challenge traditional analysis pipelines. The LSST Dark Energy Science Collaboration (DESC) aims to derive robust constraints on dark energy and dark matter from these data, requiring methods that are statistically powerful, scalable, and operationally reliable. Artificial intelligence and machine learning (AI/ML) are already embedded across DESC science workflows, from photometric redshifts and transient classification to weak lensing inference and cosmological simulations. Yet their utility for precision cosmology hinges on trustworthy uncertainty quantification, robustness to covariate shift and model misspecification, and reproducible integration within scientific pipelines. This white paper surveys the current landscape of AI/ML across DESC&#x27;s primary cosmological probes and cross-cutting analyses, revealing that the same core methodologies and fundamental challenges recur across disparate science cases. Since progress on these cross-cutting challenges would benefit multiple probes simultaneously, we identify key methodological research priorities, including Bayesian inference at scale, physics-informed methods, validation frameworks, and active learning for discovery. With an eye on emerging techniques, we also explore the potential of the latest foundation model methodologies and LLM-driven agentic AI systems to reshape DESC workflows, provided their deployment is coupled with rigorous evaluation and governance. Finally, we discuss critical software, computing, data infrastructure, and human capital requirements for the successful deployment of these new methodologies, and consider associated risks and opportunities for broader coordination with external actors.</div></details>
<details class="detail"><summary>中文标题/摘要</summary>
<div class="mono"><b>标题：</b>鲁宾LSST暗能量科学合作中的人工智能/机器学习机遇</div>
<div class="mono" style="margin-top:8px">薇拉·C·鲁宾天文台的时空遗产巡天（LSST）将产生前所未有的海量异构天文数据（图像、星表和警报），这对传统分析流程构成挑战。LSST暗能量科学合作（DESC）旨在从这些数据中获取对暗能量和暗物质的可靠约束，需要具备统计效力强、可扩展且运行可靠的方法。人工智能和机器学习（AI/ML）已全面融入DESC科学工作流，涵盖从测光红移、瞬变天体分类到弱引力透镜推断和宇宙学模拟等领域。然而，其在精密宇宙学中的应用价值取决于可信的不确定性量化、对协变量偏移和模型误设的鲁棒性，以及在科学流程中的可复现集成。本白皮书系统梳理了AI/ML在DESC主要宇宙学探针和交叉分析中的应用现状，揭示相同核心方法论和基础挑战在不同科学案例中反复出现。由于这些交叉挑战的进展将同时惠及多个探针，我们明确了关键方法论研究重点，包括大规模贝叶斯推断、物理信息方法、验证框架及用于发现的主动学习。着眼新兴技术，我们还探讨了最新基础模型方法和LLM驱动的智能体AI系统重塑DESC工作流的潜力——前提是其部署需结合严格评估与治理机制。最后，我们讨论了成功部署这些新方法所需的关键软件、计算、数据基础设施和人才资源，并考量了与外部机构广泛协作的相关风险与机遇。</div>
</details>
<details class="detail"><summary>Summary / 总结</summary>
<div class="mono">The Rubin Observatory&#x27;s LSST will generate vast, heterogeneous data that challenges conventional analysis methods for dark energy and dark matter studies. This white paper surveys how AI/ML is currently applied within the LSST Dark Energy Science Collaboration across tasks like photometric redshifts and weak lensing, but emphasizes that reliable cosmology requires addressing cross-cutting challenges such as uncertainty quantification and robustness. It identifies key research priorities including scalable Bayesian inference and physics-informed methods, explores the potential of foundation models and agentic AI, and discusses the necessary software, infrastructure, and human capital for successful deployment.</div>
<div class="mono" style="margin-top:8px">鲁宾天文台的LSST将产生海量异构数据，这对暗能量和暗物质研究的传统分析方法构成挑战。本白皮书调研了AI/ML目前在DESC工作流程（如光度红移和弱引力透镜）中的应用，但强调可靠的宇宙学研究需解决不确定性量化、稳健性等共性挑战。报告确定了包括可扩展贝叶斯推断和物理信息方法在内的关键研究重点，探讨了基础模型和智能体AI的潜力，并讨论了成功部署所需软件、计算及治理基础设施。</div>
</details>
</div>
<div class="card">
<div class="title">Q-learning with Adjoint Matching</div>
<div class="meta-line">Authors: Qiyang Li, Sergey Levine</div>
<div class="meta-line">First: 2026-01-20T18:45:34+00:00 · Latest: 2026-01-20T18:45:34+00:00</div>
<div class="meta-line">Comments: 32 pages, 8 figures, 7 tables</div>
<div class="links" style="margin-top:8px"><a href="https://arxiv.org/abs/2601.14234v1">Abs</a> · <a href="https://arxiv.org/pdf/2601.14234v1">PDF</a> · <a href="https://huggingface.co/huggingface">Code1</a> · <a href="https://huggingface.co/docs/hub/spaces">Code2</a></div>
<details class="detail"><summary>Abstract</summary>
<div class="mono">We propose Q-learning with Adjoint Matching (QAM), a novel TD-based reinforcement learning (RL) algorithm that tackles a long-standing challenge in continuous-action RL: efficient optimization of an expressive diffusion or flow-matching policy with respect to a parameterized Q-function. Effective optimization requires exploiting the first-order information of the critic, but it is challenging to do so for flow or diffusion policies because direct gradient-based optimization via backpropagation through their multi-step denoising process is numerically unstable. Existing methods work around this either by only using the value and discarding the gradient information, or by relying on approximations that sacrifice policy expressivity or bias the learned policy. QAM sidesteps both of these challenges by leveraging adjoint matching, a recently proposed technique in generative modeling, which transforms the critic&#x27;s action gradient to form a step-wise objective function that is free from unstable backpropagation, while providing an unbiased, expressive policy at the optimum. Combined with temporal-difference backup for critic learning, QAM consistently outperforms prior approaches on hard, sparse reward tasks in both offline and offline-to-online RL.</div></details>
<details class="detail"><summary>中文标题/摘要</summary>
<div class="mono"><b>标题：</b>伴随匹配Q学习</div>
<div class="mono" style="margin-top:8px">我们提出伴随匹配Q学习（QAM），这是一种基于时序差分的新型强化学习算法，解决了连续动作强化学习中长期存在的挑战：针对参数化Q函数高效优化表达能力强的扩散或流匹配策略。有效优化需要利用评论家的一阶信息，但对流或扩散策略而言，通过多步去噪过程进行基于梯度的反向传播优化存在数值不稳定性。现有方法要么仅使用价值函数而丢弃梯度信息，要么依赖近似方法牺牲策略表达能力或引入偏差。QAM通过采用生成建模中最新提出的伴随匹配技术，将评论家的动作梯度转化为分步目标函数，既避免了不稳定的反向传播，又在最优解处提供无偏且表达能力强的策略。结合评论家学习的时序差分更新，QAM在离线及离线到在线强化学习的困难稀疏奖励任务中持续超越现有方法。</div>
</details>
<details class="detail"><summary>Summary / 总结</summary>
<div class="mono">This work addresses the challenge of efficiently optimizing expressive diffusion or flow-matching policies in continuous-action reinforcement learning, where direct gradient-based optimization through the multi-step denoising process is numerically unstable. The proposed method, Q-learning with Adjoint Matching (QAM), leverages adjoint matching to transform the critic&#x27;s action gradient into a step-wise objective, avoiding unstable backpropagation while maintaining an unbiased and expressive policy at the optimum. Experimental results demonstrate that QAM, combined with temporal-difference backup for critic learning, consistently outperforms prior methods on hard, sparse reward tasks in both offline and offline-to-online RL settings.</div>
<div class="mono" style="margin-top:8px">该研究旨在解决连续动作强化学习中高效优化表达性扩散或流匹配策略的难题，其中通过多步去噪的直接梯度优化存在数值不稳定性。所提出的方法——伴随匹配Q学习（QAM）——利用伴随匹配技术将评论者的动作梯度转化为逐步目标函数，避免了不稳定的反向传播，同时保持了无偏且表达性强的策略。实验结果表明，在离线及离线到在线强化学习的困难稀疏奖励任务上，QAM持续优于现有方法。</div>
</details>
</div>
<div class="card">
<div class="title">KAGE-Bench: Fast Known-Axis Visual Generalization Evaluation for Reinforcement Learning</div>
<div class="meta-line">Authors: Egor Cherepanov, Daniil Zelezetsky, Alexey K. Kovalev, Aleksandr I. Panov</div>
<div class="meta-line">First: 2026-01-20T18:44:28+00:00 · Latest: 2026-01-20T18:44:28+00:00</div>
<div class="meta-line">Comments: 38 pages, 44 figures, 3 tables</div>
<div class="links" style="margin-top:8px"><a href="https://arxiv.org/abs/2601.14232v1">Abs</a> · <a href="https://arxiv.org/pdf/2601.14232v1">PDF</a> · <a href="https://huggingface.co/huggingface">Code1</a> · <a href="https://huggingface.co/docs/hub/spaces">Code2</a> · <a href="https://avanturist322.github.io/KAGEBench/">Project1</a></div>
<details class="detail"><summary>Abstract</summary>
<div class="mono">Pixel-based reinforcement learning agents often fail under purely visual distribution shift even when latent dynamics and rewards are unchanged, but existing benchmarks entangle multiple sources of shift and hinder systematic analysis. We introduce KAGE-Env, a JAX-native 2D platformer that factorizes the observation process into independently controllable visual axes while keeping the underlying control problem fixed. By construction, varying a visual axis affects performance only through the induced state-conditional action distribution of a pixel policy, providing a clean abstraction for visual generalization. Building on this environment, we define KAGE-Bench, a benchmark of six known-axis suites comprising 34 train-evaluation configuration pairs that isolate individual visual shifts. Using a standard PPO-CNN baseline, we observe strong axis-dependent failures, with background and photometric shifts often collapsing success, while agent-appearance shifts are comparatively benign. Several shifts preserve forward motion while breaking task completion, showing that return alone can obscure generalization failures. Finally, the fully vectorized JAX implementation enables up to 33M environment steps per second on a single GPU, enabling fast and reproducible sweeps over visual factors. Code: https://avanturist322.github.io/KAGEBench/.</div></details>
<details class="detail"><summary>中文标题/摘要</summary>
<div class="mono"><b>标题：</b>KAGE-Bench：面向强化学习的快速已知轴视觉泛化评估基准</div>
<div class="mono" style="margin-top:8px">基于像素的强化学习智能体常在纯视觉分布偏移下失效，即使潜在动态与奖励机制未变，但现有基准常混杂多种偏移源，阻碍系统分析。我们提出KAGE-Env——一个基于JAX的2D平台环境，它将观测过程分解为独立可控的视觉轴，同时保持底层控制问题不变。通过结构设计，改变视觉轴仅通过像素策略引发的状态条件动作分布影响性能，为视觉泛化提供清晰抽象框架。基于此环境，我们构建KAGE-Bench基准，包含6个已知轴测试套件共34组训练-评估配置对，可隔离单一视觉偏移。采用标准PPO-CNN基线实验发现：背景与光度偏移常导致任务完全失败，而智能体外貌偏移影响相对较小；部分偏移能维持前进动作却破坏任务完成，表明仅凭回报值可能掩盖泛化缺陷。全向量化JAX实现支持单GPU每秒3300万环境步长，实现视觉因素的高效可复现扫描。代码：https://avanturist322.github.io/KAGEBench/。</div>
</details>
<details class="detail"><summary>Summary / 总结</summary>
<div class="mono">The research addresses the challenge that pixel-based reinforcement learning agents often fail under visual distribution shifts despite unchanged latent dynamics and rewards, with existing benchmarks entangling multiple shift sources and hindering systematic analysis. The method introduces KAGE-Env, a JAX-native 2D platformer that factorizes the observation process into independently controllable visual axes while keeping the underlying control problem fixed, and defines KAGE-Bench, a benchmark of six known-axis suites comprising 34 train-evaluation pairs to isolate individual visual shifts. Experimental results using a standard PPO-CNN baseline reveal strong axis-dependent failures, where background and photometric shifts often collapse success while agent-appearance shifts are comparatively benign, and show that return alone can obscure generalization failures as some shifts preserve forward motion but break task completion; the fully vectorized JAX implementation enables up to 33M environment steps per second on a single GPU for fast, reproducible sweeps.</div>
<div class="mono" style="margin-top:8px">该研究针对基于像素的强化学习智能体在潜在动态和奖励不变的情况下，常因视觉分布偏移而失败的问题，现有基准测试混杂了多种偏移源，阻碍了系统分析。方法上引入了KAGE-Env，这是一个JAX原生的2D平台游戏环境，将观察过程分解为独立可控的视觉轴，同时保持底层控制问题不变，并定义了KAGE-Bench基准，包含六个已知轴套件和34个训练-评估配置对，以隔离个体视觉偏移。使用标准PPO-CNN基线的关键实验结果表明，存在强烈的轴依赖性失败：背景和光度偏移常导致成功率崩溃，而智能体外观偏移相对温和；一些偏移在保持前进运动的同时破坏了任务完成，表明仅靠回报可能掩盖泛化失败；完全向量化的JAX实现支持在单个GPU上每秒高达3300万环境步数，实现了快速、可重复的视觉因素扫描。</div>
</details>
</div>
<div class="card">
<div class="title">Attention-Based Offline Reinforcement Learning and Clustering for Interpretable Sepsis Treatment</div>
<div class="meta-line">Authors: Punit Kumar, Vaibhav Saran, Divyesh Patel, Nitin Kulkarni, Alina Vereshchaka</div>
<div class="meta-line">Venue: www</div>
<div class="meta-line">First: 2026-01-20T18:41:44+00:00 · Latest: 2026-01-20T18:41:44+00:00</div>
<div class="meta-line">Comments: 8 pages, 6 figures, Conference: IEEE International Conference on Machine Learning and Applications 2025 (ICMLA 2025): https://www.icmla-conference.org/icmla25/</div>
<div class="links" style="margin-top:8px"><a href="https://arxiv.org/abs/2601.14228v1">Abs</a> · <a href="https://arxiv.org/pdf/2601.14228v1">PDF</a> · <a href="https://huggingface.co/huggingface">Code1</a> · <a href="https://huggingface.co/docs/hub/spaces">Code2</a></div>
<details class="detail"><summary>Abstract</summary>
<div class="mono">Sepsis remains one of the leading causes of mortality in intensive care units, where timely and accurate treatment decisions can significantly impact patient outcomes. In this work, we propose an interpretable decision support framework. Our system integrates four core components: (1) a clustering-based stratification module that categorizes patients into low, intermediate, and high-risk groups upon ICU admission, using clustering with statistical validation; (2) a synthetic data augmentation pipeline leveraging variational autoencoders (VAE) and diffusion models to enrich underrepresented trajectories such as fluid or vasopressor administration; (3) an offline reinforcement learning (RL) agent trained using Advantage Weighted Regression (AWR) with a lightweight attention encoder and supported by an ensemble models for conservative, safety-aware treatment recommendations; and (4) a rationale generation module powered by a multi-modal large language model (LLM), which produces natural-language justifications grounded in clinical context and retrieved expert knowledge. Evaluated on the MIMIC-III and eICU datasets, our approach achieves high treatment accuracy while providing clinicians with interpretable and robust policy recommendations.</div></details>
<details class="detail"><summary>中文标题/摘要</summary>
<div class="mono"><b>标题：</b>基于注意力机制的离线强化学习与聚类在可解释性脓毒症治疗中的应用</div>
<div class="mono" style="margin-top:8px">脓毒症仍是重症监护病房的主要致死原因之一，及时准确的治疗决策对患者预后至关重要。本研究提出一个可解释的决策支持框架，系统集成四大核心模块：（1）基于聚类与统计验证的分层模块，在患者入住ICU时将其划分为低、中、高风险组；（2）利用变分自编码器与扩散模型的合成数据增强流程，扩充液体治疗或血管加压药使用等低代表性治疗轨迹；（3）采用优势加权回归训练的离线强化学习智能体，配备轻量级注意力编码器，并集成保守型安全感知治疗推荐模型；（4）基于多模态大语言模型的决策依据生成模块，结合临床语境与专家知识生成自然语言解释。在MIMIC-III和eICU数据集上的评估表明，本方法在实现高治疗准确率的同时，能为临床医生提供可解释且稳健的决策建议。</div>
</details>
<details class="detail"><summary>Summary / 总结</summary>
<div class="mono">To improve sepsis treatment decisions in intensive care units, this study develops an interpretable decision support framework. The method integrates patient risk stratification via clustering, synthetic data augmentation using VAE and diffusion models, an offline RL agent with AWR and attention mechanisms for safety-aware recommendations, and an LLM-based rationale generator. Experimental evaluation on MIMIC-III and eICU datasets demonstrates that the framework achieves high treatment accuracy while delivering interpretable and robust policy recommendations.</div>
<div class="mono" style="margin-top:8px">为改善重症监护室中脓毒症的治疗决策，本研究开发了一个可解释的决策支持框架。该方法整合了基于聚类的患者风险分层、使用VAE和扩散模型的合成数据增强、采用AWR和注意力机制的离线强化学习智能体以提供安全感知的治疗建议，以及基于大语言模型的原理生成模块。在MIMIC-III和eICU数据集上的实验结果表明，该方法实现了高治疗准确性，并提供了可解释的策略依据。</div>
</details>
</div>
<div class="card">
<div class="title">Deep Learning Approaches to Quantum Error Mitigation</div>
<div class="meta-line">Authors: Leonardo Placidi, Ifan Williams, Enrico Rinaldi, Daniel Mills, Cristina Cîrstoiu, Vanya Eccles, Ross Duncan</div>
<div class="meta-line">First: 2026-01-20T18:40:22+00:00 · Latest: 2026-01-20T18:40:22+00:00</div>
<div class="meta-line">Comments: 48 pages</div>
<div class="links" style="margin-top:8px"><a href="https://arxiv.org/abs/2601.14226v1">Abs</a> · <a href="https://arxiv.org/pdf/2601.14226v1">PDF</a> · <a href="https://huggingface.co/huggingface">Code1</a> · <a href="https://huggingface.co/docs/hub/spaces">Code2</a></div>
<details class="detail"><summary>Abstract</summary>
<div class="mono">We present a systematic investigation of deep learning methods applied to quantum error mitigation of noisy output probability distributions from measured quantum circuits. We compare different architectures, from fully connected neural networks to transformers, and we test different design/training modalities, identifying sequence-to-sequence, attention-based models as the most effective on our datasets. These models consistently produce mitigated distributions that are closer to the ideal outputs when tested on both simulated and real device data obtained from IBM superconducting quantum processing units (QPU) up to five qubits. Across several different circuit depths, our approach outperforms other baseline error mitigation techniques. We perform a series of ablation studies to examine: how different input features (circuit, device properties, noisy output statistics) affect performance; cross-dataset generalization across circuit families; and transfer learning to a different IBM QPU. We observe that generalization performance across similar devices with the same architecture works effectively, without needing to fully retrain models.</div></details>
<details class="detail"><summary>中文标题/摘要</summary>
<div class="mono"><b>标题：</b>深度学习在量子误差缓解中的应用研究</div>
<div class="mono" style="margin-top:8px">本文系统研究了深度学习在量子电路测量噪声输出概率分布的误差缓解中的应用。我们比较了从全连接神经网络到Transformer的不同架构，并测试了多种设计/训练模式，发现基于注意力机制的序列到序列模型在我们的数据集上表现最为有效。在模拟数据和IBM超导量子处理单元（QPU）最多五量子位的真实设备数据测试中，这些模型始终能生成更接近理想输出的缓解后分布。在多种不同电路深度下，我们的方法优于其他基线误差缓解技术。通过一系列消融研究，我们分析了不同输入特征（电路、设备属性、噪声输出统计）对性能的影响、跨电路族的数据集泛化能力，以及向不同IBM QPU的迁移学习效果。结果表明，相同架构的类似设备间泛化效果良好，无需完全重新训练模型。</div>
</details>
<details class="detail"><summary>Summary / 总结</summary>
<div class="mono">This research systematically explores deep learning methods for mitigating errors in noisy quantum circuit outputs, aiming to improve the accuracy of measured probability distributions. The study compares various neural network architectures, including fully connected networks and transformers, and identifies sequence-to-sequence attention-based models as the most effective. Experimental results on simulated and real IBM quantum devices with up to five qubits show that these models consistently produce mitigated distributions closer to ideal outputs, outperforming other baseline techniques across different circuit depths, and demonstrate effective generalization across similar devices without full retraining.</div>
<div class="mono" style="margin-top:8px">本研究旨在通过应用深度学习进行误差缓解，以提高含噪声量子计算的精度。该方法系统评估了包括全连接网络和Transformer在内的多种神经网络架构在模拟和真实IBM量子设备数据上的表现，确定序列到序列的注意力模型最为有效。关键实验结果表明，对于高达五个量子比特的不同电路深度，这些模型产生的概率分布比其他基线技术更接近理想输出，且消融研究证实模型能在相似量子设备间有效泛化而无需完全重新训练。</div>
</details>
</div>
<div class="card">
<div class="title">Zebra-Llama: Towards Extremely Efficient Hybrid Models</div>
<div class="meta-line">Authors: Mingyu Yang, Mehdi Rezagholizadeh, Guihong Li, Vikram Appia, Emad Barsoum</div>
<div class="meta-line">First: 2025-05-22T20:39:57+00:00 · Latest: 2026-01-20T18:39:03+00:00</div>
<div class="links" style="margin-top:8px"><a href="https://arxiv.org/abs/2505.17272v2">Abs</a> · <a href="https://arxiv.org/pdf/2505.17272v2">PDF</a> · <a href="https://huggingface.co/huggingface">Code1</a> · <a href="https://huggingface.co/docs/hub/spaces">Code2</a></div>
<details class="detail"><summary>Abstract</summary>
<div class="mono">With the growing demand for deploying large language models (LLMs) across diverse applications, improving their inference efficiency is crucial for sustainable and democratized access. However, retraining LLMs to meet new user-specific requirements is prohibitively expensive and environmentally unsustainable. In this work, we propose a practical and scalable alternative: composing efficient hybrid language models from existing pre-trained models. Our approach, Zebra-Llama, introduces a family of 1B, 3B, and 8B hybrid models by combining State Space Models (SSMs) and Multi-head Latent Attention (MLA) layers, using a refined initialization and post-training pipeline to efficiently transfer knowledge from pre-trained Transformers. Zebra-Llama achieves Transformer-level accuracy with near-SSM efficiency using only 7-11B training tokens (compared to trillions of tokens required for pre-training) and an 8B teacher. Moreover, Zebra-Llama dramatically reduces KV cache size -down to 3.9%, 2%, and 2.73% of the original for the 1B, 3B, and 8B variants, respectively-while preserving 100%, 100%, and &gt;97% of average zero-shot performance on LM Harness tasks. Compared to models like MambaInLLaMA, X-EcoMLA, Minitron, and Llamba, Zebra-Llama consistently delivers competitive or superior accuracy while using significantly fewer tokens, smaller teachers, and vastly reduced KV cache memory. Notably, Zebra-Llama-8B surpasses Minitron-8B in few-shot accuracy by 7% while using 8x fewer training tokens, over 12x smaller KV cache, and a smaller teacher (8B vs. 15B). It also achieves 2.6x-3.8x higher throughput (tokens/s) than MambaInLlama up to a 32k context length. We will release code and model checkpoints upon acceptance.</div></details>
<details class="detail"><summary>中文标题/摘要</summary>
<div class="mono"><b>标题：</b>Zebra-Llama：迈向极致高效的混合模型</div>
<div class="mono" style="margin-top:8px">随着大语言模型（LLMs）在多样化应用中的部署需求日益增长，提升其推理效率对于实现可持续且普惠的访问至关重要。然而，为满足用户特定需求而重新训练LLMs成本极高且环境不可持续。本研究提出一种实用且可扩展的替代方案：基于现有预训练模型构建高效混合语言模型。我们的Zebra-Llama方法通过融合状态空间模型（SSMs）与多头潜在注意力（MLA）层，构建了1B、3B和8B的混合模型系列，采用优化的初始化与后训练流程，高效迁移预训练Transformer的知识。Zebra-Llama仅需7-110亿训练词元（相比预训练所需的万亿级词元）和80亿参数的教师模型，即达到Transformer级精度与接近SSM的效率。此外，Zebra-Llama显著降低KV缓存大小——1B/3B/8B变体分别降至原始的3.9%、2%和2.73%——同时在LM Harness任务上保持100%、100%和&gt;97%的平均零样本性能。相较于MambaInLLaMA、X-EcoMLA、Minitron及Llamba等模型，Zebra-Llama在显著减少训练词元、缩小教师模型规模并大幅降低KV缓存占用的同时，持续提供具有竞争力或更优的精度。值得注意的是，Zebra-Llama-8B在少样本准确率上超越Minitron-8B达7%，且训练词元减少8倍、KV缓存缩小超12倍、教师模型更小（8B vs 15B）。在32k上下文长度内，其吞吐量（词元/秒）较MambaInLlama提升2.6-3.8倍。论文录用后将公开代码与模型检查点。</div>
</details>
<details class="detail"><summary>Summary / 总结</summary>
<div class="mono">To address the high cost and environmental impact of retraining large language models for diverse applications, this work proposes Zebra-Llama, a method for constructing efficient hybrid models by combining State Space Models and Multi-head Latent Attention layers. The approach uses a refined initialization and post-training pipeline to transfer knowledge from pre-trained Transformers, achieving Transformer-level accuracy with near-SSM efficiency using only 7-11B training tokens and an 8B teacher. Key experimental results show that Zebra-Llama variants dramatically reduce KV cache size to 2-3.9% of the original while preserving 97-100% of average zero-shot performance on LM Harness tasks, outperform models like Minitron-8B in few-shot accuracy by 7% with 8x fewer training tokens, and achieve 2.6x-3.8x higher throughput than MambaInLlama up to 32k context length.</div>
<div class="mono" style="margin-top:8px">为解决重新训练大语言模型以适应不同应用的高成本和环境影响，本研究提出了Zebra-Llama，一种通过结合状态空间模型和多头潜在注意力层来构建高效混合模型的方法。该方法采用精炼的初始化和后训练流程，从预训练的Transformer中迁移知识，仅需70-110亿训练令牌和一个80亿参数的教师模型。实验结果表明，Zebra-Llama在保持Transformer级别准确性的同时实现了接近SSM的效率，将KV缓存大小降至原始的2-3.9%，在LM Harness任务上保持了超过97%的平均零样本性能，并且与MambaInLLaMA和Minitron等现有模型相比，以更少的资源实现了更高的吞吐量和准确性。</div>
</details>
</div>
<div class="card">
<div class="title">Joint Score-Threshold Optimization for Interpretable Risk Assessment</div>
<div class="meta-line">Authors: Fardin Gankhanloo, Emmett Springer, Erik H. Hoyer, Daniel L. Young, Kimia Ghobadi</div>
<div class="meta-line">First: 2025-10-24T18:07:24+00:00 · Latest: 2026-01-20T18:20:51+00:00</div>
<div class="links" style="margin-top:8px"><a href="https://arxiv.org/abs/2510.21934v2">Abs</a> · <a href="https://arxiv.org/pdf/2510.21934v2">PDF</a> · <a href="https://huggingface.co/huggingface">Code1</a> · <a href="https://huggingface.co/docs/hub/spaces">Code2</a></div>
<details class="detail"><summary>Abstract</summary>
<div class="mono">Risk assessment tools in healthcare commonly employ point-based scoring systems that map patients to ordinal risk categories via thresholds. While electronic health record (EHR) data presents opportunities for data-driven optimization of these tools, two fundamental challenges impede standard supervised learning: (1) labels are often available only for extreme risk categories due to intervention-censored outcomes, and (2) misclassification cost is asymmetric and increases with ordinal distance. We propose a mixed-integer programming (MIP) framework that jointly optimizes scoring weights and category thresholds in the face of these challenges. Our approach prevents label-scarce category collapse via threshold constraints, and utilizes an asymmetric, distance-aware objective. The MIP framework supports governance constraints, including sign restrictions, sparsity, and minimal modifications to incumbent tools, ensuring practical deployability in clinical workflows. We further develop a continuous relaxation of the MIP problem to provide warm-start solutions for more efficient MIP optimization. We apply the proposed score optimization framework to a case study of inpatient falls risk assessment using the Johns Hopkins Fall Risk Assessment Tool.</div></details>
<details class="detail"><summary>中文标题/摘要</summary>
<div class="mono"><b>标题：</b>可解释风险评估的联合评分-阈值优化</div>
<div class="mono" style="margin-top:8px">医疗健康领域的风险评估工具通常采用基于分数的评分系统，通过阈值将患者映射至有序风险类别。尽管电子健康记录（EHR）数据为这些工具的数据驱动优化提供了契机，但两大根本挑战阻碍了标准监督学习的应用：（1）由于干预审查结果，标签通常仅适用于极端风险类别；（2）误分类成本具有不对称性，并随序数距离增加而上升。我们提出一种混合整数规划（MIP）框架，针对这些挑战联合优化评分权重与类别阈值。该方法通过阈值约束防止标签稀缺类别的塌缩，并采用非对称、距离感知的目标函数。MIP框架支持治理约束，包括符号限制、稀疏性以及对现有工具的最小修改，确保在临床工作流程中的实际可部署性。我们进一步开发了MIP问题的连续松弛形式，为更高效的MIP优化提供预热初始解。我们将所提出的评分优化框架应用于约翰斯·霍普金斯跌倒风险评估工具的住院患者跌倒风险评估案例研究。</div>
</details>
<details class="detail"><summary>Summary / 总结</summary>
<div class="mono">This research addresses two key challenges in data-driven optimization of healthcare risk assessment tools: the scarcity of labels for intermediate risk categories due to intervention-censored outcomes, and the asymmetric, distance-aware nature of misclassification costs. The authors propose a mixed-integer programming (MIP) framework that jointly optimizes the scoring weights and category thresholds, incorporating governance constraints for clinical deployability and a continuous relaxation for efficient optimization. In a case study applying the framework to the Johns Hopkins Fall Risk Assessment Tool for inpatient falls, the method successfully optimized the scoring system while adhering to practical clinical constraints.</div>
<div class="mono" style="margin-top:8px">本研究旨在解决医疗风险评分工具数据驱动优化中的两个关键挑战：由于干预导致的结果截断，中间风险类别的标签稀缺；以及误分类成本具有不对称性且随序数距离增加。作者提出了一个混合整数规划框架，可联合优化评分权重和定义序数风险类别的阈值。该方法结合了确保临床可部署性的治理约束，并利用连续松弛技术实现高效优化。在一个应用该框架优化约翰斯·霍普金斯跌倒风险评估工具（用于住院患者跌倒）的案例研究中，所提出的方法成功生成了一个可解释且实用的评分系统。</div>
</details>
</div>
<div class="card">
<div class="title">InT: Self-Proposed Interventions Enable Credit Assignment in LLM Reasoning</div>
<div class="meta-line">Authors: Matthew Y. R. Yang, Hao Bai, Ian Wu, Gene Yang, Amrith Setlur, Aviral Kumar</div>
<div class="meta-line">First: 2026-01-20T18:15:38+00:00 · Latest: 2026-01-20T18:15:38+00:00</div>
<div class="links" style="margin-top:8px"><a href="https://arxiv.org/abs/2601.14209v1">Abs</a> · <a href="https://arxiv.org/pdf/2601.14209v1">PDF</a> · <a href="https://huggingface.co/huggingface">Code1</a> · <a href="https://huggingface.co/docs/hub/spaces">Code2</a></div>
<details class="detail"><summary>Abstract</summary>
<div class="mono">Outcome-reward reinforcement learning (RL) has proven effective at improving the reasoning capabilities of large language models (LLMs). However, standard RL assigns credit only at the level of the final answer, penalizing entire reasoning traces when the outcome is incorrect and uniformly reinforcing all steps when it is correct. As a result, correct intermediate steps may be discouraged in failed traces, while spurious steps may be reinforced in successful ones. We refer to this failure mode as the problem of credit assignment. While a natural remedy is to train a process reward model, accurately optimizing such models to identify corrective reasoning steps remains challenging. We introduce Intervention Training (InT), a training paradigm in which the model performs fine-grained credit assignment on its own reasoning traces by proposing short, targeted corrections that steer trajectories toward higher reward. Using reference solutions commonly available in mathematical reasoning datasets and exploiting the fact that verifying a model-generated solution is easier than generating a correct one from scratch, the model identifies the first error in its reasoning and proposes a single-step intervention to redirect the trajectory toward the correct solution. We then apply supervised fine-tuning (SFT) to the on-policy rollout up to the point of error concatenated with the intervention, localizing error to the specific step that caused failure. We show that the resulting model serves as a far better initialization for RL training. After running InT and subsequent fine-tuning with RL, we improve accuracy by nearly 14% over a 4B-parameter base model on IMO-AnswerBench, outperforming larger open-source models such as gpt-oss-20b.</div></details>
<details class="detail"><summary>中文标题/摘要</summary>
<div class="mono"><b>标题：</b>InT：自提干预实现大语言模型推理中的信用分配</div>
<div class="mono" style="margin-top:8px">结果奖励强化学习（RL）已被证明能有效提升大语言模型（LLM）的推理能力。然而，标准RL仅对最终答案层面分配信用：当结果错误时惩罚整个推理轨迹，结果正确时则均匀强化所有步骤。这导致失败轨迹中正确的中间步骤可能被抑制，而成功轨迹中无关的步骤却被强化。我们将此失效模式称为信用分配问题。虽然训练过程奖励模型是一种自然解决方案，但精准优化此类模型以识别纠正性推理步骤仍具挑战性。本文提出干预训练（InT），该训练范式通过模型自主提出简短、有针对性的修正来引导轨迹获得更高奖励，从而对其推理轨迹进行细粒度信用分配。利用数学推理数据集中普遍存在的参考答案，并基于验证模型生成解比从头生成正确解更简单的事实，模型首先识别其推理中的首个错误，并提出单步干预以将轨迹重定向至正确解。随后，我们对错误发生前的策略轨迹与干预步骤进行拼接，通过监督微调（SFT）将错误定位至导致失败的具体步骤。实验表明，所得模型可作为RL训练更优的初始化基础。在IMO-AnswerBench上，经过InT及后续RL微调后，4B参数基模型的准确率提升近14%，性能超越gpt-oss-20b等更大规模开源模型。</div>
</details>
<details class="detail"><summary>Summary / 总结</summary>
<div class="mono">The research addresses the credit assignment problem in outcome-reward reinforcement learning for large language models, where entire reasoning traces are penalized or reinforced uniformly based on final answer correctness, potentially discouraging correct intermediate steps or reinforcing spurious ones. The method, Intervention Training (InT), enables the model to perform fine-grained credit assignment by identifying the first error in its own reasoning trace and proposing a single-step intervention to redirect the trajectory toward the correct solution, using reference solutions for verification; this is followed by supervised fine-tuning on the corrected trajectory. Experimental results show that InT significantly improves model initialization for subsequent RL training, leading to a nearly 14% accuracy gain over a 4B-parameter base model on IMO-AnswerBench and outperforming larger open-source models.</div>
<div class="mono" style="margin-top:8px">本研究针对大语言模型基于结果奖励的强化学习中的信用分配问题，即仅根据最终答案正确性对完整推理链进行统一奖惩，可能抑制正确中间步骤或强化错误步骤。提出的干预训练方法使模型能够进行细粒度信用分配，通过利用参考答案验证，识别自身推理链中的首个错误并提出单步干预以引导轨迹走向正确解，随后对修正后的轨迹段进行监督微调。实验结果表明，经过干预训练的模型可作为后续强化学习的更优初始化，在IMO-AnswerBench上相比4B参数基础模型准确率提升近14%，并超越了更大的开源模型。</div>
</details>
</div>
<div class="card">
<div class="title">Rig-Aware 3D Reconstruction of Vehicle Undercarriages using Gaussian Splatting</div>
<div class="meta-line">Authors: Nitin Kulkarni, Akhil Devarashetti, Charlie Cluss, Livio Forte, Dan Buckmaster, Philip Schneider, Chunming Qiao, Alina Vereshchaka</div>
<div class="meta-line">Venue: www</div>
<div class="meta-line">First: 2026-01-20T18:13:03+00:00 · Latest: 2026-01-20T18:13:03+00:00</div>
<div class="meta-line">Comments: 8 pages, 9 figures, Conference: IEEE International Conference on Machine Learning and Applications 2025 (ICMLA 2025): https://www.icmla-conference.org/icmla25/</div>
<div class="links" style="margin-top:8px"><a href="https://arxiv.org/abs/2601.14208v1">Abs</a> · <a href="https://arxiv.org/pdf/2601.14208v1">PDF</a> · <a href="https://huggingface.co/huggingface">Code1</a> · <a href="https://huggingface.co/docs/hub/spaces">Code2</a></div>
<details class="detail"><summary>Abstract</summary>
<div class="mono">Inspecting the undercarriage of used vehicles is a labor-intensive task that requires inspectors to crouch or crawl underneath each vehicle to thoroughly examine it. Additionally, online buyers rarely see undercarriage photos. We present an end-to-end pipeline that utilizes a three-camera rig to capture videos of the undercarriage as the vehicle drives over it, and produces an interactive 3D model of the undercarriage. The 3D model enables inspectors and customers to rotate, zoom, and slice through the undercarriage, allowing them to detect rust, leaks, or impact damage in seconds, thereby improving both workplace safety and buyer confidence. Our primary contribution is a rig-aware Structure-from-Motion (SfM) pipeline specifically designed to overcome the challenges of wide-angle lens distortion and low-parallax scenes. Our method overcomes the challenges of wide-angle lens distortion and low-parallax scenes by integrating precise camera calibration, synchronized video streams, and strong geometric priors from the camera rig. We use a constrained matching strategy with learned components, the DISK feature extractor, and the attention-based LightGlue matcher to generate high-quality sparse point clouds that are often unattainable with standard SfM pipelines. These point clouds seed the Gaussian splatting process to generate photorealistic undercarriage models that render in real-time. Our experiments and ablation studies demonstrate that our design choices are essential to achieve state-of-the-art quality.</div></details>
<details class="detail"><summary>中文标题/摘要</summary>
<div class="mono"><b>标题：</b>基于高斯泼溅的车辆底盘三维重建系统</div>
<div class="mono" style="margin-top:8px">二手车底盘检测是项劳动密集型任务，检测员需蹲伏或爬入车底进行细致检查，且线上买家鲜少能查看底盘照片。本文提出一种端到端流程：利用三相机阵列采集车辆驶过时的底盘视频，并生成可交互的底盘三维模型。该模型支持检测员与客户旋转、缩放及剖切观察底盘，可在数秒内识别锈蚀、泄漏或碰撞损伤，从而提升工作安全性与买家信任度。核心贡献在于专为克服广角镜头畸变和低视差场景挑战设计的阵列感知运动恢复结构流程。该方法通过整合精密相机标定、同步视频流及阵列几何先验，结合带学习组件的约束匹配策略、DISK特征提取器和基于注意力的LightGlue匹配器，生成标准SfM流程难以实现的高质量稀疏点云。这些点云作为高斯泼溅过程的初始数据，可实时渲染生成逼真的底盘三维模型。实验与消融研究证实了本设计方案对实现顶尖质量的关键作用。</div>
</details>
<details class="detail"><summary>Summary / 总结</summary>
<div class="mono">The research aims to automate the labor-intensive inspection of vehicle undercarriages and provide online buyers with visual access, addressing workplace safety and buyer confidence. The method employs a three-camera rig to capture synchronized videos, followed by a rig-aware Structure-from-Motion pipeline that integrates precise calibration, geometric priors, and a constrained matching strategy using DISK features and LightGlue to handle wide-angle distortion and low parallax, ultimately generating sparse point clouds for Gaussian splatting to produce real-time, photorealistic 3D models. Experimental results confirm that this approach achieves state-of-the-art reconstruction quality, enabling interactive inspection for detecting rust, leaks, or damage.</div>
<div class="mono" style="margin-top:8px">这项研究的动机在于手动检查车辆底盘既费时费力又不安全，且在线买家通常无法查看底盘照片。该方法提出了一种端到端的流程，使用三摄像头装置采集同步视频，其核心是一种装置感知的运动恢复结构技术，结合了精确校准、使用DISK特征和LightGlue的约束匹配策略，以及高斯泼溅进行三维重建。实验结果表明，该流程克服了广角畸变和低视差等挑战，生成了高质量稀疏点云和逼真的实时可渲染三维模型，能够高效检测锈蚀、泄漏和损坏。</div>
</details>
</div>
<div class="card">
<div class="title">Differentiated Pickup Point Offering for Emission Reduction in Last-Mile Delivery</div>
<div class="meta-line">Authors: Albina Galiullina, Wouter van Heeswijk, Tom van Woensel</div>
<div class="meta-line">First: 2026-01-20T18:00:42+00:00 · Latest: 2026-01-20T18:00:42+00:00</div>
<div class="links" style="margin-top:8px"><a href="https://arxiv.org/abs/2601.14196v1">Abs</a> · <a href="https://arxiv.org/pdf/2601.14196v1">PDF</a> · <a href="https://huggingface.co/huggingface">Code1</a> · <a href="https://huggingface.co/docs/hub/spaces">Code2</a></div>
<details class="detail"><summary>Abstract</summary>
<div class="mono">Pickup points are widely recognized as a sustainable alternative to home delivery, as consolidating orders at pickup locations can shorten delivery routes and improve first-attempt success rates. However, these benefits may be negated when customers drive to pick up their orders. This study proposes a Differentiated Pickup Point Offering (DPO) policy that aims to jointly reduce emissions from delivery truck routes and customer travel. Under DPO, each arriving customer is offered a single recommended pickup point, rather than an unrestricted choice among all locations, while retaining the option of home delivery. We study this problem in a dynamic and stochastic setting, where the pickup point offered to each customer depends on previously realized customer locations and delivery choices. To design effective DPO policies, we adopt a reinforcement learning-based approach that accounts for spatial relationships between customers and pickup points and their implications for future route consolidation. Computational experiments show that differentiated pickup point offerings can substantially reduce total carbon emissions. The proposed policies reduce total emissions by up to 9% relative to home-only delivery and by 2% on average compared with alternative policies, including unrestricted pickup point choice and nearest pickup point assignment. Differentiated offerings are particularly effective in dense urban settings with many pickup points and short inter-location distances. Moreover, explicitly accounting for the dynamic nature of customer arrivals and choices is especially important when customers are less inclined to choose pickup point delivery over home delivery.</div></details>
<details class="detail"><summary>中文标题/摘要</summary>
<div class="mono"><b>标题：</b>差异化自提点服务在最后一公里配送中的减排应用</div>
<div class="mono" style="margin-top:8px">自提点作为家庭配送的可持续替代方案被广泛认可，因其通过订单整合可缩短配送路径并提高首次投递成功率。然而，当顾客驾车取件时，这些优势可能被抵消。本研究提出一种差异化自提点服务政策，旨在同步减少配送车辆路线与顾客出行的碳排放。该政策为每位顾客仅推荐一个自提点，而非开放所有点位的自由选择，同时保留家庭配送选项。研究基于动态随机场景展开，推荐策略取决于历史顾客位置与配送选择。通过采用强化学习方法，设计出能兼顾顾客与自提点空间关联及未来路径整合效应的策略。计算实验表明，差异化推荐可显著降低总碳排放量：相较于纯家庭配送最高减排9%，较无限制自提点选择或最近点位分配等策略平均减排2%。该策略在自提点密集、点位间距短的稠密城区效果尤为显著，且当顾客对自提点配送意愿较低时，动态考量顾客到达与选择行为显得至关重要。</div>
</details>
<details class="detail"><summary>Summary / 总结</summary>
<div class="mono">This study addresses the environmental trade-off in last-mile delivery where pickup points can reduce delivery emissions but may increase customer travel emissions if customers drive to collect orders. The authors propose a Differentiated Pickup Point Offering (DPO) policy, which uses reinforcement learning to dynamically recommend a single pickup point to each customer based on prior deliveries and spatial relationships, aiming to consolidate future delivery routes while preserving home delivery as an option. Experimental results demonstrate that DPO reduces total carbon emissions by up to 9% compared to home-only delivery and by an average of 2% over alternative policies like unrestricted choice or nearest-point assignment, with particular effectiveness in dense urban areas with many closely spaced pickup points.</div>
<div class="mono" style="margin-top:8px">本研究针对最后一公里配送中的环境权衡问题：取件点虽能减少配送排放，但若顾客驾车取件则可能增加出行排放。作者提出了一种差异化取件点提供（DPO）策略，采用强化学习方法，根据空间关系和历史配送选择，动态为每位顾客推荐单一取件点，同时保留送货上门选项。实验表明，DPO策略相比纯送货上门可减少高达9%的总碳排放，相比无限制取件点选择或最近点分配策略平均减少2%，在取件点密集、距离短的稠密城区以及顾客对取件点配送偏好较低时效果尤为显著。</div>
</details>
</div>
<div class="card">
<div class="title">Tensorization of neural networks for improved privacy and interpretability</div>
<div class="meta-line">Authors: José Ramón Pareja Monturiol, Alejandro Pozas-Kerstjens, David Pérez-García</div>
<div class="meta-line">Venue: SciPost Phys. Core 8, 095 (2025)</div>
<div class="meta-line">First: 2025-01-10T19:00:06+00:00 · Latest: 2026-01-20T17:48:40+00:00</div>
<div class="meta-line">Comments: 44 pages, 9 figures, 3 tables. The code for the experiments is publicly available at https://github.com/joserapa98/tensorization-nns. V3: Published version</div>
<div class="links" style="margin-top:8px"><a href="https://arxiv.org/abs/2501.06300v3">Abs</a> · <a href="https://arxiv.org/pdf/2501.06300v3">PDF</a> · <a href="https://github.com/joserapa98/tensorization-nns">Code1</a> · <a href="https://huggingface.co/huggingface">Code2</a> · <a href="https://huggingface.co/docs/hub/spaces">Code3</a></div>
<details class="detail"><summary>Abstract</summary>
<div class="mono">We present a tensorization algorithm for constructing tensor train/matrix product state (MPS) representations of functions, drawing on sketching and cross interpolation ideas. The method only requires black-box access to the target function and a small set of sample points defining the domain of interest. Thus, it is particularly well-suited for machine learning models, where the domain of interest is naturally defined by the training dataset. We show that this approach can be used to enhance the privacy and interpretability of neural network models. Specifically, we apply our decomposition to (i) obfuscate neural networks whose parameters encode patterns tied to the training data distribution, and (ii) estimate topological phases of matter that are easily accessible from the MPS representation. Additionally, we show that this tensorization can serve as an efficient initialization method for optimizing MPS in general settings, and that, for model compression, our algorithm achieves a superior trade-off between memory and time complexity compared to conventional tensorization methods of neural networks.</div></details>
<details class="detail"><summary>中文标题/摘要</summary>
<div class="mono"><b>标题：</b>神经网络张量化以提升隐私性与可解释性</div>
<div class="mono" style="margin-top:8px">我们提出一种基于草图与交叉插值思想的张量化算法，用于构建函数的张量网络/矩阵乘积态表示。该方法仅需通过黑盒访问目标函数及少量定义感兴趣域的采样点，因此特别适用于机器学习模型——其感兴趣域自然由训练数据集定义。我们证明该方法可用于增强神经网络模型的隐私性与可解释性：具体而言，我们将分解应用于（1）混淆那些参数编码了训练数据分布相关模式的神经网络；（2）从矩阵乘积态表示中便捷估计物质的拓扑相。此外，该张量化可作为通用场景下优化矩阵乘积态的高效初始化方法；在模型压缩方面，相较于传统神经网络张量化方法，本算法在内存与时间复杂度间实现了更优的权衡。</div>
</details>
<details class="detail"><summary>Summary / 总结</summary>
<div class="mono">This research aims to enhance the privacy and interpretability of neural networks by converting them into tensor train/matrix product state (MPS) representations. The proposed method constructs these representations via a tensorization algorithm that relies on sketching and cross interpolation, requiring only black-box access to the target function and a small set of sample points from the domain defined by the training data. Experimental results demonstrate that the approach effectively obfuscates neural networks to protect training data patterns and facilitates the estimation of topological phases of matter from the MPS structure; it also serves as an efficient MPS initialization method and achieves a superior memory-time trade-off for model compression compared to conventional tensorization techniques.</div>
<div class="mono" style="margin-top:8px">本研究旨在通过将神经网络转换为张量网络/矩阵乘积态（MPS）表示，以提升其隐私性和可解释性。所提出的方法通过张量化算法构建这些表示，仅需对目标函数进行黑盒访问以及来自训练数据域的一小组样本点。实验结果表明，该分解方法能有效混淆神经网络参数以保护训练数据模式，并可直接从MPS结构中便捷地估计物质的拓扑相。此外，该算法可作为高效的MPS初始化技术，并在模型压缩方面相比传统张量化方法实现了更优的内存-时间权衡。</div>
</details>
</div>
<div class="card">
<div class="title">A model of errors in transformers</div>
<div class="meta-line">Authors: Suvrat Raju, Praneeth Netrapalli</div>
<div class="meta-line">First: 2026-01-20T17:27:03+00:00 · Latest: 2026-01-20T17:27:03+00:00</div>
<div class="meta-line">Comments: 8+17pages</div>
<div class="links" style="margin-top:8px"><a href="https://arxiv.org/abs/2601.14175v1">Abs</a> · <a href="https://arxiv.org/pdf/2601.14175v1">PDF</a> · <a href="https://huggingface.co/huggingface">Code1</a> · <a href="https://huggingface.co/docs/hub/spaces">Code2</a></div>
<details class="detail"><summary>Abstract</summary>
<div class="mono">We study the error rate of LLMs on tasks like arithmetic that require a deterministic output, and repetitive processing of tokens drawn from a small set of alternatives. We argue that incorrect predictions arise when small errors in the attention mechanism accumulate to cross a threshold, and use this insight to derive a quantitative two-parameter relationship between the accuracy and the complexity of the task. The two parameters vary with the prompt and the model; they can be interpreted in terms of an elementary noise rate, and the number of plausible erroneous tokens that can be predicted. Our analysis is inspired by an ``effective field theory&#x27;&#x27; perspective: the LLM&#x27;s many raw parameters can be reorganized into just two parameters that govern the error rate. We perform extensive empirical tests, using Gemini 2.5 Flash, Gemini 2.5 Pro and DeepSeek R1, and find excellent agreement between the predicted and observed accuracy for a variety of tasks, although we also identify deviations in some cases. Our model provides an alternative to suggestions that errors made by LLMs on long repetitive tasks indicate the ``collapse of reasoning&#x27;&#x27;, or an inability to express ``compositional&#x27;&#x27; functions. Finally, we show how to construct prompts to reduce the error rate.</div></details>
<details class="detail"><summary>中文标题/摘要</summary>
<div class="mono"><b>标题：</b>Transformer模型中的误差模型</div>
<div class="mono" style="margin-top:8px">本研究针对需要确定性输出且涉及小规模备选词元重复处理的任务（如算术），考察了大语言模型（LLM）的误差率。我们认为，当注意力机制中的微小误差累积超过阈值时，就会产生错误预测，并基于此推导出任务准确率与复杂度之间的定量双参数关系。这两个参数随提示词和模型而变化，可分别解释为基本噪声率与可能被预测的合理错误词元数量。我们的分析受“有效场论”视角启发：LLM的大量原始参数可重组为仅控制误差率的两个参数。我们使用Gemini 2.5 Flash、Gemini 2.5 Pro和DeepSeek R1进行了大量实证测试，发现多种任务的预测准确率与观测准确率高度吻合（尽管某些案例存在偏差）。该模型为“长重复任务中的LLM错误意味着‘推理崩溃’或无法表达‘组合式’函数”的观点提供了替代解释。最后，我们展示了如何构建提示词以降低误差率。</div>
</details>
<details class="detail"><summary>Summary / 总结</summary>
<div class="mono">This research investigates the error rates of large language models (LLMs) on deterministic, repetitive tasks like arithmetic, where outputs are drawn from a small set of alternatives. The authors propose that errors originate from the accumulation of small inaccuracies in the attention mechanism, which eventually cross a critical threshold. This insight leads to a quantitative two-parameter model relating task complexity to accuracy, where the parameters represent an elementary noise rate and the number of plausible erroneous tokens. Inspired by an effective field theory perspective, the model condenses many raw parameters into these two governing factors. Extensive empirical tests with models including Gemini 2.5 Flash, Gemini 2.5 Pro, and DeepSeek R1 show excellent agreement between predicted and observed accuracy across various tasks, though some deviations are noted. The findings challenge interpretations that errors indicate a fundamental &quot;collapse of reasoning&quot; or inability to handle compositional functions, and the study demonstrates how prompts can be constructed to reduce error rates.</div>
<div class="mono" style="margin-top:8px">本研究旨在探究大型语言模型在算术等确定性、重复性任务上产生错误的原因，这类任务的输出来自一个小的备选集合。作者提出，错误源于注意力机制中微小不准确性的累积，最终超过一个临界阈值。基于这一见解，他们推导出一个定量的双参数模型，将任务复杂度与准确率联系起来，这两个参数分别代表基本噪声率和可能的错误标记数量。受有效场论视角启发，该模型将大量原始参数浓缩为这两个主导因素。通过对包括Gemini 2.5 Flash、Gemini 2.5 Pro和DeepSeek R1在内的模型进行广泛实证测试，结果发现在多种任务上预测准确率与观测准确率高度吻合，但也识别出一些偏差情况。这些发现挑战了将此类错误解释为“推理崩溃”或无法处理组合函数的观点，并展示了如何通过构建提示词来降低错误率。</div>
</details>
</div>
<div class="card">
<div class="title">Penalizing Localized Dirichlet Energies in Low Rank Tensor Products</div>
<div class="meta-line">Authors: Paris A. Karakasis, Nicholas D. Sidiropoulos</div>
<div class="meta-line">First: 2026-01-20T17:25:47+00:00 · Latest: 2026-01-20T17:25:47+00:00</div>
<div class="meta-line">Comments: 19 pages</div>
<div class="links" style="margin-top:8px"><a href="https://arxiv.org/abs/2601.14173v1">Abs</a> · <a href="https://arxiv.org/pdf/2601.14173v1">PDF</a> · <a href="https://huggingface.co/huggingface">Code1</a> · <a href="https://huggingface.co/docs/hub/spaces">Code2</a></div>
<details class="detail"><summary>Abstract</summary>
<div class="mono">We study low-rank tensor-product B-spline (TPBS) models for regression tasks and investigate Dirichlet energy as a measure of smoothness. We show that TPBS models admit a closed-form expression for the Dirichlet energy, and reveal scenarios where perfect interpolation is possible with exponentially small Dirichlet energy. This renders global Dirichlet energy-based regularization ineffective. To address this limitation, we propose a novel regularization strategy based on local Dirichlet energies defined on small hypercubes centered at the training points. Leveraging pretrained TPBS models, we also introduce two estimators for inference from incomplete samples. Comparative experiments with neural networks demonstrate that TPBS models outperform neural networks in the overfitting regime for most datasets, and maintain competitive performance otherwise. Overall, TPBS models exhibit greater robustness to overfitting and consistently benefit from regularization, while neural networks are more sensitive to overfitting and less effective in leveraging regularization.</div></details>
<details class="detail"><summary>中文标题/摘要</summary>
<div class="mono"><b>标题：</b>低秩张量积中局部狄利克雷能量的惩罚机制研究</div>
<div class="mono" style="margin-top:8px">本研究探讨了用于回归任务的低秩张量积B样条模型，并以狄利克雷能量作为平滑性度量指标。研究表明，该模型存在狄利克雷能量的闭式表达式，并揭示了在指数级微小狄利克雷能量下仍可实现完美插值的情形，这导致基于全局狄利克雷能量的正则化方法失效。为突破此局限，我们提出一种基于训练点中心超立方体局部狄利克雷能量的新型正则化策略。借助预训练的TPBS模型，我们还提出了两种从不完整样本进行推断的估计器。与神经网络的对比实验表明：在多数数据集的过拟合场景下，TPBS模型表现优于神经网络；在其他场景中仍保持竞争力。总体而言，TPBS模型对过拟合具有更强鲁棒性且能持续受益于正则化，而神经网络对过拟合更敏感且利用正则化的效果较弱。</div>
</details>
<details class="detail"><summary>Summary / 总结</summary>
<div class="mono">This research addresses the ineffectiveness of global Dirichlet energy regularization in low-rank tensor-product B-spline (TPBS) models for regression, as these models can achieve perfect data interpolation with exponentially small global energy. To overcome this, the authors propose a novel regularization method that penalizes localized Dirichlet energies computed on small hypercubes around each training point, and they introduce two estimators for inference from incomplete samples using pretrained TPBS models. Experimental comparisons with neural networks show that TPBS models are more robust to overfitting, outperform neural networks in overfitting regimes on most datasets, and consistently benefit from regularization, whereas neural networks are more prone to overfitting and gain less from regularization.</div>
<div class="mono" style="margin-top:8px">本研究针对低秩张量积B样条（TPBS）回归模型中全局狄利克雷能量正则化失效的问题，因为该模型能以指数级小的能量实现完美插值。为此，作者提出了一种基于训练点周围小超立方体上局部狄利克雷能量的新型正则化策略，并利用预训练的TPBS模型引入了两种从不完整样本进行推断的估计器。实验结果表明，在大多数数据集的过拟合情况下，TPBS模型优于神经网络，其他情况下性能相当；TPBS模型对过拟合更具鲁棒性且能持续受益于正则化，而神经网络则对过拟合更敏感且利用正则化的效果较差。</div>
</details>
</div>
<div class="card">
<div class="title">DiffRatio: Training One-Step Diffusion Models Without Teacher Supervision</div>
<div class="meta-line">Authors: Wenlin Chen, Mingtian Zhang, Jiajun He, Zijing Ou, José Miguel Hernández-Lobato, Bernhard Schölkopf, David Barber</div>
<div class="meta-line">First: 2025-02-11T23:02:14+00:00 · Latest: 2026-01-20T17:24:34+00:00</div>
<div class="meta-line">Comments: 21 pages, 8 figures, 5 tables, 2 algorithms</div>
<div class="links" style="margin-top:8px"><a href="https://arxiv.org/abs/2502.08005v4">Abs</a> · <a href="https://arxiv.org/pdf/2502.08005v4">PDF</a> · <a href="https://huggingface.co/huggingface">Code1</a> · <a href="https://huggingface.co/docs/hub/spaces">Code2</a></div>
<details class="detail"><summary>Abstract</summary>
<div class="mono">Score-based distillation methods (e.g., variational score distillation) train one-step diffusion models by first pre-training a teacher score model and then distilling it into a one-step student model. However, the gradient estimator in the distillation stage usually suffers from two sources of bias: (1) biased teacher supervision due to score estimation error incurred during pre-training, and (2) the student model&#x27;s score estimation error during distillation. These biases can degrade the quality of the resulting one-step diffusion model. To address this, we propose DiffRatio, a new framework for training one-step diffusion models: instead of estimating the teacher and student scores independently and then taking their difference, we directly estimate the score difference as the gradient of a learned log density ratio between the student and data distributions across diffusion time steps. This approach greatly simplifies the training pipeline, significantly reduces gradient estimation bias, and improves one-step generation quality. Additionally, it also reduces auxiliary network size by using a lightweight density-ratio network instead of two full score networks, which improves computational and memory efficiency. DiffRatio achieves competitive one-step generation results on CIFAR-10 and ImageNet (64x64 and 512x512), outperforming most teacher-supervised distillation approaches.</div></details>
<details class="detail"><summary>中文标题/摘要</summary>
<div class="mono"><b>标题：</b>DiffRatio：无需教师监督的一步扩散模型训练方法</div>
<div class="mono" style="margin-top:8px">基于分数的蒸馏方法（如变分分数蒸馏）通过先预训练教师分数模型，再将其蒸馏为一步学生模型来训练一步扩散模型。然而，蒸馏阶段的梯度估计器通常存在两种偏差来源：（1）预训练中分数估计误差导致的教师监督偏差；（2）蒸馏过程中学生模型的分数估计误差。这些偏差会降低最终一步扩散模型的质量。为此，我们提出DiffRatio，一种训练一步扩散模型的新框架：不再独立估计教师和学生分数后计算其差值，而是直接估计分数差，将其视为学生分布与数据分布之间在扩散时间步上的对数密度比梯度的学习结果。该方法大幅简化了训练流程，显著减少了梯度估计偏差，并提升了一步生成质量。此外，通过使用轻量级密度比网络替代两个完整的分数网络，还减少了辅助网络规模，提高了计算和内存效率。DiffRatio在CIFAR-10和ImageNet（64x64与512x512）数据集上取得具有竞争力的一步生成结果，优于多数基于教师监督的蒸馏方法。</div>
</details>
<details class="detail"><summary>Summary / 总结</summary>
<div class="mono">The research aims to improve one-step diffusion model training by addressing biases in existing score-based distillation methods, which rely on pre-trained teacher models and suffer from gradient estimation errors due to both teacher and student score inaccuracies. The proposed method, DiffRatio, directly estimates the score difference as the gradient of a learned log density ratio between student and data distributions across diffusion time steps, eliminating the need for separate teacher supervision and simplifying the training pipeline. Experimental results show that DiffRatio reduces gradient bias, enhances one-step generation quality, and improves computational efficiency by using a lightweight density-ratio network, achieving competitive performance on CIFAR-10 and ImageNet datasets compared to teacher-supervised approaches.</div>
<div class="mono" style="margin-top:8px">本研究旨在改进一步扩散模型的训练，解决现有基于分数的蒸馏方法中存在的偏差问题，这些偏差源于教师模型在预训练中的分数估计误差以及学生模型在蒸馏过程中的误差。提出的DiffRatio方法直接估计分数差异，将其作为学生分布与数据分布之间跨扩散时间步的学得对数密度比梯度，从而无需独立的教师和学生分数网络，简化了训练流程。实验结果表明，DiffRatio减少了梯度估计偏差，提升了一步生成质量，并提高了计算效率，在CIFAR-10和ImageNet数据集上取得了有竞争力的性能，优于大多数教师监督的蒸馏方法。</div>
</details>
</div>
<div class="card">
<div class="title">WaveletInception Networks for on-board Vibration-Based Infrastructure Health Monitoring</div>
<div class="meta-line">Authors: Reza Riahi Samani, Alfredo Nunez, Bart De Schutter</div>
<div class="meta-line">First: 2025-07-17T10:14:20+00:00 · Latest: 2026-01-20T17:19:43+00:00</div>
<div class="meta-line">Comments: Under reviewer for the Journal of Engineering Application of Artificial Intelligence</div>
<div class="links" style="margin-top:8px"><a href="https://arxiv.org/abs/2507.12969v2">Abs</a> · <a href="https://arxiv.org/pdf/2507.12969v2">PDF</a> · <a href="https://huggingface.co/huggingface">Code1</a> · <a href="https://huggingface.co/docs/hub/spaces">Code2</a></div>
<details class="detail"><summary>Abstract</summary>
<div class="mono">This paper presents a deep learning framework for analyzing on board vibration response signals in infrastructure health monitoring. The proposed WaveletInception-BiGRU network uses a Learnable Wavelet Packet Transform (LWPT) for early spectral feature extraction, followed by one-dimensional Inception-Residual Network (1D Inception-ResNet) modules for multi-scale, high-level feature learning. Bidirectional Gated Recurrent Unit (BiGRU) modules then integrate temporal dependencies and incorporate operational conditions, such as the measurement speed. This approach enables effective analysis of vibration signals recorded at varying speeds, eliminating the need for explicit signal preprocessing. The sequential estimation head further leverages bidirectional temporal information to produce an accurate, localized assessment of infrastructure health. Ultimately, the framework generates high-resolution health profiles spatially mapped to the physical layout of the infrastructure. Case studies involving track stiffness regression and transition zone classification using real-world measurements demonstrate that the proposed framework significantly outperforms state-of-the-art methods, underscoring its potential for accurate, localized, and automated on-board infrastructure health monitoring.</div></details>
<details class="detail"><summary>中文标题/摘要</summary>
<div class="mono"><b>标题：</b>基于小波初始网络的车载振动基础设施健康监测</div>
<div class="mono" style="margin-top:8px">本文提出一种用于基础设施健康监测中车载振动响应信号分析的深度学习框架。所提出的WaveletInception-BiGRU网络采用可学习小波包变换进行早期频谱特征提取，随后通过一维初始残差网络模块实现多尺度高级特征学习。双向门控循环单元模块进一步整合时序依赖关系并纳入测量速度等运行工况。该方法能有效分析不同速度下记录的振动信号，无需显式信号预处理。序列估计头通过双向时序信息生成精确、局部化的基础设施健康评估。最终，该框架生成高分辨率健康图谱，并空间映射至基础设施的物理布局。通过实测数据进行的轨道刚度回归与过渡区分类案例研究表明，所提框架显著优于现有先进方法，凸显了其在精确、局部化、自动化车载基础设施健康监测中的应用潜力。</div>
</details>
<details class="detail"><summary>Summary / 总结</summary>
<div class="mono">This research addresses the need for automated and accurate infrastructure health monitoring using on-board vibration signals, which are often recorded at varying operational speeds and require robust analysis without extensive preprocessing. The proposed WaveletInception-BiGRU network integrates a Learnable Wavelet Packet Transform for spectral feature extraction, 1D Inception-ResNet modules for multi-scale feature learning, and Bidirectional Gated Recurrent Units to capture temporal dependencies and incorporate operational conditions like speed. Experimental results from real-world case studies on track stiffness regression and transition zone classification show that this framework significantly outperforms existing state-of-the-art methods, enabling high-resolution, localized health assessments mapped to the physical infrastructure.</div>
<div class="mono" style="margin-top:8px">本研究旨在解决基础设施健康监测中无需显式预处理即可分析不同速度下记录的振动信号的挑战。提出的WaveletInception-BiGRU网络结合了可学习小波包变换进行频谱特征提取、一维Inception-ResNet模块进行多尺度特征学习，以及双向门控循环单元模块来整合时间依赖性和测量速度等运行条件。在真实轨道刚度回归和过渡区分类任务上的实验结果表明，该框架显著优于现有先进方法，能够实现精确、局部的健康评估，并将其空间映射到物理基础设施布局上。</div>
</details>
</div>
<div class="card">
<div class="title">Generative Language Models on Nucleotide Sequences of Human Genes</div>
<div class="meta-line">Authors: Musa Nuri Ihtiyar, Arzucan Ozgur</div>
<div class="meta-line">Venue: Scientific Reports, 2024, 14.1: 22204</div>
<div class="meta-line">First: 2023-07-20T06:59:02+00:00 · Latest: 2026-01-20T17:19:40+00:00</div>
<div class="links" style="margin-top:8px"><a href="https://arxiv.org/abs/2307.10634v3">Abs</a> · <a href="https://arxiv.org/pdf/2307.10634v3">PDF</a> · <a href="https://huggingface.co/huggingface">Code1</a> · <a href="https://huggingface.co/docs/hub/spaces">Code2</a></div>
<details class="detail"><summary>Abstract</summary>
<div class="mono">Language models, especially transformer-based ones, have achieved colossal success in NLP. To be precise, studies like BERT for NLU and works like GPT-3 for NLG are very important. If we consider DNA sequences as a text written with an alphabet of four letters representing the nucleotides, they are similar in structure to natural languages. This similarity has led to the development of discriminative language models such as DNABert in the field of DNA-related bioinformatics. To our knowledge, however, the generative side of the coin is still largely unexplored. Therefore, we have focused on the development of an autoregressive generative language model such as GPT-3 for DNA sequences. Since working with whole DNA sequences is challenging without extensive computational resources, we decided to conduct our study on a smaller scale and focus on nucleotide sequences of human genes rather than the whole DNA. This decision has not changed the structure of the problem, as both DNA and genes can be considered as 1D sequences consisting of four different nucleotides without losing much information and without oversimplification. Firstly, we systematically studied an almost entirely unexplored problem and observed that RNNs perform best, while simple techniques such as N-grams are also promising. Another beneficial point was learning how to work with generative models on languages we do not understand, unlike natural languages. The importance of using real-world tasks beyond classical metrics such as perplexity was noted. In addition, we examined whether the data-hungry nature of these models can be altered by selecting a language with minimal vocabulary size, four due to four different types of nucleotides. The reason for reviewing this was that choosing such a language might make the problem easier. However, in this study, we found that this did not change the amount of data required very much.</div></details>
<details class="detail"><summary>中文标题/摘要</summary>
<div class="mono"><b>标题：</b>基于人类基因核苷酸序列的生成式语言模型</div>
<div class="mono" style="margin-top:8px">语言模型，特别是基于Transformer的模型，在自然语言处理领域取得了巨大成功。具体而言，像BERT这样的自然语言理解研究和GPT-3这样的自然语言生成工作非常重要。若将DNA序列视为由代表四种核苷酸的字母表构成的文本，其结构类似于自然语言。这种相似性促使DNA相关生物信息学领域开发了判别式语言模型，如DNABert。然而据我们所知，生成式模型方面仍存在大量未探索空间。因此，我们专注于开发针对DNA序列的自回归生成式语言模型（如GPT-3）。由于在缺乏充足计算资源的情况下处理完整DNA序列具有挑战性，我们决定缩小研究规模，专注于人类基因的核苷酸序列而非完整DNA。这一决策并未改变问题本质，因为DNA和基因均可视为由四种不同核苷酸构成的一维序列，且不会丢失过多信息或过度简化。首先，我们系统研究了这个几乎未被探索的问题，发现循环神经网络表现最佳，而N-gram等简单技术也颇具潜力。另一个收获是学会了如何在我们不理解的语言（与自然语言不同）上使用生成模型。研究强调了除困惑度等传统指标外，采用实际任务进行评估的重要性。此外，我们通过选择词汇量极小的语言（因四种核苷酸而仅有四个词汇），检验了这些模型的数据饥渴特性是否能够改变。选择这种语言可能使问题更易处理，但本研究发现这并未显著改变所需数据量。</div>
</details>
<details class="detail"><summary>Summary / 总结</summary>
<div class="mono">The study addresses the underexplored area of generative language models for DNA sequences by developing an autoregressive model akin to GPT-3, focusing on human gene nucleotide sequences as a manageable proxy for whole DNA. The method involved systematic experimentation with models including RNNs and N-grams, evaluating them on real-world tasks beyond perplexity. Key findings show that RNNs performed best, N-grams remained promising, and the minimal four-nucleotide vocabulary did not significantly reduce the data requirements for training.</div>
<div class="mono" style="margin-top:8px">本研究针对DNA序列生成式语言模型这一尚未充分探索的领域，其动机在于核苷酸序列与自然语言文本在结构上的相似性。作者开发了一种类似于GPT-3的自回归生成模型，为降低计算负担，专注于人类基因序列而非整个DNA。实验结果表明，在测试的模型中循环神经网络（RNN）表现最佳，简单的N-元文法也显示出潜力，同时指出仅包含四种核苷酸的最小词汇量并未显著降低模型训练所需的数据量。</div>
</details>
</div>
<div class="card">
<div class="title">ConceptCaps -- a Distilled Concept Dataset for Interpretability in Music Models</div>
<div class="meta-line">Authors: Bruno Sienkiewicz, Łukasz Neumann, Mateusz Modrzejewski</div>
<div class="meta-line">First: 2026-01-20T17:04:08+00:00 · Latest: 2026-01-20T17:04:08+00:00</div>
<div class="links" style="margin-top:8px"><a href="https://arxiv.org/abs/2601.14157v1">Abs</a> · <a href="https://arxiv.org/pdf/2601.14157v1">PDF</a> · <a href="https://huggingface.co/huggingface">Code1</a> · <a href="https://huggingface.co/docs/hub/spaces">Code2</a></div>
<details class="detail"><summary>Abstract</summary>
<div class="mono">Concept-based interpretability methods like TCAV require clean, well-separated positive and negative examples for each concept. Existing music datasets lack this structure: tags are sparse, noisy, or ill-defined. We introduce ConceptCaps, a dataset of 23k music-caption-audio triplets with explicit labels from a 200-attribute taxonomy. Our pipeline separates semantic modeling from text generation: a VAE learns plausible attribute co-occurrence patterns, a fine-tuned LLM converts attribute lists into professional descriptions, and MusicGen synthesizes corresponding audio. This separation improves coherence and controllability over end-to-end approaches. We validate the dataset through audio-text alignment (CLAP), linguistic quality metrics (BERTScore, MAUVE), and TCAV analysis confirming that concept probes recover musically meaningful patterns. Dataset and code are available online.</div></details>
<details class="detail"><summary>中文标题/摘要</summary>
<div class="mono"><b>标题：</b>ConceptCaps——面向音乐模型可解释性的蒸馏概念数据集</div>
<div class="mono" style="margin-top:8px">基于概念的可解释性方法（如TCAV）需要每个概念具备清晰分离的正负样本。现有音乐数据集缺乏这种结构：标签稀疏、含噪或定义模糊。我们推出ConceptCaps数据集，包含2.3万个音乐-文本-音频三元组，标注源自200个属性的分类体系。我们的流程将语义建模与文本生成分离：VAE学习合理的属性共现模式，微调LLM将属性列表转为专业描述，MusicGen合成对应音频。这种分离相比端到端方法提升了连贯性与可控性。我们通过音频-文本对齐（CLAP）、语言质量指标（BERTScore、MAUVE）及TCAV分析验证数据集，证实概念探针能提取具有音乐意义的模式。数据集与代码已开源。</div>
</details>
<details class="detail"><summary>Summary / 总结</summary>
<div class="mono">To enable concept-based interpretability methods like TCAV in music AI, which require clean and well-defined concept examples, this work introduces ConceptCaps, a dataset of 23k music-caption-audio triplets with explicit labels from a 200-attribute taxonomy. The method employs a pipeline that separates semantic modeling from text generation: a VAE learns plausible attribute co-occurrence patterns, a fine-tuned LLM converts these attribute lists into professional descriptions, and MusicGen synthesizes the corresponding audio, improving coherence and controllability over end-to-end approaches. Experimental validation through audio-text alignment (CLAP), linguistic quality metrics (BERTScore, MAUVE), and TCAV analysis confirms the dataset&#x27;s quality, showing that concept probes recover musically meaningful patterns.</div>
<div class="mono" style="margin-top:8px">为支持音乐AI中基于概念的可解释性方法（如TCAV），这些方法需要清晰的概念示例，本研究提出了ConceptCaps数据集，包含23k个音乐-描述-音频三元组，并带有来自200个属性分类法的明确标签。该方法采用了一个将语义建模与文本生成分离的流程：变分自编码器学习属性共现模式，微调的大语言模型将属性列表转换为专业描述，MusicGen则合成对应的音频，相比端到端方法提高了连贯性和可控性。实验验证通过CLAP显示了良好的音频-文本对齐，通过BERTScore和MAUVE度量了高语言质量，且TCAV分析证实概念探针能恢复具有音乐意义的模式。</div>
</details>
</div>
<div class="card">
<div class="title">Lost in the Prompt Order: Revealing the Limitations of Causal Attention in Language Models</div>
<div class="meta-line">Authors: Hyunjong Ok, Jaeho Lee</div>
<div class="meta-line">First: 2026-01-20T16:54:22+00:00 · Latest: 2026-01-20T16:54:22+00:00</div>
<div class="meta-line">Comments: preprint</div>
<div class="links" style="margin-top:8px"><a href="https://arxiv.org/abs/2601.14152v1">Abs</a> · <a href="https://arxiv.org/pdf/2601.14152v1">PDF</a> · <a href="https://huggingface.co/huggingface">Code1</a> · <a href="https://huggingface.co/docs/hub/spaces">Code2</a></div>
<details class="detail"><summary>Abstract</summary>
<div class="mono">Large language models exhibit surprising sensitivity to the structure of the prompt, but the mechanisms underlying this sensitivity remain poorly understood. In this work, we conduct an in-depth investigation on a striking case: in multiple-choice question answering, placing context before the questions and options (CQO) outperforms the reverse order (QOC) by over 14%p, consistently over a wide range of models and datasets. Through systematic architectural analysis, we identify causal attention as the core mechanism: in QOC prompts, the causal mask prevents option tokens from attending to context, creating an information bottleneck where context becomes invisible to options.</div></details>
<details class="detail"><summary>中文标题/摘要</summary>
<div class="mono"><b>标题：</b>迷失于提示顺序：揭示语言模型中因果注意力的局限性</div>
<div class="mono" style="margin-top:8px">大型语言模型对提示结构表现出惊人的敏感性，但其内在机制尚未得到充分理解。本研究针对一个显著案例展开深入探究：在多项选择题回答任务中，将上下文置于问题和选项之前（CQO）的提示方式，其表现始终优于反向顺序（QOC），优势幅度超过14个百分点，且该现象在不同模型与数据集中普遍存在。通过系统性的架构分析，我们确定因果注意力是核心机制：在QOC提示中，因果掩码会阻止选项词元关注上下文，形成信息瓶颈，导致上下文对选项不可见。</div>
</details>
<details class="detail"><summary>Summary / 总结</summary>
<div class="mono">This study investigates why large language models exhibit significant performance variations based on prompt structure, specifically in multiple-choice question answering where placing context before questions and options (CQO) consistently outperforms the reverse order (QOC) by over 14 percentage points across various models and datasets. Through systematic architectural analysis, the authors identify causal attention as the core mechanism, revealing that in QOC prompts, the causal mask prevents option tokens from attending to context, creating an information bottleneck that renders the context invisible to the options. The key experimental finding is that this architectural constraint, rather than superficial formatting, is the primary cause of the performance gap.</div>
<div class="mono" style="margin-top:8px">本研究探讨了大语言模型性能随提示结构显著变化的原因，特别是在多项选择题中，将上下文置于问题和选项之后（QOC）相比置于之前（CQO）会导致准确率下降超过14%。作者通过系统架构分析，将这一局限归因于因果注意力机制：在QOC顺序中，因果掩码阻止选项词元关注上下文，形成信息瓶颈。跨多种模型和数据集的实验结果一致证实，这种架构约束而非表面格式差异是性能差距的主要根源。</div>
</details>
</div>
<div class="card">
<div class="title">On Foundation Models for Temporal Point Processes to Accelerate Scientific Discovery</div>
<div class="meta-line">Authors: David Berghaus, Patrick Seifner, Kostadin Cvejoski, Ramses J. Sanchez</div>
<div class="meta-line">First: 2025-10-14T15:33:53+00:00 · Latest: 2026-01-20T16:37:22+00:00</div>
<div class="links" style="margin-top:8px"><a href="https://arxiv.org/abs/2510.12640v2">Abs</a> · <a href="https://arxiv.org/pdf/2510.12640v2">PDF</a> · <a href="https://huggingface.co/huggingface">Code1</a> · <a href="https://huggingface.co/docs/hub/spaces">Code2</a></div>
<details class="detail"><summary>Abstract</summary>
<div class="mono">Many scientific fields, from medicine to seismology, rely on analyzing sequences of events over time to understand complex systems. Traditionally, machine learning models must be built and trained from scratch for each new dataset, which is a slow and costly process. We introduce a new approach: a single, powerful model that learns the underlying patterns of event data in context. We trained this &quot;foundation model&quot; on millions of simulated event sequences, teaching it a general-purpose understanding of how events can unfold. As a result, our model can analyze new scientific data instantly, without retraining, simply by looking at a few examples from the dataset. It can also be quickly fine-tuned for even higher accuracy. This approach makes sophisticated event analysis more accessible and accelerates the pace of scientific discovery.</div></details>
<details class="detail"><summary>中文标题/摘要</summary>
<div class="mono"><b>标题：</b>基于时间点过程的基础模型加速科学发现</div>
<div class="mono" style="margin-top:8px">从医学到地震学，许多科学领域依赖分析随时间推移的事件序列来理解复杂系统。传统机器学习模型需为每个新数据集从头构建和训练，过程缓慢且成本高昂。我们提出一种新方法：通过单一强大模型学习事件数据的上下文潜在模式。我们在数百万模拟事件序列上训练这一“基础模型”，使其掌握事件演化规律的通用理解能力。该模型无需重新训练即可即时分析新科学数据，仅需参考数据集中的少量示例。还可通过快速微调实现更高精度。该方法使复杂事件分析更易普及，并加速科学发现进程。</div>
</details>
<details class="detail"><summary>Summary / 总结</summary>
<div class="mono">The research is motivated by the need to overcome the slow and costly process of building and training specialized machine learning models from scratch for each new dataset in fields that analyze temporal event sequences. The method introduces a foundation model for temporal point processes, which is pre-trained on millions of simulated event sequences to learn general patterns of how events unfold over time. Key experimental findings demonstrate that this model can instantly analyze new scientific datasets without retraining by leveraging few-shot examples, and it can be quickly fine-tuned to achieve even higher accuracy, thereby making advanced event analysis more accessible and accelerating scientific discovery.</div>
<div class="mono" style="margin-top:8px">本研究针对科学领域分析时间事件序列时，为每个新数据集从头构建和训练独立机器学习模型效率低下的问题。作者提出了一种基础模型，该模型在数百万模拟事件序列上进行训练，以学习事件随时间演变的一般模式。实验结果表明，该模型能够通过少量示例即时分析新的科学数据而无需重新训练，并可进行微调以获得更高精度，从而使先进的事件分析更易实现并加速科学发现。</div>
</details>
</div>
<div class="card">
<div class="title">Transport-Coupled Bayesian Flows for Molecular Graph Generation</div>
<div class="meta-line">Authors: Yida Xiong, Jiameng Chen, Kun Li, Hongzhi Zhang, Xiantao Cai, Jia Wu, Wenbin Hu</div>
<div class="meta-line">First: 2025-10-11T13:27:55+00:00 · Latest: 2026-01-20T16:35:22+00:00</div>
<div class="links" style="margin-top:8px"><a href="https://arxiv.org/abs/2510.10211v3">Abs</a> · <a href="https://arxiv.org/pdf/2510.10211v3">PDF</a> · <a href="https://huggingface.co/huggingface">Code1</a> · <a href="https://huggingface.co/docs/hub/spaces">Code2</a></div>
<details class="detail"><summary>Abstract</summary>
<div class="mono">Molecular graph generation (MGG) is essentially a multi-class generative task, aimed at predicting categories of atoms and bonds under strict chemical and structural constraints. However, many prevailing diffusion paradigms learn to regress numerical embeddings and rely on a hard discretization rule during sampling to recover discrete labels. This introduces a fundamental discrepancy between training and sampling. While models are trained for point-wise numerical fidelity, the sampling process fundamentally relies on crossing categorical decision boundaries. This discrepancy forces the model to expend efforts on intra-class variations that become irrelevant after discretization, ultimately compromising diversity, structural statistics, and generalization performance. Therefore, we propose TopBF, a unified framework that (i) performs MGG directly in continuous parameter distributions, (ii) learns graph-topological understanding through a Quasi-Wasserstein optimal-transport coupling under geodesic costs, and (iii) supports controllable, property-conditioned generation during sampling without retraining the base model. TopBF innovatively employs cumulative distribution function (CDF) to compute category probabilities induced by the Gaussian channel, thereby unifying the training objective with the sampling discretization operation. Experiments on QM9 and ZINC250k demonstrate superior structural fidelity and efficient generation with improved performance.</div></details>
<details class="detail"><summary>中文标题/摘要</summary>
<div class="mono"><b>标题：</b>基于传输耦合贝叶斯流的分子图生成方法</div>
<div class="mono" style="margin-top:8px">分子图生成本质上是一个多类别生成任务，旨在严格化学与结构约束下预测原子与键的类别。然而，现有扩散范式多学习回归数值嵌入，并依赖采样时的硬离散化规则恢复离散标签，导致训练与采样存在根本性差异：模型训练追求逐点数值保真度，而采样过程本质上依赖跨越类别决策边界。这种差异迫使模型耗费资源学习离散化后失效的类内变异，最终损害多样性、结构统计特性与泛化性能。为此，我们提出TopBF统一框架：（1）直接在连续参数分布中执行分子图生成；（2）通过测地线代价下的拟瓦瑟斯坦最优传输耦合学习图拓扑理解；（3）支持采样过程中无需重训练基础模型的可控属性条件生成。TopBF创新性地采用累积分布函数计算高斯信道诱导的类别概率，从而统一训练目标与采样离散化操作。在QM9和ZINC250k数据集上的实验证明了其卓越的结构保真度、高效生成能力及性能提升。</div>
</details>
<details class="detail"><summary>Summary / 总结</summary>
<div class="mono">Molecular graph generation faces a discrepancy because diffusion models are trained to regress continuous embeddings but rely on hard discretization during sampling, which misaligns objectives and harms diversity and generalization. To address this, the authors propose TopBF, a framework that directly models continuous parameter distributions, learns graph-topological understanding via a Quasi-Wasserstein optimal-transport coupling under geodesic costs, and enables controllable generation without retraining by using cumulative distribution functions to unify training with sampling discretization. Experiments on QM9 and ZINC250k datasets show that TopBF achieves superior structural fidelity and efficient generation with improved performance.</div>
<div class="mono" style="margin-top:8px">分子图生成任务中，许多扩散模型训练时回归连续嵌入，采样时却依赖硬离散化规则，这导致训练目标与分类决策过程不匹配，损害了生成性能。为此，研究者提出了TopBF框架，该框架直接在连续参数分布上进行建模，通过基于测地线成本的拟Wasserstein最优传输耦合学习图拓扑理解，并利用累积分布函数使训练目标与离散化操作对齐，从而支持无需重新训练的可控生成。在QM9和ZINC250k数据集上的实验表明，TopBF实现了更优的结构保真度、高效的生成能力以及性能提升。</div>
</details>
</div>
<div class="card">
<div class="title">Dynamics of Agentic Loops in Large Language Models: A Geometric Theory of Trajectories</div>
<div class="meta-line">Authors: Nicolas Tacheny</div>
<div class="meta-line">First: 2025-12-11T07:06:14+00:00 · Latest: 2026-01-20T16:35:18+00:00</div>
<div class="links" style="margin-top:8px"><a href="https://arxiv.org/abs/2512.10350v2">Abs</a> · <a href="https://arxiv.org/pdf/2512.10350v2">PDF</a> · <a href="https://huggingface.co/huggingface">Code1</a> · <a href="https://huggingface.co/docs/hub/spaces">Code2</a></div>
<details class="detail"><summary>Abstract</summary>
<div class="mono">Agentic systems built on large language models operate through recursive feedback loops, where each output becomes the next input. Yet the geometric behavior of these agentic loops (whether they converge, diverge, or exhibit more complex dynamics) remains poorly understood. This paper introduces a geometric framework for analyzing agentic trajectories in semantic embedding space, treating iterative transformations as discrete dynamical systems. We distinguish the artifact space, where linguistic transformations occur, from the embedding space, where geometric measurements are performed. Because cosine similarity is biased by embedding anisotropy, we introduce an isotonic calibration that eliminates systematic bias and aligns similarities with human semantic judgments while preserving high local stability. This enables rigorous measurement of trajectories, clusters and attractors. Through controlled experiments on singular agentic loops, we identify two fundamental regimes. A contractive rewriting loop converges toward a stable attractor with decreasing dispersion, while an exploratory summarize and negate loop produces unbounded divergence with no cluster formation. These regimes display qualitatively distinct geometric signatures of contraction and expansion. Our results show that prompt design directly governs the dynamical regime of an agentic loop, enabling systematic control of convergence, divergence and trajectory structure in iterative LLM transformations.</div></details>
<details class="detail"><summary>中文标题/摘要</summary>
<div class="mono"><b>标题：</b>大语言模型中能动性循环的动态：轨迹的几何理论</div>
<div class="mono" style="margin-top:8px">基于大语言模型的能动性系统通过递归反馈循环运作，其中每个输出成为下一个输入。然而，这些能动性循环的几何行为（无论它们是收敛、发散还是表现出更复杂的动态）仍鲜为人知。本文引入了一个几何框架，用于分析语义嵌入空间中的能动性轨迹，将迭代变换视为离散动力系统。我们区分了发生语言变换的人工制品空间与进行几何测量的嵌入空间。由于余弦相似度受嵌入各向异性影响，我们引入了一种等渗校准方法，以消除系统性偏差，使相似度与人类语义判断保持一致，同时保持较高的局部稳定性。这使得轨迹、聚类和吸引子的严格测量成为可能。通过对单一能动性循环的受控实验，我们识别出两种基本机制：收缩性重写循环向稳定吸引子收敛且离散度递减，而探索性总结与否定循环则产生无界发散且无聚类形成。这些机制展现出收缩与扩张在性质上截然不同的几何特征。我们的结果表明，提示设计直接控制着能动性循环的动态机制，从而能够系统性地控制迭代LLM变换中的收敛、发散及轨迹结构。</div>
</details>
<details class="detail"><summary>Summary / 总结</summary>
<div class="mono">The study addresses the lack of understanding of the geometric behavior of agentic loops in large language models, where outputs recursively become inputs, by developing a geometric framework to analyze these trajectories as discrete dynamical systems in semantic embedding space. The method distinguishes between artifact and embedding spaces, introduces an isotonic calibration to correct cosine similarity bias from embedding anisotropy, aligning it with human judgments while maintaining local stability, enabling rigorous measurement of trajectories, clusters, and attractors. Experimental results on singular agentic loops reveal two fundamental regimes: a contractive rewriting loop that converges to a stable attractor with decreasing dispersion, and an exploratory summarize and negate loop that diverges unboundedly without cluster formation, demonstrating that prompt design directly controls the dynamical regime, allowing systematic management of convergence, divergence, and trajectory structure.</div>
<div class="mono" style="margin-top:8px">本研究针对大型语言模型中代理反馈循环的几何行为缺乏理解的问题展开，其中输出递归地成为输入。作者提出了一个几何框架，将迭代变换视为离散动力系统，区分了工件空间和嵌入空间，并引入等张校准来修正余弦相似性偏差以实现准确的轨迹测量。在单一循环上的实验揭示了两种基本机制：收缩性重写会收敛于具有递减离散度的稳定吸引子，而探索性总结和否定则导致无界发散且不形成聚类，这表明提示设计直接控制着收敛、发散和轨迹结构的动态机制。</div>
</details>
</div>
<div class="card">
<div class="title">Towards Fast Coarse-graining and Equation Discovery with Foundation Inference Models</div>
<div class="meta-line">Authors: Manuel Hinz, Maximilian Mauel, Patrick Seifner, David Berghaus, Kostadin Cvejoski, Ramses J. Sanchez</div>
<div class="meta-line">First: 2025-10-14T15:17:23+00:00 · Latest: 2026-01-20T16:34:49+00:00</div>
<div class="links" style="margin-top:8px"><a href="https://arxiv.org/abs/2510.12618v2">Abs</a> · <a href="https://arxiv.org/pdf/2510.12618v2">PDF</a> · <a href="https://huggingface.co/huggingface">Code1</a> · <a href="https://huggingface.co/docs/hub/spaces">Code2</a></div>
<details class="detail"><summary>Abstract</summary>
<div class="mono">High-dimensional recordings of dynamical processes are often characterized by a much smaller set of effective variables, evolving on low-dimensional manifolds. Identifying these latent dynamics requires solving two intertwined problems: discovering appropriate coarse-grained variables and simultaneously fitting the governing equations. Most machine learning approaches tackle these tasks jointly by training autoencoders together with models that enforce dynamical consistency. We propose to decouple the two problems by leveraging the recently introduced Foundation Inference Models (FIMs). FIMs are pretrained models that estimate the infinitesimal generators of dynamical systems (e.g., the drift and diffusion of a stochastic differential equation) in zero-shot mode. By amortizing the inference of the dynamics through a FIM with frozen weights, and training only the encoder-decoder map, we define a simple, simulation-consistent loss that stabilizes representation learning. A proof of concept on a stochastic double-well system with semicircle diffusion, embedded into synthetic video data, illustrates the potential of this approach for fast and reusable coarse-graining pipelines.</div></details>
<details class="detail"><summary>中文标题/摘要</summary>
<div class="mono"><b>标题：</b>基于基础推理模型的快速粗粒化与方程发现研究</div>
<div class="mono" style="margin-top:8px">动态过程的高维记录通常由一组数量少得多的有效变量表征，这些变量在低维流形上演化。识别这些潜在动态需要解决两个交织的问题：发现合适的粗粒度变量并同时拟合控制方程。大多数机器学习方法通过联合训练自编码器与强制动态一致性的模型来处理这些任务。我们提出利用最近引入的基础推理模型（FIMs）来解耦这两个问题。FIMs是预训练模型，能够在零样本模式下估计动态系统的无穷小生成元（例如随机微分方程的漂移和扩散项）。通过使用权重固定的FIM对动态推断进行摊销，并仅训练编码器-解码器映射，我们定义了一个简单且模拟一致的损失函数，从而稳定了表示学习。在一个嵌入合成视频数据、具有半圆扩散的随机双阱系统上的概念验证，展示了该方法在构建快速可复用粗粒化流程方面的潜力。</div>
</details>
<details class="detail"><summary>Summary / 总结</summary>
<div class="mono">The research addresses the challenge of identifying low-dimensional latent dynamics from high-dimensional recordings of dynamical systems, which typically requires jointly discovering coarse-grained variables and fitting governing equations. The method decouples these tasks by employing pretrained Foundation Inference Models (FIMs) to estimate infinitesimal generators of dynamics in zero-shot mode, while training only an encoder-decoder map with a simulation-consistent loss for representation learning. Experimental results on a stochastic double-well system with semicircle diffusion, embedded in synthetic video data, demonstrate the approach&#x27;s potential for enabling fast and reusable coarse-graining pipelines.</div>
<div class="mono" style="margin-top:8px">该研究旨在从高维动态系统记录中高效识别低维潜在动力学，这通常需要联合学习粗粒度变量和支配方程。方法通过使用预训练的基础推理模型（FIMs）以零样本方式估计无穷小生成元，从而分摊动力学推断，然后仅训练编码器-解码器映射，并采用模拟一致损失进行表示学习，从而将两个任务解耦。在嵌入合成视频数据的半圆扩散随机双阱系统上的概念验证表明，该方法有潜力实现快速且可重用的粗粒度流程。</div>
</details>
</div>
<div class="card">
<div class="title">Physics-Informed Machine Learning Regulated by Finite Element Analysis for Simulation Acceleration of Laser Powder Bed Fusion</div>
<div class="meta-line">Authors: R. Sharma, M. Raissi, Y. B. Guo</div>
<div class="meta-line">First: 2025-06-25T15:25:01+00:00 · Latest: 2026-01-20T16:30:50+00:00</div>
<div class="meta-line">Comments: Further investigation revealed that the current version reflects an incomplete formulation and limited validation of the proposed method. We have since developed a substantially revised and extended study with updated assumptions and results, and therefore withdraw this version to prevent citation of superseded findings</div>
<div class="links" style="margin-top:8px"><a href="https://arxiv.org/abs/2506.20537v2">Abs</a> · <a href="https://arxiv.org/pdf/2506.20537v2">PDF</a> · <a href="https://huggingface.co/huggingface">Code1</a> · <a href="https://huggingface.co/docs/hub/spaces">Code2</a></div>
<details class="detail"><summary>Abstract</summary>
<div class="mono">Efficient simulation of Laser Powder Bed Fusion (LPBF) is crucial for process prediction due to the lasting issue of high computation cost using traditional numerical methods such as finite element analysis (FEA). This study presents an efficient modeling framework termed FEA-Regulated Physics-Informed Neural Network (FEA-PINN) to accelerate the thermal field prediction in a LPBF process while maintaining the FEA accuracy. A novel dynamic material updating strategy is developed to capture the dynamic phase change of powder-liquid-solid in the PINN model. The PINN model incorporates temperature-dependent material properties and phase change behavior using the apparent heat capacity method. While the PINN model demonstrates high accuracy with a small training data and enables generalization of new process parameters via transfer learning, it faces the challenge of high computation cost in time-dependent problems due to the residual accumulation. To overcome this issue, the FEA-PINN framework integrates corrective FEA simulations during inference to enforce physical consistency and reduce error drift. A comparative analysis shows that FEA-PINN achieves equivalent accuracy to FEA while significantly reducing computational cost. The framework has been validated using the benchmark FEA data and demonstrated through single-track scanning in LPBF.</div></details>
<details class="detail"><summary>中文标题/摘要</summary>
<div class="mono"><b>标题：</b>基于有限元分析调控的物理信息机器学习用于激光粉末床熔融模拟加速</div>
<div class="mono" style="margin-top:8px">激光粉末床熔融（LPBF）的高效模拟对工艺预测至关重要，传统数值方法（如有限元分析）计算成本高昂的问题长期存在。本研究提出一种称为有限元调控物理信息神经网络（FEA-PINN）的高效建模框架，在保持有限元精度的同时加速LPBF过程的热场预测。该框架开发了新颖的动态材料更新策略，以捕捉PINN模型中粉末-液体-固体的动态相变。PINN模型采用表观热容法整合了温度相关材料属性与相变行为。虽然PINN模型在少量训练数据下展现出高精度，并能通过迁移学习泛化新工艺参数，但在瞬态问题中面临残差累积导致的高计算成本挑战。为克服此问题，FEA-PINN框架在推理阶段集成校正性有限元模拟以强化物理一致性并减少误差漂移。对比分析表明，FEA-PINN在显著降低计算成本的同时达到了与有限元相当的精度。该框架已通过基准有限元数据验证，并在LPBF单道扫描案例中得以演示。</div>
</details>
<details class="detail"><summary>Summary / 总结</summary>
<div class="mono">Motivated by the high computational cost of traditional finite element analysis (FEA) for simulating Laser Powder Bed Fusion (LPBF) processes, this study proposes an FEA-Regulated Physics-Informed Neural Network (FEA-PINN) framework to accelerate thermal field prediction. The method develops a PINN model with a dynamic material updating strategy to capture powder-liquid-solid phase change using the apparent heat capacity method, and it integrates corrective FEA simulations during inference to enforce physical consistency and mitigate error drift from residual accumulation. Experimental validation using benchmark FEA data for single-track LPBF scanning shows that the FEA-PINN framework achieves accuracy equivalent to FEA while significantly reducing computational cost.</div>
<div class="mono" style="margin-top:8px">为解决传统有限元分析模拟激光粉末床熔融热场时计算成本过高的问题，本研究提出了一种有限元分析调控的物理信息神经网络框架。该方法在物理信息神经网络中开发了一种动态材料更新策略，利用表观热容法和温度相关属性来捕捉粉末-液体-固体的相变过程。基础物理信息神经网络虽能以少量训练数据实现准确预测并通过迁移学习泛化新工艺参数，但在瞬态问题中存在误差累积；在推理过程中集成的校正性有限元模拟缓解了这种误差漂移。对比分析表明，该框架在达到与标准有限元分析同等精度的同时，显著降低了计算成本，并通过单道扫描的基准有限元数据进行了验证。</div>
</details>
</div>
<div class="card">
<div class="title">Adaptive Riemannian Graph Neural Networks</div>
<div class="meta-line">Authors: Xudong Wang, Chris Ding, Tongxin Li, Jicong Fan</div>
<div class="meta-line">Venue: AAAI</div>
<div class="meta-line">First: 2025-08-04T16:55:02+00:00 · Latest: 2026-01-20T16:23:35+00:00</div>
<div class="meta-line">Comments: Accepted in The Fortieth AAAI Conference on Artificial Intelligence (AAAI-26), Main Technical Track</div>
<div class="links" style="margin-top:8px"><a href="https://arxiv.org/abs/2508.02600v2">Abs</a> · <a href="https://arxiv.org/pdf/2508.02600v2">PDF</a> · <a href="https://huggingface.co/huggingface">Code1</a> · <a href="https://huggingface.co/docs/hub/spaces">Code2</a></div>
<details class="detail"><summary>Abstract</summary>
<div class="mono">Graph data often exhibits complex geometric heterogeneity, where structures with varying local curvature, such as tree-like hierarchies and dense communities, coexist within a single network. Existing geometric GNNs, which embed graphs into single fixed-curvature manifolds or discrete product spaces, struggle to capture this diversity. We introduce Adaptive Riemannian Graph Neural Networks (ARGNN), a novel framework that learns a continuous and anisotropic Riemannian metric tensor field over the graph. It allows each node to determine its optimal local geometry, enabling the model to fluidly adapt to the graph&#x27;s structural landscape. Our core innovation is an efficient parameterization of the node-wise metric tensor, specializing to a learnable diagonal form that captures directional geometric information while maintaining computational tractability. To ensure geometric regularity and stable training, we integrate a Ricci flow-inspired regularization that smooths the learned manifold. Theoretically, we establish the rigorous geometric evolution convergence guarantee for ARGNN and provide a continuous generalization that unifies prior fixed or mixed-curvature GNNs. Empirically, our method demonstrates superior performance on both homophilic and heterophilic benchmark datasets with the ability to capture diverse structures adaptively. Moreover, the learned geometries both offer interpretable insights into the underlying graph structure and empirically corroborate our theoretical analysis.</div></details>
<details class="detail"><summary>中文标题/摘要</summary>
<div class="mono"><b>标题：</b>自适应黎曼图神经网络</div>
<div class="mono" style="margin-top:8px">图数据常呈现复杂的几何异质性，例如树状层次结构与密集社区等具有不同局部曲率的结构共存于同一网络中。现有几何图神经网络将图嵌入单一固定曲率流形或离散乘积空间，难以捕捉这种多样性。本文提出自适应黎曼图神经网络（ARGNN），该框架通过学习图上的连续各向异性黎曼度量张量场，使每个节点能确定其最优局部几何，从而灵活适应图的结构特征。核心创新在于对节点级度量张量进行高效参数化，将其特化为可学习的对角形式，既能捕捉方向性几何信息，又保持计算可行性。为确保几何正则性与训练稳定性，我们引入受里奇流启发的正则化方法以平滑学习流形。理论上，我们为ARGNN建立了严格的几何演化收敛保证，并提出统一现有固定/混合曲率图神经网络的连续泛化形式。实验表明，本方法在同配性与异配性基准数据集上均表现出优越性能，并能自适应捕捉多样化结构。此外，学习得到的几何结构既为底层图结构提供可解释的洞察，也从实证角度验证了理论分析。</div>
</details>
<details class="detail"><summary>Summary / 总结</summary>
<div class="mono">This research addresses the challenge of modeling graphs with heterogeneous geometric structures, where existing geometric graph neural networks (GNNs) that use fixed-curvature manifolds fail to capture local variations like tree-like hierarchies and dense communities. The proposed Adaptive Riemannian Graph Neural Networks (ARGNN) introduces a framework that learns a continuous, anisotropic Riemannian metric tensor field over the graph, allowing each node to adapt its local geometry; this is achieved through an efficient parameterization of a learnable diagonal metric tensor and is regularized via a Ricci flow-inspired method to ensure geometric smoothness and training stability. Theoretically, the work provides convergence guarantees and a unifying continuous generalization of prior models, while experiments on homophilic and heterophilic benchmarks show superior performance and the learned geometries offer interpretable insights into graph structure.</div>
<div class="mono" style="margin-top:8px">该研究旨在解决具有异质几何结构的图建模问题，现有基于固定曲率流形的几何图神经网络难以捕捉如树状层次和密集社区等局部变化。提出的自适应黎曼图神经网络框架通过学习图上连续、各向异性的黎曼度量张量场，使每个节点能通过可学习的对角参数化自适应调整局部几何，并引入里奇流启发的正则化以确保几何平滑性和训练稳定性。实验表明，该方法在同质和异质基准数据集上均优于先前方法，能自适应捕捉多样结构，同时提供可解释的几何洞察，与理论分析相符。</div>
</details>
</div>
<div class="card">
<div class="title">Task-Aware Mixture-of-Experts for Time Series Analysis</div>
<div class="meta-line">Authors: Xingjian Wu, Zhengyu Li, Hanyin Cheng, Xiangfei Qiu, Jilin Hu, Chenjuan Guo, Bin Yang</div>
<div class="meta-line">First: 2025-09-26T12:44:46+00:00 · Latest: 2026-01-20T16:18:00+00:00</div>
<div class="links" style="margin-top:8px"><a href="https://arxiv.org/abs/2509.22279v3">Abs</a> · <a href="https://arxiv.org/pdf/2509.22279v3">PDF</a> · <a href="https://huggingface.co/huggingface">Code1</a> · <a href="https://huggingface.co/docs/hub/spaces">Code2</a></div>
<details class="detail"><summary>Abstract</summary>
<div class="mono">Time Series Analysis is widely used in various real-world applications such as weather forecasting, financial fraud detection, imputation for missing data in IoT systems, and classification for action recognization. Mixture-of-Experts (MoE), as a powerful architecture, though demonstrating effectiveness in NLP, still falls short in adapting to versatile tasks in time series analytics due to its task-agnostic router and the lack of capability in modeling channel correlations. In this study, we propose a novel, general MoE-based time series framework called PatchMoE to support the intricate ``knowledge&#x27;&#x27; utilization for distinct tasks, thus task-aware. Based on the observation that hierarchical representations often vary across tasks, e.g., forecasting vs. classification, we propose a Recurrent Noisy Gating to utilize the hierarchical information in routing, thus obtaining task-sepcific capability. And the routing strategy is operated on time series tokens in both temporal and channel dimensions, and encouraged by a meticulously designed Temporal \&amp; Channel Load Balancing Loss to model the intricate temporal and channel correlations. Comprehensive experiments on five downstream tasks demonstrate the state-of-the-art performance of PatchMoE.</div></details>
<details class="detail"><summary>中文标题/摘要</summary>
<div class="mono"><b>标题：</b>面向任务感知的专家混合模型在时间序列分析中的应用</div>
<div class="mono" style="margin-top:8px">时间序列分析广泛应用于天气预测、金融欺诈检测、物联网系统缺失数据填补及动作识别分类等现实场景。专家混合模型作为一种强大架构，虽在自然语言处理中表现优异，但其任务无关的路由机制及对通道相关性建模能力的不足，限制了其在时间序列分析多样化任务中的适应性。本研究提出一种新颖通用的基于MoE的时间序列框架——PatchMoE，通过支持针对不同任务的复杂“知识”利用实现任务感知。基于层级表征常随任务（如预测与分类）变化的观察，我们设计了循环噪声门控机制以利用层级信息进行路由，从而获得任务特定能力。该路由策略在时间与通道双维度上操作时间序列标记，并通过精心设计的时序与通道负载均衡损失函数建模复杂的时序与通道相关性。在五项下游任务上的全面实验验证了PatchMoE的先进性能。</div>
</details>
<details class="detail"><summary>Summary / 总结</summary>
<div class="mono">The research addresses the limitations of Mixture-of-Experts (MoE) architectures in time series analysis, which are task-agnostic and lack channel correlation modeling, hindering their adaptation to diverse tasks like forecasting and classification. The proposed PatchMoE framework introduces a Recurrent Noisy Gating mechanism that leverages hierarchical task-specific information for routing and employs a Temporal &amp; Channel Load Balancing Loss to model correlations across both temporal and channel dimensions. Experiments across five downstream tasks demonstrate that PatchMoE achieves state-of-the-art performance.</div>
<div class="mono" style="margin-top:8px">本研究针对混合专家模型在时间序列分析中的局限性展开，其任务无关的路由器和无法建模通道相关性的特点，阻碍了其在预测和分类等多样化任务中的适应。所提出的PatchMoE方法引入了循环噪声门控机制，利用任务特定的层次信息进行路由，并在时间和通道维度上对令牌进行操作，通过精心设计的时序与通道负载均衡损失进行优化。在五个下游任务上的综合实验表明，PatchMoE实现了最先进的性能。</div>
</details>
</div>
<div class="card">
<div class="title">Riemannian Liquid Spatio-Temporal Graph Network</div>
<div class="meta-line">Authors: Liangsi Lu, Jingchao Wang, Zhaorong Dai, Hanqian Liu, Yang Shi</div>
<div class="meta-line">Venue: The Web Conference 2026</div>
<div class="meta-line">First: 2026-01-20T16:09:05+00:00 · Latest: 2026-01-20T16:09:05+00:00</div>
<div class="meta-line">Comments: This paper has been accepted to The Web Conference 2026</div>
<div class="links" style="margin-top:8px"><a href="https://arxiv.org/abs/2601.14115v1">Abs</a> · <a href="https://arxiv.org/pdf/2601.14115v1">PDF</a> · <a href="https://huggingface.co/huggingface">Code1</a> · <a href="https://huggingface.co/docs/hub/spaces">Code2</a> · <a href="https://rlstg.github.io">Project1</a></div>
<details class="detail"><summary>Abstract</summary>
<div class="mono">Liquid Time-Constant networks (LTCs), a type of continuous-time graph neural network, excel at modeling irregularly-sampled dynamics but are fundamentally confined to Euclidean space. This limitation introduces significant geometric distortion when representing real-world graphs with inherent non-Euclidean structures (e.g., hierarchies and cycles), degrading representation quality. To overcome this limitation, we introduce the Riemannian Liquid Spatio-Temporal Graph Network (RLSTG), a framework that unifies continuous-time liquid dynamics with the geometric inductive biases of Riemannian manifolds. RLSTG models graph evolution through an Ordinary Differential Equation (ODE) formulated directly on a curved manifold, enabling it to faithfully capture the intrinsic geometry of both structurally static and dynamic spatio-temporal graphs. Moreover, we provide rigorous theoretical guarantees for RLSTG, extending stability theorems of LTCs to the Riemannian domain and quantifying its expressive power via state trajectory analysis. Extensive experiments on real-world benchmarks demonstrate that, by combining advanced temporal dynamics with a Riemannian spatial representation, RLSTG achieves superior performance on graphs with complex structures. Project Page: https://rlstg.github.io</div></details>
<details class="detail"><summary>中文标题/摘要</summary>
<div class="mono"><b>标题：</b>黎曼流形时空图网络</div>
<div class="mono" style="margin-top:8px">液态时间常数网络（LTCs）作为一种连续时间图神经网络，擅长建模不规则采样的动态系统，但其本质上局限于欧几里得空间。当表示具有固有非欧结构（如层次结构和循环）的真实世界图时，这一限制会引入显著的几何失真，降低表示质量。为克服此限制，我们提出了黎曼流形时空图网络（RLSTG），该框架将连续时间液态动态与黎曼流形的几何归纳偏置相统一。RLSTG通过在弯曲流形上直接构建的常微分方程（ODE）来建模图演化，使其能够忠实捕捉结构静态和动态时空图的内在几何特性。此外，我们为RLSTG提供了严格的理论保证，将LTCs的稳定性定理扩展至黎曼领域，并通过状态轨迹分析量化其表达能力。在真实世界基准测试上的大量实验表明，通过将先进的时间动态与黎曼空间表示相结合，RLSTG在复杂结构图上实现了卓越性能。项目页面：https://rlstg.github.io</div>
</details>
<details class="detail"><summary>Summary / 总结</summary>
<div class="mono">The research addresses the limitation of Liquid Time-Constant networks (LTCs), which operate in Euclidean space and introduce geometric distortion when modeling real-world graphs with inherent non-Euclidean structures like hierarchies and cycles. The proposed method, the Riemannian Liquid Spatio-Temporal Graph Network (RLSTG), unifies continuous-time liquid dynamics with Riemannian manifolds by formulating graph evolution through an Ordinary Differential Equation directly on a curved manifold, enabling faithful capture of intrinsic geometry in both static and dynamic spatio-temporal graphs. Experimental results on real-world benchmarks demonstrate that RLSTG achieves superior performance on graphs with complex structures, supported by theoretical guarantees extending LTC stability theorems to the Riemannian domain and quantifying expressive power via state trajectory analysis.</div>
<div class="mono" style="margin-top:8px">本研究针对液态时间常数网络局限于欧几里得空间、在建模具有非欧几里得结构（如层次和循环）的真实世界图时产生几何失真的问题，提出了黎曼液态时空图网络。该方法通过直接在弯曲流形上构建常微分方程来统一连续时间液态动力学与黎曼几何，从而能够忠实捕捉静态和动态时空图的内在几何结构。在真实世界基准测试上的实验表明，该方法通过结合先进的时序动力学与黎曼空间表示，在复杂结构图上实现了优越的性能，并提供了将液态时间常数网络稳定性定理扩展到黎曼域的理论保证及通过状态轨迹分析量化其表达能力的理论支撑。</div>
</details>
</div>
<div class="card">
<div class="title">Learning to Explain: Supervised Token Attribution from Transformer Attention Patterns</div>
<div class="meta-line">Authors: George Mihaila</div>
<div class="meta-line">First: 2026-01-20T16:06:34+00:00 · Latest: 2026-01-20T16:06:34+00:00</div>
<div class="links" style="margin-top:8px"><a href="https://arxiv.org/abs/2601.14112v1">Abs</a> · <a href="https://arxiv.org/pdf/2601.14112v1">PDF</a> · <a href="https://huggingface.co/huggingface">Code1</a> · <a href="https://huggingface.co/docs/hub/spaces">Code2</a></div>
<details class="detail"><summary>Abstract</summary>
<div class="mono">Explainable AI (XAI) has become critical as transformer-based models are deployed in high-stakes applications including healthcare, legal systems, and financial services, where opacity hinders trust and accountability. Transformers self-attention mechanisms have proven valuable for model interpretability, with attention weights successfully used to understand model focus and behavior (Xu et al., 2015); (Wiegreffe and Pinter, 2019). However, existing attention-based explanation methods rely on manually defined aggregation strategies and fixed attribution rules (Abnar and Zuidema, 2020a); (Chefer et al., 2021), while model-agnostic approaches (LIME, SHAP) treat the model as a black box and incur significant computational costs through input perturbation. We introduce Explanation Network (ExpNet), a lightweight neural network that learns an explicit mapping from transformer attention patterns to token-level importance scores. Unlike prior methods, ExpNet discovers optimal attention feature combinations automatically rather than relying on predetermined rules. We evaluate ExpNet in a challenging cross-task setting and benchmark it against a broad spectrum of model-agnostic methods and attention-based techniques spanning four methodological families.</div></details>
<details class="detail"><summary>中文标题/摘要</summary>
<div class="mono"><b>标题：</b>学习解释：基于Transformer注意力模式的监督式词元归因</div>
<div class="mono" style="margin-top:8px">随着基于Transformer的模型被部署于医疗、司法和金融服务等高风险领域，可解释人工智能（XAI）变得至关重要——模型的不透明性会阻碍信任与问责机制。Transformer的自注意力机制已被证明对模型可解释性具有重要价值，其注意力权重能有效揭示模型的关注焦点与行为模式（Xu等，2015；Wiegreffe与Pinter，2019）。然而，现有基于注意力的解释方法依赖人工定义的聚合策略与固定归因规则（Abnar与Zuidema，2020a；Chefer等，2021），而模型无关方法（如LIME、SHAP）将模型视为黑箱，且通过输入扰动产生高昂计算成本。本文提出解释网络（ExpNet），这是一种轻量级神经网络，可学习从Transformer注意力模式到词元重要性评分的显式映射。与先前方法不同，ExpNet能自动发现最优注意力特征组合，而非依赖预设规则。我们在跨任务场景下评估ExpNet，并与涵盖四大方法族的模型无关方法及注意力技术进行基准测试。</div>
</details>
<details class="detail"><summary>Summary / 总结</summary>
<div class="mono">The research is motivated by the need for transparent and trustworthy transformer models in high-stakes domains, where existing attention-based explanation methods rely on manual aggregation rules and model-agnostic approaches are computationally expensive. The method introduces Explanation Network (ExpNet), a lightweight neural network that learns to map transformer attention patterns to token-level importance scores, automatically discovering optimal feature combinations. Experimental results from a cross-task evaluation show that ExpNet is benchmarked against a broad spectrum of model-agnostic and attention-based techniques, demonstrating its effectiveness in generating token attributions.</div>
<div class="mono" style="margin-top:8px">本研究针对高风险领域中对透明Transformer模型的需求，开发了一种从注意力模式自动生成词元级解释的方法，克服了手动聚合规则和计算成本高昂的黑盒方法的局限性。提出的解释网络（ExpNet）是一个轻量级神经网络，它学习从Transformer注意力模式到词元重要性分数的最优映射，消除了对预定归因规则的依赖。在跨任务设置中的实验评估表明，ExpNet相对于广泛的模型无关和基于注意力的解释方法具有有效性。</div>
</details>
</div></div>
    <details style="margin-top:16px" class="detail"><summary>History</summary>
      <div class="history-list"><a href="archive/20260122_0449.html">20260122_0449</a>
<a href="archive/20260122_0336.html">20260122_0336</a>
<a href="archive/20260121_0625.html">20260121_0625</a>
<a href="archive/20260121_0529.html">20260121_0529</a>
<a href="archive/20260121_0450.html">20260121_0450</a>
<a href="archive/20260121_0423.html">20260121_0423</a>
<a href="archive/20260120_0626.html">20260120_0626</a>
<a href="archive/20260120_0528.html">20260120_0528</a>
<a href="archive/20260120_0443.html">20260120_0443</a>
<a href="archive/20260120_0330.html">20260120_0330</a>
<a href="archive/20260119_0624.html">20260119_0624</a>
<a href="archive/20260119_0525.html">20260119_0525</a>
<a href="archive/20260119_0440.html">20260119_0440</a>
<a href="archive/20260119_0325.html">20260119_0325</a>
<a href="archive/20260118_2225.html">20260118_2225</a>
<a href="archive/20260118_2159.html">20260118_2159</a>
<a href="archive/20260118_2135.html">20260118_2135</a>
<a href="archive/20260118_2040.html">20260118_2040</a>
<a href="archive/20260118_1953.html">20260118_1953</a>
<a href="archive/20260118_1907.html">20260118_1907</a>
<a href="archive/20260118_0327.html">20260118_0327</a>
<a href="archive/20260117_0332.html">20260117_0332</a>
<a href="archive/20260116_0339.html">20260116_0339</a>
<a href="archive/20260115_0334.html">20260115_0334</a>
<a href="archive/20260114_0333.html">20260114_0333</a>
<a href="archive/20260113_0334.html">20260113_0334</a>
<a href="archive/20260112_0331.html">20260112_0331</a>
<a href="archive/20260111_0329.html">20260111_0329</a>
<a href="archive/20260110_0333.html">20260110_0333</a>
<a href="archive/20260109_0334.html">20260109_0334</a>
<a href="archive/20260108_0335.html">20260108_0335</a>
<a href="archive/20260107_0330.html">20260107_0330</a>
<a href="archive/20260106_0336.html">20260106_0336</a>
<a href="archive/20260105_0328.html">20260105_0328</a>
<a href="archive/20260104_0328.html">20260104_0328</a>
<a href="archive/20260103_0325.html">20260103_0325</a>
<a href="archive/20260102_0339.html">20260102_0339</a>
<a href="archive/20260101_0329.html">20260101_0329</a>
<a href="archive/20251231_0333.html">20251231_0333</a>
<a href="archive/20251230_0332.html">20251230_0332</a>
<a href="archive/20251229_0329.html">20251229_0329</a>
<a href="archive/20251228_0332.html">20251228_0332</a>
<a href="archive/20251227_0329.html">20251227_0329</a>
<a href="archive/20251226_0330.html">20251226_0330</a>
<a href="archive/20251225_0329.html">20251225_0329</a>
<a href="archive/20251224_0331.html">20251224_0331</a>
<a href="archive/20251223_0332.html">20251223_0332</a>
<a href="archive/20251222_0328.html">20251222_0328</a>
<a href="archive/20251221_0329.html">20251221_0329</a>
<a href="archive/20251220_0330.html">20251220_0330</a>
<a href="archive/20251219_0330.html">20251219_0330</a>
<a href="archive/20251218_0345.html">20251218_0345</a>
<a href="archive/20251217_0332.html">20251217_0332</a>
<a href="archive/20251216_0333.html">20251216_0333</a>
<a href="archive/20251215_0333.html">20251215_0333</a>
<a href="archive/20251214_0327.html">20251214_0327</a>
<a href="archive/20251212_0333.html">20251212_0333</a>
<a href="archive/20251211_0331.html">20251211_0331</a>
<a href="archive/20251210_0332.html">20251210_0332</a>
<a href="archive/20251209_0331.html">20251209_0331</a>
<a href="archive/20251208_0328.html">20251208_0328</a>
<a href="archive/20251207_0327.html">20251207_0327</a>
<a href="archive/20251206_0330.html">20251206_0330</a>
<a href="archive/20251205_0331.html">20251205_0331</a>
<a href="archive/20251204_0331.html">20251204_0331</a>
<a href="archive/20251203_0333.html">20251203_0333</a>
<a href="archive/20251202_0335.html">20251202_0335</a>
<a href="archive/20251201_0328.html">20251201_0328</a>
<a href="archive/20251130_0327.html">20251130_0327</a>
<a href="archive/20251129_0328.html">20251129_0328</a>
<a href="archive/20251128_0327.html">20251128_0327</a>
<a href="archive/20251127_0327.html">20251127_0327</a>
<a href="archive/20251126_0329.html">20251126_0329</a>
<a href="archive/20251125_0327.html">20251125_0327</a>
<a href="archive/20251124_0327.html">20251124_0327</a>
<a href="archive/20251123_0326.html">20251123_0326</a>
<a href="archive/20251122_0328.html">20251122_0328</a>
<a href="archive/20251121_0328.html">20251121_0328</a>
<a href="archive/20251120_0329.html">20251120_0329</a>
<a href="archive/20251119_0328.html">20251119_0328</a>
<a href="archive/20251118_0328.html">20251118_0328</a>
<a href="archive/20251117_0326.html">20251117_0326</a>
<a href="archive/20251116_0325.html">20251116_0325</a>
<a href="archive/20251115_0327.html">20251115_0327</a>
<a href="archive/20251114_0328.html">20251114_0328</a>
<a href="archive/20251113_0330.html">20251113_0330</a>
<a href="archive/20251112_0329.html">20251112_0329</a>
<a href="archive/20251111_0328.html">20251111_0328</a>
<a href="archive/20251110_0325.html">20251110_0325</a>
<a href="archive/20251109_0326.html">20251109_0326</a>
<a href="archive/20251108_0328.html">20251108_0328</a>
<a href="archive/20251107_0328.html">20251107_0328</a>
<a href="archive/20251106_0329.html">20251106_0329</a>
<a href="archive/20251105_0326.html">20251105_0326</a>
<a href="archive/20251104_0327.html">20251104_0327</a>
<a href="archive/20251103_0324.html">20251103_0324</a>
<a href="archive/20251102_0326.html">20251102_0326</a>
<a href="archive/20251101_0324.html">20251101_0324</a>
<a href="archive/20251031_0328.html">20251031_0328</a>
<a href="archive/20251030_0330.html">20251030_0330</a></div>
    </details>
    <div class="footer">Generated by arxiv-tracker</div>
  </div>
</body></html>
