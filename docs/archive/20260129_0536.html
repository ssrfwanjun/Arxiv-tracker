<!doctype html>
<html><head><meta charset="utf-8"><meta name="viewport" content="width=device-width,initial-scale=1">
<title>arXiv 论文速递</title><style>
:root {
  --bg:#f8fafc; --card:#ffffff; --text:#0f172a; --muted:#667085; --border:#e5e7eb; --acc:#2563eb;
}
:root[data-theme="dark"] {
  --bg:#0b0f17; --card:#111827; --text:#e5e7eb; --muted:#9ca3af; --border:#1f2937; --acc:#2563eb;
}
*{box-sizing:border-box} body{margin:0;background:var(--bg);color:var(--text);
  font-family:ui-sans-serif,system-ui,-apple-system,Segoe UI,Roboto,Helvetica,Arial;line-height:1.6;}
.container{max-width:900px;margin:0 auto;padding:18px;}
.header{display:flex;gap:10px;justify-content:space-between;align-items:center;margin:8px 0 16px;flex-wrap:wrap}
h1{font-size:22px;margin:0}
.badge{font-size:12px;color:#111827;background:var(--acc);padding:2px 8px;border-radius:999px}
.card{background:var(--card);border:1px solid var(--border);border-radius:16px;padding:16px 18px;margin:14px 0;box-shadow:0 1px 2px rgba(0,0,0,.04)}
.title{font-weight:700;margin:0 0 6px 0;font-size:18px}
.meta-line{color:var(--muted);font-size:13px;margin:2px 0}
.links a{color:var(--acc);text-decoration:none;margin-right:12px}
.detail{margin-top:10px;background:rgba(2,6,23,.03);border:1px solid var(--border);border-radius:10px;padding:8px 10px}
summary{cursor:pointer;color:var(--acc)}
.mono{white-space:pre-wrap;background:rgba(2,6,23,.03);border:1px solid var(--border);padding:10px;border-radius:10px}
.row{display:grid;grid-template-columns:1fr;gap:12px}
@media (min-width: 860px) {
  .row-2{grid-template-columns:1fr 1fr}
}
.footer{color:var(--muted);font-size:13px;margin:20px 0 10px}
.hr{height:1px;background:var(--border);margin:14px 0}
.history-list a{display:block;color:var(--acc);text-decoration:none;margin:4px 0}
.controls{display:flex;gap:8px;align-items:center}
.btn{border:1px solid var(--border);background:var(--card);padding:6px 10px;border-radius:10px;cursor:pointer;color:var(--text)}
.btn:hover{border-color:var(--acc)}
</style>
<script>
(function() {
  const root = document.documentElement;
  function apply(t) {
    if (t==='dark') root.setAttribute('data-theme','dark');
    else if (t==='light') root.removeAttribute('data-theme');
    else {
      if (window.matchMedia && window.matchMedia('(prefers-color-scheme: dark)').matches)
        root.setAttribute('data-theme','dark');
      else root.removeAttribute('data-theme');
    }
  }
  let t = localStorage.getItem('theme') || 'light';
  if (!['light','dark','auto'].includes(t)) t='light';
  apply(t);
  window.__toggleTheme = function() {
    let cur = localStorage.getItem('theme') || 'light';
    if (cur==='light') cur='dark';
    else if (cur==='dark') cur='auto';
    else cur='light';
    localStorage.setItem('theme', cur);
    apply(cur);
    const el=document.getElementById('theme-label');
    if(el) el.textContent = cur.toUpperCase();
  }
  window.__expandAll = function(open) {
    document.querySelectorAll('details').forEach(d => d.open = !!open);
  }
})();
</script>
</head>
<body>
  <div class="container">
    <div class="header">
      <h1>arXiv 论文速递</h1>
      <div style="display:flex;gap:10px;align-items:center">
        
<div class="controls">
  <button class="btn" onclick="__toggleTheme()">Theme: <span id="theme-label" style="margin-left:6px">AUTO</span></button>
  <button class="btn" onclick="__expandAll(true)">Expand All</button>
  <button class="btn" onclick="__expandAll(false)">Collapse All</button>
</div>

        <span class="badge">2026-01-29 05:36</span>
      </div>
    </div>
    <div class="hr"></div>
    <div>Snapshot: 20260129_0536</div>
    <div class="row"><div class="card">
<div class="title">Self-Distillation Enables Continual Learning</div>
<div class="meta-line">Authors: Idan Shenfeld, Mehul Damani, Jonas Hübotter, Pulkit Agrawal</div>
<div class="meta-line">First: 2026-01-27T18:59:08+00:00 · Latest: 2026-01-27T18:59:08+00:00</div>
<div class="links" style="margin-top:8px"><a href="https://arxiv.org/abs/2601.19897v1">Abs</a> · <a href="https://arxiv.org/pdf/2601.19897v1">PDF</a> · <a href="https://huggingface.co/huggingface">Code1</a> · <a href="https://huggingface.co/docs/hub/spaces">Code2</a></div>
<details class="detail"><summary>Abstract</summary>
<div class="mono">Continual learning, enabling models to acquire new skills and knowledge without degrading existing capabilities, remains a fundamental challenge for foundation models. While on-policy reinforcement learning can reduce forgetting, it requires explicit reward functions that are often unavailable. Learning from expert demonstrations, the primary alternative, is dominated by supervised fine-tuning (SFT), which is inherently off-policy. We introduce Self-Distillation Fine-Tuning (SDFT), a simple method that enables on-policy learning directly from demonstrations. SDFT leverages in-context learning by using a demonstration-conditioned model as its own teacher, generating on-policy training signals that preserve prior capabilities while acquiring new skills. Across skill learning and knowledge acquisition tasks, SDFT consistently outperforms SFT, achieving higher new-task accuracy while substantially reducing catastrophic forgetting. In sequential learning experiments, SDFT enables a single model to accumulate multiple skills over time without performance regression, establishing on-policy distillation as a practical path to continual learning from demonstrations.</div></details>
<details class="detail"><summary>中文标题/摘要</summary>
<div class="mono"><b>标题：</b>自蒸馏实现持续学习</div>
<div class="mono" style="margin-top:8px">持续学习旨在使模型能够获取新技能与知识而不损害现有能力，这始终是基础模型面临的核心挑战。虽然在线策略强化学习可缓解遗忘问题，但其依赖的显式奖励函数往往难以获取。基于专家示范的主流替代方案——监督微调（SFT）本质上属于离线策略方法。本文提出自蒸馏微调（SDFT），这是一种可直接从示范数据中进行在线策略学习的简洁方法。SDFT通过将示范条件化模型作为自身教师，利用上下文学习生成在线策略训练信号，从而在掌握新技能的同时保持原有能力。在技能学习与知识获取任务中，SDFT持续优于SFT，在显著降低灾难性遗忘的同时获得更高的新任务准确率。序列学习实验表明，SDFT能使单一模型随时间累积多项技能且不发生性能衰退，为基于示范的持续学习提供了切实可行的在线蒸馏路径。</div>
</details>
<details class="detail"><summary>Summary / 总结</summary>
<div class="mono">To address the challenge of continual learning in foundation models, where supervised fine-tuning (SFT) as an off-policy method often leads to catastrophic forgetting, this paper introduces Self-Distillation Fine-Tuning (SDFT) to enable on-policy learning directly from demonstrations. The method uses a demonstration-conditioned model to generate its own training signals through in-context learning, acting as its own teacher to preserve prior capabilities while acquiring new skills. Experimental results across skill learning and knowledge acquisition tasks show that SDFT consistently outperforms SFT, achieving higher new-task accuracy and substantially reducing forgetting, and it enables a single model to sequentially accumulate multiple skills without performance regression.</div>
<div class="mono" style="margin-top:8px">为解决基础模型持续学习中获取新技能常导致原有能力退化的问题，本文提出了自蒸馏微调方法。该方法通过利用演示条件模型生成自身训练信号，实现基于演示的在线策略学习，利用上下文学习使模型充当自己的教师。在技能学习和知识获取任务上的实验结果表明，该方法持续优于标准的监督微调，在获得更高新任务准确率的同时显著减少了灾难性遗忘，并使单一模型能够顺序积累多种技能而无需性能回退。</div>
</details>
</div>
<div class="card">
<div class="title">Post-LayerNorm Is Back: Stable, ExpressivE, and Deep</div>
<div class="meta-line">Authors: Chen Chen, Lai Wei</div>
<div class="meta-line">First: 2026-01-27T18:58:46+00:00 · Latest: 2026-01-27T18:58:46+00:00</div>
<div class="links" style="margin-top:8px"><a href="https://arxiv.org/abs/2601.19895v1">Abs</a> · <a href="https://arxiv.org/pdf/2601.19895v1">PDF</a> · <a href="https://huggingface.co/huggingface">Code1</a> · <a href="https://huggingface.co/docs/hub/spaces">Code2</a></div>
<details class="detail"><summary>Abstract</summary>
<div class="mono">Large language model (LLM) scaling is hitting a wall. Widening models yields diminishing returns, and extending context length does not improve fundamental expressivity. In contrast, depth scaling offers theoretically superior expressivity, yet current Transformer architectures struggle to train reliably at extreme depths. We revisit the Post-LayerNorm (Post-LN) formulation, whose instability at scale caused its replacement by Pre-LN in modern LLMs. We show that the central failure mode of Post-LN arises from the ResNet-style residual pathway, which introduces gradient vanishing in deep networks. We present Keel, a Post-LN Transformer that replaces this residual path with a Highway-style connection. This modification preserves the gradient flow through the residual branch, preventing signal vanishing from the top layers to the bottom. Unlike prior methods, Keel enables stable training at extreme depths without requiring specialized initialization or complex optimization tricks. Keel trains robustly at depths exceeding 1000 layers and consistently improves perplexity and depth-scaling characteristics over Pre-LN. These findings indicate that Post-LN, when paired with a Highway-style connection, provides a simple and effective foundation for building deeply scalable LLMs, opening the possibility for future infinite-depth architectures.</div></details>
<details class="detail"><summary>中文标题/摘要</summary>
<div class="mono"><b>标题：</b>后层归一化回归：稳定、高表达与深度扩展</div>
<div class="mono" style="margin-top:8px">大语言模型（LLM）的扩展正面临瓶颈：拓宽模型带来的收益递减，延长上下文长度也无法提升核心表达能力。相比之下，深度扩展理论上具有更优的表达潜力，但当前Transformer架构在极端深度下难以稳定训练。本文重新审视了后层归一化（Post-LN）结构——其在大规模训练中的不稳定性曾导致其被现代LLM中的前层归一化（Pre-LN）取代。我们发现Post-LN的核心缺陷源于类ResNet的残差路径，该路径会导致深层网络中的梯度消失。我们提出Keel模型，这是一种采用高速公路式连接替代传统残差路径的Post-LN Transformer。该改进通过残差分支保持梯度流动，防止信号从顶层向底层衰减。与现有方法不同，Keel无需特殊初始化或复杂优化技巧即可实现极端深度下的稳定训练。该模型在超过1000层的深度下仍能稳健训练，并在困惑度与深度扩展特性上持续优于Pre-LN。这些结果表明：结合高速公路式连接的Post-LN为构建深度可扩展的LLM提供了简洁有效的框架，为未来无限深度架构开辟了可能。</div>
</details>
<details class="detail"><summary>Summary / 总结</summary>
<div class="mono">The motivation is to overcome the diminishing returns of widening models and limited expressivity from context length extension in large language models by pursuing depth scaling, which offers superior theoretical expressivity but is hindered by training instability in deep Transformers. The method revisits the Post-LayerNorm formulation, identifies gradient vanishing in its ResNet-style residual pathway as the key failure mode, and introduces Keel, a Post-LN Transformer that replaces this with a Highway-style connection to preserve gradient flow through the residual branch. Experimental results show that Keel enables stable training at depths exceeding 1000 layers without specialized initialization or complex tricks, consistently improving perplexity and depth-scaling characteristics over Pre-LN, indicating a simple and effective foundation for deeply scalable LLMs.</div>
<div class="mono" style="margin-top:8px">该研究的动机在于，通过宽度或上下文长度扩展大语言模型存在收益递减或无法提升表达能力的局限，而深度扩展理论上能提供更优的表达能力，但在深度Transformer中受到训练不稳定性的阻碍。方法上重新审视了后层归一化（Post-LN）架构，发现其ResNet风格残差路径导致的梯度消失是主要失败模式，并提出了Keel，一种用高速公路风格连接替代该路径的Post-LN Transformer，以保持梯度流动。实验结果表明，Keel能在超过1000层的深度下稳定训练，无需专门初始化或复杂优化技巧，持续改善困惑度和深度扩展特性，优于前层归一化（Pre-LN），为构建深度可扩展的大语言模型提供了简单有效的基础。</div>
</details>
</div>
<div class="card">
<div class="title">M-SGWR: Multiscale Similarity and Geographically Weighted Regression</div>
<div class="meta-line">Authors: M. Naser Lessani, Zhenlong Li, Manzhu Yu, Helen Greatrex, Chan Shen</div>
<div class="meta-line">First: 2026-01-27T18:55:12+00:00 · Latest: 2026-01-27T18:55:12+00:00</div>
<div class="links" style="margin-top:8px"><a href="https://arxiv.org/abs/2601.19888v1">Abs</a> · <a href="https://arxiv.org/pdf/2601.19888v1">PDF</a> · <a href="https://huggingface.co/huggingface">Code1</a> · <a href="https://huggingface.co/docs/hub/spaces">Code2</a></div>
<details class="detail"><summary>Abstract</summary>
<div class="mono">The first law of geography is a cornerstone of spatial analysis, emphasizing that nearby and related locations tend to be more similar, however, defining what constitutes &quot;near&quot; and &quot;related&quot; remains challenging, as different phenomena exhibit distinct spatial patterns. Traditional local regression models, such as Geographically Weighted Regression (GWR) and Multiscale GWR (MGWR), quantify spatial relationships solely through geographic proximity. In an era of globalization and digital connectivity, however, geographic proximity alone may be insufficient to capture how locations are interconnected. To address this limitation, we propose a new multiscale local regression framework, termed M-SGWR, which characterizes spatial interaction across two dimensions: geographic proximity and attribute (variable) similarity. For each predictor, geographic and attribute-based weight matrices are constructed separately and then combined using an optimized parameter, alpha, which governs their relative contribution to local model fitting. Analogous to variable-specific bandwidths in MGWR, the optimal alpha varies by predictor, allowing the model to flexibly account for geographic, mixed, or non-spatial (remote similarity) effects. Results from two simulation experiments and one empirical application demonstrate that M-SGWR consistently outperforms GWR, SGWR, and MGWR across all goodness-of-fit metrics.</div></details>
<details class="detail"><summary>中文标题/摘要</summary>
<div class="mono"><b>标题：</b>M-SGWR：多尺度相似性与地理加权回归</div>
<div class="mono" style="margin-top:8px">地理学第一定律是空间分析的基石，强调邻近且相关的位置往往更相似，但如何定义“邻近”与“相关”仍具挑战，因为不同现象呈现各异的空间模式。传统局部回归模型（如地理加权回归GWR和多尺度GWR）仅通过地理邻近性量化空间关系。然而在全球化与数字互联时代，仅依赖地理邻近性可能不足以捕捉位置间的关联。为突破此局限，我们提出一种新的多尺度局部回归框架M-SGWR，从地理邻近性和属性（变量）相似性两个维度刻画空间交互。针对每个预测变量，分别构建基于地理和基于属性的权重矩阵，并通过优化参数α进行组合，该参数控制二者对局部模型拟合的相对贡献。类似于MGWR中变量特定带宽的机制，最优α随预测变量变化，使模型能灵活适应地理效应、混合效应或非空间（远程相似性）效应。两项模拟实验与一项实证应用的结果表明，M-SGWR在所有拟合优度指标上均持续优于GWR、SGWR和MGWR。</div>
</details>
<details class="detail"><summary>Summary / 总结</summary>
<div class="mono">The research is motivated by the challenge that traditional geographically weighted regression models rely solely on geographic proximity, which may not fully capture spatial relationships in an interconnected world. The proposed M-SGWR method extends multiscale local regression by integrating both geographic proximity and attribute similarity, using an optimized parameter alpha to balance their contributions for each predictor. Experimental results from simulations and an empirical application show that M-SGWR consistently outperforms existing models like GWR, SGWR, and MGWR in goodness-of-fit metrics.</div>
<div class="mono" style="margin-top:8px">该研究的动机在于传统地理加权回归模型仅依赖地理邻近性，而在全球化与数字互联时代，属性相似性同样重要，这可能导致空间关系捕捉不足。提出的M-SGWR方法通过整合地理邻近性和属性相似性，为每个预测变量构建独立的权重矩阵，并使用优化的参数alpha进行组合，从而灵活建模空间、混合或非空间效应。模拟实验和实证应用的结果表明，M-SGWR在所有拟合优度指标上均一致优于GWR、SGWR和MGWR等现有模型。</div>
</details>
</div>
<div class="card">
<div class="title">SONIC: Spectral Oriented Neural Invariant Convolutions</div>
<div class="meta-line">Authors: Gijs Joppe Moens, Regina Beets-Tan, Eduardo H. P. Pooch</div>
<div class="meta-line">Venue: ICLR 2026</div>
<div class="meta-line">First: 2026-01-27T18:51:11+00:00 · Latest: 2026-01-27T18:51:11+00:00</div>
<div class="meta-line">Comments: 10 pages, 4 figures. Accepted at ICLR 2026</div>
<div class="links" style="margin-top:8px"><a href="https://arxiv.org/abs/2601.19884v1">Abs</a> · <a href="https://arxiv.org/pdf/2601.19884v1">PDF</a> · <a href="https://huggingface.co/huggingface">Code1</a> · <a href="https://huggingface.co/docs/hub/spaces">Code2</a></div>
<details class="detail"><summary>Abstract</summary>
<div class="mono">Convolutional Neural Networks (CNNs) rely on fixed-size kernels scanning local patches, which limits their ability to capture global context or long-range dependencies without very deep architectures. Vision Transformers (ViTs), in turn, provide global connectivity but lack spatial inductive bias, depend on explicit positional encodings, and remain tied to the initial patch size. Bridging these limitations requires a representation that is both structured and global. We introduce SONIC (Spectral Oriented Neural Invariant Convolutions), a continuous spectral parameterisation that models convolutional operators using a small set of shared, orientation-selective components. These components define smooth responses across the full frequency domain, yielding global receptive fields and filters that adapt naturally across resolutions. Across synthetic benchmarks, large-scale image classification, and 3D medical datasets, SONIC shows improved robustness to geometric transformations, noise, and resolution shifts, and matches or exceeds convolutional, attention-based, and prior spectral architectures with an order of magnitude fewer parameters. These results demonstrate that continuous, orientation-aware spectral parameterisations provide a principled and scalable alternative to conventional spatial and spectral operators.</div></details>
<details class="detail"><summary>中文标题/摘要</summary>
<div class="mono"><b>标题：</b>SONIC：谱向神经不变卷积</div>
<div class="mono" style="margin-top:8px">卷积神经网络（CNNs）依赖固定尺寸的核对局部图像块进行扫描，这限制了其在非极深架构下捕获全局上下文或长程依赖的能力。视觉Transformer（ViTs）虽提供全局连接性，但缺乏空间归纳偏置、依赖显式位置编码，且受限于初始图像块尺寸。为突破这些限制，需要兼具结构化与全局性的表征。我们提出SONIC（谱向神经不变卷积），这是一种连续谱参数化方法，通过少量共享的朝向选择性组件对卷积算子进行建模。这些组件在全频域定义平滑响应，从而产生全局感受野和能自然适应不同分辨率的滤波器。在合成基准测试、大规模图像分类和3D医学数据集上的实验表明，SONIC对几何变换、噪声和分辨率变化具有更强的鲁棒性，且以数量级更少的参数匹配或超越了传统卷积、基于注意力的架构及先前的谱架构。这些结果证明，连续且朝向感知的谱参数化为传统空间与谱算子提供了原理性且可扩展的替代方案。</div>
</details>
<details class="detail"><summary>Summary / 总结</summary>
<div class="mono">The research addresses the limitations of Convolutional Neural Networks (CNNs) in capturing global context and Vision Transformers (ViTs) in lacking spatial inductive bias by proposing a structured, global representation. The method introduces SONIC, a continuous spectral parameterization that models convolutional operators using a small set of shared, orientation-selective components to define smooth responses across the full frequency domain, enabling global receptive fields and resolution-adaptive filters. Experimental results on synthetic benchmarks, large-scale image classification, and 3D medical datasets show that SONIC improves robustness to geometric transformations, noise, and resolution shifts, and matches or exceeds the performance of convolutional, attention-based, and prior spectral architectures with significantly fewer parameters.</div>
<div class="mono" style="margin-top:8px">本研究针对卷积神经网络因固定局部核而难以捕获全局上下文，以及视觉Transformer缺乏空间归纳偏置且依赖位置编码的局限性。方法提出了SONIC，一种连续频谱参数化方法，使用少量共享的、方向选择性的组件来建模卷积算子，从而在全频域定义平滑响应，实现全局感受野和分辨率自适应。在合成基准测试、大规模图像分类和3D医学数据集上的实验结果表明，SONIC提升了对几何变换、噪声和分辨率变化的鲁棒性，并以更少的参数匹配或超越了卷积、基于注意力及先前频谱架构的性能。</div>
</details>
</div>
<div class="card">
<div class="title">RHSIA: Real-time Hemodynamics Surrogation for Non-idealized Intracranial Aneurysms</div>
<div class="meta-line">Authors: Yiying Sheng, Wenhao Ding, Dylan Roi, Leonard Leong Litt Yeo, Hwa Liang Leo, Choon Hwai Yap</div>
<div class="meta-line">First: 2026-01-27T18:39:58+00:00 · Latest: 2026-01-27T18:39:58+00:00</div>
<div class="links" style="margin-top:8px"><a href="https://arxiv.org/abs/2601.19876v1">Abs</a> · <a href="https://arxiv.org/pdf/2601.19876v1">PDF</a> · <a href="https://huggingface.co/huggingface">Code1</a> · <a href="https://huggingface.co/docs/hub/spaces">Code2</a></div>
<details class="detail"><summary>Abstract</summary>
<div class="mono">Extensive studies suggested that fluid mechanical markers of intracranial aneurysms (IAs) derived from Computational Fluid Dynamics (CFD) can indicate disease progression risks, but to date this has not been translated clinically. This is because CFD requires specialized expertise and is time-consuming and low throughput, making it difficult to support clinical trials. A deep learning model that maps IA morphology to biomechanical markers can address this, enabling physicians to obtain these markers in real time without performing CFD. Here, we show that a Graph Transformer model that incorporates temporal information, which is supervised by large CFD data, can accurately predict Wall Shear Stress (WSS) across the cardiac cycle from IA surface meshes. The model effectively captures the temporal variations of the WSS pattern, achieving a Structural Similarity Index (SSIM) of up to 0.981 and a maximum-based relative L2 error of 2.8%. Ablation studies and SOTA comparison confirmed its optimality. Further, as pulsatile CFD data is computationally expensive to generate and sample sizes are limited, we engaged a strategy of injecting a large amount of steady-state CFD data, which are extremely low-cost to generate, as augmentation. This approach enhances network performance substantially when pulsatile CFD data sample size is small. Our study provides a proof of concept that temporal sequences cardiovascular fluid mechanical parameters can be computed in real time using a deep learning model from the geometric mesh, and this is achievable even with small pulsatile CFD sample size. Our approach is likely applicable to other cardiovascular scenarios.</div></details>
<details class="detail"><summary>中文标题/摘要</summary>
<div class="mono"><b>标题：</b>RHSIA：非理想化颅内动脉瘤的实时血流动力学替代模型</div>
<div class="mono" style="margin-top:8px">大量研究表明，基于计算流体动力学（CFD）获得的颅内动脉瘤（IAs）流体力学标志物可提示疾病进展风险，但迄今尚未实现临床转化。这主要因为CFD需要专业知识、耗时且通量低，难以支撑临床试验。通过深度学习模型将IA形态映射至生物力学标志物可解决此问题，使医生无需执行CFD即可实时获取这些标志物。本文提出一种基于大规模CFD数据监督、融合时序信息的图变换器模型，能够从IA表面网格精确预测整个心动周期内的壁面剪切应力（WSS）。该模型有效捕捉了WSS模式的时序变化，结构相似性指数（SSIM）最高达0.981，基于最大值的相对L2误差为2.8%。消融实验与前沿模型对比验证了其最优性。此外，鉴于脉动CFD数据生成计算成本高且样本有限，我们采用注入大量极低成本生成的稳态CFD数据进行数据增强的策略。该方法在脉动CFD样本量较小时显著提升网络性能。本研究通过概念验证表明：基于几何网格的深度学习模型可实时计算心血管流体力学参数的时序序列，且在小样本脉动CFD数据下仍可实现。该方法有望推广至其他心血管研究场景。</div>
</details>
<details class="detail"><summary>Summary / 总结</summary>
<div class="mono">To overcome the clinical translation barrier of computational fluid dynamics (CFD) for intracranial aneurysm risk assessment, which is slow and expertise-intensive, this research develops a deep learning model to predict hemodynamic markers in real time from aneurysm geometry. The method employs a Graph Transformer supervised by CFD data to map surface meshes to time-resolved Wall Shear Stress (WSS), and augments limited pulsatile CFD data with abundant, low-cost steady-state CFD data to improve learning. Experimental results show the model accurately captures temporal WSS variations, achieving a Structural Similarity Index up to 0.981 and a relative L2 error of 2.8%, with ablation studies confirming its optimal performance.</div>
<div class="mono" style="margin-top:8px">为解决基于计算流体动力学的颅内动脉瘤血流动力学分析在临床转化中面临的专业性强、耗时且通量低的问题，本研究提出了一种深度学习模型，可直接将动脉瘤形态映射至生物力学指标。该方法采用由CFD数据监督的图Transformer，从表面网格预测随时间变化的壁面剪切力，并通过注入大量低成本稳态CFD数据来增强有限的脉动数据样本。实验结果表明，该模型能准确捕捉壁面剪切力的时间变化模式，结构相似性指数最高达0.981，相对L2误差为2.8%，消融实验验证了其最优性能，并证明即使在脉动数据样本较小的情况下也能保持鲁棒性。</div>
</details>
</div>
<div class="card">
<div class="title">A simple algorithm for output range analysis for deep neural networks</div>
<div class="meta-line">Authors: Helder Rojas, Nilton Rojas, Espinoza J. B., Luis Huamanchumo</div>
<div class="meta-line">First: 2024-07-02T22:47:40+00:00 · Latest: 2026-01-27T18:39:11+00:00</div>
<div class="links" style="margin-top:8px"><a href="https://arxiv.org/abs/2407.02700v4">Abs</a> · <a href="https://arxiv.org/pdf/2407.02700v4">PDF</a> · <a href="https://huggingface.co/huggingface">Code1</a> · <a href="https://huggingface.co/docs/hub/spaces">Code2</a></div>
<details class="detail"><summary>Abstract</summary>
<div class="mono">This paper presents a novel approach for the output range estimation problem in Deep Neural Networks (DNNs) by integrating a Simulated Annealing (SA) algorithm tailored to operate within constrained domains and ensure convergence towards global optima. The method effectively addresses the challenges posed by the lack of local geometric information and the high non-linearity inherent to DNNs, making it applicable to a wide variety of architectures, with a special focus on Residual Networks (ResNets) due to their practical importance. Unlike existing methods, our algorithm imposes minimal assumptions on the internal architecture of neural networks, thereby extending its usability to complex models. Theoretical analysis guarantees convergence, while extensive empirical evaluations-including optimization tests involving functions with multiple local minima-demonstrate the robustness of our algorithm in navigating non-convex response surfaces. The experimental results highlight the algorithm&#x27;s efficiency in accurately estimating DNN output ranges, even in scenarios characterized by high non-linearity and complex constraints. For reproducibility, Python codes and datasets used in the experiments are publicly available through our GitHub repository.</div></details>
<details class="detail"><summary>中文标题/摘要</summary>
<div class="mono"><b>标题：</b>一种用于深度神经网络输出范围分析的简易算法</div>
<div class="mono" style="margin-top:8px">本文提出了一种解决深度神经网络输出范围估计问题的新方法，通过集成一种在约束域内运行并确保收敛至全局最优的模拟退火算法。该方法有效应对了深度神经网络因缺乏局部几何信息及高度非线性带来的挑战，适用于多种网络架构，并特别关注具有重要实践意义的残差网络。与现有方法不同，本算法对神经网络内部结构假设极少，从而可扩展至复杂模型。理论分析保证了算法的收敛性，而广泛的实证评估（包括涉及多局部极小值函数的优化测试）证明了算法在非凸响应曲面上的鲁棒性。实验结果突显了算法在高非线性和复杂约束场景下仍能高效准确估计深度神经网络输出范围的优势。为促进可复现性，实验所用Python代码及数据集已通过GitHub仓库公开。</div>
</details>
<details class="detail"><summary>Summary / 总结</summary>
<div class="mono">This research addresses the challenge of estimating output ranges for deep neural networks (DNNs), which is difficult due to their high non-linearity and lack of local geometric information. The proposed method integrates a Simulated Annealing algorithm specifically tailored to operate within constrained domains, ensuring convergence to global optima with minimal assumptions on the network&#x27;s internal architecture, making it widely applicable including to complex models like ResNets. Experimental results, including tests on functions with multiple local minima, demonstrate the algorithm&#x27;s robustness and efficiency in accurately estimating output ranges for highly non-linear DNNs under complex constraints.</div>
<div class="mono" style="margin-top:8px">本研究针对深度神经网络因高度非线性和缺乏局部几何信息而难以估计输出范围的问题，提出了一种新方法。该方法集成了模拟退火算法，专门设计用于在约束域内运行，确保收敛到全局最优解，且对网络内部架构的假设极少，因此可广泛适用于包括残差网络在内的复杂模型。实验结果表明，该算法在具有多个局部最小值的函数测试中，能够稳健地处理非凸响应面，并在高非线性和复杂约束条件下高效、准确地估计深度神经网络的输出范围。</div>
</details>
</div>
<div class="card">
<div class="title">Bandits in Flux: Adversarial Constraints in Dynamic Environments</div>
<div class="meta-line">Authors: Tareq Si Salem</div>
<div class="meta-line">First: 2026-01-27T18:26:07+00:00 · Latest: 2026-01-27T18:26:07+00:00</div>
<div class="meta-line">Comments: Accepted to AISTATS 2026</div>
<div class="links" style="margin-top:8px"><a href="https://arxiv.org/abs/2601.19867v1">Abs</a> · <a href="https://arxiv.org/pdf/2601.19867v1">PDF</a> · <a href="https://huggingface.co/huggingface">Code1</a> · <a href="https://huggingface.co/docs/hub/spaces">Code2</a></div>
<details class="detail"><summary>Abstract</summary>
<div class="mono">We investigate the challenging problem of adversarial multi-armed bandits operating under time-varying constraints, a scenario motivated by numerous real-world applications. To address this complex setting, we propose a novel primal-dual algorithm that extends online mirror descent through the incorporation of suitable gradient estimators and effective constraint handling. We provide theoretical guarantees establishing sublinear dynamic regret and sublinear constraint violation for our proposed policy. Our algorithm achieves state-of-the-art performance in terms of both regret and constraint violation. Empirical evaluations demonstrate the superiority of our approach.</div></details>
<details class="detail"><summary>中文标题/摘要</summary>
<div class="mono"><b>标题：</b>动态环境中的对抗约束：通量中的多臂赌博机问题</div>
<div class="mono" style="margin-top:8px">本文研究了在时变约束条件下运行的对抗性多臂赌博机这一具有挑战性的问题，该场景受众多实际应用驱动。为应对这一复杂设置，我们提出了一种新颖的原对偶算法，通过整合合适的梯度估计器和有效的约束处理机制，扩展了在线镜像下降法。我们提供了理论保证，证明所提策略具有次线性动态遗憾和次线性约束违反。该算法在遗憾和约束违反方面均达到了最先进的性能。实证评估验证了我们方法的优越性。</div>
</details>
<details class="detail"><summary>Summary / 总结</summary>
<div class="mono">Motivated by real-world applications requiring decisions under changing constraints, this paper studies adversarial multi-armed bandits in dynamic environments with time-varying constraints. The method introduces a novel primal-dual algorithm that extends online mirror descent with tailored gradient estimators and a mechanism for effective constraint management. Theoretically, the algorithm guarantees sublinear dynamic regret and sublinear constraint violation, achieving state-of-the-art performance, which is empirically validated through experiments demonstrating its superiority.</div>
<div class="mono" style="margin-top:8px">本研究针对具有时变约束的对抗性多臂老虎机这一挑战性问题，其动机源于约束不断演化的现实应用。该方法提出了一种新颖的原对偶算法，通过整合特定的梯度估计器和有效的约束处理机制，扩展了在线镜像下降法。理论上，该算法保证了次线性的动态遗憾和次线性的约束违反，达到了最先进的性能，并通过实验验证了其优越性。</div>
</details>
</div>
<div class="card">
<div class="title">Deep Semantic Inference over the Air: An Efficient Task-Oriented Communication System</div>
<div class="meta-line">Authors: Chenyang Wang, Roger Olsson, Stefan Forsström, Qing He</div>
<div class="meta-line">First: 2025-08-18T09:18:07+00:00 · Latest: 2026-01-27T18:26:00+00:00</div>
<div class="meta-line">Comments: Accepted at WCNC 2026</div>
<div class="links" style="margin-top:8px"><a href="https://arxiv.org/abs/2508.12748v2">Abs</a> · <a href="https://arxiv.org/pdf/2508.12748v2">PDF</a> · <a href="https://huggingface.co/huggingface">Code1</a> · <a href="https://huggingface.co/docs/hub/spaces">Code2</a></div>
<details class="detail"><summary>Abstract</summary>
<div class="mono">Empowered by deep learning, semantic communication marks a paradigm shift from transmitting raw data to conveying task-relevant meaning, enabling more efficient and intelligent wireless systems. In this study, we explore a deep learning-based task-oriented communication framework that jointly considers classification performance, computational latency, and communication cost. We evaluate ResNets-based models on the CIFAR-10 and CIFAR-100 datasets to simulate real-world classification tasks in wireless environments. We partition the model at various points to simulate split inference across a wireless channel. By varying the split location and the size of the transmitted semantic feature vector, we systematically analyze the trade-offs between task accuracy and resource efficiency. Experimental results show that, with appropriate model partitioning and semantic feature compression, the system can retain over 85\% of baseline accuracy while significantly reducing both computational load and communication overhead.</div></details>
<details class="detail"><summary>中文标题/摘要</summary>
<div class="mono"><b>标题：</b>空中深度语义推理：一种高效的任务导向通信系统</div>
<div class="mono" style="margin-top:8px">在深度学习的赋能下，语义通信标志着从传输原始数据向传递任务相关意义的范式转变，从而实现了更高效、更智能的无线系统。本研究探索了一种基于深度学习的任务导向通信框架，该框架综合考虑了分类性能、计算延迟和通信成本。我们在CIFAR-10和CIFAR-100数据集上评估基于ResNet的模型，以模拟无线环境中的真实分类任务。通过在不同位置分割模型来模拟跨无线信道的分割推理。通过改变分割位置和传输的语义特征向量大小，我们系统分析了任务准确性与资源效率之间的权衡。实验结果表明，通过适当的模型分割和语义特征压缩，系统能在显著降低计算负载和通信开销的同时，保持超过85%的基线准确率。</div>
</details>
<details class="detail"><summary>Summary / 总结</summary>
<div class="mono">This research addresses the need for efficient wireless communication systems by shifting from raw data transmission to task-relevant semantic communication, aiming to jointly optimize classification accuracy, computational latency, and communication cost. The method employs a deep learning-based framework using ResNets models on CIFAR-10 and CIFAR-100 datasets, simulating split inference over a wireless channel by partitioning the model at different points and varying the size of the transmitted semantic feature vector to explore trade-offs. Key experimental findings demonstrate that with strategic model partitioning and semantic feature compression, the system can maintain over 85% of the baseline classification accuracy while substantially reducing both computational load and communication overhead.</div>
<div class="mono" style="margin-top:8px">本研究针对无线系统中任务导向通信的效率需求，旨在超越原始数据传输以传递语义信息。方法采用基于深度学习的框架，联合优化分类性能、计算延迟和通信成本，在CIFAR-10和CIFAR-100数据集上使用ResNets模拟无线信道上的分割推理。实验结果表明，通过策略性的模型分割和语义特征压缩，系统能在保持超过85%基线准确率的同时，显著降低计算负载和通信开销。</div>
</details>
</div>
<div class="card">
<div class="title">Calibration without Ground Truth</div>
<div class="meta-line">Authors: Yuqing Kong, Mingyu Song, Yizhou Wang, Yifan Wu</div>
<div class="meta-line">First: 2026-01-27T18:18:47+00:00 · Latest: 2026-01-27T18:18:47+00:00</div>
<div class="links" style="margin-top:8px"><a href="https://arxiv.org/abs/2601.19862v1">Abs</a> · <a href="https://arxiv.org/pdf/2601.19862v1">PDF</a> · <a href="https://huggingface.co/huggingface">Code1</a> · <a href="https://huggingface.co/docs/hub/spaces">Code2</a></div>
<details class="detail"><summary>Abstract</summary>
<div class="mono">Villalobos et al. [2024] predict that publicly available human text will be exhausted within the next decade. Thus, improving models without access to ground-truth labels becomes increasingly important. We propose a label-free post-processing framework that improves a strong but miscalibrated model using a weaker yet better-calibrated reference. Our framework guarantees a strict performance improvement under any proper loss. Our approach is based on a characterization of when strict improvement is possible: when the strong and reference models are not mutually calibrated. We formalize this condition, connect it to arbitrage and no-trade results from economics, and develop an efficient Bregman projection algorithm that guarantees worst-case loss reduction without labels. Experiments on representative LLMs across varying scales demonstrate that our label-free method significantly reduces proper losses and calibration errors, achieving performance competitive with supervised baselines.</div></details>
<details class="detail"><summary>中文标题/摘要</summary>
<div class="mono"><b>标题：</b>无需真实标签的校准方法</div>
<div class="mono" style="margin-top:8px">Villalobos等人[2024]预测，公开可用的人类文本将在未来十年内耗尽。因此，在无法获取真实标签的情况下改进模型变得日益重要。我们提出一种无需标签的后处理框架，利用校准效果更好但性能较弱的参考模型来改进强大但校准不佳的模型。该框架在任何适当损失函数下均保证严格性能提升。我们的方法基于对严格改进可能性的理论刻画：当强模型与参考模型未达到相互校准时。我们将此条件形式化，将其与经济学中的套利和无交易定理相联系，并开发了一种高效的布雷格曼投影算法，可在无标签情况下保证最坏情况损失降低。在不同规模的典型大语言模型上的实验表明，我们的无标签方法能显著降低适当损失和校准误差，达到与有监督基线相当的性能水平。</div>
</details>
<details class="detail"><summary>Summary / 总结</summary>
<div class="mono">The impending exhaustion of publicly available human text necessitates methods to improve models without ground-truth labels. This work proposes a label-free post-processing framework that refines a strong but miscalibrated model using a weaker yet better-calibrated reference model, guaranteeing strict improvement under any proper loss. The method is based on a formal condition of when improvement is possible—when the models are not mutually calibrated—and employs an efficient Bregman projection algorithm. Experiments on large language models of varying scales show the method significantly reduces proper losses and calibration errors, achieving performance competitive with supervised baselines.</div>
<div class="mono" style="margin-top:8px">本研究针对人类生成文本即将耗尽且模型需在无真实标签下改进的问题，提出了一种无需标签的后处理框架，利用一个较弱但校准更好的参考模型来改进强大但校准不佳的模型，保证在任何适当损失函数下严格提升性能。该方法基于互校准条件形式化改进可能性，将其与经济学中的套利理论相联系，并采用高效的布雷格曼投影算法。在不同规模的代表性大语言模型上的实验表明，该无标签方法显著降低了适当损失和校准误差，性能与有监督基线方法相当。</div>
</details>
</div>
<div class="card">
<div class="title">MIP against Agent: Malicious Image Patches Hijacking Multimodal OS Agents</div>
<div class="meta-line">Authors: Lukas Aichberger, Alasdair Paren, Guohao Li, Philip Torr, Yarin Gal, Adel Bibi</div>
<div class="meta-line">Venue: NeurIPS 2025</div>
<div class="meta-line">First: 2025-03-13T18:59:12+00:00 · Latest: 2026-01-27T18:10:17+00:00</div>
<div class="meta-line">Comments: NeurIPS 2025</div>
<div class="links" style="margin-top:8px"><a href="https://arxiv.org/abs/2503.10809v3">Abs</a> · <a href="https://arxiv.org/pdf/2503.10809v3">PDF</a> · <a href="https://huggingface.co/huggingface">Code1</a> · <a href="https://huggingface.co/docs/hub/spaces">Code2</a></div>
<details class="detail"><summary>Abstract</summary>
<div class="mono">Recent advances in operating system (OS) agents have enabled vision-language models (VLMs) to directly control a user&#x27;s computer. Unlike conventional VLMs that passively output text, OS agents autonomously perform computer-based tasks in response to a single user prompt. OS agents do so by capturing, parsing, and analysing screenshots and executing low-level actions via application programming interfaces (APIs), such as mouse clicks and keyboard inputs. This direct interaction with the OS significantly raises the stakes, as failures or manipulations can have immediate and tangible consequences. In this work, we uncover a novel attack vector against these OS agents: Malicious Image Patches (MIPs), adversarially perturbed screen regions that, when captured by an OS agent, induce it to perform harmful actions by exploiting specific APIs. For instance, a MIP can be embedded in a desktop wallpaper or shared on social media to cause an OS agent to exfiltrate sensitive user data. We show that MIPs generalise across user prompts and screen configurations, and that they can hijack multiple OS agents even during the execution of benign instructions. These findings expose critical security vulnerabilities in OS agents that have to be carefully addressed before their widespread deployment.</div></details>
<details class="detail"><summary>中文标题/摘要</summary>
<div class="mono"><b>标题：</b>针对智能体攻击的恶意图像补丁：劫持多模态操作系统智能体</div>
<div class="mono" style="margin-top:8px">操作系统智能体的最新进展使视觉语言模型能够直接控制用户计算机。与传统被动输出文本的视觉语言模型不同，操作系统智能体能根据单一用户指令自主执行基于计算机的任务，通过捕获、解析和分析屏幕截图，并经由应用程序接口执行鼠标点击、键盘输入等底层操作。这种与操作系统的直接交互显著提高了风险，因为故障或操纵可能立即产生实质性后果。本研究揭示了一种针对此类操作系统智能体的新型攻击向量：恶意图像补丁——经过对抗性扰动的屏幕区域，当被操作系统智能体捕获时，会诱使其通过利用特定应用程序接口执行有害操作。例如，可将恶意图像补丁嵌入桌面壁纸或发布于社交媒体，导致操作系统智能体窃取敏感用户数据。研究表明，恶意图像补丁能泛化适应不同用户指令和屏幕配置，并能在执行良性指令期间劫持多个操作系统智能体。这些发现揭示了操作系统智能体中亟待广泛部署前审慎解决的关键安全漏洞。</div>
</details>
<details class="detail"><summary>Summary / 总结</summary>
<div class="mono">This research addresses security risks in operating system agents, which use vision-language models to autonomously control computers through screen analysis and API execution. The authors introduce Malicious Image Patches (MIPs), adversarially perturbed screen regions that hijack OS agents by exploiting their APIs to perform harmful actions like data exfiltration. Experiments demonstrate that MIPs generalize across different user prompts and screen configurations, successfully compromising multiple OS agents even during benign task execution, revealing critical vulnerabilities that require mitigation before widespread deployment.</div>
<div class="mono" style="margin-top:8px">本研究动机源于操作系统（OS）代理带来的安全风险，这些代理是基于视觉语言模型、通过API直接控制计算机的系统，其故障可能导致直接的现实后果。方法提出了一种名为恶意图像补丁（MIP）的新型攻击向量，即对抗性扰动的屏幕区域，当被OS代理捕获时，通过利用其API来劫持代理行为。主要实验结果表明，MIP能够泛化到不同的用户指令和屏幕配置，成功诱导多个OS代理执行有害操作（如窃取敏感数据），即使在执行良性任务时也能生效，从而揭示了在广泛部署前必须解决的关键安全漏洞。</div>
</details>
</div>
<div class="card">
<div class="title">Generative Latent Alignment for Interpretable Radar Based Occupancy Detection in Ambient Assisted Living</div>
<div class="meta-line">Authors: Huy Trinh</div>
<div class="meta-line">First: 2026-01-27T18:06:51+00:00 · Latest: 2026-01-27T18:06:51+00:00</div>
<div class="links" style="margin-top:8px"><a href="https://arxiv.org/abs/2601.19853v1">Abs</a> · <a href="https://arxiv.org/pdf/2601.19853v1">PDF</a> · <a href="https://huggingface.co/huggingface">Code1</a> · <a href="https://huggingface.co/docs/hub/spaces">Code2</a></div>
<details class="detail"><summary>Abstract</summary>
<div class="mono">In this work, we study how to make mmWave radar presence detection more interpretable for Ambient Assisted Living (AAL) settings, where camera-based sensing raises privacy concerns. We propose a Generative Latent Alignment (GLA) framework that combines a lightweight convolutional variational autoencoder with a frozen CLIP text encoder to learn a low-dimensional latent representation of radar Range-Angle (RA) heatmaps. The latent space is softly aligned with two semantic anchors corresponding to &quot;empty room&quot; and &quot;person present&quot;, and Grad-CAM is applied in this aligned latent space to visualize which spatial regions support each presence decision. On our mmWave radar dataset, we qualitatively observe that the &quot;person present&quot; class produces compact Grad-CAM blobs that coincide with strong RA returns, whereas &quot;empty room&quot; samples yield diffuse or no evidence. We also conduct an ablation study using unrelated text prompts, which degrades both reconstruction and localization, suggesting that radar-specific anchors are important for meaningful explanations in this setting.</div></details>
<details class="detail"><summary>中文标题/摘要</summary>
<div class="mono"><b>标题：</b>基于生成式潜在对齐的可解释雷达占用检测在环境辅助生活中的应用</div>
<div class="mono" style="margin-top:8px">本研究针对环境辅助生活场景中摄像头传感引发的隐私顾虑，探索如何提升毫米波雷达存在检测的可解释性。我们提出生成式潜在对齐框架，将轻量级卷积变分自编码器与冻结的CLIP文本编码器结合，学习雷达距离-角度热图的低维潜在表征。该潜在空间通过软对齐方式关联&#x27;空房间&#x27;与&#x27;有人存在&#x27;两个语义锚点，并在此对齐空间应用梯度加权类激活映射技术，可视化支撑各存在决策的空间区域。在毫米波雷达数据集上的定性观察显示：&#x27;有人存在&#x27;类别产生与强距离-角度回波重合的紧凑激活区域，而&#x27;空房间&#x27;样本则呈现弥散或无证据特征。通过无关文本提示的消融实验表明，雷达专用锚点对生成有意义解释具有重要作用，无关提示会导致重建与定位性能同时下降。</div>
</details>
<details class="detail"><summary>Summary / 总结</summary>
<div class="mono">This research aims to enhance the interpretability of millimeter-wave radar for occupancy detection in Ambient Assisted Living, addressing privacy limitations of camera-based systems. The method introduces a Generative Latent Alignment framework that trains a lightweight convolutional variational autoencoder on radar Range-Angle heatmaps and aligns its latent space with semantic text embeddings for &quot;empty room&quot; and &quot;person present&quot; using a frozen CLIP encoder; Grad-CAM is then applied in this aligned space to visualize decision-supporting regions. Experimental results on a radar dataset show that the &quot;person present&quot; class yields compact Grad-CAM activations aligned with strong radar returns, while &quot;empty room&quot; samples produce diffuse or no evidence, and an ablation study confirms that task-specific semantic anchors are crucial for both reconstruction quality and localization accuracy.</div>
<div class="mono" style="margin-top:8px">为解决环境辅助生活（AAL）中的隐私问题并提升可解释性，本研究提出了一种生成式潜在对齐（GLA）框架，用于毫米波雷达的占位检测。该方法采用轻量级卷积变分自编码器学习雷达距离-角度热图的潜在表示，并利用冻结的CLIP文本编码器将该空间与“空房间”和“有人存在”的语义锚点进行软对齐，从而通过Grad-CAM实现可视化。在毫米波雷达数据集上的实验结果表明，对齐后的模型对于有人状态能产生紧凑且与人体位置一致的Grad-CAM激活，对于空房间则产生弥散或无证据的响应；消融实验进一步证实，特定于雷达任务的语义锚点对于准确重建和定位解释至关重要。</div>
</details>
</div>
<div class="card">
<div class="title">Learning Dynamic Representations via An Optimally-Weighted Maximum Mean Discrepancy Optimization Framework for Continual Learning</div>
<div class="meta-line">Authors: KaiHui Huang, RunQing Wu, JinHui Sheng, HanYi Zhang, Ling Ge, JinYu Guo, Fei Ye</div>
<div class="meta-line">First: 2025-01-21T13:33:45+00:00 · Latest: 2026-01-27T18:04:09+00:00</div>
<div class="links" style="margin-top:8px"><a href="https://arxiv.org/abs/2501.12121v5">Abs</a> · <a href="https://arxiv.org/pdf/2501.12121v5">PDF</a> · <a href="https://huggingface.co/huggingface">Code1</a> · <a href="https://huggingface.co/docs/hub/spaces">Code2</a></div>
<details class="detail"><summary>Abstract</summary>
<div class="mono">Continual learning has emerged as a pivotal area of research, primarily due to its advantageous characteristic that allows models to persistently acquire and retain information. However, catastrophic forgetting can severely impair model performance. In this study, we address network forgetting by introducing a novel framework termed Optimally-Weighted Maximum Mean Discrepancy (OWMMD), which imposes penalties on representation alterations via a Multi-Level Feature Matching Mechanism (MLFMM). Furthermore, we propose an Adaptive Regularization Optimization (ARO) strategy to refine the adaptive weight vectors, which autonomously assess the significance of each feature layer throughout the optimization process, The proposed ARO approach can relieve the over-regularization problem and promote the future task learning. We conduct a comprehensive series of experiments, benchmarking our proposed method against several established baselines. The empirical findings indicate that our approach achieves state-of-the-art performance.</div></details>
<details class="detail"><summary>中文标题/摘要</summary>
<div class="mono"><b>标题：</b>基于最优加权最大均值差异优化框架的持续学习动态表示方法</div>
<div class="mono" style="margin-top:8px">持续学习因其能使模型持续获取并保留信息的优势而成为关键研究领域，但灾难性遗忘会严重损害模型性能。本研究通过提出名为最优加权最大均值差异（OWMMD）的新框架来解决网络遗忘问题，该框架通过多级特征匹配机制（MLFMM）对表示变化施加惩罚。此外，我们提出自适应正则化优化（ARO）策略来优化自适应权重向量，该策略能在整个优化过程中自主评估各特征层的重要性。所提出的ARO方法能缓解过正则化问题并促进未来任务学习。我们进行了全面实验，将所提方法与多个基准方法进行比较。实证结果表明，我们的方法达到了最先进的性能水平。</div>
</details>
<details class="detail"><summary>Summary / 总结</summary>
<div class="mono">This research addresses catastrophic forgetting in continual learning by proposing an Optimally-Weighted Maximum Mean Discrepancy (OWMMD) framework. The method penalizes changes in learned representations using a Multi-Level Feature Matching Mechanism and refines the process with an Adaptive Regularization Optimization (ARO) strategy to automatically weigh feature layer importance and mitigate over-regularization. Experimental results demonstrate that the approach achieves state-of-the-art performance against established baselines.</div>
<div class="mono" style="margin-top:8px">本研究针对持续学习中的灾难性遗忘问题，提出了一个最优加权最大均值差异（OWMMD）框架。该方法通过多层特征匹配机制惩罚学习表征的变化，并采用自适应正则化优化（ARO）策略来自主评估各特征层的重要性以缓解过正则化。实验结果表明，与现有基线方法相比，该方法取得了最先进的性能。</div>
</details>
</div>
<div class="card">
<div class="title">The Sparse Frontier: Sparse Attention Trade-offs in Transformer LLMs</div>
<div class="meta-line">Authors: Piotr Nawrot, Robert Li, Renjie Huang, Sebastian Ruder, Kelly Marchisio, Edoardo M. Ponti</div>
<div class="meta-line">First: 2025-04-24T17:39:25+00:00 · Latest: 2026-01-27T17:59:04+00:00</div>
<div class="links" style="margin-top:8px"><a href="https://arxiv.org/abs/2504.17768v2">Abs</a> · <a href="https://arxiv.org/pdf/2504.17768v2">PDF</a> · <a href="https://github.com/PiotrNawrot/sparse-frontier">Code1</a> · <a href="https://huggingface.co/huggingface">Code2</a> · <a href="https://huggingface.co/docs/hub/spaces">Code3</a></div>
<details class="detail"><summary>Abstract</summary>
<div class="mono">Sparse attention offers a promising strategy to extend long-context capabilities in Transformer LLMs, yet its efficiency-accuracy trade-offs remain unclear due to the lack of comprehensive evaluation. We address this gap with the largest-scale empirical analysis to date of training-free sparse attention, evaluating six methods across multiple model families and sizes, sequences up to 128K tokens, and sparsity levels up to 0.95 (i.e., $1/20$ attention budget) on nine diverse tasks. We first organise the rapidly evolving landscape of sparse attention methods into a taxonomy along four design axes. Our analysis then yields actionable insights: 1) sparse attention is effective -- larger sparse models outperform smaller dense ones at equivalent cost, improving the Pareto frontier; 2) due to computational constraints, token-to-page importance estimation is unfeasible during prefilling, where the choice of an alternative solution (global-to-token or block-to-block) depends on the task, but is possible during decoding, enabling better generalisation and tolerance to higher sparsity; 3) longer sequences tolerate higher sparsity, suggesting that fixed-budget methods in production are suboptimal. Together, these findings provide practical guidance for deploying sparse attention and methodological recommendations for future evaluations. Our code is available at https://github.com/PiotrNawrot/sparse-frontier.</div></details>
<details class="detail"><summary>中文标题/摘要</summary>
<div class="mono"><b>标题：</b>稀疏前沿：Transformer大语言模型中的稀疏注意力权衡</div>
<div class="mono" style="margin-top:8px">稀疏注意力为扩展Transformer大语言模型的长上下文能力提供了有前景的策略，但由于缺乏全面评估，其效率与准确性的权衡仍不明确。我们通过迄今最大规模的免训练稀疏注意力实证分析填补了这一空白，评估了六种方法，涵盖多个模型家族与规模、序列长度达128K标记、稀疏度高达0.95（即1/20注意力预算），并在九项多样化任务中展开测试。我们首先将快速演进的稀疏注意力方法沿四个设计维度归类为分类体系。分析得出可操作的见解：1）稀疏注意力有效——在同等成本下，更大的稀疏模型优于更小的稠密模型，改进了帕累托前沿；2）受计算限制，预填充阶段无法进行标记到页面的重要性估计，此时替代方案（全局到标记或块到块）的选择取决于任务，但在解码阶段可行，可实现更好的泛化能力与对更高稀疏度的容忍；3）更长序列能容忍更高稀疏度，表明生产环境中固定预算的方法并非最优。这些发现共同为部署稀疏注意力提供了实用指导，并为未来评估提出了方法论建议。代码发布于https://github.com/PiotrNawrot/sparse-frontier。</div>
</details>
<details class="detail"><summary>Summary / 总结</summary>
<div class="mono">This study addresses the unclear efficiency-accuracy trade-offs of sparse attention in Transformer LLMs, which is a promising technique for extending long-context capabilities. The authors conduct the largest-scale empirical analysis of training-free sparse attention to date, evaluating six methods across multiple model families, sequence lengths up to 128K tokens, and sparsity levels up to 0.95 on nine diverse tasks, first organizing the methods into a taxonomy. Key findings show that sparse attention is effective, with larger sparse models outperforming smaller dense ones at equivalent cost; computational constraints make token-to-page importance estimation unfeasible during prefilling, but possible during decoding for better generalization; and longer sequences tolerate higher sparsity, indicating fixed-budget methods in production are suboptimal.</div>
<div class="mono" style="margin-top:8px">本研究针对Transformer大语言模型中稀疏注意力在长上下文处理中效率与准确性权衡不明确的问题，进行了迄今最大规模的实证分析。它评估了六种无需训练的稀疏注意力方法，涵盖多种模型规模和长达128K标记的序列，并根据四个设计轴将其组织成分类体系。主要发现表明，稀疏注意力改善了帕累托前沿，在同等成本下，较大的稀疏模型性能优于较小的密集模型；在预填充阶段，计算限制使得令牌到页面的重要性估计不可行，需根据任务选择全局到令牌或块到块等替代方案，而在解码阶段则允许此类估计以实现更好的泛化和更高的稀疏度容忍度；且较长序列能容忍更高稀疏度，表明固定预算方法并非最优。</div>
</details>
</div>
<div class="card">
<div class="title">Chaotic Hedging with Iterated Integrals and Neural Networks</div>
<div class="meta-line">Authors: Ariel Neufeld, Philipp Schmocker</div>
<div class="meta-line">First: 2022-09-21T07:57:07+00:00 · Latest: 2026-01-27T17:46:03+00:00</div>
<div class="links" style="margin-top:8px"><a href="https://arxiv.org/abs/2209.10166v5">Abs</a> · <a href="https://arxiv.org/pdf/2209.10166v5">PDF</a> · <a href="https://huggingface.co/huggingface">Code1</a> · <a href="https://huggingface.co/docs/hub/spaces">Code2</a></div>
<details class="detail"><summary>Abstract</summary>
<div class="mono">In this paper, we derive an $L^p$-chaos expansion based on iterated Stratonovich integrals with respect to a given exponentially integrable continuous semimartingale. By omitting the orthogonality of the expansion, we show that every $p$-integrable functional, $p \in [1,\infty)$, can be approximated by a finite sum of iterated Stratonovich integrals. Using (possibly random) neural networks as integrands, we therefere obtain universal approximation results for $p$-integrable financial derivatives in the $L^p$-sense. Moreover, we can approximately solve the $L^p$-hedging problem (coinciding for $p = 2$ with the quadratic hedging problem), where the approximating hedging strategy can be computed in closed form within short runtime.</div></details>
<details class="detail"><summary>中文标题/摘要</summary>
<div class="mono"><b>标题：</b>基于迭代积分与神经网络的混沌对冲</div>
<div class="mono" style="margin-top:8px">本文基于给定指数可积连续半鞅的迭代Stratonovich积分，推导了$L^p$-混沌展开。通过放弃展开的正交性，我们证明任意$p$可积泛函（$p \in [1,\infty)$）均可由有限项迭代Stratonovich积分逼近。利用（可能随机的）神经网络作为被积函数，我们由此获得了$L^p$意义下$p$可积金融衍生品的通用逼近结果。此外，我们能够近似求解$L^p$-对冲问题（当$p=2$时与二次对冲问题一致），其中逼近对冲策略可在短时间内以闭合形式计算得出。</div>
</details>
<details class="detail"><summary>Summary / 总结</summary>
<div class="mono">This research addresses the challenge of approximating and hedging financial derivatives in L^p spaces, particularly when p=2 corresponds to quadratic hedging. The method develops an L^p-chaos expansion using iterated Stratonovich integrals without requiring orthogonality, then approximates integrands with random neural networks. Experimental results demonstrate that this approach achieves universal approximation of p-integrable derivatives in the L^p sense and provides closed-form solutions for approximating hedging strategies with short computational runtime.</div>
<div class="mono" style="margin-top:8px">本研究旨在为L^p可积金融衍生品开发一种通用逼近方法，并解决相关的对冲问题。该方法基于给定的指数可积连续半鞅，使用迭代Stratonovich积分构建L^p混沌展开，并放宽了展开的正交性要求，同时采用神经网络作为被积函数来逼近目标泛函。主要实验结果表明，该方法能在L^p意义上通用逼近任意p可积的衍生品，并能以封闭形式高效计算近似对冲策略，从而解决L^p对冲问题，其中p=2的情况对应于二次对冲。</div>
</details>
</div>
<div class="card">
<div class="title">A Multi-directional Meta-Learning Framework for Class-Generalizable Anomaly Detection</div>
<div class="meta-line">Authors: Padmaksha Roy, Lamine Mili, Almuatazbellah Boker</div>
<div class="meta-line">First: 2026-01-27T17:39:11+00:00 · Latest: 2026-01-27T17:39:11+00:00</div>
<div class="links" style="margin-top:8px"><a href="https://arxiv.org/abs/2601.19833v1">Abs</a> · <a href="https://arxiv.org/pdf/2601.19833v1">PDF</a> · <a href="https://huggingface.co/huggingface">Code1</a> · <a href="https://huggingface.co/docs/hub/spaces">Code2</a></div>
<details class="detail"><summary>Abstract</summary>
<div class="mono">In this paper, we address the problem of class-generalizable anomaly detection, where the objective is to develop a unified model by focusing our learning on the available normal data and a small amount of anomaly data in order to detect the completely unseen anomalies, also referred to as the out-of-distribution (OOD) classes. Adding to this challenge is the fact that the anomaly data is rare and costly to label. To achieve this, we propose a multidirectional meta-learning algorithm -- at the inner level, the model aims to learn the manifold of the normal data (representation); at the outer level, the model is meta-tuned with a few anomaly samples to maximize the softmax confidence margin between the normal and anomaly samples (decision surface calibration), treating normals as in-distribution (ID) and anomalies as out-of-distribution (OOD). By iteratively repeating this process over multiple episodes of predominantly normal and a small number of anomaly samples, we realize a multidirectional meta-learning framework. This two-level optimization, enhanced by multidirectional training, enables stronger generalization to unseen anomaly classes.</div></details>
<details class="detail"><summary>中文标题/摘要</summary>
<div class="mono"><b>标题：</b>面向类别泛化异常检测的多向元学习框架</div>
<div class="mono" style="margin-top:8px">本文研究类别泛化异常检测问题，其目标是通过聚焦于可用正常数据和少量异常数据来构建统一模型，以检测完全未见过的异常（亦称分布外类别）。该任务的挑战在于异常数据稀缺且标注成本高昂。为此，我们提出一种多向元学习算法：在内部层级，模型学习正常数据的流形结构（表征学习）；在外部层级，利用少量异常样本对模型进行元调优，以最大化正常样本与异常样本间的softmax置信度边界（决策面校准），将正常样本视为分布内数据，异常样本视为分布外数据。通过在以正常样本为主、异常样本为辅的多次迭代中重复此过程，我们实现了多向元学习框架。这种通过多向训练增强的双层优化机制，能够对未见异常类别实现更强的泛化能力。</div>
</details>
<details class="detail"><summary>Summary / 总结</summary>
<div class="mono">This research addresses class-generalizable anomaly detection, aiming to build a unified model that can identify unseen anomaly classes using only normal data and a few labeled anomaly samples, which are scarce and costly to obtain. The proposed method employs a multidirectional meta-learning framework with a two-level optimization: at the inner level, it learns the manifold of normal data for representation, while at the outer level, it meta-tunes with limited anomaly samples to calibrate the decision surface by maximizing the softmax confidence margin between normal (in-distribution) and anomaly (out-of-distribution) samples. Experimental results demonstrate that this iterative, episode-based approach enhances generalization to unseen anomaly classes compared to existing methods.</div>
<div class="mono" style="margin-top:8px">本研究针对类别泛化异常检测问题，旨在利用正常数据和少量标记的异常数据（这些数据稀有且标注成本高）构建一个统一模型，以检测未见过的异常类别。所提出的方法是一个多方向元学习框架，执行双层优化：在内层，学习正常数据的流形以获取表示；在外层，使用少量异常样本对模型进行元调优，通过最大化正常（分布内）和异常（分布外）样本之间的softmax置信度间隔来校准决策表面。实验结果表明，这种基于迭代和分幕的训练能够实现对完全未见异常类别更强的泛化能力。</div>
</details>
</div>
<div class="card">
<div class="title">Neural Neural Scaling Laws</div>
<div class="meta-line">Authors: Michael Y. Hu, Jane Pan, Ayush Rajesh Jhaveri, Nicholas Lourie, Kyunghyun Cho</div>
<div class="meta-line">First: 2026-01-27T17:38:11+00:00 · Latest: 2026-01-27T17:38:11+00:00</div>
<div class="links" style="margin-top:8px"><a href="https://arxiv.org/abs/2601.19831v1">Abs</a> · <a href="https://arxiv.org/pdf/2601.19831v1">PDF</a> · <a href="https://huggingface.co/huggingface">Code1</a> · <a href="https://huggingface.co/docs/hub/spaces">Code2</a></div>
<details class="detail"><summary>Abstract</summary>
<div class="mono">Neural scaling laws predict how language model performance improves with increased compute. While aggregate metrics like validation loss can follow smooth power-law curves, individual downstream tasks exhibit diverse scaling behaviors: some improve monotonically, others plateau, and some even degrade with scale. We argue that predicting downstream performance from validation perplexity suffers from two limitations: averaging token-level losses obscures signal, and no simple parametric family can capture the full spectrum of scaling behaviors. To address this, we propose Neural Neural Scaling Laws (NeuNeu), a neural network that frames scaling law prediction as time-series extrapolation. NeuNeu combines temporal context from observed accuracy trajectories with token-level validation losses, learning to predict future performance without assuming any bottleneck or functional form. Trained entirely on open-source model checkpoints from HuggingFace, NeuNeu achieves 2.04% mean absolute error in predicting model accuracy on 66 downstream tasks -- a 38% reduction compared to logistic scaling laws (3.29% MAE). Furthermore, NeuNeu generalizes zero-shot to unseen model families, parameter counts, and downstream tasks. Our work suggests that predicting downstream scaling laws directly from data outperforms parametric alternatives.</div></details>
<details class="detail"><summary>中文标题/摘要</summary>
<div class="mono"><b>标题：</b>神经神经缩放定律</div>
<div class="mono" style="margin-top:8px">神经缩放定律预测语言模型性能如何随计算量增加而提升。虽然验证损失等聚合指标可能遵循平滑的幂律曲线，但个体下游任务展现出多样化的缩放行为：部分任务单调提升，部分趋于平稳，部分甚至随规模扩大而性能下降。我们认为基于验证困惑度预测下游性能存在双重局限：词元级损失的平均化会掩盖信号特征，且不存在简单的参数族能完整捕捉缩放行为的全谱特征。为此，我们提出神经神经缩放定律（NeuNeu），这是一种将缩放定律预测构建为时间序列外推任务的神经网络。NeuNeu通过融合观测精度轨迹的时间上下文与词元级验证损失，无需假设任何瓶颈或函数形式即可学习预测未来性能。完全基于HuggingFace开源模型检查点训练后，NeuNeu在66个下游任务的模型精度预测中达到2.04%平均绝对误差——较逻辑缩放定律（3.29% MAE）降低38%。此外，NeuNeu能零样本泛化至未见过的模型族、参数量级及下游任务。我们的研究表明，直接基于数据预测下游缩放定律优于参数化替代方案。</div>
</details>
<details class="detail"><summary>Summary / 总结</summary>
<div class="mono">The research addresses the limitations of using validation perplexity to predict downstream task performance, as aggregate metrics obscure individual task behaviors and no simple parametric model captures the full range of scaling patterns. The proposed method, Neural Neural Scaling Laws (NeuNeu), frames scaling law prediction as time-series extrapolation, combining observed accuracy trajectories with token-level validation losses in a neural network that learns to forecast performance without assuming a functional form. Experiments using open-source model checkpoints show that NeuNeu achieves a mean absolute error of 2.04% in predicting accuracy across 66 downstream tasks, a 38% improvement over logistic scaling laws, and demonstrates zero-shot generalization to unseen model families, parameter counts, and tasks.</div>
<div class="mono" style="margin-top:8px">该研究的动机是观察到，虽然验证损失等聚合指标遵循平滑的幂律缩放，但个体下游任务展现出多样化的缩放行为——有些随模型规模增大而提升、趋于平稳甚至下降，这些无法用简单的参数化族捕捉。为解决此问题，作者提出了神经神经缩放定律（NeuNeu），该方法将缩放定律预测构建为时间序列外推问题，通过神经网络结合观察到的准确率轨迹的时间上下文与词元级验证损失，从而无需假设特定函数形式即可学习预测未来性能。关键实验结果基于HuggingFace的开源模型检查点，显示NeuNeu在66个下游任务的准确率预测上达到2.04%的平均绝对误差，相比逻辑缩放定律（3.29% MAE）降低了38%，并能零样本泛化到未见过的模型家族、参数量及任务。</div>
</details>
</div>
<div class="card">
<div class="title">APEX-Agents</div>
<div class="meta-line">Authors: Bertie Vidgen, Austin Mann, Abby Fennelly, John Wright Stanly, Lucas Rothman, Marco Burstein, Julien Benchek, David Ostrofsky, Anirudh Ravichandran, Debnil Sur, Neel Venugopal, Alannah Hsia, Isaac Robinson, Calix Huang, Olivia Varones, Daniyal Khan, Michael Haines, Zach Richards, Chirag Mahapatra, Brendan Foody, Osvald Nitski</div>
<div class="meta-line">First: 2026-01-20T18:53:44+00:00 · Latest: 2026-01-27T17:31:16+00:00</div>
<div class="links" style="margin-top:8px"><a href="https://arxiv.org/abs/2601.14242v2">Abs</a> · <a href="https://arxiv.org/pdf/2601.14242v2">PDF</a> · <a href="https://huggingface.co/huggingface">Code1</a> · <a href="https://huggingface.co/docs/hub/spaces">Code2</a></div>
<details class="detail"><summary>Abstract</summary>
<div class="mono">We introduce the AI Productivity Index for Agents (APEX-Agents), a benchmark for assessing whether AI agents can execute long-horizon, cross-application tasks created by investment banking analysts, management consultants, and corporate lawyers. APEX-Agents requires agents to navigate realistic work environments with files and tools. We test eight agents for the leaderboard using Pass@1. Gemini 3 Flash (Thinking=High) achieves the highest score of 24.0%, followed by GPT-5.2 (Thinking=High), Claude Opus 4.5 (Thinking=High), and Gemini 3 Pro (Thinking=High). We open source the APEX-Agents benchmark (n=480) with all prompts, rubrics, gold outputs, files, and metadata. We also open-source Archipelago, our infrastructure for agent execution and evaluation.</div></details>
<details class="detail"><summary>中文标题/摘要</summary>
<div class="mono"><b>标题：</b>APEX-Agents</div>
<div class="mono" style="margin-top:8px">我们推出了AI智能体生产力指数（APEX-Agents），这是一个用于评估AI智能体能否执行由投行分析师、管理顾问和企业律师创建的跨应用长周期任务的基准测试。APEX-Agents要求智能体在包含文件与工具的真实工作环境中进行操作。我们采用Pass@1指标对八个智能体进行排行榜测试，其中Gemini 3 Flash（思考模式=高）以24.0%得分位居榜首，其次是GPT-5.2（思考模式=高）、Claude Opus 4.5（思考模式=高）和Gemini 3 Pro（思考模式=高）。我们开源了包含全部提示词、评分标准、标准答案、文件及元数据的APEX-Agents基准测试集（n=480），同时开源了用于智能体执行与评估的基础设施Archipelago。</div>
</details>
<details class="detail"><summary>Summary / 总结</summary>
<div class="mono">The research is motivated by the need to evaluate AI agents on complex, real-world professional tasks that span multiple applications and require long-term planning, as encountered in fields like investment banking and law. The method introduces the APEX-Agents benchmark, which simulates realistic work environments with files and tools, and assesses agents using a Pass@1 metric on a set of 480 tasks. Key experimental results show that Gemini 3 Flash (Thinking=High) achieved the highest score of 24.0%, outperforming other leading models including GPT-5.2 and Claude Opus 4.5, with the benchmark and an associated execution infrastructure, Archipelago, being open-sourced.</div>
<div class="mono" style="margin-top:8px">该研究的动机是评估AI智能体在投资银行、管理咨询等专业领域中执行跨应用、长周期复杂现实任务的能力。方法上提出了APEX-Agents基准测试，该测试模拟了包含文件和工具的真实工作环境，并使用Pass@1指标对480个任务进行评估。主要实验结果表明，Gemini 3 Flash（Thinking=High）以24.0%的最高得分领先，优于GPT-5.2和Claude Opus 4.5等其他模型，同时该基准测试及其配套的执行评估框架Archipelago均已开源。</div>
</details>
</div>
<div class="card">
<div class="title">Learn and Verify: A Framework for Rigorous Verification of Physics-Informed Neural Networks</div>
<div class="meta-line">Authors: Kazuaki Tanaka, Kohei Yatabe</div>
<div class="meta-line">First: 2026-01-27T17:21:33+00:00 · Latest: 2026-01-27T17:21:33+00:00</div>
<div class="meta-line">Comments: 13 pages, 10 figures</div>
<div class="links" style="margin-top:8px"><a href="https://arxiv.org/abs/2601.19818v1">Abs</a> · <a href="https://arxiv.org/pdf/2601.19818v1">PDF</a> · <a href="https://huggingface.co/huggingface">Code1</a> · <a href="https://huggingface.co/docs/hub/spaces">Code2</a></div>
<details class="detail"><summary>Abstract</summary>
<div class="mono">The numerical solution of differential equations using neural networks has become a central topic in scientific computing, with Physics-Informed Neural Networks (PINNs) emerging as a powerful paradigm for both forward and inverse problems. However, unlike classical numerical methods that offer established convergence guarantees, neural network-based approximations typically lack rigorous error bounds. Furthermore, the non-deterministic nature of their optimization makes it difficult to mathematically certify their accuracy. To address these challenges, we propose a &quot;Learn and Verify&quot; framework that provides computable, mathematically rigorous error bounds for the solutions of differential equations. By combining a novel Doubly Smoothed Maximum (DSM) loss for training with interval arithmetic for verification, we compute rigorous a posteriori error bounds as machine-verifiable proofs. Numerical experiments on nonlinear Ordinary Differential Equations (ODEs), including problems with time-varying coefficients and finite-time blow-up, demonstrate that the proposed framework successfully constructs rigorous enclosures of the true solutions, establishing a foundation for trustworthy scientific machine learning.</div></details>
<details class="detail"><summary>中文标题/摘要</summary>
<div class="mono"><b>标题：</b>学习与验证：物理信息神经网络的严格验证框架</div>
<div class="mono" style="margin-top:8px">利用神经网络求解微分方程的数值方法已成为科学计算的核心课题，其中物理信息神经网络（PINNs）作为处理正反问题的强大范式而兴起。然而，与具备成熟收敛保证的经典数值方法不同，基于神经网络的近似通常缺乏严格的误差界。此外，其优化的非确定性特征使得难以从数学上确保其精度。为应对这些挑战，我们提出一种“学习与验证”框架，为微分方程解提供可计算的严格数学误差界。通过结合训练用的新型双平滑最大值损失函数与验证用的区间算术，我们计算出可作为机器可验证证明的严格后验误差界。在非线性常微分方程（包括含时变系数和有限时间爆破问题）上的数值实验表明，该框架成功构建了真实解的严格包络，为可信赖的科学机器学习奠定了基础。</div>
</details>
<details class="detail"><summary>Summary / 总结</summary>
<div class="mono">The study addresses the lack of rigorous error bounds and convergence guarantees in Physics-Informed Neural Networks (PINNs) for solving differential equations, which contrasts with classical numerical methods. The proposed &quot;Learn and Verify&quot; framework combines a novel Doubly Smoothed Maximum (DSM) loss for training with interval arithmetic for verification to compute mathematically rigorous, a posteriori error bounds. Experimental results on nonlinear ODEs, including problems with time-varying coefficients and finite-time blow-up, show that the framework successfully constructs rigorous enclosures of the true solutions, providing a foundation for trustworthy scientific machine learning.</div>
<div class="mono" style="margin-top:8px">针对物理信息神经网络（PINN）相比经典数值方法缺乏严格误差界和数学验证的问题，本研究提出了一个“学习与验证”框架，为微分方程解提供可计算的、数学上严格的误差界。该方法结合了用于训练的新型双平滑最大（DSM）损失函数和用于验证的区间算术，以计算可作为机器可验证证明的严格后验误差界。在非线性常微分方程（包括具有时变系数和有限时间爆破的问题）上的关键实验结果表明，该框架成功构建了真实解的严格包络。</div>
</details>
</div>
<div class="card">
<div class="title">Predicting Startup Success Using Large Language Models: A Novel In-Context Learning Approach</div>
<div class="meta-line">Authors: Abdurahman Maarouf, Alket Bakiaj, Stefan Feuerriegel</div>
<div class="meta-line">First: 2026-01-23T09:08:52+00:00 · Latest: 2026-01-27T17:16:47+00:00</div>
<div class="links" style="margin-top:8px"><a href="https://arxiv.org/abs/2601.16568v2">Abs</a> · <a href="https://arxiv.org/pdf/2601.16568v2">PDF</a> · <a href="https://huggingface.co/huggingface">Code1</a> · <a href="https://huggingface.co/docs/hub/spaces">Code2</a></div>
<details class="detail"><summary>Abstract</summary>
<div class="mono">Venture capital (VC) investments in early-stage startups that end up being successful can yield high returns. However, predicting early-stage startup success remains challenging due to data scarcity (e.g., many VC firms have information about only a few dozen of early-stage startups and whether they were successful). This limits the effectiveness of traditional machine learning methods that rely on large labeled datasets for model training. To address this challenge, we propose an in-context learning framework for startup success prediction using large language models (LLMs) that requires no model training and leverages only a small set of labeled startups as demonstration examples. Specifically, we propose a novel k-nearest-neighbor-based in-context learning framework, called kNN-ICL, which selects the most relevant past startups as examples based on similarity. Using real-world profiles from Crunchbase, we find that the kNN-ICL approach achieves higher prediction accuracy than supervised machine learning baselines and vanilla in-context learning. Further, we study how performance varies with the number of in-context examples and find that a high balanced accuracy can be achieved with as few as 50 examples. Together, we demonstrate that in-context learning can serve as a decision-making tool for VC firms operating in data-scarce environments.</div></details>
<details class="detail"><summary>中文标题/摘要</summary>
<div class="mono"><b>标题：</b>利用大语言模型预测初创企业成功：一种新颖的上下文学习方法</div>
<div class="mono" style="margin-top:8px">风险投资（VC）对最终成功的早期初创企业的投资可能带来高回报。然而，由于数据稀缺（例如，许多风投机构仅掌握几十家早期初创企业的信息及其成功与否），预测早期初创企业成功仍具挑战性。这限制了依赖大规模标注数据集进行模型训练的传统机器学习方法的有效性。为解决这一挑战，我们提出了一种基于大语言模型（LLMs）的初创企业成功预测上下文学习框架，该框架无需模型训练，仅利用少量标注初创企业作为演示示例。具体而言，我们提出了一种新颖的基于k近邻的上下文学习框架（称为kNN-ICL），它根据相似性选择最相关的过往初创企业作为示例。通过使用Crunchbase的真实企业资料，我们发现kNN-ICL方法的预测准确率高于监督机器学习基线和普通上下文学习方法。此外，我们研究了性能如何随上下文示例数量变化，发现仅需50个示例即可实现较高的平衡准确率。综上，我们证明上下文学习可作为在数据稀缺环境中运营的风投机构的决策工具。</div>
</details>
<details class="detail"><summary>Summary / 总结</summary>
<div class="mono">Predicting early-stage startup success is difficult for venture capital firms due to limited labeled data, which hinders traditional machine learning methods. To address this, this study introduces a k-nearest-neighbor in-context learning (kNN-ICL) framework that uses large language models without training, selecting the most similar past startups as examples for prediction. Experiments on Crunchbase data show that kNN-ICL outperforms supervised baselines and standard in-context learning, achieving high balanced accuracy with as few as 50 examples, demonstrating its potential as a decision-support tool in data-scarce settings.</div>
<div class="mono" style="margin-top:8px">由于历史数据有限，预测早期初创企业的成功对风险投资公司而言颇具挑战，这限制了传统监督式机器学习方法的有效性。为此，研究者提出了kNN-ICL，一种新颖的上下文学习框架，该方法无需训练大型语言模型，而是基于相似性通过k近邻算法选择最相关的过往初创企业作为示例。在Crunchbase真实数据上的实验表明，kNN-ICL在预测准确性上优于监督学习基线方法和标准上下文学习，仅需50个示例即可实现较高的平衡准确率，证明了其在数据稀缺环境下作为决策支持工具的潜力。</div>
</details>
</div>
<div class="card">
<div class="title">Revisiting Incremental Stochastic Majorization-Minimization Algorithms with Applications to Mixture of Experts</div>
<div class="meta-line">Authors: TrungKhang Tran, TrungTin Nguyen, Gersende Fort, Tung Doan, Hien Duy Nguyen, Binh T. Nguyen, Florence Forbes, Christopher Drovandi</div>
<div class="meta-line">First: 2026-01-27T17:12:15+00:00 · Latest: 2026-01-27T17:12:15+00:00</div>
<div class="meta-line">Comments: TrungKhang Tran and TrungTin Nguyen are co-first authors</div>
<div class="links" style="margin-top:8px"><a href="https://arxiv.org/abs/2601.19811v1">Abs</a> · <a href="https://arxiv.org/pdf/2601.19811v1">PDF</a> · <a href="https://huggingface.co/huggingface">Code1</a> · <a href="https://huggingface.co/docs/hub/spaces">Code2</a></div>
<details class="detail"><summary>Abstract</summary>
<div class="mono">Processing high-volume, streaming data is increasingly common in modern statistics and machine learning, where batch-mode algorithms are often impractical because they require repeated passes over the full dataset. This has motivated incremental stochastic estimation methods, including the incremental stochastic Expectation-Maximization (EM) algorithm formulated via stochastic approximation. In this work, we revisit and analyze an incremental stochastic variant of the Majorization-Minimization (MM) algorithm, which generalizes incremental stochastic EM as a special case. Our approach relaxes key EM requirements, such as explicit latent-variable representations, enabling broader applicability and greater algorithmic flexibility. We establish theoretical guarantees for the incremental stochastic MM algorithm, proving consistency in the sense that the iterates converge to a stationary point characterized by a vanishing gradient of the objective. We demonstrate these advantages on a softmax-gated mixture of experts (MoE) regression problem, for which no stochastic EM algorithm is available. Empirically, our method consistently outperforms widely used stochastic optimizers, including stochastic gradient descent, root mean square propagation, adaptive moment estimation, and second-order clipped stochastic optimization. These results support the development of new incremental stochastic algorithms, given the central role of softmax-gated MoE architectures in contemporary deep neural networks for heterogeneous data modeling. Beyond synthetic experiments, we also validate practical effectiveness on two real-world datasets, including a bioinformatics study of dent maize genotypes under drought stress that integrates high-dimensional proteomics with ecophysiological traits, where incremental stochastic MM yields stable gains in predictive performance.</div></details>
<details class="detail"><summary>中文标题/摘要</summary>
<div class="mono"><b>标题：</b>增量随机主优化-最小化算法及其在专家混合模型中的应用再探</div>
<div class="mono" style="margin-top:8px">处理大规模流式数据在现代统计学和机器学习中日益普遍，批处理算法因需多次遍历完整数据集而常不实用。这推动了增量随机估计方法的发展，包括通过随机逼近构建的增量随机期望最大化算法。本研究重新审视并分析了一种增量随机主优化-最小化算法的变体，该算法将增量随机EM算法作为特例进行推广。我们的方法放宽了EM算法的关键要求（如显式隐变量表示），从而拓展了适用范围并增强算法灵活性。我们为增量随机MM算法建立了理论保证，证明其迭代序列以目标函数梯度消失的平稳点为收敛方向。我们在softmax门控的专家混合回归问题上展示了这些优势——该问题目前尚无随机EM算法可用。实证表明，我们的方法持续优于广泛使用的随机优化器，包括随机梯度下降、均方根传播、自适应矩估计及二阶截断随机优化。鉴于softmax门控MoE架构在异质数据建模的现代深度神经网络中的核心地位，这些结果为开发新型增量随机算法提供了支持。除合成实验外，我们还在两个真实数据集上验证了其实用有效性，包括一项整合高维蛋白质组学与生态生理性状的干旱胁迫下齿玉米基因型生物信息学研究，其中增量随机MM算法在预测性能上实现了稳定提升。</div>
</details>
<details class="detail"><summary>Summary / 总结</summary>
<div class="mono">To address the challenge of processing high-volume streaming data where batch algorithms are impractical, this work revisits and analyzes an incremental stochastic variant of the Majorization-Minimization (MM) algorithm, which generalizes incremental stochastic EM. The method relaxes key EM requirements like explicit latent-variable representations, broadening applicability and offering greater algorithmic flexibility. Theoretically, the algorithm is proven consistent with iterates converging to a stationary point. Empirically, on a softmax-gated mixture of experts regression problem, it consistently outperforms stochastic gradient descent, RMSprop, Adam, and second-order clipped stochastic optimization, and shows stable predictive gains on real-world datasets including a bioinformatics study of dent maize under drought stress.</div>
<div class="mono" style="margin-top:8px">为应对处理高容量流式数据时批处理算法不切实际的挑战，本研究重新审视并分析了增量随机Majorization-Minimization（MM）算法的一种变体，该算法通过放宽显式隐变量表示等要求，推广了增量随机EM算法，从而具有更广泛的适用性。该方法建立了理论保证，证明了迭代收敛到平稳点的一致性。在softmax门控混合专家回归问题上的实验验证表明，其性能一致优于随机梯度下降、RMSprop、Adam和二阶裁剪随机优化等广泛使用的优化器，并在包括干旱胁迫玉米基因组的生物信息学数据集在内的真实世界数据上展现了稳定的预测性能提升。</div>
</details>
</div>
<div class="card">
<div class="title">Unsupervised Learning of Efficient Exploration: Pre-training Adaptive Policies via Self-Imposed Goals</div>
<div class="meta-line">Authors: Octavio Pappalardo</div>
<div class="meta-line">Venue: ICLR 2026</div>
<div class="meta-line">First: 2026-01-27T17:10:29+00:00 · Latest: 2026-01-27T17:10:29+00:00</div>
<div class="meta-line">Comments: To appear at ICLR 2026</div>
<div class="links" style="margin-top:8px"><a href="https://arxiv.org/abs/2601.19810v1">Abs</a> · <a href="https://arxiv.org/pdf/2601.19810v1">PDF</a> · <a href="https://huggingface.co/huggingface">Code1</a> · <a href="https://huggingface.co/docs/hub/spaces">Code2</a></div>
<details class="detail"><summary>Abstract</summary>
<div class="mono">Unsupervised pre-training can equip reinforcement learning agents with prior knowledge and accelerate learning in downstream tasks. A promising direction, grounded in human development, investigates agents that learn by setting and pursuing their own goals. The core challenge lies in how to effectively generate, select, and learn from such goals. Our focus is on broad distributions of downstream tasks where solving every task zero-shot is infeasible. Such settings naturally arise when the target tasks lie outside of the pre-training distribution or when their identities are unknown to the agent. In this work, we (i) optimize for efficient multi-episode exploration and adaptation within a meta-learning framework, and (ii) guide the training curriculum with evolving estimates of the agent&#x27;s post-adaptation performance. We present ULEE, an unsupervised meta-learning method that combines an in-context learner with an adversarial goal-generation strategy that maintains training at the frontier of the agent&#x27;s capabilities. On XLand-MiniGrid benchmarks, ULEE pre-training yields improved exploration and adaptation abilities that generalize to novel objectives, environment dynamics, and map structures. The resulting policy attains improved zero-shot and few-shot performance, and provides a strong initialization for longer fine-tuning processes. It outperforms learning from scratch, DIAYN pre-training, and alternative curricula.</div></details>
<details class="detail"><summary>中文标题/摘要</summary>
<div class="mono"><b>标题：</b>高效探索的无监督学习：通过自设目标预训练自适应策略</div>
<div class="mono" style="margin-top:8px">无监督预训练可为强化学习智能体提供先验知识，加速下游任务学习。基于人类发展机制的研究方向，探索智能体通过自主设定并追求目标进行学习。核心挑战在于如何有效生成、选择并从此类目标中学习。我们关注下游任务分布广泛、无法零样本解决所有任务的情境，例如目标任务超出预训练分布范围或智能体未知任务特性时。本研究（i）在元学习框架内优化多回合探索与适应效率，（ii）通过动态评估智能体适应后表现来指导训练课程。我们提出ULEE方法，结合上下文学习器与对抗性目标生成策略，使训练持续处于智能体能力前沿。在XLand-MiniGrid基准测试中，ULEE预训练展现出可泛化至新目标、环境动态与地图结构的探索适应能力，获得更优的零样本/少样本性能，并为长时微调提供优质初始化。其表现优于从头学习、DIAYN预训练及其他课程设置方法。</div>
</details>
<details class="detail"><summary>Summary / 总结</summary>
<div class="mono">The research aims to enhance unsupervised pre-training for reinforcement learning agents by enabling them to learn through self-generated goals, which is motivated by the need to accelerate adaptation in downstream tasks that are outside the pre-training distribution or unknown. The method, ULEE, combines meta-learning for efficient multi-episode exploration with an adversarial goal-generation curriculum that continuously challenges the agent at its capability frontier. Experimental results on XLand-MiniGrid benchmarks show that ULEE improves exploration and adaptation, leading to better zero-shot and few-shot performance on novel objectives, dynamics, and maps, outperforming learning from scratch, DIAYN, and other curricula.</div>
<div class="mono" style="margin-top:8px">该研究旨在通过让智能体学习自生成目标来增强强化学习的无监督预训练，其动机是需要在预训练分布之外或未知的下游任务中加速适应。方法ULEE结合了用于高效多回合探索的元学习和对抗性目标生成策略，使训练保持在智能体能力的前沿。在XLand-MiniGrid基准测试中的实验结果表明，ULEE提升了探索和适应能力，带来了更好的零样本和少样本性能以及更强的微调初始化，优于从头学习、DIAYN预训练和其他课程学习方法。</div>
</details>
</div>
<div class="card">
<div class="title">Learning under Distributional Drift: Reproducibility as an Intrinsic Statistical Resource</div>
<div class="meta-line">Authors: Sofiya Zaichyk</div>
<div class="meta-line">First: 2025-12-15T16:34:47+00:00 · Latest: 2026-01-27T17:09:04+00:00</div>
<div class="meta-line">Comments: 37 pages, 4 figures</div>
<div class="links" style="margin-top:8px"><a href="https://arxiv.org/abs/2512.13506v2">Abs</a> · <a href="https://arxiv.org/pdf/2512.13506v2">PDF</a> · <a href="https://huggingface.co/huggingface">Code1</a> · <a href="https://huggingface.co/docs/hub/spaces">Code2</a></div>
<details class="detail"><summary>Abstract</summary>
<div class="mono">Statistical learning under distributional drift remains insufficiently characterized: when each observation alters the data-generating law, classical generalization bounds can collapse. We introduce a new statistical primitive, the reproducibility budget $C_T$, which quantifies a system&#x27;s finite capacity for statistical reproducibility: the extent to which its sampling process can remain governed by a consistent underlying distribution in the presence of both exogenous change and endogenous feedback. Formally, $C_T$ is defined as the cumulative Fisher-Rao path length of the coupled learner-environment evolution, measuring the total distributional motion accumulated during learning. From this construct we derive a drift-feedback generalization bound of order $O(T^{-1/2} + C_T/T)$, and we prove a matching minimax lower bound showing that this rate is minimax-optimal. Consequently, the results establish a reproducibility speed limit: no algorithm can achieve smaller worst-case generalization error than that imposed by the average Fisher-Rao drift rate $C_T/T$ of the data-generating process. The framework situates exogenous drift, adaptive data analysis, and performative prediction within a common geometric structure, with $C_T$ emerging as the intrinsic quantity measuring distributional motion across these settings.</div></details>
<details class="detail"><summary>中文标题/摘要</summary>
<div class="mono"><b>标题：</b>分布漂移下的学习：可复现性作为内在统计资源</div>
<div class="mono" style="margin-top:8px">分布漂移下的统计学习仍缺乏充分刻画：当每个观测都会改变数据生成规律时，经典泛化界可能失效。我们引入一种新的统计原语——可复现性预算$C_T$，用于量化系统有限的统计可复现能力：在外生变化与内生反馈并存时，其抽样过程能在多大程度上保持由一致底层分布支配。形式化定义中，$C_T$被定义为耦合学习者-环境演化的累积费舍尔-拉奥路径长度，用于度量学习过程中积累的总分布运动量。基于此构造，我们推导出阶数为$O(T^{-1/2} + C_T/T)$的漂移-反馈泛化界，并证明匹配的极小极大下界表明该速率是极小极大最优的。因此，研究结果确立了一个可复现性速度极限：任何算法都无法突破数据生成过程的平均费舍尔-拉奥漂移率$C_T/T$所决定的最坏情况泛化误差下界。该框架将外生漂移、自适应数据分析和执行预测置于统一的几何结构中，而$C_T$正是衡量这些场景中分布运动的内在度量指标。</div>
</details>
<details class="detail"><summary>Summary / 总结</summary>
<div class="mono">The research addresses the challenge of statistical learning under distributional drift, where classical generalization bounds may fail because each observation can alter the data-generating distribution. The method introduces a reproducibility budget, denoted as C_T, which quantifies the system&#x27;s finite capacity for statistical reproducibility by measuring the cumulative Fisher-Rao path length of the coupled learner-environment evolution. Key experimental findings include a derived generalization bound of order O(T^{-1/2} + C_T/T), a matching minimax lower bound proving its optimality, and the establishment of a reproducibility speed limit, showing that no algorithm can surpass the error imposed by the average Fisher-Rao drift rate C_T/T, thereby unifying exogenous drift, adaptive data analysis, and performative prediction within a common geometric framework.</div>
<div class="mono" style="margin-top:8px">该研究针对分布漂移下的统计学习挑战，即每个观测都可能改变底层数据生成分布，导致经典泛化界失效。方法引入了一个新的统计原语——可重复性预算C_T，其定义为学习器与环境耦合演化的累积Fisher-Rao路径长度，用于量化系统在外部变化和内部反馈下保持统计可重复性的有限能力。主要实验结果包括推导出阶为O(T^{-1/2} + C_T/T)的漂移-反馈泛化界，匹配的极小极大下界证明该速率是最优的，并建立了一个可重复性速度极限，表明任何算法的性能都无法超越由平均Fisher-Rao漂移率C_T/T所决定的最坏情况误差。</div>
</details>
</div>
<div class="card">
<div class="title">LLM-Generated Explanations Do Not Suffice for Ultra-Strong Machine Learning</div>
<div class="meta-line">Authors: Lun Ai, Johannes Langer, Ute Schmid, Stephen Muggleton</div>
<div class="meta-line">First: 2025-08-31T19:04:31+00:00 · Latest: 2026-01-27T17:01:53+00:00</div>
<div class="links" style="margin-top:8px"><a href="https://arxiv.org/abs/2509.00961v2">Abs</a> · <a href="https://arxiv.org/pdf/2509.00961v2">PDF</a> · <a href="https://huggingface.co/huggingface">Code1</a> · <a href="https://huggingface.co/docs/hub/spaces">Code2</a></div>
<details class="detail"><summary>Abstract</summary>
<div class="mono">Ultra Strong Machine Learning (USML) refers to symbolic learning systems that not only improve their own performance but can also teach their acquired knowledge to quantifiably improve human performance. We introduce LENS (Logic Programming Explanation via Neural Summarisation), a neuro-symbolic framework that combines symbolic program synthesis with large language models (LLMs). This framework automatically generates natural language explanations of learned logic programs, replacing hand-crafted templates used in prior USML work. Using LLMs-as-judges evaluation and expert validation, we show that LENS produces higher-quality explanations than both direct LLM prompting and hand-crafted templates. We then examine whether LENS explanations suffice for achieving USML in a human trial teaching active learning strategies across three related domains. Our exploratory analysis suggests that concise, expert-written explanations may benefit learners with higher initial performance, while LLM-generated explanations provide no advantage over human self learning despite being rated as higher quality. This case study reveals that achieving USML requires methods grounded in human learning, where current LLM-generated explanations do not capture human cognitive constraints and LLMs-as-judges evaluations do not reflect what effectively supports human learning.</div></details>
<details class="detail"><summary>中文标题/摘要</summary>
<div class="mono"><b>标题：</b>LLM生成解释不足以实现超强机器学习</div>
<div class="mono" style="margin-top:8px">超强机器学习（USML）指不仅能提升自身性能，还能将习得知识传授给人类以量化提升人类表现的符号学习系统。本文提出LENS（基于神经摘要的逻辑编程解释框架），一种将符号程序合成与大型语言模型（LLM）结合的神经符号框架。该框架能自动生成已学习逻辑程序的自然语言解释，取代了先前USML研究中手工设计的模板。通过LLM作为评判者的评估和专家验证，我们证明LENS生成的解释质量优于直接LLM提示和手工模板。随后，我们在跨三个相关领域教授主动学习策略的人类试验中，检验LENS解释是否足以实现USML。探索性分析表明：简洁的专家撰写解释可能对初始表现较高的学习者有益，而LLM生成解释尽管被评价为更高质量，却未显示出优于人类自主学习的效果。本案例研究表明，实现USML需要基于人类学习机制的方法，当前LLM生成解释未能捕捉人类认知约束，且LLM作为评判者的评估无法反映对人类学习真正有效的支持。</div>
</details>
<details class="detail"><summary>Summary / 总结</summary>
<div class="mono">This research addresses the challenge of Ultra-Strong Machine Learning (USML), where systems must not only learn but also effectively teach their knowledge to improve human performance. The authors propose LENS, a neuro-symbolic framework that integrates symbolic program synthesis with large language models (LLMs) to automatically generate natural language explanations for learned logic programs, moving beyond hand-crafted templates. Evaluations using LLMs-as-judges and expert validation show LENS produces higher-quality explanations than both direct LLM prompting and prior template-based methods. However, a human trial teaching active learning strategies across three domains found that while expert-written explanations aided higher-performing learners, LLM-generated explanations provided no learning advantage over self-study, indicating that current LLM methods fail to capture human cognitive constraints and that automated quality metrics do not align with effective human learning support.</div>
<div class="mono" style="margin-top:8px">本研究针对超强机器学习（USML）的挑战，即符号学习系统不仅需要自主改进，还需有效传递知识以提升人类表现。作者提出了LENS，一个结合符号程序合成与大语言模型（LLM）的神经符号框架，用于自动生成学习到的逻辑程序的自然语言解释，取代了先前USML工作中手工制作的模板。通过使用LLM作为评判者的评估和专家验证，结果表明LENS产生的解释质量高于直接LLM提示和手工模板方法。然而，在三个相关领域教授主动学习策略的人类试验表明，尽管LLM生成的解释被评价为质量更高，但它们并未为学习者提供优于自学的好处，这表明当前的LLM生成解释未能捕捉人类认知约束，且自动评估方法不能反映对人类学习的有效支持。</div>
</details>
</div>
<div class="card">
<div class="title">Component-Aware Pruning Framework for Neural Network Controllers via Gradient-Based Importance Estimation</div>
<div class="meta-line">Authors: Ganesh Sundaram, Jonas Ulmen, Daniel Görges</div>
<div class="meta-line">First: 2026-01-27T16:53:19+00:00 · Latest: 2026-01-27T16:53:19+00:00</div>
<div class="meta-line">Comments: 8 pages, Submitted to the 2026 IFAC World Congress</div>
<div class="links" style="margin-top:8px"><a href="https://arxiv.org/abs/2601.19794v1">Abs</a> · <a href="https://arxiv.org/pdf/2601.19794v1">PDF</a> · <a href="https://huggingface.co/huggingface">Code1</a> · <a href="https://huggingface.co/docs/hub/spaces">Code2</a></div>
<details class="detail"><summary>Abstract</summary>
<div class="mono">The transition from monolithic to multi-component neural architectures in advanced neural network controllers poses substantial challenges due to the high computational complexity of the latter. Conventional model compression techniques for complexity reduction, such as structured pruning based on norm-based metrics to estimate the relative importance of distinct parameter groups, often fail to capture functional significance. This paper introduces a component-aware pruning framework that utilizes gradient information to compute three distinct importance metrics during training: Gradient Accumulation, Fisher Information, and Bayesian Uncertainty. Experimental results with an autoencoder and a TD-MPC agent demonstrate that the proposed framework reveals critical structural dependencies and dynamic shifts in importance that static heuristics often miss, supporting more informed compression decisions.</div></details>
<details class="detail"><summary>中文标题/摘要</summary>
<div class="mono"><b>标题：</b>基于梯度重要性估计的神经网络控制器组件感知剪枝框架</div>
<div class="mono" style="margin-top:8px">先进神经网络控制器从单体架构向多组件架构的转变，因其高计算复杂度带来显著挑战。传统基于范数度量的结构化剪枝等模型压缩技术，在评估参数组相对重要性时常难以捕捉功能意义。本文提出一种组件感知剪枝框架，利用梯度信息在训练中计算三种重要性度量：梯度累积量、费舍尔信息与贝叶斯不确定性。通过自编码器与TD-MPC智能体的实验表明，该框架能揭示静态启发式方法常忽略的关键结构依赖性与重要性动态变化，为压缩决策提供更充分的依据。</div>
</details>
<details class="detail"><summary>Summary / 总结</summary>
<div class="mono">The research addresses the challenge of compressing multi-component neural network controllers, where conventional norm-based pruning methods fail to capture functional significance. The proposed method introduces a component-aware pruning framework that leverages gradient information during training to compute three importance metrics: Gradient Accumulation, Fisher Information, and Bayesian Uncertainty. Experiments on an autoencoder and a TD-MPC agent show the framework reveals critical structural dependencies and dynamic importance shifts missed by static heuristics, enabling more informed compression decisions.</div>
<div class="mono" style="margin-top:8px">该研究的动机在于需要降低多组件神经网络控制器的高计算复杂度，而传统的基于范数度量的结构化剪枝方法往往无法捕捉功能重要性。所提出的方法引入了一个组件感知的剪枝框架，利用训练过程中的梯度信息计算三种重要性度量：梯度累积、费舍尔信息和贝叶斯不确定性。使用自编码器和TD-MPC代理的实验结果表明，该框架揭示了静态启发式方法常忽略的关键结构依赖性和动态重要性变化，从而支持更明智的压缩决策。</div>
</details>
</div>
<div class="card">
<div class="title">To Grok Grokking: Provable Grokking in Ridge Regression</div>
<div class="meta-line">Authors: Mingyue Xu, Gal Vardi, Itay Safran</div>
<div class="meta-line">First: 2026-01-27T16:52:04+00:00 · Latest: 2026-01-27T16:52:04+00:00</div>
<div class="links" style="margin-top:8px"><a href="https://arxiv.org/abs/2601.19791v1">Abs</a> · <a href="https://arxiv.org/pdf/2601.19791v1">PDF</a> · <a href="https://huggingface.co/huggingface">Code1</a> · <a href="https://huggingface.co/docs/hub/spaces">Code2</a></div>
<details class="detail"><summary>Abstract</summary>
<div class="mono">We study grokking, the onset of generalization long after overfitting, in a classical ridge regression setting. We prove end-to-end grokking results for learning over-parameterized linear regression models using gradient descent with weight decay. Specifically, we prove that the following stages occur: (i) the model overfits the training data early during training; (ii) poor generalization persists long after overfitting has manifested; and (iii) the generalization error eventually becomes arbitrarily small. Moreover, we show, both theoretically and empirically, that grokking can be amplified or eliminated in a principled manner through proper hyperparameter tuning. To the best of our knowledge, these are the first rigorous quantitative bounds on the generalization delay (which we refer to as the &quot;grokking time&quot;) in terms of training hyperparameters. Lastly, going beyond the linear setting, we empirically demonstrate that our quantitative bounds also capture the behavior of grokking on non-linear neural networks. Our results suggest that grokking is not an inherent failure mode of deep learning, but rather a consequence of specific training conditions, and thus does not require fundamental changes to the model architecture or learning algorithm to avoid.</div></details>
<details class="detail"><summary>中文标题/摘要</summary>
<div class="mono"><b>标题：</b>理解“顿悟”：岭回归中可证明的顿悟现象</div>
<div class="mono" style="margin-top:8px">我们在经典岭回归设定下研究“顿悟”现象，即模型在过拟合后很久才突然开始泛化。我们证明了使用带权重衰减的梯度下降学习过参数化线性回归模型时，会出现端到端的顿悟结果。具体而言，我们证明了以下阶段的发生：(i) 模型在训练早期过拟合训练数据；(ii) 过拟合出现后，泛化能力长期保持较差；(iii) 最终泛化误差变得任意小。此外，我们从理论和实验上表明，通过适当的超参数调整，可以原则性地放大或消除顿悟现象。据我们所知，这是首次针对泛化延迟（我们称之为“顿悟时间”）与训练超参数之间关系给出的严格定量界限。最后，在线性设定之外，我们通过实验证明，我们的定量界限也能捕捉非线性神经网络上顿悟的行为。结果表明，顿悟并非深度学习的固有失败模式，而是特定训练条件的结果，因此无需对模型架构或学习算法进行根本性改变即可避免。</div>
</details>
<details class="detail"><summary>Summary / 总结</summary>
<div class="mono">This research investigates grokking, the phenomenon where generalization emerges long after overfitting, aiming to provide a rigorous theoretical understanding of its causes and dynamics. The method employs an over-parameterized linear regression model trained with gradient descent and weight decay, proving end-to-end that the learning process exhibits three distinct stages: initial overfitting, a prolonged period of poor generalization, and eventual convergence to arbitrarily small generalization error. Key experimental findings include the derivation of the first quantitative bounds for the &#x27;grokking time&#x27; in terms of hyperparameters, demonstrating that grokking can be systematically amplified or eliminated through hyperparameter tuning, and empirical evidence that these insights extend to non-linear neural networks, suggesting grokking is a consequence of specific training conditions rather than a fundamental flaw.</div>
<div class="mono" style="margin-top:8px">本研究探讨了“顿悟”现象，即泛化能力在过拟合发生很久后才出现，旨在对其动态提供严格的理论理解。方法是在过参数化的线性岭回归模型上使用带权重衰减的梯度下降，证明了训练会经历不同阶段：初始过拟合、长时间的泛化能力差，以及最终收敛到任意小的泛化误差。关键的实验发现包括首次推导出关于超参数的顿悟时间的定量界限，证明通过超参数调优可以系统地放大或消除顿悟现象，并通过实证表明这些见解可扩展到非线性神经网络，从而提示顿悟是训练条件导致的现象，而非深度学习的基本缺陷。</div>
</details>
</div>
<div class="card">
<div class="title">Knowledge-Aware Evolution for Streaming Federated Continual Learning with Category Overlap and without Task Identifiers</div>
<div class="meta-line">Authors: Sixing Tan, Xianmin Liu</div>
<div class="meta-line">First: 2026-01-27T16:50:48+00:00 · Latest: 2026-01-27T16:50:48+00:00</div>
<div class="links" style="margin-top:8px"><a href="https://arxiv.org/abs/2601.19788v1">Abs</a> · <a href="https://arxiv.org/pdf/2601.19788v1">PDF</a> · <a href="https://huggingface.co/huggingface">Code1</a> · <a href="https://huggingface.co/docs/hub/spaces">Code2</a></div>
<details class="detail"><summary>Abstract</summary>
<div class="mono">Federated Continual Learning (FCL) leverages inter-client collaboration to balance new knowledge acquisition and prior knowledge retention in non-stationary data. However, existing batch-based FCL methods lack adaptability to streaming scenarios featuring category overlap between old and new data and absent task identifiers, leading to indistinguishability of old and new knowledge, uncertain task assignments for samples, and knowledge confusion.To address this, we propose streaming federated continual learning setting: per federated learning (FL) round, clients process streaming data with disjoint samples and potentially overlapping categories without task identifiers, necessitating sustained inference capability for all prior categories after each FL round.Next, we introduce FedKACE: 1) an adaptive inference model switching mechanism that enables unidirectional switching from local model to global model to achieve a trade-off between personalization and generalization; 2) a adaptive gradient-balanced replay scheme that reconciles new knowledge learning and old knowledge retention under overlapping-class scenarios; 3) a kernel spectral boundary buffer maintenance that preserves high-information and high-boundary-influence samples to optimize cross-round knowledge retention. Experiments across multiple scenarios and regret analysis demonstrate the effectiveness of FedKACE.</div></details>
<details class="detail"><summary>中文标题/摘要</summary>
<div class="mono"><b>标题：</b>面向类别重叠且无任务标识的流式联邦持续学习的知识感知演进方法</div>
<div class="mono" style="margin-top:8px">联邦持续学习（FCL）通过客户端间协作，在非平稳数据中平衡新知识获取与旧知识保留。然而，现有基于批处理的FCL方法难以适应流式场景中旧新数据类别重叠且缺乏任务标识的挑战，导致新旧知识难以区分、样本任务分配不确定及知识混淆。为此，我们提出流式联邦持续学习设定：每轮联邦学习（FL）中，客户端处理样本独立但类别可能重叠且无任务标识的流式数据，并要求每轮FL后保持对所有历史类别的持续推理能力。我们进一步提出FedKACE方法：1）自适应推理模型切换机制，支持从本地模型单向切换至全局模型，实现个性化与泛化的平衡；2）自适应梯度平衡回放策略，在类别重叠场景下协调新知识学习与旧知识保留；3）核谱边界缓冲区维护机制，保留高信息量及高边界影响力的样本以优化跨轮次知识留存。多场景实验与遗憾分析验证了FedKACE的有效性。</div>
</details>
<details class="detail"><summary>Summary / 总结</summary>
<div class="mono">This work addresses the challenge of streaming federated continual learning where data arrives sequentially with overlapping categories and without task identifiers, which can cause knowledge confusion and hinder stable inference. The proposed method, FedKACE, introduces an adaptive inference model switching mechanism to balance personalization and generalization, an adaptive gradient-balanced replay scheme to manage overlapping classes, and a kernel spectral boundary buffer to retain informative samples for knowledge preservation. Experimental results across various scenarios and regret analysis confirm the effectiveness of FedKACE in maintaining inference capability for prior categories after each federated learning round.</div>
<div class="mono" style="margin-top:8px">本研究针对流式联邦持续学习中数据按序到达、类别重叠且无任务标识符的挑战，该挑战会导致知识混淆并难以区分新旧知识。提出的FedKACE方法引入了自适应推理模型切换机制以平衡个性化和泛化，自适应梯度平衡重放方案以处理重叠类别下的学习，以及核谱边界缓冲区来保留信息丰富的样本以优化跨轮次知识保持。多种场景下的实验和遗憾分析结果验证了FedKACE在每轮联邦学习后对所有先前类别保持持续推理能力的有效性。</div>
</details>
</div>
<div class="card">
<div class="title">Optimal Scaling Needs Optimal Norm</div>
<div class="meta-line">Authors: Oleg Filatov, Jiangtao Wang, Jan Ebert, Stefan Kesselheim</div>
<div class="meta-line">First: 2025-10-04T16:48:36+00:00 · Latest: 2026-01-27T16:32:23+00:00</div>
<div class="links" style="margin-top:8px"><a href="https://arxiv.org/abs/2510.03871v2">Abs</a> · <a href="https://arxiv.org/pdf/2510.03871v2">PDF</a> · <a href="https://huggingface.co/huggingface">Code1</a> · <a href="https://huggingface.co/docs/hub/spaces">Code2</a></div>
<details class="detail"><summary>Abstract</summary>
<div class="mono">Despite recent progress in optimal hyperparameter transfer under model and dataset scaling, no unifying explanatory principle has been established. For Adam and Scion optimizers, we discover that joint optimal scaling across model and dataset sizes is conditioned on a single invariant: the operator norm of the output layer. Across models with up to 1.3B parameters trained on up to 138B tokens, the optimal learning rate/batch size pair $(η^{\ast}, B^{\ast})$ consistently has the same operator norm value - a phenomenon we term norm transfer. This constant norm condition is necessary but not sufficient: while for each dataset size, multiple $(η, B)$ reach the optimal norm, only a unique $(η^{\ast}, B^{\ast})$ achieves the best loss. As a sufficient condition, we provide the first measurement of $(η^{\ast}, B^{\ast})$ scaling with dataset size for Scion, and find that the scaling rules are consistent with those of Adam. Tuning per-layer-group learning rates also improves model performance, with the output layer being the most sensitive and hidden layers benefiting from lower learning rates. We provide practical insights on norm-guided optimal scaling and release our Distributed Scion (Disco) implementation with logs from over two thousand runs to support research on LLM training dynamics at scale.</div></details>
<details class="detail"><summary>中文标题/摘要</summary>
<div class="mono"><b>标题：</b>最优缩放需最优范数</div>
<div class="mono" style="margin-top:8px">尽管近期在模型与数据集缩放下的最优超参数迁移方面取得进展，但尚未建立统一解释原理。针对Adam与Scion优化器，我们发现模型与数据集规模的联合最优缩放取决于单一不变量：输出层的算子范数。在参数高达13亿、训练令牌数达1380亿的模型中，最优学习率/批量大小对$(η^{\ast}, B^{\ast})$始终具有相同的算子范数值——这一现象称为范数迁移。该恒定范数条件是必要非充分的：虽然每个数据集规模下存在多个$(η, B)$达到最优范数，但仅唯一$(η^{\ast}, B^{\ast})$能实现最佳损失。作为充分条件，我们首次测量了Scion的$(η^{\ast}, B^{\ast})$随数据集规模的缩放规律，发现其与Adam的缩放规则一致。按层组调整学习率也能提升模型性能，其中输出层最敏感，隐藏层则受益于较低学习率。我们提供了范数引导最优缩放的实用见解，并开源分布式Scion（Disco）实现及两千余次实验日志，以支持大规模语言模型训练动态研究。</div>
</details>
<details class="detail"><summary>Summary / 总结</summary>
<div class="mono">The research aims to establish a unifying principle for optimal hyperparameter transfer across model and dataset scaling, addressing the lack of explanatory frameworks in this area. The method involves analyzing the operator norm of the output layer as a key invariant, discovering that for Adam and Scion optimizers, the optimal learning rate and batch size pair consistently yields the same operator norm value across models up to 1.3B parameters and datasets up to 138B tokens, a phenomenon termed norm transfer. Key experimental findings show that while multiple hyperparameter combinations can achieve the optimal norm for a given dataset size, only a unique pair attains the best loss, and scaling rules for Scion align with those of Adam, with per-layer-group tuning further improving performance, particularly highlighting the output layer&#x27;s sensitivity.</div>
<div class="mono" style="margin-top:8px">本研究旨在为模型和数据规模扩展中的最优超参数迁移建立一个统一原则，以解决该领域缺乏解释性框架的问题。方法上，通过分析输出层算子范数作为关键不变量，发现在Adam和Scion优化器中，对于高达13亿参数的模型和1380亿标记的数据集，最优学习率和批量大小组合始终产生相同的算子范数值，这一现象被称为范数迁移。实验结果表明，虽然多个超参数组合能达到这一最优范数，但只有唯一组合能实现最佳损失，其中Scion的缩放规则与Adam一致，且调整逐层组学习率（特别是降低隐藏层学习率）能进一步提升模型性能。</div>
</details>
</div>
<div class="card">
<div class="title">GAVEL: Towards rule-based safety through activation monitoring</div>
<div class="meta-line">Authors: Shir Rozenfeld, Rahul Pankajakshan, Itay Zloczower, Eyal Lenga, Gilad Gressel, Yisroel Mirsky</div>
<div class="meta-line">Venue: ICLR 2026</div>
<div class="meta-line">First: 2026-01-27T16:31:39+00:00 · Latest: 2026-01-27T16:31:39+00:00</div>
<div class="meta-line">Comments: Accepted to ICLR 2026</div>
<div class="links" style="margin-top:8px"><a href="https://arxiv.org/abs/2601.19768v1">Abs</a> · <a href="https://arxiv.org/pdf/2601.19768v1">PDF</a> · <a href="https://huggingface.co/huggingface">Code1</a> · <a href="https://huggingface.co/docs/hub/spaces">Code2</a></div>
<details class="detail"><summary>Abstract</summary>
<div class="mono">Large language models (LLMs) are increasingly paired with activation-based monitoring to detect and prevent harmful behaviors that may not be apparent at the surface-text level. However, existing activation safety approaches, trained on broad misuse datasets, struggle with poor precision, limited flexibility, and lack of interpretability. This paper introduces a new paradigm: rule-based activation safety, inspired by rule-sharing practices in cybersecurity. We propose modeling activations as cognitive elements (CEs), fine-grained, interpretable factors such as &#x27;&#x27;making a threat&#x27;&#x27; and &#x27;&#x27;payment processing&#x27;&#x27;, that can be composed to capture nuanced, domain-specific behaviors with higher precision. Building on this representation, we present a practical framework that defines predicate rules over CEs and detects violations in real time. This enables practitioners to configure and update safeguards without retraining models or detectors, while supporting transparency and auditability. Our results show that compositional rule-based activation safety improves precision, supports domain customization, and lays the groundwork for scalable, interpretable, and auditable AI governance. We will release GAVEL as an open-source framework and provide an accompanying automated rule creation tool.</div></details>
<details class="detail"><summary>中文标题/摘要</summary>
<div class="mono"><b>标题：</b>GAVEL：通过激活监控实现基于规则的安全性</div>
<div class="mono" style="margin-top:8px">大型语言模型（LLMs）越来越多地与基于激活的监控结合使用，以检测和预防在表层文本中可能不明显的危害行为。然而，现有基于广泛滥用数据集训练的激活安全方法存在精度低、灵活性有限和可解释性不足的问题。本文提出一种新范式：基于规则的激活安全，其灵感来源于网络安全领域的规则共享实践。我们将激活建模为认知元素（CEs），即细粒度、可解释的因子（如“发出威胁”和“支付处理”），这些元素可组合起来以更高精度捕捉细微的、领域特定的行为。基于此表示，我们提出一个实用框架，该框架定义CEs的谓词规则并实时检测违规行为。这使得实践者能够在不重新训练模型或检测器的情况下配置和更新安全措施，同时支持透明度和可审计性。我们的结果表明，基于组合规则的激活安全提高了精度，支持领域定制，并为可扩展、可解释和可审计的人工智能治理奠定了基础。我们将以开源框架形式发布GAVEL，并提供配套的自动化规则创建工具。</div>
</details>
<details class="detail"><summary>Summary / 总结</summary>
<div class="mono">To address the limitations of existing activation safety approaches for large language models, which suffer from poor precision, limited flexibility, and lack of interpretability, this paper introduces a rule-based paradigm inspired by cybersecurity practices. The method models activations as fine-grained, interpretable cognitive elements (CEs) and defines predicate rules over them to detect nuanced, domain-specific harmful behaviors in real time, allowing safeguards to be configured without retraining. Experimental results demonstrate that this compositional rule-based approach improves precision, supports domain customization, and provides a foundation for scalable, interpretable, and auditable AI governance.</div>
<div class="mono" style="margin-top:8px">针对现有基于激活的大型语言模型安全监控方法精度低、灵活性差且缺乏可解释性的问题，本文提出了一种基于规则的激活安全新范式。该方法将激活建模为细粒度、可解释的认知要素（如“发出威胁”），并在此基础上定义谓词规则，以实时检测细微、领域特定的有害行为，支持无需重新训练模型即可配置规则。实验结果表明，这种基于组合规则的方法提高了检测精度，支持领域定制，并为可扩展、可审计的AI治理奠定了基础。</div>
</details>
</div>
<div class="card">
<div class="title">The Effect of Architecture During Continual Learning</div>
<div class="meta-line">Authors: Allyson Hahn, Krishnan Raghavan</div>
<div class="meta-line">First: 2026-01-27T16:29:42+00:00 · Latest: 2026-01-27T16:29:42+00:00</div>
<div class="links" style="margin-top:8px"><a href="https://arxiv.org/abs/2601.19766v1">Abs</a> · <a href="https://arxiv.org/pdf/2601.19766v1">PDF</a> · <a href="https://huggingface.co/huggingface">Code1</a> · <a href="https://huggingface.co/docs/hub/spaces">Code2</a></div>
<details class="detail"><summary>Abstract</summary>
<div class="mono">Continual learning is a challenge for models with static architecture, as they fail to adapt to when data distributions evolve across tasks. We introduce a mathematical framework that jointly models architecture and weights in a Sobolev space, enabling a rigorous investigation into the role of neural network architecture in continual learning and its effect on the forgetting loss. We derive necessary conditions for the continual learning solution and prove that learning only model weights is insufficient to mitigate catastrophic forgetting under distribution shifts. Consequently, we prove that by learning the architecture and weights simultaneously at each task, we can reduce catastrophic forgetting.
  To learn weights and architecture simultaneously, we formulate continual learning as a bilevel optimization problem: the upper level selects an optimal architecture for a given task, while the lower level computes optimal weights via dynamic programming over all tasks. To solve the upper level problem, we introduce a derivative-free direct search algorithm to determine the optimal architecture. Once found, we must transfer knowledge from the current architecture to the optimal one. However, the optimal architecture will result in a weights parameter space different from the current architecture (i.e., dimensions of weights matrices will not match). To bridge the dimensionality gap, we develop a low-rank transfer mechanism to map knowledge across architectures of mismatched dimensions. Empirical studies across regression and classification problems, including feedforward, convolutional, and graph neural networks, demonstrate that learning the optimal architecture and weights simultaneously yields substantially improved performance (up to two orders of magnitude), reduced forgetting, and enhanced robustness to noise compared with static architecture approaches.</div></details>
<details class="detail"><summary>中文标题/摘要</summary>
<div class="mono"><b>标题：</b>架构在持续学习中的作用</div>
<div class="mono" style="margin-top:8px">持续学习对静态架构模型构成挑战，因其难以适应任务间数据分布的演变。我们提出一个在Sobolev空间中联合建模架构与权重的数学框架，从而严格探究神经网络架构在持续学习中的作用及其对遗忘损失的影响。我们推导出持续学习解的必要条件，并证明仅学习模型权重不足以缓解分布偏移下的灾难性遗忘。因此，我们证实通过在每项任务中同步学习架构与权重，可有效降低灾难性遗忘。为实现权重与架构的同步学习，我们将持续学习构建为双层优化问题：上层为给定任务选择最优架构，下层通过跨任务的动态规划计算最优权重。针对上层问题，我们引入无导数直接搜索算法以确定最优架构。确定最优架构后，需将知识从当前架构迁移至新架构，但两者权重参数空间维度不匹配。为此，我们开发了低秩迁移机制，实现跨维度不匹配架构的知识映射。在回归与分类问题（包括前馈、卷积及图神经网络）上的实证研究表明：相较于静态架构方法，同步学习最优架构与权重能显著提升性能（最高达两个数量级）、减少遗忘并增强对噪声的鲁棒性。</div>
</details>
<details class="detail"><summary>Summary / 总结</summary>
<div class="mono">This research addresses the challenge of catastrophic forgetting in continual learning, where static neural network architectures struggle to adapt to evolving data distributions across tasks. The authors propose a mathematical framework that jointly models architecture and weights in a Sobolev space, establishing necessary conditions for continual learning solutions and proving that learning only weights is insufficient to mitigate forgetting. They formulate continual learning as a bilevel optimization problem: the upper level selects an optimal architecture via a derivative-free direct search algorithm, while the lower level computes optimal weights via dynamic programming, with a low-rank transfer mechanism to map knowledge across architectures of mismatched dimensions. Experimental results on regression and classification tasks with feedforward, convolutional, and graph neural networks show that simultaneously learning architecture and weights yields performance improvements up to two orders of magnitude, reduces forgetting, and enhances robustness to noise compared to static architecture methods.</div>
<div class="mono" style="margin-top:8px">本研究针对持续学习中静态神经网络架构难以适应任务间数据分布变化而导致的灾难性遗忘问题。作者提出了一个在Sobolev空间中联合建模架构和权重的数学框架，推导了持续学习解的必要条件，并证明仅学习权重不足以缓解分布偏移下的遗忘。他们将持续学习构建为一个双层优化问题：上层通过无导数直接搜索算法选择最优架构，下层通过动态规划计算所有权重；同时开发了低秩迁移机制来解决不同架构间的维度不匹配问题。在回归和分类任务上的实验表明，与静态架构方法相比，同时学习最优架构和权重能使性能提升高达两个数量级，显著减少遗忘，并增强对噪声的鲁棒性。</div>
</details>
</div>
<div class="card">
<div class="title">Provable Learning of Random Hierarchy Models and Hierarchical Shallow-to-Deep Chaining</div>
<div class="meta-line">Authors: Yunwei Ren, Yatin Dandi, Florent Krzakala, Jason D. Lee</div>
<div class="meta-line">First: 2026-01-27T16:19:54+00:00 · Latest: 2026-01-27T16:19:54+00:00</div>
<div class="links" style="margin-top:8px"><a href="https://arxiv.org/abs/2601.19756v1">Abs</a> · <a href="https://arxiv.org/pdf/2601.19756v1">PDF</a> · <a href="https://huggingface.co/huggingface">Code1</a> · <a href="https://huggingface.co/docs/hub/spaces">Code2</a></div>
<details class="detail"><summary>Abstract</summary>
<div class="mono">The empirical success of deep learning is often attributed to deep networks&#x27; ability to exploit hierarchical structure in data, constructing increasingly complex features across layers. Yet despite substantial progress in deep learning theory, most optimization results sill focus on networks with only two or three layers, leaving the theoretical understanding of hierarchical learning in genuinely deep models limited. This leads to a natural question: can we prove that deep networks, trained by gradient-based methods, can efficiently exploit hierarchical structure?
  In this work, we consider Random Hierarchy Models -- a hierarchical context-free grammar introduced by arXiv:2307.02129 and conjectured to separate deep and shallow networks. We prove that, under mild conditions, a deep convolutional network can be efficiently trained to learn this function class. Our proof builds on a general observation: if intermediate layers can receive clean signal from the labels and the relevant features are weakly identifiable, then layerwise training each individual layer suffices to hierarchically learn the target function.</div></details>
<details class="detail"><summary>中文标题/摘要</summary>
<div class="mono"><b>标题：</b>随机层次模型与层次化浅层至深层链式结构的可证明学习</div>
<div class="mono" style="margin-top:8px">深度学习的实证成功常归因于深度网络能利用数据的层次结构，在逐层构建日益复杂的特征。尽管深度学习理论取得显著进展，多数优化结果仍聚焦于仅含两至三层的网络，使得对真正深度模型中层次化学习的理论认知有限。这引出一个自然问题：能否证明基于梯度方法训练的深度网络能有效利用层次结构？本研究采用随机层次模型——一种由arXiv:2307.02129提出且被推测能区分深度与浅层网络的层次化上下文无关文法。我们证明在温和条件下，深度卷积网络可通过高效训练学习此类函数。证明基于一个普遍观察：若中间层能从标签获得清晰信号且相关特征具有弱可识别性，则逐层训练足以层次化地学习目标函数。</div>
</details>
<details class="detail"><summary>Summary / 总结</summary>
<div class="mono">Motivated by the limited theoretical understanding of how deep networks exploit hierarchical structure beyond shallow architectures, this work investigates whether gradient-based training can efficiently learn hierarchical functions. The method analyzes Random Hierarchy Models, a context-free grammar conjectured to separate deep and shallow networks, proving that under mild conditions deep convolutional networks can learn this class through layerwise training when intermediate layers receive clean label signals and features are weakly identifiable. Key experimental findings demonstrate that this approach enables provable hierarchical learning, addressing the gap between empirical deep learning success and theoretical guarantees for genuinely deep models.</div>
<div class="mono" style="margin-top:8px">本研究针对深度网络如何利用层次结构这一理论空白，旨在验证基于梯度的训练能否有效学习层次函数。方法上分析了随机层次模型——一类被认为能区分深浅网络的功能类，证明在温和条件下，当中间层能获得清晰标签信号且特征可弱识别时，通过逐层训练即可使深度卷积网络高效学习该函数类。关键实验结果表明，该方法能实现目标函数的层次化学习，为深度模型中层次特征构建提供了理论依据。</div>
</details>
</div></div>
    <details style="margin-top:16px" class="detail"><summary>History</summary>
      <div class="history-list"><a href="archive/20260129_0450.html">20260129_0450</a>
<a href="archive/20260129_0336.html">20260129_0336</a>
<a href="archive/20260128_0625.html">20260128_0625</a>
<a href="archive/20260128_0439.html">20260128_0439</a>
<a href="archive/20260128_0334.html">20260128_0334</a>
<a href="archive/20260127_0627.html">20260127_0627</a>
<a href="archive/20260127_0529.html">20260127_0529</a>
<a href="archive/20260127_0439.html">20260127_0439</a>
<a href="archive/20260127_0333.html">20260127_0333</a>
<a href="archive/20260126_0626.html">20260126_0626</a>
<a href="archive/20260126_0526.html">20260126_0526</a>
<a href="archive/20260126_0327.html">20260126_0327</a>
<a href="archive/20260125_0624.html">20260125_0624</a>
<a href="archive/20260125_0524.html">20260125_0524</a>
<a href="archive/20260125_0440.html">20260125_0440</a>
<a href="archive/20260125_0325.html">20260125_0325</a>
<a href="archive/20260124_0627.html">20260124_0627</a>
<a href="archive/20260124_0526.html">20260124_0526</a>
<a href="archive/20260124_0444.html">20260124_0444</a>
<a href="archive/20260124_0334.html">20260124_0334</a>
<a href="archive/20260123_0627.html">20260123_0627</a>
<a href="archive/20260123_0529.html">20260123_0529</a>
<a href="archive/20260123_0446.html">20260123_0446</a>
<a href="archive/20260123_0334.html">20260123_0334</a>
<a href="archive/20260122_2019.html">20260122_2019</a>
<a href="archive/20260122_2013.html">20260122_2013</a>
<a href="archive/20260122_2008.html">20260122_2008</a>
<a href="archive/20260122_2001.html">20260122_2001</a>
<a href="archive/20260122_0629.html">20260122_0629</a>
<a href="archive/20260122_0535.html">20260122_0535</a>
<a href="archive/20260122_0449.html">20260122_0449</a>
<a href="archive/20260122_0336.html">20260122_0336</a>
<a href="archive/20260121_0625.html">20260121_0625</a>
<a href="archive/20260121_0529.html">20260121_0529</a>
<a href="archive/20260121_0450.html">20260121_0450</a>
<a href="archive/20260121_0423.html">20260121_0423</a>
<a href="archive/20260120_0626.html">20260120_0626</a>
<a href="archive/20260120_0528.html">20260120_0528</a>
<a href="archive/20260120_0443.html">20260120_0443</a>
<a href="archive/20260120_0330.html">20260120_0330</a>
<a href="archive/20260119_0624.html">20260119_0624</a>
<a href="archive/20260119_0525.html">20260119_0525</a>
<a href="archive/20260119_0440.html">20260119_0440</a>
<a href="archive/20260119_0325.html">20260119_0325</a>
<a href="archive/20260118_2225.html">20260118_2225</a>
<a href="archive/20260118_2159.html">20260118_2159</a>
<a href="archive/20260118_2135.html">20260118_2135</a>
<a href="archive/20260118_2040.html">20260118_2040</a>
<a href="archive/20260118_1953.html">20260118_1953</a>
<a href="archive/20260118_1907.html">20260118_1907</a>
<a href="archive/20260118_0327.html">20260118_0327</a>
<a href="archive/20260117_0332.html">20260117_0332</a>
<a href="archive/20260116_0339.html">20260116_0339</a>
<a href="archive/20260115_0334.html">20260115_0334</a>
<a href="archive/20260114_0333.html">20260114_0333</a>
<a href="archive/20260113_0334.html">20260113_0334</a>
<a href="archive/20260112_0331.html">20260112_0331</a>
<a href="archive/20260111_0329.html">20260111_0329</a>
<a href="archive/20260110_0333.html">20260110_0333</a>
<a href="archive/20260109_0334.html">20260109_0334</a>
<a href="archive/20260108_0335.html">20260108_0335</a>
<a href="archive/20260107_0330.html">20260107_0330</a>
<a href="archive/20260106_0336.html">20260106_0336</a>
<a href="archive/20260105_0328.html">20260105_0328</a>
<a href="archive/20260104_0328.html">20260104_0328</a>
<a href="archive/20260103_0325.html">20260103_0325</a>
<a href="archive/20260102_0339.html">20260102_0339</a>
<a href="archive/20260101_0329.html">20260101_0329</a>
<a href="archive/20251231_0333.html">20251231_0333</a>
<a href="archive/20251230_0332.html">20251230_0332</a>
<a href="archive/20251229_0329.html">20251229_0329</a>
<a href="archive/20251228_0332.html">20251228_0332</a>
<a href="archive/20251227_0329.html">20251227_0329</a>
<a href="archive/20251226_0330.html">20251226_0330</a>
<a href="archive/20251225_0329.html">20251225_0329</a>
<a href="archive/20251224_0331.html">20251224_0331</a>
<a href="archive/20251223_0332.html">20251223_0332</a>
<a href="archive/20251222_0328.html">20251222_0328</a>
<a href="archive/20251221_0329.html">20251221_0329</a>
<a href="archive/20251220_0330.html">20251220_0330</a>
<a href="archive/20251219_0330.html">20251219_0330</a>
<a href="archive/20251218_0345.html">20251218_0345</a>
<a href="archive/20251217_0332.html">20251217_0332</a>
<a href="archive/20251216_0333.html">20251216_0333</a>
<a href="archive/20251215_0333.html">20251215_0333</a>
<a href="archive/20251214_0327.html">20251214_0327</a>
<a href="archive/20251212_0333.html">20251212_0333</a>
<a href="archive/20251211_0331.html">20251211_0331</a>
<a href="archive/20251210_0332.html">20251210_0332</a>
<a href="archive/20251209_0331.html">20251209_0331</a>
<a href="archive/20251208_0328.html">20251208_0328</a>
<a href="archive/20251207_0327.html">20251207_0327</a>
<a href="archive/20251206_0330.html">20251206_0330</a>
<a href="archive/20251205_0331.html">20251205_0331</a>
<a href="archive/20251204_0331.html">20251204_0331</a>
<a href="archive/20251203_0333.html">20251203_0333</a>
<a href="archive/20251202_0335.html">20251202_0335</a>
<a href="archive/20251201_0328.html">20251201_0328</a>
<a href="archive/20251130_0327.html">20251130_0327</a>
<a href="archive/20251129_0328.html">20251129_0328</a></div>
    </details>
    <div class="footer">Generated by arxiv-tracker</div>
  </div>
</body></html>
