<!doctype html>
<html><head><meta charset="utf-8"><meta name="viewport" content="width=device-width,initial-scale=1">
<title>arXiv 论文速递</title><style>
:root {
  --bg:#f8fafc; --card:#ffffff; --text:#0f172a; --muted:#667085; --border:#e5e7eb; --acc:#2563eb;
}
:root[data-theme="dark"] {
  --bg:#0b0f17; --card:#111827; --text:#e5e7eb; --muted:#9ca3af; --border:#1f2937; --acc:#2563eb;
}
*{box-sizing:border-box} body{margin:0;background:var(--bg);color:var(--text);
  font-family:ui-sans-serif,system-ui,-apple-system,Segoe UI,Roboto,Helvetica,Arial;line-height:1.6;}
.container{max-width:900px;margin:0 auto;padding:18px;}
.header{display:flex;gap:10px;justify-content:space-between;align-items:center;margin:8px 0 16px;flex-wrap:wrap}
h1{font-size:22px;margin:0}
.badge{font-size:12px;color:#111827;background:var(--acc);padding:2px 8px;border-radius:999px}
.card{background:var(--card);border:1px solid var(--border);border-radius:16px;padding:16px 18px;margin:14px 0;box-shadow:0 1px 2px rgba(0,0,0,.04)}
.title{font-weight:700;margin:0 0 6px 0;font-size:18px}
.meta-line{color:var(--muted);font-size:13px;margin:2px 0}
.links a{color:var(--acc);text-decoration:none;margin-right:12px}
.detail{margin-top:10px;background:rgba(2,6,23,.03);border:1px solid var(--border);border-radius:10px;padding:8px 10px}
summary{cursor:pointer;color:var(--acc)}
.mono{white-space:pre-wrap;background:rgba(2,6,23,.03);border:1px solid var(--border);padding:10px;border-radius:10px}
.row{display:grid;grid-template-columns:1fr;gap:12px}
@media (min-width: 860px) {
  .row-2{grid-template-columns:1fr 1fr}
}
.footer{color:var(--muted);font-size:13px;margin:20px 0 10px}
.hr{height:1px;background:var(--border);margin:14px 0}
.history-list a{display:block;color:var(--acc);text-decoration:none;margin:4px 0}
.controls{display:flex;gap:8px;align-items:center}
.btn{border:1px solid var(--border);background:var(--card);padding:6px 10px;border-radius:10px;cursor:pointer;color:var(--text)}
.btn:hover{border-color:var(--acc)}
</style>
<script>
(function() {
  const root = document.documentElement;
  function apply(t) {
    if (t==='dark') root.setAttribute('data-theme','dark');
    else if (t==='light') root.removeAttribute('data-theme');
    else {
      if (window.matchMedia && window.matchMedia('(prefers-color-scheme: dark)').matches)
        root.setAttribute('data-theme','dark');
      else root.removeAttribute('data-theme');
    }
  }
  let t = localStorage.getItem('theme') || 'light';
  if (!['light','dark','auto'].includes(t)) t='light';
  apply(t);
  window.__toggleTheme = function() {
    let cur = localStorage.getItem('theme') || 'light';
    if (cur==='light') cur='dark';
    else if (cur==='dark') cur='auto';
    else cur='light';
    localStorage.setItem('theme', cur);
    apply(cur);
    const el=document.getElementById('theme-label');
    if(el) el.textContent = cur.toUpperCase();
  }
  window.__expandAll = function(open) {
    document.querySelectorAll('details').forEach(d => d.open = !!open);
  }
})();
</script>
</head>
<body>
  <div class="container">
    <div class="header">
      <h1>arXiv 论文速递</h1>
      <div style="display:flex;gap:10px;align-items:center">
        
<div class="controls">
  <button class="btn" onclick="__toggleTheme()">Theme: <span id="theme-label" style="margin-left:6px">AUTO</span></button>
  <button class="btn" onclick="__expandAll(true)">Expand All</button>
  <button class="btn" onclick="__expandAll(false)">Collapse All</button>
</div>

        <span class="badge">2026-01-21 04:23</span>
      </div>
    </div>
    <div class="hr"></div>
    <div>Snapshot: 20260121_0423</div>
    <div class="row"><div class="card">
<div class="title">Do explanations generalize across large reasoning models?</div>
<div class="meta-line">Authors: Koyena Pal, David Bau, Chandan Singh</div>
<div class="meta-line">First: 2026-01-16T18:55:29+00:00 · Latest: 2026-01-16T18:55:29+00:00</div>
<div class="links" style="margin-top:8px"><a href="https://arxiv.org/abs/2601.11517v1">Abs</a> · <a href="https://arxiv.org/pdf/2601.11517v1">PDF</a> · <a href="https://huggingface.co/huggingface">Code1</a> · <a href="https://huggingface.co/docs/hub/spaces">Code2</a></div>
<details class="detail"><summary>Abstract</summary>
<div class="mono">Large reasoning models (LRMs) produce a textual chain of thought (CoT) in the process of solving a problem, which serves as a potentially powerful tool to understand the problem by surfacing a human-readable, natural-language explanation. However, it is unclear whether these explanations generalize, i.e. whether they capture general patterns about the underlying problem rather than patterns which are esoteric to the LRM. This is a crucial question in understanding or discovering new concepts, e.g. in AI for science. We study this generalization question by evaluating a specific notion of generalizability: whether explanations produced by one LRM induce the same behavior when given to other LRMs. We find that CoT explanations often exhibit this form of generalization (i.e. they increase consistency between LRMs) and that this increased generalization is correlated with human preference rankings and post-training with reinforcement learning. We further analyze the conditions under which explanations yield consistent answers and propose a straightforward, sentence-level ensembling strategy that improves consistency. Taken together, these results prescribe caution when using LRM explanations to yield new insights and outline a framework for characterizing LRM explanation generalization.</div></details>
<details class="detail"><summary>中文标题/摘要</summary>
<div class="mono"><b>标题：</b>大推理模型的解释是否具有跨模型泛化能力？</div>
<div class="mono" style="margin-top:8px">大推理模型在解决问题时会生成文本形式的思维链，这种人类可读的自然语言解释为理解问题提供了潜在的有力工具。然而，这些解释是否具有泛化性尚不明确——即它们捕捉的是底层问题的普遍规律，还是仅适用于特定模型的特殊模式。这对于理解或发现新概念（如科学人工智能领域）至关重要。我们通过评估一种具体的泛化概念来研究该问题：一个LRM生成的解释输入其他LRM时是否引发相同行为。研究发现思维链解释常具备此类泛化特性（即提升LRM间一致性），且这种增强的泛化性与人类偏好排序及强化学习后训练相关。我们进一步分析了解释产生一致答案的条件，并提出一种简单的句子级集成策略以提升一致性。综合而言，这些结果提示在使用LRM解释获取新见解时需保持谨慎，并为描述LRM解释泛化特性提供了框架。</div>
</details>
<details class="detail"><summary>Summary / 总结</summary>
<div class="mono">The research is motivated by the need to assess whether the chain-of-thought explanations generated by large reasoning models capture generalizable patterns about problems rather than model-specific quirks, which is critical for reliable use in domains like AI for science. The method evaluates explanation generalizability by testing if explanations from one model induce consistent behavior when provided to other models, and it further analyzes conditions for consistency and proposes a sentence-level ensembling strategy. Key experimental findings show that such explanations often increase inter-model consistency, with this generalization correlating with human preference rankings and reinforcement learning post-training, while also highlighting caution in using explanations for new insights and offering a framework for characterization.</div>
<div class="mono" style="margin-top:8px">本研究探讨大型推理模型生成的思维链解释是否具有泛化性，即解释应反映问题的通用模式而非模型特定特性，这对于AI科学发现等应用至关重要。方法通过测试一个模型生成的解释能否在其他模型中引发一致行为来评估泛化性，衡量模型间答案一致性的提升。主要发现表明，解释通常能泛化，提高了模型间一致性，且这种提升与人类偏好排名和强化学习后训练相关；此外，提出了一种句子级集成策略以进一步增强一致性，建议谨慎使用解释来获取新见解，同时提供了一个评估解释泛化性的框架。</div>
</details>
</div>
<div class="card">
<div class="title">Building Production-Ready Probes For Gemini</div>
<div class="meta-line">Authors: János Kramár, Joshua Engels, Zheng Wang, Bilal Chughtai, Rohin Shah, Neel Nanda, Arthur Conmy</div>
<div class="meta-line">First: 2026-01-16T18:54:29+00:00 · Latest: 2026-01-16T18:54:29+00:00</div>
<div class="links" style="margin-top:8px"><a href="https://arxiv.org/abs/2601.11516v1">Abs</a> · <a href="https://arxiv.org/pdf/2601.11516v1">PDF</a> · <a href="https://huggingface.co/huggingface">Code1</a> · <a href="https://huggingface.co/docs/hub/spaces">Code2</a></div>
<details class="detail"><summary>Abstract</summary>
<div class="mono">Frontier language model capabilities are improving rapidly. We thus need stronger mitigations against bad actors misusing increasingly powerful systems. Prior work has shown that activation probes may be a promising misuse mitigation technique, but we identify a key remaining challenge: probes fail to generalize under important production distribution shifts. In particular, we find that the shift from short-context to long-context inputs is difficult for existing probe architectures. We propose several new probe architecture that handle this long-context distribution shift.
  We evaluate these probes in the cyber-offensive domain, testing their robustness against various production-relevant shifts, including multi-turn conversations, static jailbreaks, and adaptive red teaming. Our results demonstrate that while multimax addresses context length, a combination of architecture choice and training on diverse distributions is required for broad generalization. Additionally, we show that pairing probes with prompted classifiers achieves optimal accuracy at a low cost due to the computational efficiency of probes.
  These findings have informed the successful deployment of misuse mitigation probes in user-facing instances of Gemini, Google&#x27;s frontier language model. Finally, we find early positive results using AlphaEvolve to automate improvements in both probe architecture search and adaptive red teaming, showing that automating some AI safety research is already possible.</div></details>
<details class="detail"><summary>中文标题/摘要</summary>
<div class="mono"><b>标题：</b>为Gemini构建生产就绪型探测模型</div>
<div class="mono" style="margin-top:8px">前沿语言模型能力正快速提升，因此需要更强有力的措施来防止恶意行为者滥用日益强大的系统。先前研究表明激活探测可能是一种有前景的滥用缓解技术，但我们发现一个关键挑战：探测模型在重要的生产分布偏移下泛化能力不足。特别是从短上下文到长上下文的输入偏移对现有探测架构构成困难。我们提出了几种能处理这种长上下文分布偏移的新型探测架构。

我们在网络攻防领域评估这些探测模型，测试其对多轮对话、静态越狱和自适应红队测试等生产相关偏移的鲁棒性。结果表明，虽然多最大值方法能应对上下文长度问题，但需要结合架构选择与多样化分布训练才能实现广泛泛化。此外，由于探测模型的计算效率优势，将其与提示分类器结合能以较低成本实现最优精度。

这些发现已成功指导了Gemini（谷歌前沿语言模型）用户端实例中滥用缓解探测模型的部署。最后，我们利用AlphaEvolve在探测架构搜索和自适应红队测试自动化改进方面取得了初步积极成果，表明部分AI安全研究已具备自动化可能。</div>
</details>
<details class="detail"><summary>Summary / 总结</summary>
<div class="mono">As frontier language models become more capable, stronger mitigations are needed to prevent misuse by bad actors. This work addresses the challenge that existing activation probes fail to generalize under production distribution shifts, particularly from short to long contexts, by proposing new probe architectures. Evaluated in the cyber-offensive domain against shifts like multi-turn conversations and adaptive red teaming, the results show that robust generalization requires both architectural innovations like multimax for context length and training on diverse distributions, and that pairing probes with prompted classifiers achieves optimal accuracy cost-effectively. These findings have informed the deployment of probes in Gemini, and early results indicate automation via AlphaEvolve can improve both probe architecture and red teaming.</div>
<div class="mono" style="margin-top:8px">随着前沿语言模型能力快速提升，需要更强的滥用缓解技术。本研究指出现有激活探针在生产环境分布变化下泛化能力不足，特别是从短上下文到长上下文的转变，因此提出了新的探针架构来解决这一挑战。在网络安全攻击领域的评估表明，虽然multimax架构能处理上下文长度问题，但广泛的泛化需要架构创新和多样化分布训练相结合，且探针与提示分类器结合能以较低计算成本实现最佳准确率。这些方法已部署于面向用户的Gemini系统中，早期结果显示通过AlphaEvolve自动化改进探针架构搜索和自适应红队测试是可行的。</div>
</details>
</div>
<div class="card">
<div class="title">From Aggregation to Selection: User-Validated Distributed Social Recommendation</div>
<div class="meta-line">Authors: Jingyuan Huang, Dan Luo, Zihe Ye, Weixin Chen, Minghao Guo, Yongfeng Zhang</div>
<div class="meta-line">Venue: WWW 2026</div>
<div class="meta-line">First: 2025-05-27T16:17:06+00:00 · Latest: 2026-01-16T18:45:34+00:00</div>
<div class="meta-line">Comments: Accepted by HCRS@WWW 2026</div>
<div class="links" style="margin-top:8px"><a href="https://arxiv.org/abs/2505.21388v3">Abs</a> · <a href="https://arxiv.org/pdf/2505.21388v3">PDF</a> · <a href="https://github.com/agiresearch/DeSocial">Code1</a> · <a href="https://huggingface.co/huggingface">Code2</a> · <a href="https://huggingface.co/docs/hub/spaces">Code3</a></div>
<details class="detail"><summary>Abstract</summary>
<div class="mono">Social recommender systems facilitate social connections by identifying potential friends for users. Each user maintains a local social network centered around themselves, resulting in a naturally distributed social structure. Recent research on distributed modeling for social recommender systems has gained increasing attention, as it naturally aligns with the user-centric structure of user interactions. Current distributed social recommender systems rely on automatically combining predictions from multiple models, often overlooking the user&#x27;s active role in validating whether suggested connections are appropriate. Moreover, recommendation decisions are validated by individual users rather than derived from a single global ordering of candidates. As a result, standard ranking-based evaluation metrics make it difficult to evaluate whether a user-confirmed recommendation decision is actually correct. To address these limitations, we propose DeSocial, a distributed social recommendation framework with user-validation. DeSocial enables users to select recommendation algorithms to validate their potential connections, and the verification is processed through majority consensus among multiple independent user validators. To evaluate the distributed recommender system with user validator, we formulate this setting as a link prediction and verification task and introduce Acc@K, a consensus-based evaluation metric that measures whether user-approved recommendations are correct. Experiments on 4 real-world social networks shows that DeSocial improves decision correctness and robustness compared to single-point and distributed baselines. These findings highlight the potential of user-validated distributed recommender systems as a practical approach to social recommendation, with broader applicability to distributed and decentralized recommendations. Code: https://github.com/agiresearch/DeSocial.</div></details>
<details class="detail"><summary>中文标题/摘要</summary>
<div class="mono"><b>标题：</b>从聚合到选择：用户验证的分布式社交推荐</div>
<div class="mono" style="margin-top:8px">社交推荐系统通过为用户识别潜在好友来促进社交连接。每个用户维护以自身为中心的本地社交网络，形成天然分布式社交结构。近期针对社交推荐系统的分布式建模研究日益受到关注，因其与用户交互的以用户为中心结构自然契合。现有分布式社交推荐系统依赖自动聚合多模型预测，常忽视用户在验证推荐连接适宜性中的主动作用。此外，推荐决策由个体用户验证，而非基于全局候选排序。因此，标准基于排序的评估指标难以判断用户确认的推荐决策是否正确。为应对这些局限，我们提出DeSocial——具备用户验证机制的分布式社交推荐框架。该框架允许用户选择推荐算法验证潜在连接，并通过多独立验证者间的多数共识完成验证。为评估含用户验证的分布式推荐系统，我们将此场景构建为链接预测与验证任务，并提出Acc@K——基于共识的评估指标，用于衡量用户认可的推荐是否正确。在4个真实社交网络上的实验表明，DeSocial相比单点与分布式基线方法提升了决策正确性与鲁棒性。这些发现凸显了用户验证分布式推荐系统作为社交推荐实用方案的潜力，对分布式与去中心化推荐具有更广泛适用性。代码：https://github.com/agiresearch/DeSocial。</div>
</details>
<details class="detail"><summary>Summary / 总结</summary>
<div class="mono">The research addresses limitations in distributed social recommender systems, which typically aggregate predictions automatically without involving users in validating suggested connections and rely on global ranking metrics that poorly reflect individual user decisions. The proposed DeSocial framework introduces user-validation by allowing users to select recommendation algorithms to verify potential connections through majority consensus among independent validators, and it formulates evaluation as a link prediction and verification task using a new consensus-based metric, Acc@K. Experiments on four real-world social networks demonstrate that DeSocial enhances decision correctness and robustness over single-point and distributed baselines, indicating its practical potential for distributed and decentralized recommendation scenarios.</div>
<div class="mono" style="margin-top:8px">该研究针对分布式社交推荐系统的局限性，即现有系统通常自动聚合预测而忽视用户对推荐连接的验证作用，且标准排序指标难以评估用户确认的决策。提出的方法DeSocial是一个用户验证框架，允许用户选择推荐算法来验证潜在连接，并通过独立验证者的多数共识做出决策，同时引入了基于共识的评估指标Acc@K。在四个真实社交网络上的实验结果表明，DeSocial在决策正确性和鲁棒性上优于单点和分布式基线，突显了其在社交及更广泛去中心化推荐场景中的实用潜力。</div>
</details>
</div>
<div class="card">
<div class="title">MetaboNet: The Largest Publicly Available Consolidated Dataset for Type 1 Diabetes Management</div>
<div class="meta-line">Authors: Miriam K. Wolff, Peter Calhoun, Eleonora Maria Aiello, Yao Qin, Sam F. Royston</div>
<div class="meta-line">First: 2026-01-16T18:38:33+00:00 · Latest: 2026-01-16T18:38:33+00:00</div>
<div class="meta-line">Comments: 22 pages, 5 figures, 7 supplementary figures, submitted to JDST</div>
<div class="links" style="margin-top:8px"><a href="https://arxiv.org/abs/2601.11505v1">Abs</a> · <a href="https://arxiv.org/pdf/2601.11505v1">PDF</a> · <a href="https://huggingface.co/huggingface">Code1</a> · <a href="https://huggingface.co/docs/hub/spaces">Code2</a></div>
<details class="detail"><summary>Abstract</summary>
<div class="mono">Progress in Type 1 Diabetes (T1D) algorithm development is limited by the fragmentation and lack of standardization across existing T1D management datasets. Current datasets differ substantially in structure and are time-consuming to access and process, which impedes data integration and reduces the comparability and generalizability of algorithmic developments. This work aims to establish a unified and accessible data resource for T1D algorithm development. Multiple publicly available T1D datasets were consolidated into a unified resource, termed the MetaboNet dataset. Inclusion required the availability of both continuous glucose monitoring (CGM) data and corresponding insulin pump dosing records. Additionally, auxiliary information such as reported carbohydrate intake and physical activity was retained when present. The MetaboNet dataset comprises 3135 subjects and 1228 patient-years of overlapping CGM and insulin data, making it substantially larger than existing standalone benchmark datasets. The resource is distributed as a fully public subset available for immediate download at https://metabo-net.org/ , and with a Data Use Agreement (DUA)-restricted subset accessible through their respective application processes. For the datasets in the latter subset, processing pipelines are provided to automatically convert the data into the standardized MetaboNet format. A consolidated public dataset for T1D research is presented, and the access pathways for both its unrestricted and DUA-governed components are described. The resulting dataset covers a broad range of glycemic profiles and demographics and thus can yield more generalizable algorithmic performance than individual datasets.</div></details>
<details class="detail"><summary>中文标题/摘要</summary>
<div class="mono"><b>标题：</b>MetaboNet：用于1型糖尿病管理的最大公开整合数据集</div>
<div class="mono" style="margin-top:8px">1型糖尿病（T1D）算法开发进展受限于现有T1D管理数据集的碎片化与标准化缺失。当前数据集结构差异显著，访问与处理耗时，阻碍数据整合并降低算法开发的可比性与泛化性。本研究旨在为T1D算法开发建立统一且可访问的数据资源。通过整合多个公开T1D数据集构建了名为MetaboNet的统一资源，其纳入标准要求同时具备连续血糖监测（CGM）数据与对应胰岛素泵给药记录，并保留碳水化合物摄入报告及体力活动等辅助信息。MetaboNet数据集涵盖3135名受试者及1228患者年的同步CGM与胰岛素数据，规模显著超越现有独立基准数据集。该资源分为完全公开子集（可通过https://metabo-net.org/直接下载）与需签署数据使用协议（DUA）的受限子集（需经申请流程获取）。针对后者，提供自动化数据处理流程以转换为标准化MetaboNet格式。本研究提出了面向T1D研究的整合公共数据集，阐明了其无限制与DUA管辖组分的访问路径。该数据集覆盖广泛的血糖谱与人口统计学特征，相比独立数据集能产生更具泛化性的算法性能。</div>
</details>
<details class="detail"><summary>Summary / 总结</summary>
<div class="mono">The research addresses the challenge of fragmented and non-standardized Type 1 Diabetes (T1D) datasets, which hinder algorithm development by impeding data integration and reducing comparability. To create a unified resource, the authors consolidated multiple public T1D datasets into MetaboNet, requiring the presence of both continuous glucose monitoring and insulin pump data, while preserving auxiliary information like carbohydrate intake. The resulting dataset is the largest of its kind, containing data from 3135 subjects over 1228 patient-years, and is made available through both a fully public subset and a restricted subset with standardized processing pipelines. Experimental consolidation demonstrates that MetaboNet covers a broad range of glycemic profiles and demographics, enabling more generalizable algorithmic performance than individual datasets alone.</div>
<div class="mono" style="margin-top:8px">本研究旨在解决1型糖尿病（T1D）数据集分散且缺乏标准化的问题，这些问题阻碍了数据整合，降低了算法开发的可比性和泛化能力。为创建统一资源，作者将多个公开的T1D数据集整合为“MetaboNet”，要求同时包含连续血糖监测和胰岛素泵数据，并保留了如碳水化合物摄入等辅助信息。最终数据集包含3135名受试者和1228患者年的重叠数据，规模远超现有基准，并通过完全公开子集和需数据使用协议限制的子集提供，后者附有数据处理流程。实验结果表明，该数据集涵盖了广泛的血糖谱和人口统计学特征，因此能比单个数据集产生更具泛化性的算法性能。</div>
</details>
</div>
<div class="card">
<div class="title">Beneficial Reasoning Behaviors in Agentic Search and Effective Post-training to Obtain Them</div>
<div class="meta-line">Authors: Jiahe Jin, Abhijay Paladugu, Chenyan Xiong</div>
<div class="meta-line">First: 2025-10-08T00:20:35+00:00 · Latest: 2026-01-16T18:30:29+00:00</div>
<div class="links" style="margin-top:8px"><a href="https://arxiv.org/abs/2510.06534v3">Abs</a> · <a href="https://arxiv.org/pdf/2510.06534v3">PDF</a> · <a href="https://github.com/cxcscmu/Behavior-Priming-for-Agentic-Search">Code1</a> · <a href="https://huggingface.co/huggingface">Code2</a> · <a href="https://huggingface.co/docs/hub/spaces">Code3</a></div>
<details class="detail"><summary>Abstract</summary>
<div class="mono">Agentic search requires large language models (LLMs) to perform multi-step search to solve complex information-seeking tasks, imposing unique challenges on their reasoning capabilities. However, what constitutes effective reasoning for agentic search and how it can be learned remains unclear. In this work, we first investigate the reasoning behaviors that enable success in agentic search. By comparing successful and failed trajectories via an LLM-based analysis pipeline, we identify four beneficial behaviors: Information Verification, Authority Evaluation, Adaptive Search, and Error Recovery. Building on this, we propose Behavior Priming, a training approach that equips agentic search models with these reasoning behaviors before reinforcement learning (RL). Specifically, it first performs supervised fine-tuning (SFT) on collected trajectories exhibiting the identified behaviors to cultivate these behaviors, and then applies standard RL to further improve task performance. Experiments on Qwen3-1.7B and Llama3.2-3B-Instruct show that Behavior Priming yields relative improvements over direct RL by 37.2\% on three web benchmarks and 6.2\% on seven multi-hop QA benchmarks, and outperforms the SFT-then-RL baseline using outcome-correct trajectories for fine-tuning. Crucially, we show that these reasoning behaviors matter more than outcome correctness in the priming stage prior to RL. Further analysis reveals that Behavior Priming enhances exploration (pass@8) and test-time scaling (search step number), providing a robust foundation for RL. Our code are avalible at https://github.com/cxcscmu/Behavior-Priming-for-Agentic-Search.</div></details>
<details class="detail"><summary>中文标题/摘要</summary>
<div class="mono"><b>标题：</b>智能体搜索中的有益推理行为及其有效后训练方法</div>
<div class="mono" style="margin-top:8px">智能体搜索要求大语言模型（LLMs）通过多步搜索解决复杂信息检索任务，对其推理能力提出独特挑战。然而，何种推理对智能体搜索有效及其学习机制尚不明确。本研究首先探究促成智能体搜索成功的推理行为：通过基于LLM的分析流程对比成功与失败轨迹，识别出四种有益行为——信息验证、权威性评估、自适应搜索和错误恢复。基于此，我们提出行为引导训练法，该方法在强化学习（RL）前为智能体搜索模型注入这些推理行为：先对展现目标行为的轨迹进行监督微调（SFT）以培养行为模式，再通过标准RL提升任务性能。在Qwen3-1.7B和Llama3.2-3B-Instruct上的实验表明，行为引导法在三个网页基准上相对直接RL提升37.2%，在七个多跳问答基准上提升6.2%，且优于使用结果正确轨迹进行微调的SFT+RL基线。关键发现表明：在RL前的引导阶段，这些推理行为比结果正确性更重要。进一步分析揭示，该方法能增强探索能力（pass@8）和测试时扩展性（搜索步数），为RL奠定坚实基础。代码已开源：https://github.com/cxcscmu/Behavior-Priming-for-Agentic-Search。</div>
</details>
<details class="detail"><summary>Summary / 总结</summary>
<div class="mono">This research addresses the unclear nature of effective reasoning for agentic search, where large language models perform multi-step information-seeking tasks. To identify beneficial reasoning behaviors, the authors first analyze successful and failed search trajectories using an LLM-based pipeline, pinpointing four key behaviors: Information Verification, Authority Evaluation, Adaptive Search, and Error Recovery. They then propose Behavior Priming, a two-stage training approach that first uses supervised fine-tuning on trajectories exhibiting these behaviors, followed by reinforcement learning. Experiments on Qwen3-1.7B and Llama3.2-3B-Instruct models demonstrate that this method yields substantial improvements over direct reinforcement learning, achieving relative gains of 37.2% on web benchmarks and 6.2% on multi-hop QA benchmarks, while also outperforming a baseline that fine-tunes on outcome-correct trajectories. The findings confirm that cultivating these specific reasoning behaviors prior to reinforcement learning is more critical than focusing solely on final answer correctness.</div>
<div class="mono" style="margin-top:8px">为解决大型语言模型在自主搜索中有效推理需求不明确的问题，本研究首先通过分析成功与失败的搜索轨迹，识别出四种有益的推理行为：信息验证、权威性评估、自适应搜索和错误恢复。在此基础上，提出了行为引导训练方法，该方法先利用展现这些行为的轨迹进行监督微调以培养这些行为，再通过强化学习提升任务性能。在Qwen3-1.7B和Llama3.2-3B-Instruct等模型上的实验表明，该方法在三个网页基准上相对直接强化学习提升了37.2%，在七个多跳问答基准上提升了6.2%，优于使用结果正确轨迹进行微调的基线，并增强了探索能力和测试时扩展性。</div>
</details>
</div>
<div class="card">
<div class="title">A Distributed Generative AI Approach for Heterogeneous Multi-Domain Environments under Data Sharing constraints</div>
<div class="meta-line">Authors: Youssef Tawfilis, Hossam Amer, Minar El-Aasser, Tallal Elshabrawy</div>
<div class="meta-line">First: 2025-07-17T10:31:31+00:00 · Latest: 2026-01-16T18:20:30+00:00</div>
<div class="meta-line">Comments: Accepted and published in Transactions on Machine Learning Research (TMLR), 2026</div>
<div class="links" style="margin-top:8px"><a href="https://arxiv.org/abs/2507.12979v3">Abs</a> · <a href="https://arxiv.org/pdf/2507.12979v3">PDF</a> · <a href="https://huggingface.co/huggingface">Code1</a> · <a href="https://huggingface.co/docs/hub/spaces">Code2</a> · <a href="https://distributed-gen-ai.github.io/huscf-gan.github.io/">Project1</a></div>
<details class="detail"><summary>Abstract</summary>
<div class="mono">Federated Learning has gained attention for its ability to enable multiple nodes to collaboratively train machine learning models without sharing raw data. At the same time, Generative AI -- particularly Generative Adversarial Networks (GANs) -- have achieved remarkable success across a wide range of domains, such as healthcare, security, and Image Generation. However, training generative models typically requires large datasets and significant computational resources, which are often unavailable in real-world settings. Acquiring such resources can be costly and inefficient, especially when many underutilized devices -- such as IoT devices and edge devices -- with varying capabilities remain idle. Moreover, obtaining large datasets is challenging due to privacy concerns and copyright restrictions, as most devices are unwilling to share their data. To address these challenges, we propose a novel approach for decentralized GAN training that enables utilizing distributed data and underutilized, low-capability devices while not sharing data in its raw form. Our approach is designed to tackle key challenges in decentralized environments, combining KLD-weighted Clustered Federated Learning to address the issues of data heterogeneity and multi-domain datasets, with Heterogeneous U-Shaped split learning to tackle the challenge of device heterogeneity under strict data sharing constraints -- ensuring that no labels or raw data, whether real or synthetic, are ever shared between nodes. Experiments show that our approach demonstrates significant improvements across key metrics, where it achieves an average 10% boost in classification metrics (up to 60% in multi-domain non-IID settings), 1.1x -- 3x higher image generation scores for the MNIST family datasets, and 2x -- 70x lower FID scores for higher resolution datasets. Find our code at https://distributed-gen-ai.github.io/huscf-gan.github.io/.</div></details>
<details class="detail"><summary>中文标题/摘要</summary>
<div class="mono"><b>标题：</b>数据共享约束下异构多域环境的分布式生成式人工智能方法</div>
<div class="mono" style="margin-top:8px">联邦学习因其能使多个节点在不共享原始数据的情况下协作训练机器学习模型而备受关注。与此同时，生成式人工智能——特别是生成对抗网络——在医疗、安全和图像生成等多个领域取得了显著成功。然而，训练生成模型通常需要大规模数据集和大量计算资源，这在现实场景中往往难以满足。获取此类资源成本高昂且效率低下，尤其是在大量能力各异的未充分利用设备（如物联网设备和边缘设备）处于闲置状态时。此外，由于隐私担忧和版权限制，获取大规模数据集具有挑战性，因为大多数设备不愿共享其数据。为应对这些挑战，我们提出了一种去中心化GAN训练的新方法，能够在分布式数据和未充分利用的低能力设备上进行训练，同时不以原始形式共享数据。该方法旨在解决去中心化环境中的关键挑战：结合KLD加权聚类联邦学习应对数据异构性和多域数据集问题，并采用异构U形分割学习在严格数据共享约束下解决设备异构性挑战——确保节点间不共享任何标签或原始数据（无论是真实数据还是合成数据）。实验表明，该方法在关键指标上均有显著提升：分类指标平均提升10%（在多域非独立同分布设置中最高达60%），MNIST系列数据集的图像生成分数提高1.1-3倍，高分辨率数据集的FID分数降低2-70倍。代码详见：https://distributed-gen-ai.github.io/huscf-gan.github.io/。</div>
</details>
<details class="detail"><summary>Summary / 总结</summary>
<div class="mono">This research addresses the challenges of training generative models like GANs in real-world settings where large, centralized datasets and high computational power are often unavailable due to privacy concerns, copyright restrictions, and the prevalence of heterogeneous, underutilized devices. The proposed method combines KLD-weighted Clustered Federated Learning to manage data heterogeneity across multiple domains with Heterogeneous U-Shaped split learning to accommodate devices of varying capabilities, all while enforcing strict constraints that prevent the sharing of any raw or synthetic data between nodes. Experimental results demonstrate that this decentralized approach yields significant performance gains, including an average 10% improvement in classification metrics (up to 60% in multi-domain non-IID settings), a 1.1x to 3x increase in image generation scores for MNIST-family datasets, and a 2x to 70x reduction in FID scores for higher-resolution datasets.</div>
<div class="mono" style="margin-top:8px">为应对数据隐私限制和计算资源有限条件下训练生成模型的挑战，本研究提出了一种去中心化的生成对抗网络训练框架。该方法结合了KLD加权聚类联邦学习以处理数据异构性，以及异构U形分割学习以适应不同的设备能力，同时执行严格的数据共享约束，确保节点间不交换任何原始或合成数据。实验结果表明，该方法带来了显著的性能提升，包括分类指标平均提高10%（在多领域非独立同分布设置中最高达60%），在MNIST系列数据集上的图像生成分数提高了1.1至3倍，对于高分辨率数据集的FID分数降低了2至70倍。</div>
</details>
</div>
<div class="card">
<div class="title">The Poisoned Apple Effect: Strategic Manipulation of Mediated Markets via Technology Expansion of AI Agents</div>
<div class="meta-line">Authors: Eilam Shapira, Roi Reichart, Moshe Tennenholtz</div>
<div class="meta-line">First: 2026-01-16T18:18:03+00:00 · Latest: 2026-01-16T18:18:03+00:00</div>
<div class="links" style="margin-top:8px"><a href="https://arxiv.org/abs/2601.11496v1">Abs</a> · <a href="https://arxiv.org/pdf/2601.11496v1">PDF</a> · <a href="https://huggingface.co/huggingface">Code1</a> · <a href="https://huggingface.co/docs/hub/spaces">Code2</a></div>
<details class="detail"><summary>Abstract</summary>
<div class="mono">The integration of AI agents into economic markets fundamentally alters the landscape of strategic interaction. We investigate the economic implications of expanding the set of available technologies in three canonical game-theoretic settings: bargaining (resource division), negotiation (asymmetric information trade), and persuasion (strategic information transmission). We find that simply increasing the choice of AI delegates can drastically shift equilibrium payoffs and regulatory outcomes, often creating incentives for regulators to proactively develop and release technologies. Conversely, we identify a strategic phenomenon termed the &quot;Poisoned Apple&quot; effect: an agent may release a new technology, which neither they nor their opponent ultimately uses, solely to manipulate the regulator&#x27;s choice of market design in their favor. This strategic release improves the releaser&#x27;s welfare at the expense of their opponent and the regulator&#x27;s fairness objectives. Our findings demonstrate that static regulatory frameworks are vulnerable to manipulation via technology expansion, necessitating dynamic market designs that adapt to the evolving landscape of AI capabilities.</div></details>
<details class="detail"><summary>中文标题/摘要</summary>
<div class="mono"><b>标题：</b>毒苹果效应：通过AI智能体技术扩张对中介市场进行策略性操纵</div>
<div class="mono" style="margin-top:8px">AI智能体融入经济市场从根本上改变了策略互动的格局。本研究在三种经典博弈论场景中探讨技术选择范围扩大的经济影响：议价（资源分配）、谈判（非对称信息交易）与劝服（策略性信息传递）。研究发现，仅增加AI代理人的选择就能显著改变均衡收益与监管结果，常促使监管机构主动开发并发布新技术。反之，我们识别出名为&#x27;毒苹果&#x27;效应的策略现象：行为主体可能发布一项新技术（其自身与对手最终皆不采用），纯粹为操纵监管机构选择对其有利的市场设计方案。这种策略性发布以牺牲对手利益与监管公平目标为代价，提升了发布者的福利。研究结果表明，静态监管框架易受技术扩张的操纵，亟需能适应AI能力动态演进的市场设计机制。</div>
</details>
<details class="detail"><summary>Summary / 总结</summary>
<div class="mono">This research investigates how expanding the set of technologies available to AI agents in mediated markets can strategically alter economic outcomes, challenging static regulatory frameworks. The method involves analyzing three canonical game-theoretic models—bargaining, negotiation, and persuasion—to study equilibrium shifts when agents have more AI delegate choices. Key findings reveal that technology expansion can drastically shift payoffs, incentivizing regulators to proactively release technologies, but also enables a &#x27;Poisoned Apple&#x27; effect where an agent releases an unused technology solely to manipulate the regulator&#x27;s market design in its favor, improving its own welfare at the expense of opponents and fairness objectives.</div>
<div class="mono" style="margin-top:8px">本研究探讨了扩展AI智能体技术集合如何策略性地操纵受中介的经济市场，从而挑战静态监管框架。研究方法基于三个经典的博弈论模型——讨价还价、谈判和说服，以分析当智能体拥有更多技术选择时的均衡变化。主要实验结果表明，仅仅增加可用技术就能显著改变收益分配，并激励监管者主动发布工具；更重要的是，研究揭示了一种“毒苹果”效应，即一方发布一种双方最终都不会使用的技术，其唯一目的是使监管者的市场设计偏向发布方，从而以牺牲对手利益和公平目标为代价提升发布方的福利。</div>
</details>
</div>
<div class="card">
<div class="title">BoxMind: Closed-loop AI strategy optimization for elite boxing validated in the 2024 Olympics</div>
<div class="meta-line">Authors: Kaiwen Wang, Kaili Zheng, Rongrong Deng, Qingmin Fan, Milin Zhang, Zongrui Li, Xuesi Zhou, Bo Han, Liren Chen, Chenyi Guo, Ji Wu</div>
<div class="meta-line">First: 2026-01-16T18:14:46+00:00 · Latest: 2026-01-16T18:14:46+00:00</div>
<div class="links" style="margin-top:8px"><a href="https://arxiv.org/abs/2601.11492v1">Abs</a> · <a href="https://arxiv.org/pdf/2601.11492v1">PDF</a> · <a href="https://huggingface.co/huggingface">Code1</a> · <a href="https://huggingface.co/docs/hub/spaces">Code2</a></div>
<details class="detail"><summary>Abstract</summary>
<div class="mono">Competitive sports require sophisticated tactical analysis, yet combat disciplines like boxing remain underdeveloped in AI-driven analytics due to the complexity of action dynamics and the lack of structured tactical representations. To address this, we present BoxMind, a closed-loop AI expert system validated in elite boxing competition. By defining atomic punch events with precise temporal boundaries and spatial and technical attributes, we parse match footage into 18 hierarchical technical-tactical indicators. We then propose a graph-based predictive model that fuses these explicit technical-tactical profiles with learnable, time-variant latent embeddings to capture the dynamics of boxer matchups. Modeling match outcome as a differentiable function of technical-tactical indicators, we turn winning probability gradients into executable tactical adjustments. Experiments show that the outcome prediction model achieves state-of-the-art performance, with 69.8% accuracy on BoxerGraph test set and 87.5% on Olympic matches. Using this predictive model as a foundation, the system generates strategic recommendations that demonstrate proficiency comparable to human experts. BoxMind is validated through a closed-loop deployment during the 2024 Paris Olympics, directly contributing to the Chinese National Team&#x27;s historic achievement of three gold and two silver medals. BoxMind establishes a replicable paradigm for transforming unstructured video data into strategic intelligence, bridging the gap between computer vision and decision support in competitive sports.</div></details>
<details class="detail"><summary>中文标题/摘要</summary>
<div class="mono"><b>标题：</b>BoxMind：经2024奥运会验证的精英拳击闭环人工智能策略优化系统</div>
<div class="mono" style="margin-top:8px">竞技体育需要精细的战术分析，但拳击等格斗类项目因动作动态复杂且缺乏结构化战术表征，在人工智能驱动分析领域发展滞后。为此，我们提出BoxMind——一个在精英拳击赛事中验证的闭环人工智能专家系统。通过定义具有精确时间边界及空间与技术属性的原子击打事件，我们将比赛录像解析为18项层级化技战术指标。进而提出基于图的预测模型，融合这些显式技战术特征与可学习的时变潜在嵌入，以捕捉拳手对战的动态特性。通过将比赛结果建模为技战术指标的可微函数，我们将获胜概率梯度转化为可执行的战术调整。实验表明，结果预测模型达到最先进性能：在BoxerGraph测试集准确率为69.8%，奥运赛事准确率达87.5%。以此预测模型为基础，系统生成的战略建议展现出与人类专家相当的专业水平。BoxMind在2024年巴黎奥运会期间通过闭环部署得到验证，直接助力中国国家队取得三金两银的历史性成就。该系统建立了将非结构化视频数据转化为战略情报的可复现范式，弥合了竞技体育中计算机视觉与决策支持之间的鸿沟。</div>
</details>
<details class="detail"><summary>Summary / 总结</summary>
<div class="mono">Motivated by the lack of AI-driven tactical analysis in complex combat sports like boxing, this research introduces BoxMind, a closed-loop AI expert system. The method parses match footage into hierarchical technical-tactical indicators from atomic punch events and employs a graph-based predictive model that fuses these explicit profiles with learnable latent embeddings to capture matchup dynamics. Key experimental results show the outcome prediction model achieves state-of-the-art performance (69.8% accuracy on a test set, 87.5% on Olympic matches), and the system&#x27;s strategic recommendations, validated in a closed-loop deployment during the 2024 Olympics, demonstrated proficiency comparable to human experts and contributed to a historic medal haul for the Chinese National Team.</div>
<div class="mono" style="margin-top:8px">该研究旨在解决拳击等格斗运动因动作动态复杂和数据非结构化而缺乏AI战术分析的问题。方法包括将比赛录像解析为基于原子击打动作的层次化技战术指标，并开发一个基于图的预测模型，该模型融合了这些显式指标与可学习的潜在嵌入以捕捉对战动态；随后利用该模型的梯度推导战术调整。实验结果表明，结果预测模型在测试集上达到69.8%的准确率，在奥运比赛中达到87.5%，其战略建议在2024年巴黎奥运会的闭环部署中得到验证，并助力中国国家队取得了历史性的奖牌成绩。</div>
</details>
</div>
<div class="card">
<div class="title">Generalizable Domain Adaptation for Sim-and-Real Policy Co-Training</div>
<div class="meta-line">Authors: Shuo Cheng, Liqian Ma, Zhenyang Chen, Ajay Mandlekar, Caelan Garrett, Danfei Xu</div>
<div class="meta-line">Venue: NeurIPS 2025</div>
<div class="meta-line">First: 2025-09-23T04:32:53+00:00 · Latest: 2026-01-16T18:05:09+00:00</div>
<div class="meta-line">Comments: Accepted to NeurIPS 2025</div>
<div class="links" style="margin-top:8px"><a href="https://arxiv.org/abs/2509.18631v3">Abs</a> · <a href="https://arxiv.org/pdf/2509.18631v3">PDF</a> · <a href="https://huggingface.co/huggingface">Code1</a> · <a href="https://huggingface.co/docs/hub/spaces">Code2</a> · <a href="https://ot-sim2real.github.io/">Project1</a></div>
<details class="detail"><summary>Abstract</summary>
<div class="mono">Behavior cloning has shown promise for robot manipulation, but real-world demonstrations are costly to acquire at scale. While simulated data offers a scalable alternative, particularly with advances in automated demonstration generation, transferring policies to the real world is hampered by various simulation and real domain gaps. In this work, we propose a unified sim-and-real co-training framework for learning generalizable manipulation policies that primarily leverages simulation and only requires a few real-world demonstrations. Central to our approach is learning a domain-invariant, task-relevant feature space. Our key insight is that aligning the joint distributions of observations and their corresponding actions across domains provides a richer signal than aligning observations (marginals) alone. We achieve this by embedding an Optimal Transport (OT)-inspired loss within the co-training framework, and extend this to an Unbalanced OT framework to handle the imbalance between abundant simulation data and limited real-world examples. We validate our method on challenging manipulation tasks, showing it can leverage abundant simulation data to achieve up to a 30% improvement in the real-world success rate and even generalize to scenarios seen only in simulation. Project webpage: https://ot-sim2real.github.io/.</div></details>
<details class="detail"><summary>中文标题/摘要</summary>
<div class="mono"><b>标题：</b>可泛化的领域自适应：仿真与真实策略协同训练</div>
<div class="mono" style="margin-top:8px">行为克隆在机器人操作任务中展现出潜力，但大规模获取真实世界演示数据成本高昂。仿真数据虽能提供可扩展的替代方案（尤其在自动演示生成技术进步的背景下），但策略向真实世界的迁移仍受多种仿真与真实领域差异的制约。本研究提出一种统一的仿真-真实协同训练框架，用于学习可泛化的操作策略，该框架主要利用仿真数据，仅需少量真实世界演示。方法的核心在于学习一个领域不变且与任务相关的特征空间。我们的关键见解是：跨领域对齐观测数据及其对应动作的联合分布，比仅对齐观测数据（边缘分布）能提供更丰富的信号。为此，我们在协同训练框架中嵌入了一种受最优传输理论启发的损失函数，并将其扩展至非平衡最优传输框架，以处理丰富仿真数据与有限真实样本之间的不平衡问题。我们在具有挑战性的操作任务上验证了该方法，结果表明其能利用大量仿真数据将真实世界成功率提升高达30%，甚至能泛化至仅在仿真中见过的场景。项目网页：https://ot-sim2real.github.io/。</div>
</details>
<details class="detail"><summary>Summary / 总结</summary>
<div class="mono">This research addresses the challenge of transferring robot manipulation policies from simulation to reality, where real-world demonstrations are costly to obtain while simulation data is abundant but suffers from domain gaps. The proposed method introduces a sim-and-real co-training framework that learns a domain-invariant feature space by aligning the joint distributions of observations and actions across domains, rather than observations alone, using an Optimal Transport (OT)-inspired loss extended to an Unbalanced OT formulation to handle data imbalance. Experimental validation on manipulation tasks demonstrates that the method leverages simulation data to improve real-world success rates by up to 30% and enables generalization to scenarios only seen in simulation.</div>
<div class="mono" style="margin-top:8px">为解决机器人演示数据在现实世界中采集成本高昂，以及策略从仿真迁移到现实时因领域差异而面临的困难，本研究提出了一个仿真与现实协同训练框架，主要利用丰富的仿真数据和少量真实演示来学习可泛化的操作策略。该方法的核心是通过对齐跨领域的观测与动作的联合分布来学习领域不变的特征空间，这比仅对齐观测提供了更丰富的信号；这是通过嵌入一个最优传输（OT）启发的损失函数实现的，并扩展为不平衡OT框架以处理数据不平衡问题。在具有挑战性的操作任务上的实验验证表明，该框架能够利用仿真数据将现实世界成功率提升高达30%，甚至能泛化到仅在仿真中见过的场景。</div>
</details>
</div>
<div class="card">
<div class="title">Health Facility Location in Ethiopia: Leveraging LLMs to Integrate Expert Knowledge into Algorithmic Planning</div>
<div class="meta-line">Authors: Yohai Trabelsi, Guojun Xiong, Fentabil Getnet, Stéphane Verguet, Milind Tambe</div>
<div class="meta-line">First: 2026-01-16T18:02:09+00:00 · Latest: 2026-01-16T18:02:09+00:00</div>
<div class="links" style="margin-top:8px"><a href="https://arxiv.org/abs/2601.11479v1">Abs</a> · <a href="https://arxiv.org/pdf/2601.11479v1">PDF</a> · <a href="https://huggingface.co/huggingface">Code1</a> · <a href="https://huggingface.co/docs/hub/spaces">Code2</a></div>
<details class="detail"><summary>Abstract</summary>
<div class="mono">Ethiopia&#x27;s Ministry of Health is upgrading health posts to improve access to essential services, particularly in rural areas. Limited resources, however, require careful prioritization of which facilities to upgrade to maximize population coverage while accounting for diverse expert and stakeholder preferences. In collaboration with the Ethiopian Public Health Institute and Ministry of Health, we propose a hybrid framework that systematically integrates expert knowledge with optimization techniques. Classical optimization methods provide theoretical guarantees but require explicit, quantitative objectives, whereas stakeholder criteria are often articulated in natural language and difficult to formalize. To bridge these domains, we develop the Large language model and Extended Greedy (LEG) framework. Our framework combines a provable approximation algorithm for population coverage optimization with LLM-driven iterative refinement that incorporates human-AI alignment to ensure solutions reflect expert qualitative guidance while preserving coverage guarantees. Experiments on real-world data from three Ethiopian regions demonstrate the framework&#x27;s effectiveness and its potential to inform equitable, data-driven health system planning.</div></details>
<details class="detail"><summary>中文标题/摘要</summary>
<div class="mono"><b>标题：</b>埃塞俄比亚医疗设施选址：利用大语言模型将专家知识融入算法规划</div>
<div class="mono" style="margin-top:8px">埃塞俄比亚卫生部正升级卫生站以提升基础医疗服务可及性，尤其在农村地区。资源有限需审慎确定设施升级优先级，在兼顾多元专家与利益相关方偏好的同时实现人口覆盖最大化。我们与埃塞俄比亚公共卫生研究院及卫生部合作，提出融合专家知识与优化技术的混合框架。经典优化方法虽具理论保证，但需明确量化目标，而利益相关方的标准常以自然语言表述且难以形式化。为此，我们开发了“大语言模型扩展贪心算法（LEG）”框架，将人口覆盖优化的可证明近似算法与LLM驱动的迭代优化相结合，通过人机对齐机制确保方案既遵循专家定性指导，又保持覆盖保障。基于埃塞俄比亚三个地区的实际数据实验验证了该框架的有效性，展现了其在促进公平、数据驱动的卫生系统规划方面的潜力。</div>
</details>
<details class="detail"><summary>Summary / 总结</summary>
<div class="mono">To support Ethiopia&#x27;s health system upgrade, this research addresses the challenge of prioritizing health facility improvements with limited resources, where expert preferences expressed in natural language are difficult to integrate into classical optimization models. The proposed Large language model and Extended Greedy (LEG) framework combines a provable approximation algorithm for maximizing population coverage with an LLM-driven iterative process that aligns solutions with qualitative expert guidance. Experiments on real-world data from three Ethiopian regions show the framework effectively produces equitable, data-driven plans that respect expert criteria while maintaining formal coverage guarantees.</div>
<div class="mono" style="margin-top:8px">为支持埃塞俄比亚的卫生系统升级，本研究旨在解决资源有限条件下卫生设施升级的优先排序问题，其中专家用自然语言表达的偏好难以融入经典优化模型。提出的LEG框架结合了用于最大化人口覆盖率的可证明近似算法，以及一个由大语言模型驱动的迭代优化过程，该过程将算法输出与专家的定性指导对齐。在埃塞俄比亚三个地区的真实数据上的实验表明，该框架能有效生成公平、数据驱动的规划方案，在尊重专家标准的同时保持了正式的覆盖保障。</div>
</details>
</div>
<div class="card">
<div class="title">What Makes a Good Speech Tokenizer for LLM-Centric Speech Generation? A Systematic Study</div>
<div class="meta-line">Authors: Xiaoran Fan, Zhichao Sun, Yangfan Gao, Jingfei Xiong, Hang Yan, Yifei Cao, Jiajun Sun, Shuo Li, Zhihao Zhang, Zhiheng Xi, Yuhao Zhou, Senjie Jin, Changhao Jiang, Junjie Ye, Ming Zhang, Rui Zheng, Zhenhua Han, Yunke Zhang, Demei Yan, Shaokang Dong, Tao Ji, Tao Gui</div>
<div class="meta-line">First: 2025-06-14T15:26:31+00:00 · Latest: 2026-01-16T17:59:34+00:00</div>
<div class="links" style="margin-top:8px"><a href="https://arxiv.org/abs/2506.12537v3">Abs</a> · <a href="https://arxiv.org/pdf/2506.12537v3">PDF</a> · <a href="https://huggingface.co/huggingface">Code1</a> · <a href="https://huggingface.co/docs/hub/spaces">Code2</a></div>
<details class="detail"><summary>Abstract</summary>
<div class="mono">Speech-language models (SLMs) offer a promising path toward unifying speech and text understanding and generation. However, challenges remain in achieving effective cross-modal alignment and high-quality speech generation. In this work, we systematically investigate the role of speech tokenizer designs in LLM-centric SLMs, augmented by speech heads and speaker modeling. We compare coupled, semi-decoupled, and fully decoupled speech tokenizers under a fair SLM framework and find that decoupled tokenization significantly improves alignment and synthesis quality. To address the information density mismatch between speech and text, we introduce multi-token prediction (MTP) into SLMs, enabling each hidden state to decode multiple speech tokens. This leads to up to 12$\times$ faster decoding and a substantial drop in word error rate (from 6.07 to 3.01). Furthermore, we propose a speaker-aware generation paradigm and introduce RoleTriviaQA, a large-scale role-playing knowledge QA benchmark with diverse speaker identities. Experiments demonstrate that our methods enhance both knowledge understanding and speaker consistency.</div></details>
<details class="detail"><summary>中文标题/摘要</summary>
<div class="mono"><b>标题：</b>面向LLM中心化语音生成的高质量语音分词器设计：一项系统性研究</div>
<div class="mono" style="margin-top:8px">语音语言模型为统一语音与文本的理解与生成提供了可行路径，但在实现有效的跨模态对齐与高质量语音生成方面仍面临挑战。本研究系统探讨了在配备语音头部和说话人建模的LLM中心化语音语言模型中，语音分词器设计的关键作用。通过在公平的语音语言模型框架下对比耦合式、半解耦式与全解耦式语音分词器，发现解耦分词能显著提升对齐效果与合成质量。为缓解语音与文本信息密度不匹配问题，我们提出在语音语言模型中引入多令牌预测机制，使每个隐藏状态可解码多个语音令牌，实现最高12倍的解码加速，并将词错误率从6.07显著降低至3.01。此外，我们提出说话人感知生成范式，并构建RoleTriviaQA——一个包含多样化说话人身份的大规模角色扮演知识问答基准。实验表明，所提方法能同步提升知识理解能力与说话人一致性。</div>
</details>
<details class="detail"><summary>Summary / 总结</summary>
<div class="mono">This study systematically investigates speech tokenizer designs for speech-language models (SLMs) to improve cross-modal alignment and speech generation quality. The authors compare coupled, semi-decoupled, and fully decoupled tokenizers within a unified SLM framework and find that decoupled tokenization yields better alignment and synthesis. To address the speech-text information density mismatch, they introduce multi-token prediction (MTP), which allows each hidden state to decode multiple speech tokens, resulting in up to 12× faster decoding and a significant reduction in word error rate from 6.07 to 3.01. Additionally, they propose a speaker-aware generation paradigm and evaluate it using the new RoleTriviaQA benchmark, demonstrating enhanced knowledge understanding and speaker consistency.</div>
<div class="mono" style="margin-top:8px">本研究系统探究了面向语音语言模型的语音分词器设计，旨在提升跨模态对齐和语音生成质量。研究在一个统一的语音语言模型框架下比较了耦合、半解耦和完全解耦的分词器，发现解耦分词能有效改善对齐与合成效果。针对语音与文本信息密度不匹配的问题，该方法引入了多令牌预测技术，使每个隐藏状态能解码多个语音令牌，从而将解码速度提升高达12倍，并将词错误率从6.07降至3.01。此外，研究提出了说话人感知生成范式并构建了RoleTriviaQA基准测试，实验结果表明该方法增强了知识理解和说话人一致性。</div>
</details>
</div>
<div class="card">
<div class="title">Exploring LLM Features in Predictive Process Monitoring for Small-Scale Event-Logs</div>
<div class="meta-line">Authors: Alessandro Padella, Massimiliano de Leoni, Marlon Dumas</div>
<div class="meta-line">First: 2026-01-16T17:54:55+00:00 · Latest: 2026-01-16T17:54:55+00:00</div>
<div class="meta-line">Comments: 19 pages, 4 figure, TMIS journal submission</div>
<div class="links" style="margin-top:8px"><a href="https://arxiv.org/abs/2601.11468v1">Abs</a> · <a href="https://arxiv.org/pdf/2601.11468v1">PDF</a> · <a href="https://huggingface.co/huggingface">Code1</a> · <a href="https://huggingface.co/docs/hub/spaces">Code2</a></div>
<details class="detail"><summary>Abstract</summary>
<div class="mono">Predictive Process Monitoring is a branch of process mining that aims to predict the outcome of an ongoing process. Recently, it leveraged machine-and-deep learning architectures. In this paper, we extend our prior LLM-based Predictive Process Monitoring framework, which was initially focused on total time prediction via prompting. The extension consists of comprehensively evaluating its generality, semantic leverage, and reasoning mechanisms, also across multiple Key Performance Indicators. Empirical evaluations conducted on three distinct event logs and across the Key Performance Indicators of Total Time and Activity Occurrence prediction indicate that, in data-scarce settings with only 100 traces, the LLM surpasses the benchmark methods. Furthermore, the experiments also show that the LLM exploits both its embodied prior knowledge and the internal correlations among training traces. Finally, we examine the reasoning strategies employed by the model, demonstrating that the LLM does not merely replicate existing predictive methods but performs higher-order reasoning to generate the predictions.</div></details>
<details class="detail"><summary>中文标题/摘要</summary>
<div class="mono"><b>标题：</b>探索小规模事件日志预测性流程监控中的大语言模型特性</div>
<div class="mono" style="margin-top:8px">预测性流程监控是流程挖掘的一个分支，旨在预测进行中流程的结果。近年来，该领域开始利用机器学习和深度学习架构。本文扩展了我们先前基于大语言模型的预测性流程监控框架——该框架最初通过提示工程专注于总时长预测。扩展内容包括全面评估其泛化能力、语义利用机制和推理机制，并覆盖多个关键绩效指标。在三个不同事件日志上，针对总时长和活动发生频次两个关键绩效指标进行的实证评估表明：在仅含100条轨迹的数据稀缺场景中，大语言模型性能超越基准方法。实验还揭示该模型同时利用了其内化的先验知识与训练轨迹间的内部关联。最后，我们剖析了模型采用的推理策略，证明大语言模型并非简单复现现有预测方法，而是通过高阶推理生成预测结果。</div>
</details>
<details class="detail"><summary>Summary / 总结</summary>
<div class="mono">This study extends a prior LLM-based framework for predictive process monitoring to assess its generality, semantic leverage, and reasoning across multiple Key Performance Indicators (KPIs), motivated by the need for effective prediction in data-scarce settings. The method involves evaluating the framework&#x27;s performance on total time and activity occurrence prediction using three distinct event logs. Experimental results show that with only 100 training traces, the LLM outperforms benchmark methods, leveraging both its prior knowledge and internal correlations among traces, and employs higher-order reasoning rather than merely replicating existing predictive approaches.</div>
<div class="mono" style="margin-top:8px">本研究扩展了先前基于大语言模型的预测性过程监控框架，旨在评估其在数据稀缺环境下对多个关键绩效指标的通用性、语义利用和推理机制。方法上，该框架在三个不同的事件日志上对总时间和活动发生等关键绩效指标进行了预测性能评估。实验结果表明，在仅使用100条训练轨迹的数据稀缺设置中，大语言模型超越了基准方法，它同时利用了其内嵌的先验知识和训练轨迹间的内部关联，并且采用了高阶推理策略，而非简单复制现有的预测方法。</div>
</details>
</div>
<div class="card">
<div class="title">MHA2MLA-VLM: Enabling DeepSeek&#x27;s Economical Multi-Head Latent Attention across Vision-Language Models</div>
<div class="meta-line">Authors: Xiaoran Fan, Zhichao Sun, Tao Ji, Lixing Shen, Tao Gui</div>
<div class="meta-line">First: 2026-01-16T17:45:34+00:00 · Latest: 2026-01-16T17:45:34+00:00</div>
<div class="links" style="margin-top:8px"><a href="https://arxiv.org/abs/2601.11464v1">Abs</a> · <a href="https://arxiv.org/pdf/2601.11464v1">PDF</a> · <a href="https://huggingface.co/huggingface">Code1</a> · <a href="https://huggingface.co/docs/hub/spaces">Code2</a></div>
<details class="detail"><summary>Abstract</summary>
<div class="mono">As vision-language models (VLMs) tackle increasingly complex and multimodal tasks, the rapid growth of Key-Value (KV) cache imposes significant memory and computational bottlenecks during inference. While Multi-Head Latent Attention (MLA) offers an effective means to compress the KV cache and accelerate inference, adapting existing VLMs to the MLA architecture without costly pretraining remains largely unexplored. In this work, we present MHA2MLA-VLM, a parameter-efficient and multimodal-aware framework for converting off-the-shelf VLMs to MLA. Our approach features two core techniques: (1) a modality-adaptive partial-RoPE strategy that supports both traditional and multimodal settings by selectively masking nonessential dimensions, and (2) a modality-decoupled low-rank approximation method that independently compresses the visual and textual KV spaces. Furthermore, we introduce parameter-efficient fine-tuning to minimize adaptation cost and demonstrate that minimizing output activation error, rather than parameter distance, substantially reduces performance loss. Extensive experiments on three representative VLMs show that MHA2MLA-VLM restores original model performance with minimal supervised data, significantly reduces KV cache footprint, and integrates seamlessly with KV quantization.</div></details>
<details class="detail"><summary>中文标题/摘要</summary>
<div class="mono"><b>标题：</b>MHA2MLA-VLM：实现DeepSeek经济型多头部潜在注意力在视觉语言模型中的跨模态应用</div>
<div class="mono" style="margin-top:8px">随着视觉语言模型处理日益复杂的多模态任务，键值缓存快速增长导致推理时出现显著的内存与计算瓶颈。多头部潜在注意力虽能有效压缩键值缓存并加速推理，但如何在不进行昂贵预训练的情况下将现有视觉语言模型适配至该架构仍待探索。本研究提出MHA2MLA-VLM——一种参数高效且多模态感知的框架，可将现成视觉语言模型转换为多头部潜在注意力架构。该框架包含两项核心技术：(1) 模态自适应部分旋转位置编码策略，通过选择性掩蔽非必要维度同时支持传统与多模态场景；(2) 模态解耦的低秩近似方法，独立压缩视觉与文本键值空间。此外，我们引入参数高效微调以最小化适配成本，并证明最小化输出激活误差（而非参数距离）能显著降低性能损失。在三个代表性视觉语言模型上的大量实验表明，MHA2MLA-VLM能以极少量监督数据恢复原始模型性能，显著降低键值缓存占用，并与键值量化技术无缝集成。</div>
</details>
<details class="detail"><summary>Summary / 总结</summary>
<div class="mono">The research addresses the memory and computational bottlenecks caused by the growing Key-Value (KV) cache in vision-language models (VLMs) during inference. To enable efficient adaptation of existing VLMs to a Multi-Head Latent Attention (MLA) architecture without full pretraining, the authors propose MHA2MLA-VLM, a parameter-efficient framework featuring a modality-adaptive partial-RoPE strategy and a modality-decoupled low-rank approximation method for compressing visual and textual KV spaces. Experimental results on three VLMs demonstrate that the method restores original model performance with minimal supervised data, significantly reduces KV cache size, and works effectively with KV quantization.</div>
<div class="mono" style="margin-top:8px">视觉语言模型（VLM）中键值（KV）缓存的快速增长在推理过程中造成了显著的内存和计算瓶颈。为解决此问题，本研究提出了MHA2MLA-VLM，这是一个参数高效的框架，无需昂贵的预训练即可将现有VLM转换为多头潜在注意力（MLA）架构，其核心采用了模态自适应的部分RoPE策略和模态解耦的低秩近似方法，以独立压缩视觉和文本的KV空间。在三个代表性VLM上的实验表明，该方法能以极少的监督数据恢复原始模型性能，显著减少KV缓存占用，并能与KV量化无缝集成。</div>
</details>
</div>
<div class="card">
<div class="title">Interactive Narrative Analytics: Bridging Computational Narrative Extraction and Human Sensemaking</div>
<div class="meta-line">Authors: Brian Keith</div>
<div class="meta-line">Venue: IEEE Access, vol. 14, pp. 2268-2284, 2026</div>
<div class="meta-line">First: 2026-01-16T17:34:37+00:00 · Latest: 2026-01-16T17:34:37+00:00</div>
<div class="meta-line">Comments: 17 pages, 5 figures, published in IEEE Access as open access paper</div>
<div class="links" style="margin-top:8px"><a href="https://arxiv.org/abs/2601.11459v1">Abs</a> · <a href="https://arxiv.org/pdf/2601.11459v1">PDF</a> · <a href="https://huggingface.co/huggingface">Code1</a> · <a href="https://huggingface.co/docs/hub/spaces">Code2</a></div>
<details class="detail"><summary>Abstract</summary>
<div class="mono">Information overload and misinformation create significant challenges in extracting meaningful narratives from large news collections. This paper defines the nascent field of Interactive Narrative Analytics (INA), which combines computational narrative extraction with interactive visual analytics to support sensemaking. INA approaches enable the interactive exploration of narrative structures through computational methods and visual interfaces that facilitate human interpretation. The field faces challenges in scalability, interactivity, knowledge integration, and evaluation standardization, yet offers promising opportunities across news analysis, intelligence, scientific literature exploration, and social media analysis. Through the combination of computational and human insight, INA addresses complex challenges in narrative sensemaking.</div></details>
<details class="detail"><summary>中文标题/摘要</summary>
<div class="mono"><b>标题：</b>交互式叙事分析：连接计算叙事提取与人类意义建构</div>
<div class="mono" style="margin-top:8px">信息过载与虚假信息为从大规模新闻集合中提取有意义叙事带来显著挑战。本文界定了新兴的交互式叙事分析领域，该领域结合计算叙事提取与交互式可视分析以支持意义建构。INA方法通过计算手段和促进人类解读的可视界面，实现对叙事结构的交互式探索。该领域在可扩展性、交互性、知识整合及评估标准化方面面临挑战，但在新闻分析、情报、科学文献探索和社交媒体分析等领域展现出广阔前景。通过计算与人类洞察的结合，INA致力于应对叙事意义建构中的复杂挑战。</div>
</details>
<details class="detail"><summary>Summary / 总结</summary>
<div class="mono">To address information overload and misinformation in large news collections, this paper defines the field of Interactive Narrative Analytics (INA), which integrates computational narrative extraction with interactive visual analytics to support human sensemaking. The proposed method combines computational techniques for extracting narrative structures with interactive visual interfaces that facilitate user exploration and interpretation. The research identifies key challenges in scalability, interactivity, knowledge integration, and evaluation, while highlighting promising applications in news analysis, intelligence, scientific literature, and social media, demonstrating how INA bridges computational power and human insight for complex narrative understanding.</div>
<div class="mono" style="margin-top:8px">为应对海量新闻数据中的信息过载和虚假信息挑战，本文定义了交互式叙事分析这一新兴领域，该领域将计算叙事提取与交互式可视分析相结合以支持人类意义建构。其方法是通过计算技术提取叙事结构，并提供交互式可视化界面供用户探索和解读。研究指出了该领域在可扩展性、交互性和评估标准化方面的挑战，同时展望了其在新闻分析、情报工作和社交媒体分析等领域的应用前景。</div>
</details>
</div>
<div class="card">
<div class="title">Probabilistic Mission Design for Neuro-Symbolic Unmanned Aircraft Systems</div>
<div class="meta-line">Authors: Simon Kohaut, Benedict Flade, Daniel Ochs, Devendra Singh Dhami, Julian Eggert, Kristian Kersting</div>
<div class="meta-line">First: 2024-12-25T11:04:00+00:00 · Latest: 2026-01-16T17:27:13+00:00</div>
<div class="meta-line">Comments: arXiv admin note: text overlap with arXiv:2406.03454</div>
<div class="links" style="margin-top:8px"><a href="https://arxiv.org/abs/2501.01439v2">Abs</a> · <a href="https://arxiv.org/pdf/2501.01439v2">PDF</a> · <a href="https://huggingface.co/huggingface">Code1</a> · <a href="https://huggingface.co/docs/hub/spaces">Code2</a></div>
<details class="detail"><summary>Abstract</summary>
<div class="mono">Advanced Air Mobility (AAM) is a growing field that demands accurate and trustworthy models of legal concepts and restrictions for navigating Unmanned Aircraft Systems (UAS). In addition, any implementation of AAM needs to face the challenges posed by inherently dynamic and uncertain human-inhabited spaces robustly. Nevertheless, the employment of UAS beyond visual line of sight (BVLOS) is an endearing task that promises to significantly enhance today&#x27;s logistics and emergency response capabilities. Hence, we propose Probabilistic Mission Design (ProMis), a novel neuro-symbolic approach to navigating UAS within legal frameworks. ProMis is an interpretable and adaptable system architecture that links uncertain geospatial data and noisy perception with declarative, Hybrid Probabilistic Logic Programs (HPLP) to reason over the agent&#x27;s state space and its legality. To inform planning with legal restrictions and uncertainty in mind, ProMis yields Probabilistic Mission Landscapes (PML). These scalar fields quantify the belief that the HPLP is satisfied across the agent&#x27;s state space. Extending prior work on ProMis&#x27; reasoning capabilities and computational characteristics, we show its integration with potent machine learning models such as Large Language Models (LLM) and Transformer-based vision models. Hence, our experiments underpin the application of ProMis with multi-modal input data and how our method applies to many AAM scenarios.</div></details>
<details class="detail"><summary>中文标题/摘要</summary>
<div class="mono"><b>标题：</b>神经符号无人机系统的概率任务设计</div>
<div class="mono" style="margin-top:8px">先进空中交通（AAM）是一个不断发展的领域，需要准确可靠的法律概念与限制模型来引导无人机系统（UAS）。此外，任何AAM的实施都必须稳健应对人类居住空间固有的动态性和不确定性带来的挑战。然而，超视距（BVLOS）无人机系统的应用是一项重要任务，有望显著提升当今物流和应急响应能力。为此，我们提出了概率任务设计（ProMis），一种在法规框架内导航UAS的新型神经符号方法。ProMis是一种可解释且适应性强的系统架构，它将不确定的地理空间数据和噪声感知与声明性的混合概率逻辑程序（HPLP）相结合，以推理智能体的状态空间及其合法性。为了在规划中考虑法律限制和不确定性，ProMis生成概率任务景观（PML）。这些标量场量化了HPLP在智能体状态空间内被满足的置信度。通过扩展先前关于ProMis推理能力和计算特性的研究，我们展示了其与大型语言模型（LLM）和基于Transformer的视觉模型等强大机器学习模型的集成。因此，我们的实验验证了ProMis在多模态输入数据中的应用，以及该方法如何适用于多种AAM场景。</div>
</details>
<details class="detail"><summary>Summary / 总结</summary>
<div class="mono">The research is motivated by the need for trustworthy and legally compliant navigation of Unmanned Aircraft Systems (UAS) in dynamic, uncertain Advanced Air Mobility (AAM) environments, particularly for beyond visual line of sight (BVLOS) operations. The method introduces Probabilistic Mission Design (ProMis), a neuro-symbolic architecture that integrates uncertain geospatial and perceptual data with declarative Hybrid Probabilistic Logic Programs (HPLP) to reason about legal constraints, generating Probabilistic Mission Landscapes (PML) to quantify the belief of constraint satisfaction across the state space. Key experimental findings demonstrate the integration of ProMis with large language models and transformer-based vision models, validating its application with multi-modal input data across various AAM scenarios.</div>
<div class="mono" style="margin-top:8px">本研究旨在解决先进空中交通（AAM）领域中，无人机系统（UAS）在动态、不确定环境中进行超视距（BVLOS）运行时所面临的可靠且合规导航的需求。所提出的方法名为概率任务设计（ProMis），这是一种神经符号架构，它将不确定的地理空间数据和感知数据与声明性的混合概率逻辑程序（HPLP）相结合，以推理智能体的状态及其合法性，并生成概率任务景观（PML）来指导规划。主要实验结果展示了ProMis与大型语言模型和基于Transformer的视觉模型的集成，证明了该方法在处理多模态输入数据和适用于多种AAM场景方面的能力。</div>
</details>
</div>
<div class="card">
<div class="title">PRISM-CAFO: Prior-conditioned Remote-sensing Infrastructure Segmentation and Mapping for CAFOs</div>
<div class="meta-line">Authors: Oishee Bintey Hoque, Nibir Chandra Mandal, Kyle Luong, Amanda Wilson, Samarth Swarup, Madhav Marathe, Abhijin Adiga</div>
<div class="meta-line">First: 2026-01-16T17:16:26+00:00 · Latest: 2026-01-16T17:16:26+00:00</div>
<div class="links" style="margin-top:8px"><a href="https://arxiv.org/abs/2601.11451v1">Abs</a> · <a href="https://arxiv.org/pdf/2601.11451v1">PDF</a> · <a href="https://huggingface.co/huggingface">Code1</a> · <a href="https://huggingface.co/docs/hub/spaces">Code2</a></div>
<details class="detail"><summary>Abstract</summary>
<div class="mono">Large-scale livestock operations pose significant risks to human health and the environment, while also being vulnerable to threats such as infectious diseases and extreme weather events. As the number of such operations continues to grow, accurate and scalable mapping has become increasingly important. In this work, we present an infrastructure-first, explainable pipeline for identifying and characterizing Concentrated Animal Feeding Operations (CAFOs) from aerial and satellite imagery. Our method (1) detects candidate infrastructure (e.g., barns, feedlots, manure lagoons, silos) with a domain-tuned YOLOv8 detector, then derives SAM2 masks from these boxes and filters component-specific criteria, (2) extracts structured descriptors (e.g., counts, areas, orientations, and spatial relations) and fuses them with deep visual features using a lightweight spatial cross-attention classifier, and (3) outputs both CAFO type predictions and mask-level attributions that link decisions to visible infrastructure. Through comprehensive evaluation, we show that our approach achieves state-of-the-art performance, with Swin-B+PRISM-CAFO surpassing the best performing baseline by up to 15\%. Beyond strong predictive performance across diverse U.S. regions, we run systematic gradient--activation analyses that quantify the impact of domain priors and show ho</div></details>
<details class="detail"><summary>中文标题/摘要</summary>
<div class="mono"><b>标题：</b>PRISM-CAFO：面向集中式动物饲养场的先验条件遥感基础设施分割与测绘框架</div>
<div class="mono" style="margin-top:8px">大规模畜牧养殖对人类健康和环境构成显著风险，同时易受传染病和极端天气等威胁影响。随着此类养殖场数量持续增长，精准且可扩展的测绘技术日益重要。本研究提出一种以基础设施为先导、可解释的流程，用于从航空与卫星影像中识别和表征集中式动物饲养场。该方法：（1）通过领域调优的YOLOv8检测器识别候选基础设施（如畜舍、饲喂场、粪污池、筒仓），基于检测框生成SAM2掩码并筛选组件特定标准；（2）提取结构化描述符（如数量、面积、朝向及空间关系），并通过轻量级空间交叉注意力分类器与深度视觉特征融合；（3）同步输出CAFO类型预测及关联决策与可见基础设施的掩码级归因分析。综合评估表明，该方法达到最先进性能，其中Swin-B+PRISM-CAFO较最佳基线模型提升达15%。除在美国多区域展现卓越预测性能外，系统化的梯度-激活分析量化了领域先验知识的影响，并揭示了</div>
</details>
<details class="detail"><summary>Summary / 总结</summary>
<div class="mono">The research is motivated by the need for accurate and scalable mapping of Concentrated Animal Feeding Operations (CAFOs) due to their significant environmental and health risks and vulnerability to threats. The method introduces an infrastructure-first, explainable pipeline that first detects candidate infrastructure components (e.g., barns, lagoons) using a domain-tuned YOLOv8 detector and refines them with SAM2 masks, then fuses structured geometric descriptors with deep visual features via a spatial cross-attention classifier for final CAFO type prediction and mask-level attribution. Key experimental results demonstrate state-of-the-art performance, with the Swin-B+PRISM-CAFO model outperforming the best baseline by up to 15% in comprehensive evaluations across diverse U.S. regions, while systematic analyses quantify the impact of domain priors on the model&#x27;s decisions.</div>
<div class="mono" style="margin-top:8px">本研究旨在应对大规模畜牧养殖场（CAFOs）带来的重大环境与健康风险及其易受外部威胁的挑战，因此需要精确且可扩展的测绘方法。该方法提出了一种以基础设施为先、可解释的流程：首先使用领域调优的YOLOv8检测器识别如畜棚和粪池等候选基础设施，并通过SAM2生成掩码进行过滤；随后提取结构化描述符（如数量、面积和空间关系），并通过轻量级空间交叉注意力分类器将其与深度视觉特征融合，以预测CAFO类型并提供掩码级归因。实验结果表明，该方法达到了最先进的性能，Swin-B+PRISM-CAFO模型相比最佳基线提升高达15%，在不同美国地区均表现出强大的预测准确性，并通过梯度-激活分析量化了领域先验的影响。</div>
</details>
</div>
<div class="card">
<div class="title">Map2Thought: Explicit 3D Spatial Reasoning via Metric Cognitive Maps</div>
<div class="meta-line">Authors: Xiangjun Gao, Zhensong Zhang, Dave Zhenyu Chen, Songcen Xu, Long Quan, Eduardo Pérez-Pellitero, Youngkyoon Jang</div>
<div class="meta-line">First: 2026-01-16T17:02:46+00:00 · Latest: 2026-01-16T17:02:46+00:00</div>
<div class="links" style="margin-top:8px"><a href="https://arxiv.org/abs/2601.11442v1">Abs</a> · <a href="https://arxiv.org/pdf/2601.11442v1">PDF</a> · <a href="https://huggingface.co/huggingface">Code1</a> · <a href="https://huggingface.co/docs/hub/spaces">Code2</a></div>
<details class="detail"><summary>Abstract</summary>
<div class="mono">We propose Map2Thought, a framework that enables explicit and interpretable spatial reasoning for 3D VLMs. The framework is grounded in two key components: Metric Cognitive Map (Metric-CogMap) and Cognitive Chain-of-Thought (Cog-CoT). Metric-CogMap provides a unified spatial representation by integrating a discrete grid for relational reasoning with a continuous, metric-scale representation for precise geometric understanding. Building upon the Metric-CogMap, Cog-CoT performs explicit geometric reasoning through deterministic operations, including vector operations, bounding-box distances, and occlusion-aware appearance order cues, producing interpretable inference traces grounded in 3D structure. Experimental results show that Map2Thought enables explainable 3D understanding, achieving 59.9% accuracy using only half the supervision, closely matching the 60.9% baseline trained with the full dataset. It consistently outperforms state-of-the-art methods by 5.3%, 4.8%, and 4.0% under 10%, 25%, and 50% training subsets, respectively, on the VSI-Bench.</div></details>
<details class="detail"><summary>中文标题/摘要</summary>
<div class="mono"><b>标题：</b>Map2Thought：基于度量认知地图的显式三维空间推理</div>
<div class="mono" style="margin-top:8px">我们提出Map2Thought框架，通过度量认知地图与认知思维链两大核心组件，实现三维视觉语言模型可解释的显式空间推理。度量认知地图融合离散网格关系推理与连续度量尺度表征，构建统一空间表示；认知思维链在此基础上通过向量运算、边界框距离、遮挡感知外观顺序等确定性操作进行显式几何推理，生成基于三维结构的可解释推断轨迹。实验表明，Map2Thought仅用半数监督数据即达到59.9%准确率（全数据基线为60.9%），在VSI-Bench的10%/25%/50%训练子集上分别以5.3%/4.8%/4.0%优势持续超越现有最优方法。</div>
</details>
<details class="detail"><summary>Summary / 总结</summary>
<div class="mono">To enable explicit and interpretable spatial reasoning for 3D Vision-Language Models (VLMs), this research introduces Map2Thought, a framework grounded in a Metric Cognitive Map (Metric-CogMap) and a Cognitive Chain-of-Thought (Cog-CoT). The method constructs Metric-CogMap as a unified spatial representation combining a discrete grid for relational reasoning with a continuous metric-scale representation for geometric precision; Cog-CoT then performs deterministic geometric reasoning using vector operations, bounding-box distances, and occlusion-aware cues to produce interpretable inference traces. Experiments demonstrate that Map2Thought achieves explainable 3D understanding, reaching 59.9% accuracy with only half the supervision, closely matching the 60.9% full-dataset baseline, and consistently outperforms state-of-the-art methods by 5.3%, 4.8%, and 4.0% on 10%, 25%, and 50% training subsets of VSI-Bench, respectively.</div>
<div class="mono" style="margin-top:8px">为使三维视觉语言模型具备显式且可解释的空间推理能力，本研究提出了Map2Thought框架，其核心包含度量认知地图与认知思维链两个组件。该方法首先构建度量认知地图，将用于关系推理的离散网格与用于精确几何理解的连续度量尺度表示相统一；随后，认知思维链通过向量运算、边界框距离和遮挡感知的外观顺序线索进行确定性几何推理，生成基于三维结构的可解释推理轨迹。在VSI-Bench上的实验表明，Map2Thought仅使用一半监督数据即可实现可解释的三维理解，达到59.9%的准确率，接近全数据训练基线（60.9%），并在10%、25%和50%训练子集上分别以5.3%、4.8%和4.0%的优势持续超越现有最优方法。</div>
</details>
</div>
<div class="card">
<div class="title">Hierarchical Orthogonal Residual Spread for Precise Massive Editing in Large Language Models</div>
<div class="meta-line">Authors: Xiaojie Gu, Guangxu Chen, Yuheng Yang, Jingxin Han, Andi Zhang</div>
<div class="meta-line">Venue: ICASSP 2026</div>
<div class="meta-line">First: 2026-01-16T17:02:19+00:00 · Latest: 2026-01-16T17:02:19+00:00</div>
<div class="meta-line">Comments: ICASSP 2026</div>
<div class="links" style="margin-top:8px"><a href="https://arxiv.org/abs/2601.11441v1">Abs</a> · <a href="https://arxiv.org/pdf/2601.11441v1">PDF</a> · <a href="https://github.com/XiaojieGu/HORSE">Code1</a> · <a href="https://huggingface.co/huggingface">Code2</a> · <a href="https://huggingface.co/docs/hub/spaces">Code3</a></div>
<details class="detail"><summary>Abstract</summary>
<div class="mono">Large language models (LLMs) exhibit exceptional performance across various domains, yet they face critical safety concerns. Model editing has emerged as an effective approach to mitigate these issues. Existing model editing methods often focus on optimizing an information matrix that blends new and old knowledge. While effective, these approaches can be computationally expensive and may cause conflicts. In contrast, we shift our attention to Hierarchical Orthogonal Residual SprEad of the information matrix, which reduces noisy gradients and enables more stable edits from a different perspective. We demonstrate the effectiveness of our method HORSE through a clear theoretical comparison with several popular methods and extensive experiments conducted on two datasets across multiple LLMs. The results show that HORSE maintains precise massive editing across diverse scenarios. The code is available at https://github.com/XiaojieGu/HORSE</div></details>
<details class="detail"><summary>中文标题/摘要</summary>
<div class="mono"><b>标题：</b>分层正交残差扩散：实现大语言模型精准大规模编辑</div>
<div class="mono" style="margin-top:8px">大语言模型（LLMs）在各领域展现出卓越性能，但仍面临严峻的安全隐患。模型编辑已成为缓解这些问题的有效途径。现有方法多聚焦于优化融合新旧知识的信息矩阵，虽有效但计算成本高昂且易引发冲突。本研究转而关注信息矩阵的分层正交残差扩散机制，通过降低噪声梯度，从新视角实现更稳定的编辑。我们通过清晰的理论对比与跨多个LLM的双数据集实验，验证了HORSE方法的有效性。结果表明，HORSE能在多样场景中保持精准的大规模编辑能力。代码已开源：https://github.com/XiaojieGu/HORSE</div>
</details>
<details class="detail"><summary>Summary / 总结</summary>
<div class="mono">To address safety concerns in large language models (LLMs) where existing model editing methods are computationally expensive and prone to knowledge conflicts, this research proposes HORSE, a method based on Hierarchical Orthogonal Residual Spread of the information matrix. This approach reduces noisy gradients and enables more stable edits from a different perspective than prior techniques that blend new and old knowledge. Extensive experiments on two datasets across multiple LLMs demonstrate that HORSE maintains precise performance in massive editing scenarios, as validated through theoretical comparisons with popular methods.</div>
<div class="mono" style="margin-top:8px">为解决大语言模型的安全性问题，并克服现有模型编辑方法计算成本高、易引发知识冲突的局限，本研究提出了HORSE（分层正交残差扩散）方法。该方法聚焦于信息矩阵的分层正交残差扩散，从不同角度减少噪声梯度，实现更稳定的编辑。在多个大语言模型和两个数据集上的实验结果表明，HORSE能够在多样场景下保持精确的大规模编辑能力，其有效性通过理论对比和广泛测试得到验证。</div>
</details>
</div>
<div class="card">
<div class="title">GenDA: Generative Data Assimilation on Complex Urban Areas via Classifier-Free Diffusion Guidance</div>
<div class="meta-line">Authors: Francisco Giral, Álvaro Manzano, Ignacio Gómez, Ricardo Vinuesa, Soledad Le Clainche</div>
<div class="meta-line">First: 2026-01-16T17:02:00+00:00 · Latest: 2026-01-16T17:02:00+00:00</div>
<div class="links" style="margin-top:8px"><a href="https://arxiv.org/abs/2601.11440v1">Abs</a> · <a href="https://arxiv.org/pdf/2601.11440v1">PDF</a> · <a href="https://huggingface.co/huggingface">Code1</a> · <a href="https://huggingface.co/docs/hub/spaces">Code2</a></div>
<details class="detail"><summary>Abstract</summary>
<div class="mono">Urban wind flow reconstruction is essential for assessing air quality, heat dispersion, and pedestrian comfort, yet remains challenging when only sparse sensor data are available. We propose GenDA, a generative data assimilation framework that reconstructs high-resolution wind fields on unstructured meshes from limited observations. The model employs a multiscale graph-based diffusion architecture trained on computational fluid dynamics (CFD) simulations and interprets classifier-free guidance as a learned posterior reconstruction mechanism: the unconditional branch learns a geometry-aware flow prior, while the sensor-conditioned branch injects observational constraints during sampling. This formulation enables obstacle-aware reconstruction and generalization across unseen geometries, wind directions, and mesh resolutions without retraining. We consider both sparse fixed sensors and trajectory-based observations using the same reconstruction procedure. When evaluated against supervised graph neural network (GNN) baselines and classical reduced-order data assimilation methods, GenDA reduces the relative root-mean-square error (RRMSE) by 25-57% and increases the structural similarity index (SSIM) by 23-33% across the tested meshes. Experiments are conducted on Reynolds-averaged Navier-Stokes (RANS) simulations of a real urban neighbourhood in Bristol, United Kingdom, at a characteristic Reynolds number of $\mathrm{Re}\approx2\times10^{7}$, featuring complex building geometry and irregular terrain. The proposed framework provides a scalable path toward generative, geometry-aware data assimilation for environmental monitoring in complex domains.</div></details>
<details class="detail"><summary>中文标题/摘要</summary>
<div class="mono"><b>标题：</b>GenDA：基于无分类器扩散引导的复杂城市区域生成式数据同化</div>
<div class="mono" style="margin-top:8px">城市风场重建对评估空气质量、热量扩散及行人舒适度至关重要，但在仅有稀疏传感器数据时仍具挑战。本文提出GenDA，一种生成式数据同化框架，能从有限观测数据中重建非结构化网格上的高分辨率风场。该模型采用基于多尺度图结构的扩散架构，通过计算流体动力学（CFD）模拟训练，并将无分类器引导解释为一种学习的后验重建机制：无条件分支学习几何感知的流场先验，而传感器条件分支在采样时注入观测约束。此框架支持障碍物感知重建，并能在未经重新训练的情况下泛化至未见过的几何结构、风向和网格分辨率。研究通过同一重建流程处理稀疏固定传感器与基于轨迹的观测数据。与监督式图神经网络（GNN）基线及经典降阶数据同化方法相比，GenDA在所有测试网格上将相对均方根误差（RRMSE）降低25-57%，并将结构相似性指数（SSIM）提升23-33%。实验基于英国布里斯托尔真实城市街区的雷诺平均纳维-斯托克斯（RANS）模拟，特征雷诺数为$\mathrm{Re}\approx2\times10^{7}$，包含复杂建筑几何与不规则地形。该框架为复杂环境监测领域的生成式、几何感知数据同化提供了可扩展的路径。</div>
</details>
<details class="detail"><summary>Summary / 总结</summary>
<div class="mono">Accurate urban wind flow reconstruction from sparse sensor data is crucial for environmental monitoring but remains difficult. The authors propose GenDA, a generative data assimilation framework that uses a multiscale graph-based diffusion model trained on CFD simulations; it employs classifier-free guidance to combine an unconditional, geometry-aware prior with observational constraints from sensor data. Evaluated on RANS simulations of a real urban area, GenDA outperforms supervised GNN and classical reduced-order methods, reducing relative RMSE by 25-57% and increasing SSIM by 23-33% across various meshes, while generalizing to unseen geometries, wind directions, and mesh resolutions without retraining.</div>
<div class="mono" style="margin-top:8px">从稀疏传感器数据中准确重建城市风流对环境评估至关重要，但一直存在挑战。研究者提出了GenDA，一种生成式数据同化框架，它采用基于计算流体动力学模拟训练的多尺度图扩散模型，利用无分类器引导将无条件、几何感知的先验与传感器观测约束相结合，从而能在非结构化网格上实现重建，且无需针对新几何或条件重新训练。在真实城市区域的雷诺平均纳维-斯托克斯模拟实验表明，与监督式图神经网络和经典数据同化基线相比，GenDA将相对均方根误差降低了25-57%，并将结构相似性指数提高了23-33%。</div>
</details>
</div>
<div class="card">
<div class="title">From Noise to Signal to Selbstzweck: Reframing Human Label Variation in the Era of Post-training in NLP</div>
<div class="meta-line">Authors: Shanshan Xu, Santosh T. Y. S. S, Barbara Plank</div>
<div class="meta-line">First: 2025-10-09T17:48:29+00:00 · Latest: 2026-01-16T17:00:35+00:00</div>
<div class="links" style="margin-top:8px"><a href="https://arxiv.org/abs/2510.12817v2">Abs</a> · <a href="https://arxiv.org/pdf/2510.12817v2">PDF</a> · <a href="https://huggingface.co/huggingface">Code1</a> · <a href="https://huggingface.co/docs/hub/spaces">Code2</a></div>
<details class="detail"><summary>Abstract</summary>
<div class="mono">Human Label Variation (HLV) refers to legitimate disagreement in annotation that reflects the diversity of human perspectives rather than mere error. Long treated in NLP as noise to be eliminated, HLV has only recently been reframed as a signal for improving model robustness. With the rise of large language models (LLMs) and post-training methods such as human feedback-based alignment, the role of HLV has become increasingly consequential. Yet current preference-learning datasets routinely collapse multiple annotations into a single label, flattening diverse perspectives into artificial consensus. Preserving HLV is necessary not only for pluralistic alignment but also for sociotechnical safety evaluation, where model behavior must be assessed in relation to human interaction and societal context. This position paper argues that preserving HLV as an embodiment of human pluralism must be treated as a Selbstzweck, an intrinsic value in itself. We analyze the limitations of existing preference datasets and propose actionable strategies for incorporating HLV into dataset construction to better preserve pluralistic human values.</div></details>
<details class="detail"><summary>中文标题/摘要</summary>
<div class="mono"><b>标题：</b>从噪声到信号再到自在目的：后训练时代NLP中人类标注差异的重构</div>
<div class="mono" style="margin-top:8px">人类标注差异（HLV）指标注过程中反映人类视角多样性的合理分歧，而非单纯错误。长期以来NLP领域将其视为需消除的噪声，直至近期才被重构为提升模型鲁棒性的信号。随着大语言模型（LLMs）及基于人类反馈对齐等后训练方法的兴起，HLV的影响日益显著。然而当前偏好学习数据集常将多重标注压缩为单一标签，使多元视角扁平化为人工共识。保留HLV不仅是实现多元对齐的必要条件，也是社会技术安全评估的关键——模型行为必须置于人类互动与社会语境中评估。本立场文件主张：将HLV作为人类多元性的具现予以保留，应被视为“自在目的”，即其内在价值本身。我们分析了现有偏好数据集的局限，并提出在数据集构建中融入HLV的可操作策略，以更好地保存多元人类价值。</div>
</details>
<details class="detail"><summary>Summary / 总结</summary>
<div class="mono">This position paper argues that Human Label Variation (HLV), traditionally treated as annotation noise to be removed, should be reframed as a valuable signal and an intrinsic goal (Selbstzweck) in NLP, especially in the era of large language models and post-training alignment. The authors critique current practices where preference datasets collapse multiple annotations into artificial consensus, and propose actionable strategies for constructing datasets that preserve HLV. Their analysis suggests that incorporating such variation is crucial for achieving pluralistic model alignment and for robust sociotechnical safety evaluations that reflect diverse human perspectives.</div>
<div class="mono" style="margin-top:8px">这篇立场论文主张，在大型语言模型和后训练对齐的时代，人类标注差异（HLV）不应再被传统视为需要消除的标注噪声，而应被重新定义为有价值的信号和内在目标（Selbstzweck）。作者分析了当前偏好学习数据集的局限性，这些数据集将多个标注压缩为人工共识，并提出了在数据集构建中纳入HLV的可操作策略，以保存多元化的人类视角。分析表明，保留HLV对于提升模型鲁棒性、实现多元化对齐以及开展考虑不同人类价值观和社会背景的社会技术安全评估至关重要。</div>
</details>
</div>
<div class="card">
<div class="title">Relational Linearity is a Predictor of Hallucinations</div>
<div class="meta-line">Authors: Yuetian Lu, Yihong Liu, Hinrich Schütze</div>
<div class="meta-line">First: 2026-01-16T16:47:49+00:00 · Latest: 2026-01-16T16:47:49+00:00</div>
<div class="meta-line">Comments: 11 pages, 4 figures, 8 tables</div>
<div class="links" style="margin-top:8px"><a href="https://arxiv.org/abs/2601.11429v1">Abs</a> · <a href="https://arxiv.org/pdf/2601.11429v1">PDF</a> · <a href="https://huggingface.co/huggingface">Code1</a> · <a href="https://huggingface.co/docs/hub/spaces">Code2</a></div>
<details class="detail"><summary>Abstract</summary>
<div class="mono">Hallucination is a central failure mode in large language models (LLMs). We focus on hallucinations of answers to questions like: &quot;Which instrument did Glenn Gould play?&quot;, but we ask these questions for synthetic entities that are unknown to the model. Surprisingly, we find that medium-size models like Gemma-7B-IT frequently hallucinate, i.e., they have difficulty recognizing that the hallucinated fact is not part of their knowledge. We hypothesize that an important factor in causing these hallucinations is the linearity of the relation: linear relations tend to be stored more abstractly, making it difficult for the LLM to assess its knowledge; the facts of nonlinear relations tend to be stored more directly, making knowledge assessment easier. To investigate this hypothesis, we create SyntHal, a dataset of 6000 synthetic entities for six relations. In our experiments with four models, we determine, for each relation, the hallucination rate on SyntHal and also measure its linearity, using $Δ\cos$. We find a strong correlation ($r \in [.78,.82]$) between relational linearity and hallucination rate, providing evidence for our hypothesis that the underlying storage of triples of a relation is a factor in how well a model can self-assess its knowledge. This finding has implications for how to manage hallucination behavior and suggests new research directions for improving the representation of factual knowledge in LLMs.</div></details>
<details class="detail"><summary>中文标题/摘要</summary>
<div class="mono"><b>标题：</b>关系线性度是幻觉现象的预测指标</div>
<div class="mono" style="margin-top:8px">幻觉是大语言模型（LLMs）的核心失效模式。我们聚焦于对诸如“格伦·古尔德演奏什么乐器？”这类问题的答案幻觉现象，但针对模型未知的合成实体提出这些问题。令人惊讶的是，我们发现中等规模模型（如Gemma-7B-IT）常出现幻觉，即难以识别幻觉事实不属于其知识范畴。我们假设导致此类幻觉的关键因素是关系线性度：线性关系往往以更抽象方式存储，使LLM难以评估其知识；非线性关系的事实则更直接存储，便于知识评估。为验证该假设，我们创建了SyntHal数据集，包含六个关系的6000个合成实体。通过对四个模型的实验，我们测定了每个关系在SyntHal上的幻觉率，并使用$Δ\cos$度量其线性度。研究发现关系线性度与幻觉率呈强相关性（$r \in [.78,.82]$），这为“关系三元组的底层存储方式是模型自我评估能力的影响因素”的假设提供了证据。该发现对管理幻觉行为具有启示意义，并为改进LLM事实知识表征提出了新研究方向。</div>
</details>
<details class="detail"><summary>Summary / 总结</summary>
<div class="mono">This study investigates hallucination in large language models (LLMs), focusing on their tendency to generate false answers about synthetic entities unknown to the model. The authors hypothesize that the linearity of a relation—measured via Δcos—influences hallucination rates, with linear relations being stored more abstractly and thus harder for the model to assess its knowledge. They test this using the SyntHal dataset of 6000 synthetic entities across six relations with four models, finding a strong correlation (r ∈ [.78,.82]) between relational linearity and hallucination rate, supporting the hypothesis that knowledge representation affects self-assessment.</div>
<div class="mono" style="margin-top:8px">本研究调查了大语言模型（LLMs）中的幻觉问题，重点关注模型对未知合成实体生成错误答案的倾向。作者假设关系的线性程度（通过Δcos测量）会影响幻觉率，线性关系以更抽象的方式存储，从而阻碍模型自我评估知识的能力。为验证此假设，他们创建了包含六个关系共6000个合成实体的SyntHal数据集，并评估了四个模型，发现关系线性与幻觉率之间存在强相关性（r ∈ [.78,.82]），这支持了关于事实三元组底层存储方式影响知识评估的假设。</div>
</details>
</div>
<div class="card">
<div class="title">The Great March 100: 100 Detail-oriented Tasks for Evaluating Embodied AI Agents</div>
<div class="meta-line">Authors: Ziyu Wang, Chenyuan Liu, Yushun Xiang, Runhao Zhang, Qingbo Hao, Hongliang Lu, Houyu Chen, Zhizhong Feng, Kaiyue Zheng, Dehao Ye, Xianchao Zeng, Xinyu Zhou, Boran Wen, Jiaxin Li, Mingyu Zhang, Kecheng Zheng, Qian Zhu, Ran Cheng, Yong-Lu Li</div>
<div class="meta-line">First: 2026-01-16T16:42:05+00:00 · Latest: 2026-01-16T16:42:05+00:00</div>
<div class="links" style="margin-top:8px"><a href="https://arxiv.org/abs/2601.11421v1">Abs</a> · <a href="https://arxiv.org/pdf/2601.11421v1">PDF</a> · <a href="https://huggingface.co/huggingface">Code1</a> · <a href="https://huggingface.co/docs/hub/spaces">Code2</a> · <a href="https://rhos.ai/research/gm-100">Project1</a></div>
<details class="detail"><summary>Abstract</summary>
<div class="mono">Recently, with the rapid development of robot learning and imitation learning, numerous datasets and methods have emerged. However, these datasets and their task designs often lack systematic consideration and principles. This raises important questions: Do the current datasets and task designs truly advance the capabilities of robotic agents? Do evaluations on a few common tasks accurately reflect the differentiated performance of various methods proposed by different teams and evaluated on different tasks? To address these issues, we introduce the Great March 100 (\textbf{GM-100}) as the first step towards a robot learning Olympics. GM-100 consists of 100 carefully designed tasks that cover a wide range of interactions and long-tail behaviors, aiming to provide a diverse and challenging set of tasks to comprehensively evaluate the capabilities of robotic agents and promote diversity and complexity in robot dataset task designs. These tasks are developed through systematic analysis and expansion of existing task designs, combined with insights from human-object interaction primitives and object affordances. We collect a large amount of trajectory data on different robotic platforms and evaluate several baseline models. Experimental results demonstrate that the GM-100 tasks are 1) feasible to execute and 2) sufficiently challenging to effectively differentiate the performance of current VLA models. Our data and code are available at https://rhos.ai/research/gm-100.</div></details>
<details class="detail"><summary>中文标题/摘要</summary>
<div class="mono"><b>标题：</b>伟大征程100：面向具身智能体评估的100项精细化任务</div>
<div class="mono" style="margin-top:8px">近年来，随着机器人学习与模仿学习的快速发展，涌现出大量数据集与方法。然而，这些数据集及其任务设计往往缺乏系统性考量与原则，这引发重要疑问：当前数据集与任务设计是否真正提升了机器人智能体的能力？在少数常见任务上的评估能否准确反映不同团队在不同任务中提出的各类方法的差异化性能？为解决这些问题，我们推出“伟大征程100”（GM-100）作为迈向机器人学习奥林匹克的第一步。GM-100包含100项精心设计的任务，涵盖广泛交互场景与长尾行为，旨在通过多样化、高挑战性的任务集全面评估机器人智能体能力，并促进机器人数据集任务设计的多样性与复杂性。这些任务通过对现有任务设计的系统性分析与拓展，结合人-物交互基元与物体功能属性的洞见开发而成。我们在不同机器人平台上采集了大量轨迹数据，并评估了多种基线模型。实验结果表明GM-100任务具有两大特性：1）具备可执行性；2）具有足够挑战性，能有效区分当前视觉语言动作模型的性能差异。我们的数据与代码已开源：https://rhos.ai/research/gm-100。</div>
</details>
<details class="detail"><summary>Summary / 总结</summary>
<div class="mono">Motivated by concerns that existing robot learning datasets lack systematic design principles and may not accurately differentiate method performance, this paper introduces the Great March 100 (GM-100), a benchmark of 100 detail-oriented tasks for embodied AI agents. The method involves systematically analyzing and expanding existing task designs, incorporating insights from human-object interaction primitives and object affordances to create a diverse set covering a wide range of interactions and long-tail behaviors. Experimental results on collected trajectory data show the tasks are both executable and sufficiently challenging to effectively distinguish the performance of current Vision-Language-Action (VLA) models.</div>
<div class="mono" style="margin-top:8px">本研究针对当前机器人学习数据集缺乏系统性设计原则、可能无法准确区分方法性能的问题，提出了包含100个细节导向任务的基准“Great March 100”（GM-100）。该方法通过对现有任务设计进行系统性分析和扩展，结合人-物交互基元与物体可供性洞见，构建了一个涵盖广泛交互和长尾行为的多样化任务集。在收集的轨迹数据上进行的实验结果表明，这些任务既可在机器人平台上执行，又具有足够的挑战性，能够有效区分当前视觉-语言-动作（VLA）模型的性能。</div>
</details>
</div>
<div class="card">
<div class="title">Tug-of-war between idioms&#x27; figurative and literal interpretations in LLMs</div>
<div class="meta-line">Authors: Soyoung Oh, Xinting Huang, Mathis Pink, Michael Hahn, Vera Demberg</div>
<div class="meta-line">First: 2025-06-02T14:29:46+00:00 · Latest: 2026-01-16T16:31:58+00:00</div>
<div class="links" style="margin-top:8px"><a href="https://arxiv.org/abs/2506.01723v5">Abs</a> · <a href="https://arxiv.org/pdf/2506.01723v5">PDF</a> · <a href="https://huggingface.co/huggingface">Code1</a> · <a href="https://huggingface.co/docs/hub/spaces">Code2</a></div>
<details class="detail"><summary>Abstract</summary>
<div class="mono">Idioms present a unique challenge for language models due to their non-compositional figurative interpretations, which often strongly diverge from the idiom&#x27;s literal interpretation. In this paper, we employ causal tracing to systematically analyze how pretrained causal transformers deal with this ambiguity. We localize three mechanisms: (i) Early sublayers and specific attention heads retrieve an idiom&#x27;s figurative interpretation, while suppressing its literal interpretation. (ii) When disambiguating context precedes the idiom, the model leverages it from the earliest layer and later layers refine the interpretation if the context conflicts with the retrieved interpretation. (iii) Then, selective, competing pathways carry both interpretations: an intermediate pathway prioritizes the figurative interpretation and a parallel direct route favors the literal interpretation, ensuring that both readings remain available. Our findings provide mechanistic evidence for idiom comprehension in autoregressive transformers.</div></details>
<details class="detail"><summary>中文标题/摘要</summary>
<div class="mono"><b>标题：</b>大语言模型中习语比喻义与字面义的拉锯战</div>
<div class="mono" style="margin-top:8px">习语因其非组合性的比喻义常与字面义显著偏离，对语言模型构成独特挑战。本文采用因果追踪方法，系统分析预训练因果Transformer如何处理这种歧义。研究发现三种机制：(i) 早期子层与特定注意力头负责提取习语比喻义并抑制字面义；(ii) 当消歧语境先于习语出现时，模型从最底层即开始利用语境信息，若语境与已提取的释义冲突，后续层会对释义进行修正；(iii) 选择性竞争通路同时承载两种释义：中间通路优先处理比喻义，并行直达通路倾向字面义，确保两种解读均保持可用。本研究为自回归Transformer的习语理解机制提供了实证依据。</div>
</details>
<details class="detail"><summary>Summary / 总结</summary>
<div class="mono">This study investigates how pretrained causal transformer language models handle the ambiguity of idioms, which have both non-compositional figurative meanings and literal interpretations. Using causal tracing, the authors systematically localize three key mechanisms: early sublayers and specific attention heads retrieve and suppress the figurative and literal meanings, respectively; preceding disambiguating context is leveraged from the first layer and refined in later layers if conflicting; and selective, competing pathways maintain both interpretations, with an intermediate pathway prioritizing the figurative meaning and a parallel direct route favoring the literal one. The experimental findings provide mechanistic evidence that these models maintain a tug-of-war between the two interpretations, keeping both available during processing.</div>
<div class="mono" style="margin-top:8px">本研究探讨了预训练的因果Transformer语言模型如何处理习语的非组合性比喻义与字面义之间的歧义。通过因果追踪方法，作者系统性地定位了三个关键机制：早期子层和特定注意力头负责检索比喻义并抑制字面义；若存在前置消歧语境，模型从第一层就开始利用它，并在后续层中细化与检索义冲突的解读；同时，选择性竞争通路并行承载两种解读，其中一条中间通路优先处理比喻义，而另一条直接通路则偏向字面义，确保两种解读均保持可用。实验结果为此类模型的习语理解机制提供了证据。</div>
</details>
</div>
<div class="card">
<div class="title">Topology-Guaranteed Image Segmentation: Enforcing Connectivity, Genus, and Width Constraints</div>
<div class="meta-line">Authors: Wenxiao Li, Xue-Cheng Tai, Jun Liu</div>
<div class="meta-line">First: 2026-01-16T16:29:48+00:00 · Latest: 2026-01-16T16:29:48+00:00</div>
<div class="links" style="margin-top:8px"><a href="https://arxiv.org/abs/2601.11409v1">Abs</a> · <a href="https://arxiv.org/pdf/2601.11409v1">PDF</a> · <a href="https://huggingface.co/huggingface">Code1</a> · <a href="https://huggingface.co/docs/hub/spaces">Code2</a></div>
<details class="detail"><summary>Abstract</summary>
<div class="mono">Existing research highlights the crucial role of topological priors in image segmentation, particularly in preserving essential structures such as connectivity and genus. Accurately capturing these topological features often requires incorporating width-related information, including the thickness and length inherent to the image structures. However, traditional mathematical definitions of topological structures lack this dimensional width information, limiting methods like persistent homology from fully addressing practical segmentation needs. To overcome this limitation, we propose a novel mathematical framework that explicitly integrates width information into the characterization of topological structures. This method leverages persistent homology, complemented by smoothing concepts from partial differential equations (PDEs), to modify local extrema of upper-level sets. This approach enables the resulting topological structures to inherently capture width properties. We incorporate this enhanced topological description into variational image segmentation models. Using some proper loss functions, we are also able to design neural networks that can segment images with the required topological and width properties. Through variational constraints on the relevant topological energies, our approach successfully preserves essential topological invariants such as connectivity and genus counts, simultaneously ensuring that segmented structures retain critical width attributes, including line thickness and length. Numerical experiments demonstrate the effectiveness of our method, showcasing its capability to maintain topological fidelity while explicitly embedding width characteristics into segmented image structures.</div></details>
<details class="detail"><summary>中文标题/摘要</summary>
<div class="mono"><b>标题：</b>拓扑保证的图像分割：强制连通性、亏格与宽度约束</div>
<div class="mono" style="margin-top:8px">现有研究强调了拓扑先验在图像分割中的关键作用，特别是在保持连通性和亏格等基本结构方面。准确捕捉这些拓扑特征通常需要结合宽度相关信息，包括图像结构固有的厚度与长度。然而，传统拓扑结构的数学定义缺乏此类维度宽度信息，使得持续同调等方法难以完全满足实际分割需求。为克服这一局限，我们提出一种新颖的数学框架，将宽度信息显式整合到拓扑结构表征中。该方法利用持续同调，辅以偏微分方程（PDE）的平滑概念，修改上层集的局部极值，使生成的拓扑结构能内在地捕获宽度属性。我们将这种增强的拓扑描述融入变分图像分割模型，并通过设计适当的损失函数构建能够分割具有所需拓扑与宽度特性图像的神经网络。通过对相关拓扑能量施加变分约束，我们的方法成功保持了连通性与亏格数等关键拓扑不变量，同时确保分割结构保留线宽与长度等核心宽度属性。数值实验验证了本方法的有效性，展示了其在保持拓扑保真度的同时，将宽度特征显式嵌入分割图像结构的能力。</div>
</details>
<details class="detail"><summary>Summary / 总结</summary>
<div class="mono">The research is motivated by the need to incorporate width information, such as thickness and length, into topological priors for image segmentation, as traditional topological definitions and methods like persistent homology lack this dimensional detail. The proposed method integrates width into topological characterization by combining persistent homology with PDE-based smoothing to adjust local extrema, enabling the capture of width properties, and embeds this into variational segmentation models and neural networks via tailored loss functions. Experimental results show that the approach effectively preserves topological invariants like connectivity and genus while ensuring segmented structures retain critical width attributes.</div>
<div class="mono" style="margin-top:8px">针对传统拓扑方法（如持续同调）缺乏宽度信息（如厚度和长度）而难以满足图像分割实际需求的问题，本文提出了一种将宽度信息整合到拓扑表征中的数学框架。该方法结合持续同调和偏微分方程平滑概念来修改上层集的局部极值，使拓扑结构能固有地捕获宽度属性，并通过损失函数将其融入变分分割模型和神经网络设计中。数值实验表明，该方法能有效保持连通性和亏格等拓扑不变量，同时确保分割结构保留线宽和长度等关键宽度特征。</div>
</details>
</div>
<div class="card">
<div class="title">Shapley Revisited: Tractable Responsibility Measures for Query Answers</div>
<div class="meta-line">Authors: Meghyn Bienvenu, Diego Figueira, Pierre Lafourcade</div>
<div class="meta-line">First: 2025-03-28T11:52:26+00:00 · Latest: 2026-01-16T16:29:20+00:00</div>
<div class="meta-line">Comments: Journal version of PODS&#x27;25 paper, with added material (cf. Section 1.2)</div>
<div class="links" style="margin-top:8px"><a href="https://arxiv.org/abs/2503.22358v3">Abs</a> · <a href="https://arxiv.org/pdf/2503.22358v3">PDF</a> · <a href="https://huggingface.co/huggingface">Code1</a> · <a href="https://huggingface.co/docs/hub/spaces">Code2</a></div>
<details class="detail"><summary>Abstract</summary>
<div class="mono">The Shapley value, originating from cooperative game theory, has been employed to define responsibility measures that quantify the contributions of database facts to obtaining a given query answer. For non-numeric queries, this is done by considering a cooperative game whose players are the facts and whose wealth function assigns 1 or 0 to each subset of the database, depending on whether the query answer holds in the given subset. While conceptually simple, this approach suffers from a notable drawback: the problem of computing such Shapley values is #P-hard in data complexity, even for simple conjunctive queries. This motivates us to revisit the question of what constitutes a reasonable responsibility measure and to introduce a new family of responsibility measures -- weighted sums of minimal supports (WSMS) -- which satisfy intuitive properties. Interestingly, while the definition of WSMSs is simple and bears no obvious resemblance to the Shapley value formula, we prove that every WSMS measure can be equivalently seen as the Shapley value of a suitably defined cooperative game. Moreover, WSMS measures enjoy tractable data complexity for a large class of queries, including all unions of conjunctive queries. We further explore the combined complexity of WSMS computation and establish (in)tractability results for various subclasses of conjunctive queries.</div></details>
<details class="detail"><summary>中文标题/摘要</summary>
<div class="mono"><b>标题：</b>重温沙普利值：面向查询答案的可计算责任度量</div>
<div class="mono" style="margin-top:8px">源自合作博弈论的沙普利值已被用于定义责任度量，以量化数据库事实对获得特定查询答案的贡献。对于非数值查询，该方法通过构建一个合作博弈实现：博弈参与者为数据库事实，财富函数根据查询答案在给定子集中是否成立，为每个数据库子集分配1或0。尽管概念简洁，该方法存在显著缺陷：即使对于简单合取查询，计算此类沙普利值的数据复杂度也是#P难问题。这促使我们重新审视合理责任度量的构成标准，并引入新的责任度量族——最小支持加权和（WSMS），其满足直观性质。有趣的是，虽然WSMS定义简洁且与沙普利值公式无明显相似性，我们证明每个WSMS度量均可等价视为特定合作博弈的沙普利值。此外，WSMS度量对包括所有合取查询并集在内的大类查询具有可计算的数据复杂度。我们进一步探究WSMS计算的组合复杂度，并为合取查询的多个子类建立（不）可计算性结果。</div>
</details>
<details class="detail"><summary>Summary / 总结</summary>
<div class="mono">The Shapley value, used to quantify the responsibility of database facts for query answers, suffers from #P-hard computational complexity even for simple queries, motivating the search for more tractable alternatives. This work introduces weighted sums of minimal supports (WSMS), a new family of responsibility measures that satisfy intuitive properties and, despite their simple definition, are proven to be equivalent to Shapley values of suitably defined cooperative games. Key experimental findings show that WSMS measures enjoy tractable data complexity for a large class of queries, including all unions of conjunctive queries, while combined complexity analysis reveals (in)tractability results for various subclasses of conjunctive queries.</div>
<div class="mono" style="margin-top:8px">用于量化数据库事实对查询答案贡献的Shapley值存在计算复杂度高的问题，即使在简单查询下也是#P-难的，这促使研究者寻找更易处理的责任度量方法。本文引入了一种称为最小支持加权和的新度量家族，该度量满足直观性质，且在数据复杂度上对于联合查询具有可处理性。作者证明每个WSMS度量都等价于适当定义的合作博弈的Shapley值，并建立了组合复杂度结果，展示了该方法在多种查询子类中的可处理性。</div>
</details>
</div>
<div class="card">
<div class="title">Causal-SAM-LLM: Large Language Models as Causal Reasoners for Robust Medical Segmentation</div>
<div class="meta-line">Authors: Tao Tang, Shijie Xu, Jionglong Su, Zhixiang Lu</div>
<div class="meta-line">Venue: ICASSP 2026</div>
<div class="meta-line">First: 2025-07-04T13:52:16+00:00 · Latest: 2026-01-16T16:16:45+00:00</div>
<div class="meta-line">Comments: Accepted by IEEE ICASSP 2026</div>
<div class="links" style="margin-top:8px"><a href="https://arxiv.org/abs/2507.03585v2">Abs</a> · <a href="https://arxiv.org/pdf/2507.03585v2">PDF</a> · <a href="https://huggingface.co/huggingface">Code1</a> · <a href="https://huggingface.co/docs/hub/spaces">Code2</a></div>
<details class="detail"><summary>Abstract</summary>
<div class="mono">The clinical utility of deep learning models for medical image segmentation is severely constrained by their inability to generalize to unseen domains. This failure is often rooted in the models learning spurious correlations between anatomical content and domain-specific imaging styles. To overcome this fundamental challenge, we introduce Causal-SAM-LLM, a novel framework that elevates Large Language Models (LLMs) to the role of causal reasoners. Our framework, built upon a frozen Segment Anything Model (SAM) encoder, incorporates two synergistic innovations. First, Linguistic Adversarial Disentanglement (LAD) employs a Vision-Language Model to generate rich, textual descriptions of confounding image styles. By training the segmentation model&#x27;s features to be contrastively dissimilar to these style descriptions, it learns a representation robustly purged of non-causal information. Second, Test-Time Causal Intervention (TCI) provides an interactive mechanism where an LLM interprets a clinician&#x27;s natural language command to modulate the segmentation decoder&#x27;s features in real-time, enabling targeted error correction. We conduct an extensive empirical evaluation on a composite benchmark from four public datasets (BTCV, CHAOS, AMOS, BraTS), assessing generalization under cross-scanner, cross-modality, and cross-anatomy settings. Causal-SAM-LLM establishes a new state of the art in out-of-distribution (OOD) robustness, improving the average Dice score by up to 6.2 points and reducing the Hausdorff Distance by 15.8 mm over the strongest baseline, all while using less than 9% of the full model&#x27;s trainable parameters. Our work charts a new course for building robust, efficient, and interactively controllable medical AI systems.</div></details>
<details class="detail"><summary>中文标题/摘要</summary>
<div class="mono"><b>标题：</b>Causal-SAM-LLM：将大语言模型作为因果推理器以实现鲁棒的医学图像分割</div>
<div class="mono" style="margin-top:8px">深度学习模型在医学图像分割中的临床应用，因其难以泛化至未见领域而受到严重制约。这一缺陷通常源于模型学习了解剖内容与领域特异性成像风格之间的伪相关性。为克服这一根本性挑战，我们提出了Causal-SAM-LLM——一个将大语言模型提升为因果推理角色的创新框架。该框架基于冻结的Segment Anything Model编码器构建，融合了两项协同创新技术：其一，语言对抗解耦利用视觉-语言模型生成丰富的混淆图像风格文本描述，通过训练分割模型特征使其与这些风格描述形成对比差异，从而学习到能稳健剔除非因果信息的表征；其二，测试时因果干预提供了一种交互机制，由大语言模型解析临床医生的自然语言指令，实时调控分割解码器的特征，实现针对性误差修正。我们在整合四个公开数据集（BTCV、CHAOS、AMOS、BraTS）的复合基准上进行了广泛实证评估，涵盖跨扫描仪、跨模态及跨解剖结构的泛化场景。Causal-SAM-LLM在分布外鲁棒性上确立了新的技术标杆，相较于最强基线模型，其平均Dice系数提升最高达6.2个百分点，豪斯多夫距离减少15.8毫米，且仅使用全模型不足9%的可训练参数。本研究为构建鲁棒、高效且可交互控制的医疗AI系统开辟了新路径。</div>
</details>
<details class="detail"><summary>Summary / 总结</summary>
<div class="mono">The clinical application of deep learning for medical image segmentation is limited by poor generalization to unseen domains, often due to models learning spurious correlations between anatomy and imaging style. To address this, the authors propose Causal-SAM-LLM, a framework that uses Large Language Models (LLMs) as causal reasoners, built upon a frozen Segment Anything Model (SAM) encoder. The method introduces Linguistic Adversarial Disentanglement (LAD) to generate textual style descriptions and train features to be dissimilar from them, purging non-causal information, and Test-Time Causal Intervention (TCI), where an LLM interprets clinician commands to modulate decoder features for real-time error correction. Evaluated on a composite benchmark from four public datasets (BTCV, CHAOS, AMOS, BraTS) under cross-scanner, cross-modality, and cross-anatomy settings, the framework achieves state-of-the-art out-of-distribution robustness, improving the average Dice score by up to 6.2 points and reducing the Hausdorff Distance by 15.8 mm over the strongest baseline while using less than 9% of trainable parameters.</div>
<div class="mono" style="margin-top:8px">深度学习在医学图像分割中的临床应用，常因模型学习到解剖结构与成像风格间的虚假相关性，导致其在未见域上泛化能力差而受限。为此，研究者提出了Causal-SAM-LLM框架，将大语言模型提升为因果推理器，并基于冻结的Segment Anything Model编码器构建。该方法引入了语言对抗解耦，利用文本描述来剔除非因果的风格信息，以及测试时因果干预，通过大语言模型解析临床医生的自然语言指令来实时修正分割错误。在整合四个公共数据集的复合基准上，针对跨扫描仪、跨模态和跨解剖结构的设置进行评估，该框架在分布外鲁棒性上达到了新的最优水平，将平均Dice分数提升了高达6.2分，并将豪斯多夫距离减少了15.8毫米，同时使用的可训练参数不到全模型的9%。</div>
</details>
</div>
<div class="card">
<div class="title">Wetland mapping from sparse annotations with satellite image time series and temporal-aware segment anything model</div>
<div class="meta-line">Authors: Shuai Yuan, Tianwu Lin, Shuang Chen, Yu Xia, Peng Qin, Xiangyu Liu, Xiaoqing Xu, Nan Xu, Hongsheng Zhang, Jie Wang, Peng Gong</div>
<div class="meta-line">First: 2026-01-16T16:10:32+00:00 · Latest: 2026-01-16T16:10:32+00:00</div>
<div class="links" style="margin-top:8px"><a href="https://arxiv.org/abs/2601.11400v1">Abs</a> · <a href="https://arxiv.org/pdf/2601.11400v1">PDF</a> · <a href="https://huggingface.co/huggingface">Code1</a> · <a href="https://huggingface.co/docs/hub/spaces">Code2</a></div>
<details class="detail"><summary>Abstract</summary>
<div class="mono">Accurate wetland mapping is essential for ecosystem monitoring, yet dense pixel-level annotation is prohibitively expensive and practical applications usually rely on sparse point labels, under which existing deep learning models perform poorly, while strong seasonal and inter-annual wetland dynamics further render single-date imagery inadequate and lead to significant mapping errors; although foundation models such as SAM show promising generalization from point prompts, they are inherently designed for static images and fail to model temporal information, resulting in fragmented masks in heterogeneous wetlands. To overcome these limitations, we propose WetSAM, a SAM-based framework that integrates satellite image time series for wetland mapping from sparse point supervision through a dual-branch design, where a temporally prompted branch extends SAM with hierarchical adapters and dynamic temporal aggregation to disentangle wetland characteristics from phenological variability, and a spatial branch employs a temporally constrained region-growing strategy to generate reliable dense pseudo-labels, while a bidirectional consistency regularization jointly optimizes both branches. Extensive experiments across eight global regions of approximately 5,000 km2 each demonstrate that WetSAM substantially outperforms state-of-the-art methods, achieving an average F1-score of 85.58%, and delivering accurate and structurally consistent wetland segmentation with minimal labeling effort, highlighting its strong generalization capability and potential for scalable, low-cost, high-resolution wetland mapping.</div></details>
<details class="detail"><summary>中文标题/摘要</summary>
<div class="mono"><b>标题：</b>基于卫星影像时间序列与时间感知Segment Anything模型的稀疏标注湿地制图</div>
<div class="mono" style="margin-top:8px">精准湿地制图对生态系统监测至关重要，但密集像素级标注成本高昂，实际应用通常依赖稀疏点标注，现有深度学习模型在此条件下表现不佳，而强烈的季节性与年际湿地动态变化使单时相影像不足并导致显著制图误差；尽管SAM等基础模型在点提示泛化方面表现良好，但其本质为静态图像设计，无法建模时序信息，导致异质湿地中掩膜破碎。为突破这些限制，我们提出WetSAM——一个基于SAM的双分支框架，通过卫星影像时间序列实现稀疏点监督下的湿地制图：时序提示分支通过层级适配器与动态时序聚合扩展SAM以解耦湿地特征与物候变异，空间分支采用时序约束区域生长策略生成可靠密集伪标签，双向一致性正则化协同优化双分支。在八个总面积约5,000 km²的全球区域实验表明，WetSAM显著优于现有最优方法，平均F1分数达85.58%，能以最小标注成本实现结构一致的精准湿地分割，凸显其强大泛化能力及规模化、低成本、高分辨率湿地制图潜力。</div>
</details>
<details class="detail"><summary>Summary / 总结</summary>
<div class="mono">Accurate wetland mapping is hindered by the high cost of dense annotations and the limitations of single-date imagery in capturing seasonal dynamics, while foundation models like SAM struggle with temporal information. To address this, the authors propose WetSAM, a dual-branch framework that integrates satellite image time series with sparse point supervision: one branch extends SAM with hierarchical adapters and dynamic temporal aggregation to model phenological variability, and another uses temporally constrained region-growing to generate pseudo-labels, jointly optimized via bidirectional consistency regularization. Experiments across eight global regions show WetSAM achieves an average F1-score of 85.58%, outperforming state-of-the-art methods and enabling accurate, consistent segmentation with minimal labeling effort.</div>
<div class="mono" style="margin-top:8px">精确的湿地制图对生态系统监测至关重要，但密集像素级标注成本高昂，且单时相影像无法捕捉湿地强烈的季节和年际动态，导致现有深度学习模型在稀疏点标注下性能不佳；尽管基础模型如SAM在静态图像上能通过点提示泛化，但其无法建模时序信息，在异质湿地中产生碎片化分割。为克服这些限制，本研究提出WetSAM，一个基于SAM的框架，通过双分支设计集成卫星影像时间序列进行稀疏点监督下的湿地制图：时序提示分支使用分层适配器和动态时序聚合来分离湿地特征与物候变化，空间分支采用时序约束的区域生长策略生成可靠密集伪标签，并通过双向一致性正则化联合优化两分支。在八个全球区域（各约5000平方公里）上的大量实验表明，WetSAM显著优于现有先进方法，平均F1分数达85.58%，能以最小标注努力实现准确且结构一致的湿地分割，凸显了其强大的泛化能力和可扩展、低成本、高分辨率湿地制图的潜力。</div>
</details>
</div>
<div class="card">
<div class="title">Hyperparameter Optimization of Constraint Programming Solvers</div>
<div class="meta-line">Authors: Hedieh Haddad, Thibault Falque, Pierre Talbot, Pascal Bouvry</div>
<div class="meta-line">First: 2026-01-16T16:02:36+00:00 · Latest: 2026-01-16T16:02:36+00:00</div>
<div class="meta-line">Comments: 28 pages, 3 figures. Submitted to Journal of Combinatorial Optimization. Special Issue: Recent applications, models and algorithms in Combinatorial Optimization</div>
<div class="links" style="margin-top:8px"><a href="https://arxiv.org/abs/2601.11389v1">Abs</a> · <a href="https://arxiv.org/pdf/2601.11389v1">PDF</a> · <a href="https://huggingface.co/huggingface">Code1</a> · <a href="https://huggingface.co/docs/hub/spaces">Code2</a></div>
<details class="detail"><summary>Abstract</summary>
<div class="mono">The performance of constraint programming solvers is highly sensitive to the choice of their hyperparameters. Manually finding the best solver configuration is a difficult, time-consuming task that typically requires expert knowledge. In this paper, we introduce probe and solve algorithm, a novel two-phase framework for automated hyperparameter optimization integrated into the CPMpy library. This approach partitions the available time budget into two phases: a probing phase that explores different sets of hyperparameters using configurable hyperparameter optimization methods, followed by a solving phase where the best configuration found is used to tackle the problem within the remaining time.
  We implement and compare two hyperparameter optimization methods within the probe and solve algorithm: Bayesian optimization and Hamming distance search. We evaluate the algorithm on two different constraint programming solvers, ACE and Choco, across 114 combinatorial problem instances, comparing their performance against the solver&#x27;s default configurations.
  Results show that using Bayesian optimization, the algorithm outperforms the solver&#x27;s default configurations, improving solution quality for ACE in 25.4% of instances and matching the default performance in 57.9%, and for Choco, achieving superior results in 38.6% of instances. It also consistently surpasses Hamming distance search within the same framework, confirming the advantage of model-based exploration over simple local search. Overall, the probe and solve algorithm offers a practical, resource-aware approach for tuning constraint solvers that yields robust improvements across diverse problem types.</div></details>
<details class="detail"><summary>中文标题/摘要</summary>
<div class="mono"><b>标题：</b>约束规划求解器的超参数优化</div>
<div class="mono" style="margin-top:8px">约束规划求解器的性能对其超参数的选择高度敏感。手动寻找最佳求解器配置是一项困难且耗时的任务，通常需要专业知识。本文提出了一种新颖的两阶段框架——探测求解算法，该算法集成于CPMpy库中，用于实现自动化超参数优化。该方法将可用时间预算划分为两个阶段：探测阶段使用可配置的超参数优化方法探索不同的超参数组合，随后在求解阶段利用找到的最佳配置在剩余时间内解决问题。我们在探测求解算法中实现并比较了两种超参数优化方法：贝叶斯优化和汉明距离搜索。通过在114个组合问题实例上对两种约束规划求解器（ACE和Choco）进行评估，并将其性能与求解器默认配置进行对比。结果显示，采用贝叶斯优化的算法性能优于求解器默认配置：在25.4%的实例中提升了ACE的求解质量，在57.9%的实例中与默认性能持平；对于Choco，在38.6%的实例中取得了更优结果。该算法在同一框架内也持续超越汉明距离搜索，证实了基于模型的探索相较于简单局部搜索的优势。总体而言，探测求解算法为约束求解器调参提供了一种实用且资源感知的方法，能在多样化问题类型上实现稳健的性能提升。</div>
</details>
<details class="detail"><summary>Summary / 总结</summary>
<div class="mono">Constraint programming solvers require careful hyperparameter tuning for optimal performance, but manual configuration is time-consuming and expert-dependent. To address this, the authors propose a two-phase &#x27;probe and solve&#x27; algorithm integrated into the CPMpy library, which allocates a time budget first to exploring hyperparameters via configurable optimization methods and then to solving the problem with the best configuration. They implement and compare Bayesian optimization and Hamming distance search within this framework, evaluating on two solvers (ACE and Choco) across 114 combinatorial instances. Experimental results demonstrate that Bayesian optimization outperforms default configurations, improving solution quality for ACE in 25.4% of instances and for Choco in 38.6%, while consistently surpassing Hamming distance search, highlighting the efficacy of model-based exploration.</div>
<div class="mono" style="margin-top:8px">约束规划求解器的性能高度依赖于超参数选择，但手动配置耗时且需要专业知识。为此，研究者提出了一种集成到CPMpy库中的两阶段“探测与求解”算法，该算法将时间预算分为两个阶段：首先使用可配置的超参数优化方法探索不同参数集，随后利用最佳配置在剩余时间内解决问题。他们在该框架内实现并比较了贝叶斯优化和汉明距离搜索两种方法，并在两个求解器（ACE和Choco）上对114个组合问题实例进行了评估。实验结果表明，贝叶斯优化优于默认配置，在25.4%的实例中提升了ACE的求解质量，在57.9%的实例中与默认性能持平，对于Choco则在38.6%的实例中取得更优结果，同时始终超越汉明距离搜索，证实了基于模型的探索相对于简单局部搜索的优势。</div>
</details>
</div>
<div class="card">
<div class="title">Policy alone is probably not the solution: A large-scale experiment on how developers struggle to design meaningful end-user explanations</div>
<div class="meta-line">Authors: Nadia Nahar, Zahra Abba Omar, Jacob Tjaden, Inès M. Gilles, Fikir Mekonnen, Erica Okeh, Jane Hsieh, Christian Kästner, Alka Menon</div>
<div class="meta-line">First: 2025-01-28T23:54:00+00:00 · Latest: 2026-01-16T16:00:12+00:00</div>
<div class="links" style="margin-top:8px"><a href="https://arxiv.org/abs/2503.15512v4">Abs</a> · <a href="https://arxiv.org/pdf/2503.15512v4">PDF</a> · <a href="https://huggingface.co/huggingface">Code1</a> · <a href="https://huggingface.co/docs/hub/spaces">Code2</a></div>
<details class="detail"><summary>Abstract</summary>
<div class="mono">Developers play a central role in determining how machine learning systems are explained in practice, yet they are rarely trained to design explanations for non-technical audiences. Despite this, transparency and explainability requirements are increasingly codified in regulation and organizational policy. It remains unclear how such policies influence developer behavior or the quality of the explanations they produce. We report results from two controlled experiments with 194 participants, typical developers without specialized training in human-centered explainable AI, who designed explanations for an ML-powered diabetic retinopathy screening tool. In the first experiment, differences in policy purpose and level of detail had little effect: policy guidance was often ignored and explanation quality remained low. In the second experiment, stronger enforcement increased formal compliance, but explanations largely remained poorly suited to medical professionals and patients. We further observed that across both experiments, developers repeatedly produced explanations that were technically flawed or difficult to interpret, framed for developers rather than end users, reliant on medical jargon, or insufficiently grounded in the clinical decision context and workflow, with developer-centric framing being the most prevalent. These findings suggest that policy and policy enforcement alone are insufficient to produce meaningful end-user explanations and that responsible AI frameworks may overestimate developers&#x27; ability to translate high-level requirements into human-centered designs without additional training, tools, or implementation support.</div></details>
<details class="detail"><summary>中文标题/摘要</summary>
<div class="mono"><b>标题：</b>仅靠政策可能并非解决之道：关于开发者如何难以设计有意义终端用户解释的大规模实验</div>
<div class="mono" style="margin-top:8px">开发者在决定机器学习系统实际解释方式中扮演核心角色，但他们很少接受为非技术受众设计解释的培训。尽管如此，透明度和可解释性要求正日益被纳入法规和组织政策。此类政策如何影响开发者行为或其产出解释的质量仍不明确。我们报告了两项对照实验的结果，涉及194名未接受过人本可解释AI专业培训的典型开发者，他们为基于ML的糖尿病视网膜病变筛查工具设计解释。首次实验中，政策目的和详细程度的差异影响甚微：政策指引常被忽视，解释质量持续偏低。二次实验中，强化执行提高了形式合规性，但解释大多仍难以适配医疗专业人员与患者。我们进一步观察到，在两次实验中，开发者反复产出存在技术缺陷或难以解读的解释，其框架面向开发者而非终端用户，依赖医学术语，或未能充分结合临床决策情境与工作流程，其中以开发者为中心的框架最为普遍。这些发现表明，仅靠政策及政策执行不足以产生有意义的终端用户解释，负责任AI框架可能高估了开发者在缺乏额外培训、工具或实施支持的情况下，将高层级需求转化为人本设计的能力。</div>
</details>
<details class="detail"><summary>Summary / 总结</summary>
<div class="mono">Motivated by the increasing regulatory and organizational requirements for explainable AI and the central role developers play in implementing explanations, this study investigates how policy guidance influences developers&#x27; ability to design meaningful explanations for end-users. The method involved two controlled experiments with 194 typical developers, who were tasked with designing explanations for a diabetic retinopathy screening tool under varying policy conditions, including differences in purpose, detail, and enforcement. Key experimental findings revealed that policy details had little effect on explanation quality, stronger enforcement only increased formal compliance without improving suitability for medical professionals or patients, and developers consistently produced explanations that were technically flawed, developer-centric, jargon-heavy, or contextually ungrounded, indicating that policy alone is insufficient for generating human-centered explanations.</div>
<div class="mono" style="margin-top:8px">本研究探讨了在开发者通常缺乏以人为中心的可解释人工智能专门培训的情况下，监管和组织政策是否能有效指导他们为机器学习系统的终端用户创建有意义的解释。通过对194名典型开发者设计糖尿病视网膜病变筛查工具解释的两项对照实验，研究人员考察了政策差异和执行力度对解释质量的影响。结果显示，政策目的和细节的差异影响甚微，政策常被忽视且解释质量低下；而更强的执行力度虽提高了形式合规性，但解释仍不适合医疗专业人员和患者，普遍存在以开发者为中心的框架、技术缺陷、医学术语以及缺乏临床背景等问题。这些发现表明，仅靠政策和执行是不够的，负责任的人工智能框架需要辅以培训、工具和支持，以弥合高层要求与以人为中心的设计之间的差距。</div>
</details>
</div>
<div class="card">
<div class="title">Theorem Prover as a Judge for Synthetic Data Generation</div>
<div class="meta-line">Authors: Joshua Ong Jun Leang, Giwon Hong, Wenda Li, Shay B. Cohen</div>
<div class="meta-line">Venue: ACL 2025</div>
<div class="meta-line">First: 2025-02-18T18:57:09+00:00 · Latest: 2026-01-16T15:59:43+00:00</div>
<div class="links" style="margin-top:8px"><a href="https://arxiv.org/abs/2502.13137v2">Abs</a> · <a href="https://arxiv.org/pdf/2502.13137v2">PDF</a> · <a href="https://huggingface.co/huggingface">Code1</a> · <a href="https://huggingface.co/docs/hub/spaces">Code2</a></div>
<details class="detail"><summary>Abstract</summary>
<div class="mono">The demand for synthetic data in mathematical reasoning has increased due to its potential to enhance the mathematical capabilities of large language models (LLMs). However, ensuring the validity of intermediate reasoning steps remains a significant challenge, affecting data quality. While formal verification via theorem provers effectively validates LLM reasoning, the autoformalisation of mathematical proofs remains error-prone. In response, we introduce iterative autoformalisation, an approach that iteratively refines theorem prover formalisation to mitigate errors, thereby increasing the execution rate on the Lean prover from 60% to 87%. Building upon that, we introduce Theorem Prover as a Judge (TP-as-a-Judge), a method that employs theorem prover formalisation to rigorously assess LLM intermediate reasoning, effectively integrating autoformalisation with synthetic data generation. Finally, we present Reinforcement Learning from Theorem Prover Feedback (RLTPF), a framework that replaces human annotation with theorem prover feedback in Reinforcement Learning from Human Feedback (RLHF). Across multiple LLMs, applying TP-as-a-Judge and RLTPF improves benchmarks with only 3,508 samples, achieving 5.56% accuracy gain on Mistral-7B for MultiArith, 6.00% on Llama-2-7B for SVAMP, and 3.55% on Llama-3.1-8B for AQUA.</div></details>
<details class="detail"><summary>中文标题/摘要</summary>
<div class="mono"><b>标题：</b>定理证明器作为合成数据生成的评判者</div>
<div class="mono" style="margin-top:8px">数学推理中对合成数据的需求日益增长，因其能增强大语言模型（LLM）的数学能力。然而，确保中间推理步骤的有效性仍是重大挑战，影响数据质量。虽然通过定理证明器进行形式化验证能有效检验LLM推理，但数学证明的自动形式化仍易出错。为此，我们提出迭代自动形式化方法，通过迭代优化定理证明器的形式化来减少错误，从而将Lean证明器上的执行率从60%提升至87%。在此基础上，我们引入“定理证明器作为评判者”（TP-as-a-Judge）方法，利用定理证明器形式化严格评估LLM中间推理，有效整合自动形式化与合成数据生成。最后，我们提出“基于定理证明器反馈的强化学习”（RLTPF）框架，在人类反馈强化学习（RLHF）中用定理证明器反馈替代人工标注。在多个LLM中，应用TP-as-a-Judge和RLTPF仅需3,508个样本即可提升基准测试表现：Mistral-7B在MultiArith上准确率提升5.56%，Llama-2-7B在SVAMP上提升6.00%，Llama-3.1-8B在AQUA上提升3.55%。</div>
</details>
<details class="detail"><summary>Summary / 总结</summary>
<div class="mono">The research addresses the challenge of ensuring the validity of intermediate reasoning steps in synthetic mathematical data, which is crucial for improving large language models&#x27; mathematical capabilities. The method introduces iterative autoformalisation to refine theorem prover formalisation, boosting execution rates on the Lean prover from 60% to 87%, and proposes Theorem Prover as a Judge (TP-as-a-Judge) to rigorously assess reasoning steps, integrating this with synthetic data generation. Experimental results show that applying TP-as-a-Judge and the Reinforcement Learning from Theorem Prover Feedback (RLTPF) framework with only 3,508 samples leads to accuracy gains of 5.56% on Mistral-7B for MultiArith, 6.00% on Llama-2-7B for SVAMP, and 3.55% on Llama-3.1-8B for AQUA.</div>
<div class="mono" style="margin-top:8px">为解决大语言模型数学推理合成数据中确保中间推理步骤有效性的难题，本研究提出了迭代自动形式化方法，通过精炼定理证明器的形式化过程，将Lean证明器的执行率从60%提升至87%。核心方法“定理证明器作为评判者”利用该形式化过程严格评估大语言模型的推理，并与新框架“基于定理证明器反馈的强化学习”相结合，用自动化的定理证明器反馈替代人工标注。实验结果表明，仅使用3,508个样本应用这些方法，即可在多个大语言模型上取得显著的准确率提升，包括Mistral-7B在MultiArith上提升5.56%，Llama-2-7B在SVAMP上提升6.00%，以及Llama-3.1-8B在AQUA上提升3.55%。</div>
</details>
</div></div>
    <details style="margin-top:16px" class="detail"><summary>History</summary>
      <div class="history-list"><a href="archive/20260120_0626.html">20260120_0626</a>
<a href="archive/20260120_0528.html">20260120_0528</a>
<a href="archive/20260120_0443.html">20260120_0443</a>
<a href="archive/20260120_0330.html">20260120_0330</a>
<a href="archive/20260119_0624.html">20260119_0624</a>
<a href="archive/20260119_0525.html">20260119_0525</a>
<a href="archive/20260119_0440.html">20260119_0440</a>
<a href="archive/20260119_0325.html">20260119_0325</a>
<a href="archive/20260118_2225.html">20260118_2225</a>
<a href="archive/20260118_2159.html">20260118_2159</a>
<a href="archive/20260118_2135.html">20260118_2135</a>
<a href="archive/20260118_2040.html">20260118_2040</a>
<a href="archive/20260118_1953.html">20260118_1953</a>
<a href="archive/20260118_1907.html">20260118_1907</a>
<a href="archive/20260118_0327.html">20260118_0327</a>
<a href="archive/20260117_0332.html">20260117_0332</a>
<a href="archive/20260116_0339.html">20260116_0339</a>
<a href="archive/20260115_0334.html">20260115_0334</a>
<a href="archive/20260114_0333.html">20260114_0333</a>
<a href="archive/20260113_0334.html">20260113_0334</a>
<a href="archive/20260112_0331.html">20260112_0331</a>
<a href="archive/20260111_0329.html">20260111_0329</a>
<a href="archive/20260110_0333.html">20260110_0333</a>
<a href="archive/20260109_0334.html">20260109_0334</a>
<a href="archive/20260108_0335.html">20260108_0335</a>
<a href="archive/20260107_0330.html">20260107_0330</a>
<a href="archive/20260106_0336.html">20260106_0336</a>
<a href="archive/20260105_0328.html">20260105_0328</a>
<a href="archive/20260104_0328.html">20260104_0328</a>
<a href="archive/20260103_0325.html">20260103_0325</a>
<a href="archive/20260102_0339.html">20260102_0339</a>
<a href="archive/20260101_0329.html">20260101_0329</a>
<a href="archive/20251231_0333.html">20251231_0333</a>
<a href="archive/20251230_0332.html">20251230_0332</a>
<a href="archive/20251229_0329.html">20251229_0329</a>
<a href="archive/20251228_0332.html">20251228_0332</a>
<a href="archive/20251227_0329.html">20251227_0329</a>
<a href="archive/20251226_0330.html">20251226_0330</a>
<a href="archive/20251225_0329.html">20251225_0329</a>
<a href="archive/20251224_0331.html">20251224_0331</a>
<a href="archive/20251223_0332.html">20251223_0332</a>
<a href="archive/20251222_0328.html">20251222_0328</a>
<a href="archive/20251221_0329.html">20251221_0329</a>
<a href="archive/20251220_0330.html">20251220_0330</a>
<a href="archive/20251219_0330.html">20251219_0330</a>
<a href="archive/20251218_0345.html">20251218_0345</a>
<a href="archive/20251217_0332.html">20251217_0332</a>
<a href="archive/20251216_0333.html">20251216_0333</a>
<a href="archive/20251215_0333.html">20251215_0333</a>
<a href="archive/20251214_0327.html">20251214_0327</a>
<a href="archive/20251212_0333.html">20251212_0333</a>
<a href="archive/20251211_0331.html">20251211_0331</a>
<a href="archive/20251210_0332.html">20251210_0332</a>
<a href="archive/20251209_0331.html">20251209_0331</a>
<a href="archive/20251208_0328.html">20251208_0328</a>
<a href="archive/20251207_0327.html">20251207_0327</a>
<a href="archive/20251206_0330.html">20251206_0330</a>
<a href="archive/20251205_0331.html">20251205_0331</a>
<a href="archive/20251204_0331.html">20251204_0331</a>
<a href="archive/20251203_0333.html">20251203_0333</a>
<a href="archive/20251202_0335.html">20251202_0335</a>
<a href="archive/20251201_0328.html">20251201_0328</a>
<a href="archive/20251130_0327.html">20251130_0327</a>
<a href="archive/20251129_0328.html">20251129_0328</a>
<a href="archive/20251128_0327.html">20251128_0327</a>
<a href="archive/20251127_0327.html">20251127_0327</a>
<a href="archive/20251126_0329.html">20251126_0329</a>
<a href="archive/20251125_0327.html">20251125_0327</a>
<a href="archive/20251124_0327.html">20251124_0327</a>
<a href="archive/20251123_0326.html">20251123_0326</a>
<a href="archive/20251122_0328.html">20251122_0328</a>
<a href="archive/20251121_0328.html">20251121_0328</a>
<a href="archive/20251120_0329.html">20251120_0329</a>
<a href="archive/20251119_0328.html">20251119_0328</a>
<a href="archive/20251118_0328.html">20251118_0328</a>
<a href="archive/20251117_0326.html">20251117_0326</a>
<a href="archive/20251116_0325.html">20251116_0325</a>
<a href="archive/20251115_0327.html">20251115_0327</a>
<a href="archive/20251114_0328.html">20251114_0328</a>
<a href="archive/20251113_0330.html">20251113_0330</a>
<a href="archive/20251112_0329.html">20251112_0329</a>
<a href="archive/20251111_0328.html">20251111_0328</a>
<a href="archive/20251110_0325.html">20251110_0325</a>
<a href="archive/20251109_0326.html">20251109_0326</a>
<a href="archive/20251108_0328.html">20251108_0328</a>
<a href="archive/20251107_0328.html">20251107_0328</a>
<a href="archive/20251106_0329.html">20251106_0329</a>
<a href="archive/20251105_0326.html">20251105_0326</a>
<a href="archive/20251104_0327.html">20251104_0327</a>
<a href="archive/20251103_0324.html">20251103_0324</a>
<a href="archive/20251102_0326.html">20251102_0326</a>
<a href="archive/20251101_0324.html">20251101_0324</a>
<a href="archive/20251031_0328.html">20251031_0328</a>
<a href="archive/20251030_0330.html">20251030_0330</a>
<a href="archive/20251029_0329.html">20251029_0329</a>
<a href="archive/20251028_0329.html">20251028_0329</a>
<a href="archive/20251027_0322.html">20251027_0322</a>
<a href="archive/20251026_0327.html">20251026_0327</a>
<a href="archive/20251025_0331.html">20251025_0331</a>
<a href="archive/20251024_0329.html">20251024_0329</a></div>
    </details>
    <div class="footer">Generated by arxiv-tracker</div>
  </div>
</body></html>
