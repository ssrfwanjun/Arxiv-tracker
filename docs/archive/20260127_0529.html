<!doctype html>
<html><head><meta charset="utf-8"><meta name="viewport" content="width=device-width,initial-scale=1">
<title>arXiv 论文速递</title><style>
:root {
  --bg:#f8fafc; --card:#ffffff; --text:#0f172a; --muted:#667085; --border:#e5e7eb; --acc:#2563eb;
}
:root[data-theme="dark"] {
  --bg:#0b0f17; --card:#111827; --text:#e5e7eb; --muted:#9ca3af; --border:#1f2937; --acc:#2563eb;
}
*{box-sizing:border-box} body{margin:0;background:var(--bg);color:var(--text);
  font-family:ui-sans-serif,system-ui,-apple-system,Segoe UI,Roboto,Helvetica,Arial;line-height:1.6;}
.container{max-width:900px;margin:0 auto;padding:18px;}
.header{display:flex;gap:10px;justify-content:space-between;align-items:center;margin:8px 0 16px;flex-wrap:wrap}
h1{font-size:22px;margin:0}
.badge{font-size:12px;color:#111827;background:var(--acc);padding:2px 8px;border-radius:999px}
.card{background:var(--card);border:1px solid var(--border);border-radius:16px;padding:16px 18px;margin:14px 0;box-shadow:0 1px 2px rgba(0,0,0,.04)}
.title{font-weight:700;margin:0 0 6px 0;font-size:18px}
.meta-line{color:var(--muted);font-size:13px;margin:2px 0}
.links a{color:var(--acc);text-decoration:none;margin-right:12px}
.detail{margin-top:10px;background:rgba(2,6,23,.03);border:1px solid var(--border);border-radius:10px;padding:8px 10px}
summary{cursor:pointer;color:var(--acc)}
.mono{white-space:pre-wrap;background:rgba(2,6,23,.03);border:1px solid var(--border);padding:10px;border-radius:10px}
.row{display:grid;grid-template-columns:1fr;gap:12px}
@media (min-width: 860px) {
  .row-2{grid-template-columns:1fr 1fr}
}
.footer{color:var(--muted);font-size:13px;margin:20px 0 10px}
.hr{height:1px;background:var(--border);margin:14px 0}
.history-list a{display:block;color:var(--acc);text-decoration:none;margin:4px 0}
.controls{display:flex;gap:8px;align-items:center}
.btn{border:1px solid var(--border);background:var(--card);padding:6px 10px;border-radius:10px;cursor:pointer;color:var(--text)}
.btn:hover{border-color:var(--acc)}
</style>
<script>
(function() {
  const root = document.documentElement;
  function apply(t) {
    if (t==='dark') root.setAttribute('data-theme','dark');
    else if (t==='light') root.removeAttribute('data-theme');
    else {
      if (window.matchMedia && window.matchMedia('(prefers-color-scheme: dark)').matches)
        root.setAttribute('data-theme','dark');
      else root.removeAttribute('data-theme');
    }
  }
  let t = localStorage.getItem('theme') || 'light';
  if (!['light','dark','auto'].includes(t)) t='light';
  apply(t);
  window.__toggleTheme = function() {
    let cur = localStorage.getItem('theme') || 'light';
    if (cur==='light') cur='dark';
    else if (cur==='dark') cur='auto';
    else cur='light';
    localStorage.setItem('theme', cur);
    apply(cur);
    const el=document.getElementById('theme-label');
    if(el) el.textContent = cur.toUpperCase();
  }
  window.__expandAll = function(open) {
    document.querySelectorAll('details').forEach(d => d.open = !!open);
  }
})();
</script>
</head>
<body>
  <div class="container">
    <div class="header">
      <h1>arXiv 论文速递</h1>
      <div style="display:flex;gap:10px;align-items:center">
        
<div class="controls">
  <button class="btn" onclick="__toggleTheme()">Theme: <span id="theme-label" style="margin-left:6px">AUTO</span></button>
  <button class="btn" onclick="__expandAll(true)">Expand All</button>
  <button class="btn" onclick="__expandAll(false)">Collapse All</button>
</div>

        <span class="badge">2026-01-27 05:29</span>
      </div>
    </div>
    <div class="hr"></div>
    <div>Snapshot: 20260127_0529</div>
    <div class="row"><div class="card">
<div class="title">AnyView: Synthesizing Any Novel View in Dynamic Scenes</div>
<div class="meta-line">Authors: Basile Van Hoorick, Dian Chen, Shun Iwase, Pavel Tokmakov, Muhammad Zubair Irshad, Igor Vasiljevic, Swati Gupta, Fangzhou Cheng, Sergey Zakharov, Vitor Campagnolo Guizilini</div>
<div class="meta-line">First: 2026-01-23T18:59:58+00:00 · Latest: 2026-01-23T18:59:58+00:00</div>
<div class="meta-line">Comments: Project webpage: https://tri-ml.github.io/AnyView/</div>
<div class="links" style="margin-top:8px"><a href="https://arxiv.org/abs/2601.16982v1">Abs</a> · <a href="https://arxiv.org/pdf/2601.16982v1">PDF</a> · <a href="https://huggingface.co/huggingface">Code1</a> · <a href="https://huggingface.co/docs/hub/spaces">Code2</a> · <a href="https://tri-ml.github.io/AnyView/">Project1</a></div>
<details class="detail"><summary>Abstract</summary>
<div class="mono">Modern generative video models excel at producing convincing, high-quality outputs, but struggle to maintain multi-view and spatiotemporal consistency in highly dynamic real-world environments. In this work, we introduce \textbf{AnyView}, a diffusion-based video generation framework for \emph{dynamic view synthesis} with minimal inductive biases or geometric assumptions. We leverage multiple data sources with various levels of supervision, including monocular (2D), multi-view static (3D) and multi-view dynamic (4D) datasets, to train a generalist spatiotemporal implicit representation capable of producing zero-shot novel videos from arbitrary camera locations and trajectories. We evaluate AnyView on standard benchmarks, showing competitive results with the current state of the art, and propose \textbf{AnyViewBench}, a challenging new benchmark tailored towards \emph{extreme} dynamic view synthesis in diverse real-world scenarios. In this more dramatic setting, we find that most baselines drastically degrade in performance, as they require significant overlap between viewpoints, while AnyView maintains the ability to produce realistic, plausible, and spatiotemporally consistent videos when prompted from \emph{any} viewpoint. Results, data, code, and models can be viewed at: https://tri-ml.github.io/AnyView/</div></details>
<details class="detail"><summary>中文标题/摘要</summary>
<div class="mono"><b>标题：</b>AnyView：动态场景中任意新视角的合成</div>
<div class="mono" style="margin-top:8px">现代生成式视频模型在生成逼真的高质量输出方面表现出色，但在高度动态的真实世界环境中难以保持多视角和时空一致性。本文提出\textbf{AnyView}，一种基于扩散的视频生成框架，用于\emph{动态视角合成}，仅需最少的归纳偏置或几何假设。我们利用多种监督级别的数据源（包括单目（2D）、多视角静态（3D）和多视角动态（4D）数据集），训练一个通用的时空隐式表示模型，能够从任意相机位置和轨迹生成零样本新视频。我们在标准基准上评估AnyView，结果显示其与当前最优方法具有竞争力，并提出了\textbf{AnyViewBench}——一个专为多样化真实场景中\emph{极端}动态视角合成而设计的新基准。在这一更具挑战性的设定下，我们发现大多数基线方法性能急剧下降，因为它们需要视角间有显著重叠，而AnyView在从\emph{任意}视角提示时，仍能保持生成真实、合理且时空一致的视频的能力。结果、数据、代码和模型可见：https://tri-ml.github.io/AnyView/</div>
</details>
<details class="detail"><summary>Summary / 总结</summary>
<div class="mono">The research is motivated by the limitations of current generative video models in maintaining multi-view and spatiotemporal consistency for dynamic scenes. The method introduces AnyView, a diffusion-based framework that trains a generalist spatiotemporal implicit representation using multiple data sources with varying supervision levels, including monocular, multi-view static, and multi-view dynamic datasets, to enable zero-shot novel video synthesis from arbitrary camera trajectories. Experimental results show competitive performance on standard benchmarks and superior capability on the proposed AnyViewBench for extreme dynamic view synthesis, where AnyView maintains realistic and consistent outputs while baselines degrade significantly due to their reliance on viewpoint overlap.</div>
<div class="mono" style="margin-top:8px">该研究的动机源于现代生成式视频模型在高度动态的真实世界场景中难以保持多视角和时空一致性的挑战。方法提出了AnyView，这是一个基于扩散的视频生成框架，以最小的归纳偏置或几何假设来合成动态场景中的新视角，通过利用包括单目、多视角静态和多视角动态数据集在内的多种数据源进行训练，学习一个通用的时空隐式表示。实验结果表明，AnyView在标准基准测试中取得了有竞争力的性能，并在提出的AnyViewBench（一个针对极端动态视角合成的挑战性基准）上表现优异，能够从任意视角生成真实且一致的视频，而基线方法由于依赖视角重叠而性能大幅下降。</div>
</details>
</div>
<div class="card">
<div class="title">A Scalable Measure of Loss Landscape Curvature for Analyzing the Training Dynamics of LLMs</div>
<div class="meta-line">Authors: Dayal Singh Kalra, Jean-Christophe Gagnon-Audet, Andrey Gromov, Ishita Mediratta, Kelvin Niu, Alexander H Miller, Michael Shvartsman</div>
<div class="meta-line">First: 2026-01-23T18:59:40+00:00 · Latest: 2026-01-23T18:59:40+00:00</div>
<div class="meta-line">Comments: 9 pages, 6 figures</div>
<div class="links" style="margin-top:8px"><a href="https://arxiv.org/abs/2601.16979v1">Abs</a> · <a href="https://arxiv.org/pdf/2601.16979v1">PDF</a> · <a href="https://huggingface.co/huggingface">Code1</a> · <a href="https://huggingface.co/docs/hub/spaces">Code2</a></div>
<details class="detail"><summary>Abstract</summary>
<div class="mono">Understanding the curvature evolution of the loss landscape is fundamental to analyzing the training dynamics of neural networks. The most commonly studied measure, Hessian sharpness ($λ_{\max}^H$) -- the largest eigenvalue of the loss Hessian -- determines local training stability and interacts with the learning rate throughout training. Despite its significance in analyzing training dynamics, direct measurement of Hessian sharpness remains prohibitive for Large Language Models (LLMs) due to high computational cost. We analyze $\textit{critical sharpness}$ ($λ_c$), a computationally efficient measure requiring fewer than $10$ forward passes given the update direction $Δ\mathbfθ$. Critically, this measure captures well-documented Hessian sharpness phenomena, including progressive sharpening and Edge of Stability. Using this measure, we provide the first demonstration of these sharpness phenomena at scale, up to $7$B parameters, spanning both pre-training and mid-training of OLMo-2 models. We further introduce $\textit{relative critical sharpness}$ ($λ_c^{1\to 2}$), which quantifies the curvature of one loss landscape while optimizing another, to analyze the transition from pre-training to fine-tuning and guide data mixing strategies. Critical sharpness provides practitioners with a practical tool for diagnosing curvature dynamics and informing data composition choices at scale. More broadly, our work shows that scalable curvature measures can provide actionable insights for large-scale training.</div></details>
<details class="detail"><summary>中文标题/摘要</summary>
<div class="mono"><b>标题：</b>一种可扩展的损失景观曲率度量方法：用于分析大语言模型的训练动态</div>
<div class="mono" style="margin-top:8px">理解损失景观曲率的演化是分析神经网络训练动态的基础。最常研究的度量指标——Hessian锐度（$λ_{\max}^H$，即损失函数Hessian矩阵的最大特征值）决定了局部训练的稳定性，并在整个训练过程中与学习率相互作用。尽管该指标对分析训练动态至关重要，但由于计算成本高昂，直接测量大语言模型的Hessian锐度仍不可行。本文分析了计算高效的临界锐度（$λ_c$），该度量在给定更新方向$Δ\mathbfθ$时仅需少于10次前向传播。关键的是，该度量能捕捉到文献充分记录的Hessian锐度现象，包括渐进锐化与稳定性边界。利用此度量，我们首次在大规模（最高70亿参数）上展示了这些锐度现象，涵盖OLMo-2模型的预训练与中期训练全过程。我们进一步提出相对临界锐度（$λ_c^{1\to 2}$），用于量化优化某一损失景观时另一损失景观的曲率，以分析从预训练到微调的过渡过程并指导数据混合策略。临界锐度为实践者提供了诊断曲率动态和指导大规模数据组合选择的实用工具。更广泛而言，我们的研究表明可扩展的曲率度量能为大规模训练提供可操作的见解。</div>
</details>
<details class="detail"><summary>Summary / 总结</summary>
<div class="mono">To analyze the training dynamics of large language models (LLMs) where directly computing Hessian sharpness is computationally prohibitive, this work proposes a scalable measure called critical sharpness (λ_c), which approximates curvature using fewer than 10 forward passes given a parameter update direction. The method is applied to study phenomena like progressive sharpening and the Edge of Stability during pre-training and mid-training of models up to 7B parameters, and introduces relative critical sharpness (λ_c^{1→2}) to analyze transitions between training objectives, such as from pre-training to fine-tuning, to inform data mixing strategies. Experimental results demonstrate that critical sharpness effectively captures established Hessian sharpness trends at scale, providing a practical tool for diagnosing curvature dynamics and guiding data composition in large-scale training.</div>
<div class="mono" style="margin-top:8px">为分析大语言模型的训练动态，需要一种可扩展的损失景观曲率度量方法，因为直接计算海森矩阵锐度在计算上代价过高。本研究提出了临界锐度这一高效度量，它仅需给定参数更新方向下的不到10次前向传播，便能捕捉渐进锐化和稳定性边缘等已知的海森矩阵现象。在高达70亿参数的OLMo-2模型上进行预训练和中期训练的实验，首次大规模验证了这些锐度现象；此外，引入的相对临界锐度可用于分析从预训练到微调的过渡阶段，并指导数据混合策略。</div>
</details>
</div>
<div class="card">
<div class="title">MapAnything: Universal Feed-Forward Metric 3D Reconstruction</div>
<div class="meta-line">Authors: Nikhil Keetha, Norman Müller, Johannes Schönberger, Lorenzo Porzi, Yuchen Zhang, Tobias Fischer, Arno Knapitsch, Duncan Zauss, Ethan Weber, Nelson Antunes, Jonathon Luiten, Manuel Lopez-Antequera, Samuel Rota Bulò, Christian Richardt, Deva Ramanan, Sebastian Scherer, Peter Kontschieder</div>
<div class="meta-line">First: 2025-09-16T18:00:14+00:00 · Latest: 2026-01-23T18:59:33+00:00</div>
<div class="meta-line">Comments: 3DV 2026. Project Page: https://map-anything.github.io/</div>
<div class="links" style="margin-top:8px"><a href="https://arxiv.org/abs/2509.13414v3">Abs</a> · <a href="https://arxiv.org/pdf/2509.13414v3">PDF</a> · <a href="https://huggingface.co/huggingface">Code1</a> · <a href="https://huggingface.co/docs/hub/spaces">Code2</a> · <a href="https://map-anything.github.io/">Project1</a></div>
<details class="detail"><summary>Abstract</summary>
<div class="mono">We introduce MapAnything, a unified transformer-based feed-forward model that ingests one or more images along with optional geometric inputs such as camera intrinsics, poses, depth, or partial reconstructions, and then directly regresses the metric 3D scene geometry and cameras. MapAnything leverages a factored representation of multi-view scene geometry, i.e., a collection of depth maps, local ray maps, camera poses, and a metric scale factor that effectively upgrades local reconstructions into a globally consistent metric frame. Standardizing the supervision and training across diverse datasets, along with flexible input augmentation, enables MapAnything to address a broad range of 3D vision tasks in a single feed-forward pass, including uncalibrated structure-from-motion, calibrated multi-view stereo, monocular depth estimation, camera localization, depth completion, and more. We provide extensive experimental analyses and model ablations demonstrating that MapAnything outperforms or matches specialist feed-forward models while offering more efficient joint training behavior, thus paving the way toward a universal 3D reconstruction backbone.</div></details>
<details class="detail"><summary>中文标题/摘要</summary>
<div class="mono"><b>标题：</b>MapAnything：通用前馈式度量三维重建</div>
<div class="mono" style="margin-top:8px">本文提出MapAnything，一种基于Transformer的统一前馈模型。该模型可接收单张或多张图像，以及相机内参、位姿、深度或局部重建结果等可选几何输入，直接回归出度量化的三维场景几何与相机参数。MapAnything采用多视角场景几何的分解表示形式，即通过深度图集合、局部射线图、相机位姿及度量尺度因子，将局部重建有效升级至全局一致的度量坐标系。通过跨数据集的标准化监督训练与灵活的输入增强策略，MapAnything能在单次前馈计算中处理广泛的三维视觉任务，包括未标定的运动恢复结构、已标定的多视角立体视觉、单目深度估计、相机定位、深度补全等。大量实验分析与模型消融研究表明，MapAnything在保持高效联合训练特性的同时，其性能优于或匹配专用前馈模型，为构建通用三维重建基础模型开辟了新路径。</div>
</details>
<details class="detail"><summary>Summary / 总结</summary>
<div class="mono">The research aims to develop a universal model for diverse 3D vision tasks, which are typically addressed by separate specialized models. The method introduces MapAnything, a unified transformer-based feed-forward model that processes one or more images along with optional geometric inputs and directly regresses metric 3D geometry and cameras using a factored representation of multi-view scene geometry. Experimental results demonstrate that MapAnything outperforms or matches specialist feed-forward models across tasks like structure-from-motion, multi-view stereo, and monocular depth estimation, while enabling more efficient joint training.</div>
<div class="mono" style="margin-top:8px">本研究旨在开发一种通用的前馈模型，用于从多样化输入中进行度量三维重建，以解决针对不同任务的专门模型碎片化问题。该方法MapAnything是一种基于Transformer的统一模型，可处理图像及相机参数或深度等可选几何输入，并通过深度图、局部射线图、位姿和尺度因子的分解表示直接回归度量三维几何与相机。实验结果表明，在未标定运动恢复结构、多视图立体视觉和单目深度估计等任务上，MapAnything的性能优于或匹配专门的前馈模型，同时展现出更高效的联合训练特性。</div>
</details>
</div>
<div class="card">
<div class="title">Towards Reasoning for PDE Foundation Models: A Reward-Model-Driven Inference-Time-Scaling Algorithm</div>
<div class="meta-line">Authors: Siddharth Mansingh, James Amarel, Ragib Arnab, Arvind Mohan, Kamaljeet Singh, Gerd J. Kunde, Nicolas Hengartner, Benjamin Migliori, Emily Casleton, Nathan A. Debardeleben, Ayan Biswas, Diane Oyen, Earl Lawrence</div>
<div class="meta-line">First: 2025-09-02T21:31:32+00:00 · Latest: 2026-01-23T18:55:13+00:00</div>
<div class="links" style="margin-top:8px"><a href="https://arxiv.org/abs/2509.02846v3">Abs</a> · <a href="https://arxiv.org/pdf/2509.02846v3">PDF</a> · <a href="https://huggingface.co/huggingface">Code1</a> · <a href="https://huggingface.co/docs/hub/spaces">Code2</a></div>
<details class="detail"><summary>Abstract</summary>
<div class="mono">Partial Differential Equations (PDEs) are the bedrock for modern computational sciences and engineering, and inherently computationally expensive. While PDE foundation models have shown much promise for simulating such complex spatio-temporal phenomena, existing models remain constrained by the pretraining datasets and struggle with auto-regressive rollout performance, especially in out-of-distribution (OOD) cases. Furthermore, they have significant compute and training data requirements which hamper their use in many critical applications. Inspired by recent advances in ``thinking&quot; strategies used in large language models (LLMs), we introduce the first test-time computing (TTC) strategy for PDEs that utilizes computational resources during inference to achieve more accurate predictions with fewer training samples and smaller models. We accomplish this with two types of reward models that evaluate predictions of a stochastic based model for spatio-temporal consistency. We demonstrate this method on compressible Euler-equation simulations from the PDEGym benchmark and show that TTC captures improved predictions relative to standard non-adaptive auto-regressive inference. This TTC framework marks a foundational step towards more advanced reasoning algorithms or PDE modeling, inluding building reinforcement-learning-based approaches, potentially transforming computational workflows in physics and engineering.</div></details>
<details class="detail"><summary>中文标题/摘要</summary>
<div class="mono"><b>标题：</b>迈向偏微分方程基础模型的推理：一种奖励模型驱动的推理时缩放算法</div>
<div class="mono" style="margin-top:8px">偏微分方程（PDE）是现代计算科学与工程的基石，其求解本质上是计算密集的。尽管PDE基础模型在模拟复杂时空现象方面展现出巨大潜力，但现有模型仍受限于预训练数据集，且在自回归推演性能（尤其是分布外场景）上存在不足。此外，其庞大的计算与训练数据需求阻碍了在关键领域的应用。受大语言模型“思维”策略的启发，我们首次提出针对PDE的测试时计算策略，通过在推理阶段动态调配计算资源，以更少的训练样本和更小的模型实现更精确的预测。该策略通过两类奖励模型评估随机基础模型的时空一致性预测质量。我们在PDEGym基准的可压缩欧拉方程模拟中验证了该方法，证明其相较于标准非自适应自回归推理能获得更优的预测结果。该框架标志着向更先进的PDE推理算法（包括基于强化学习的方法）迈出了基础性一步，有望革新物理与工程领域的计算工作流。</div>
</details>
<details class="detail"><summary>Summary / 总结</summary>
<div class="mono">The research addresses the limitations of current PDE foundation models, which are constrained by pretraining data and struggle with auto-regressive rollout performance, especially in out-of-distribution scenarios, while also facing high computational and data requirements. The method introduces a test-time computing strategy that uses computational resources during inference to enhance accuracy with fewer training samples and smaller models, employing two reward models to evaluate the spatio-temporal consistency of predictions from a stochastic model. Experimental results on compressible Euler-equation simulations from the PDEGym benchmark demonstrate that this approach achieves improved predictions compared to standard non-adaptive auto-regressive inference, marking a step toward advanced reasoning algorithms for PDE modeling.</div>
<div class="mono" style="margin-top:8px">偏微分方程基础模型在分布外泛化和高计算成本方面面临挑战。为此，作者提出了一种测试时计算策略，在推理过程中使用奖励模型来评估随机基础模型预测的时空一致性，从而在不需更大模型或更多训练数据的情况下提高准确性。在PDEGym基准的压缩欧拉方程模拟上的实验表明，这种推理时缩放方法相比标准的自回归推理能产生更准确的预测。</div>
</details>
</div>
<div class="card">
<div class="title">Latent Diffusion for Internet of Things Attack Data Generation in Intrusion Detection</div>
<div class="meta-line">Authors: Estela Sánchez-Carballo, Francisco M. Melgarejo-Meseguer, José Luis Rojo-Álvarez</div>
<div class="meta-line">First: 2026-01-23T18:55:07+00:00 · Latest: 2026-01-23T18:55:07+00:00</div>
<div class="meta-line">Comments: Submitted to IEEE. 15 pages, 2 figures</div>
<div class="links" style="margin-top:8px"><a href="https://arxiv.org/abs/2601.16976v1">Abs</a> · <a href="https://arxiv.org/pdf/2601.16976v1">PDF</a> · <a href="https://huggingface.co/huggingface">Code1</a> · <a href="https://huggingface.co/docs/hub/spaces">Code2</a></div>
<details class="detail"><summary>Abstract</summary>
<div class="mono">Intrusion Detection Systems (IDSs) are a key component for protecting Internet of Things (IoT) environments. However, in Machine Learning-based (ML-based) IDSs, performance is often degraded by the strong class imbalance between benign and attack traffic. Although data augmentation has been widely explored to mitigate this issue, existing approaches typically rely on simple oversampling techniques or generative models that struggle to simultaneously achieve high sample fidelity, diversity, and computational efficiency. To address these limitations, we propose the use of a Latent Diffusion Model (LDM) for attack data augmentation in IoT intrusion detection and provide a comprehensive comparison against state-of-the-art baselines. Experiments were conducted on three representative IoT attack types, specifically Distributed Denial-of-Service (DDoS), Mirai, and Man-in-the-Middle, evaluating both downstream IDS performance and intrinsic generative quality using distributional, dependency-based, and diversity metrics. Results show that balancing the training data with LDM-generated samples substantially improves IDS performance, achieving F1-scores of up to 0.99 for DDoS and Mirai attacks and consistently outperforming competing methods. Additionally, quantitative and qualitative analyses demonstrate that LDMs effectively preserve feature dependencies while generating diverse samples and reduce sampling time by approximately 25\% compared to diffusion models operating directly in data space. These findings highlight latent diffusion as an effective and scalable solution for synthetic IoT attack data generation, substantially mitigating the impact of class imbalance in ML-based IDSs for IoT scenarios.</div></details>
<details class="detail"><summary>中文标题/摘要</summary>
<div class="mono"><b>标题：</b>基于隐扩散模型的物联网入侵检测攻击数据生成</div>
<div class="mono" style="margin-top:8px">入侵检测系统是保护物联网环境的关键组件，但基于机器学习的入侵检测系统常因正常流量与攻击流量的严重类别不平衡导致性能下降。虽然数据增强技术被广泛用于缓解此问题，现有方法通常依赖简单的过采样技术或生成模型，难以同时实现高样本保真度、多样性和计算效率。为克服这些局限，本研究提出使用隐扩散模型进行物联网入侵检测的攻击数据增强，并与前沿基线方法进行全面对比。实验针对三种典型物联网攻击类型（分布式拒绝服务攻击、Mirai攻击、中间人攻击）展开，通过分布性指标、依赖关系指标和多样性指标评估下游入侵检测系统性能及生成质量。结果表明：使用隐扩散模型生成的样本平衡训练数据可显著提升入侵检测系统性能，对分布式拒绝服务攻击和Mirai攻击的F1分数最高达0.99，且持续优于对比方法。定量与定性分析进一步表明，隐扩散模型在生成多样样本时能有效保持特征依赖关系，相比直接在数据空间运行的扩散模型减少约25%的采样时间。这些发现证明隐扩散模型是生成合成物联网攻击数据的有效可扩展方案，能显著缓解物联网场景中基于机器学习的入侵检测系统面临的类别不平衡问题。</div>
</details>
<details class="detail"><summary>Summary / 总结</summary>
<div class="mono">To address the class imbalance problem in machine learning-based intrusion detection systems for IoT environments, which often degrades performance, this study proposes using a Latent Diffusion Model for attack data augmentation. The method is comprehensively compared against state-of-the-art baselines on three IoT attack types (DDoS, Mirai, Man-in-the-Middle), evaluating both downstream IDS performance and intrinsic generative quality using distributional, dependency-based, and diversity metrics. Experimental results show that balancing training data with LDM-generated samples substantially improves IDS performance, achieving F1-scores up to 0.99 for DDoS and Mirai attacks while consistently outperforming other methods; the LDM also effectively preserves feature dependencies, generates diverse samples, and reduces sampling time by approximately 25% compared to diffusion models operating in data space.</div>
<div class="mono" style="margin-top:8px">本研究针对物联网中基于机器学习的入侵检测系统因正常流量与攻击流量类别严重不平衡而导致的性能下降问题。为克服现有数据增强方法在实现高保真度、多样性和效率方面的局限，作者提出使用潜在扩散模型来生成合成攻击数据。在DDoS、Mirai和中间人攻击上的实验评估表明，使用LDM生成的样本平衡训练数据能显著提升入侵检测系统的性能，对DDoS和Mirai攻击的F1分数最高可达0.99，且始终优于基线方法，同时有效保持了特征依赖性，增强了样本多样性，并将采样时间较标准扩散模型减少了约25%。</div>
</details>
</div>
<div class="card">
<div class="title">Auto-Regressive Masked Diffusion Models</div>
<div class="meta-line">Authors: Mahdi Karami, Ali Ghodsi</div>
<div class="meta-line">Venue: 29th International Conference on Artificial Intelligence and Statistics (AISTATS) 2026</div>
<div class="meta-line">First: 2026-01-23T18:42:30+00:00 · Latest: 2026-01-23T18:42:30+00:00</div>
<div class="links" style="margin-top:8px"><a href="https://arxiv.org/abs/2601.16971v1">Abs</a> · <a href="https://arxiv.org/pdf/2601.16971v1">PDF</a> · <a href="https://huggingface.co/huggingface">Code1</a> · <a href="https://huggingface.co/docs/hub/spaces">Code2</a></div>
<details class="detail"><summary>Abstract</summary>
<div class="mono">Masked diffusion models (MDMs) have emerged as a promising approach for language modeling, yet they face a performance gap compared to autoregressive models (ARMs) and require more training iterations. In this work, we present the Auto-Regressive Masked Diffusion (ARMD) model, an architecture designed to close this gap by unifying the training efficiency of autoregressive models with the parallel generation capabilities of diffusion-based models. Our key insight is to reframe the masked diffusion process as a block-wise causal model. This perspective allows us to design a strictly causal, permutation-equivariant architecture that computes all conditional probabilities across multiple denoising steps in a single, parallel forward pass. The resulting architecture supports efficient, autoregressive-style decoding and a progressive permutation training scheme, allowing the model to learn both canonical left-to-right and random token orderings. Leveraging this flexibility, we introduce a novel strided parallel generation strategy that accelerates inference by generating tokens in parallel streams while maintaining global coherence. Empirical results demonstrate that ARMD achieves state-of-the-art performance on standard language modeling benchmarks, outperforming established diffusion baselines while requiring significantly fewer training steps. Furthermore, it establishes a new benchmark for parallel text generation, effectively bridging the performance gap between parallel and sequential decoding.</div></details>
<details class="detail"><summary>中文标题/摘要</summary>
<div class="mono"><b>标题：</b>自回归掩码扩散模型</div>
<div class="mono" style="margin-top:8px">掩码扩散模型（MDMs）已成为语言建模中一种有前景的方法，但其性能仍落后于自回归模型（ARMs），且需要更多训练迭代。本研究提出自回归掩码扩散（ARMD）模型，该架构通过融合自回归模型的训练效率与扩散模型的并行生成能力来弥合这一差距。核心思路是将掩码扩散过程重构为块级因果模型，从而设计出严格因果且置换等变的架构，可在单次并行前向传播中计算多步去噪的条件概率。该架构支持高效的自回归式解码和渐进置换训练方案，使模型能同时学习规范左向右和随机词元排序。利用这种灵活性，我们提出一种新颖的跨步并行生成策略，通过并行流生成词元并保持全局连贯性以加速推理。实验结果表明，ARMD在标准语言建模基准上达到最先进性能，显著超越现有扩散基线且所需训练步数更少。此外，该模型为并行文本生成设立了新基准，有效弥合了并行与顺序解码间的性能差距。</div>
</details>
<details class="detail"><summary>Summary / 总结</summary>
<div class="mono">This research addresses the performance gap between masked diffusion models (MDMs) and autoregressive models (ARMs) in language modeling, where MDMs typically require more training iterations. The proposed Auto-Regressive Masked Diffusion (ARMD) model unifies autoregressive training efficiency with diffusion-based parallel generation by reframing masked diffusion as a block-wise causal process. This enables a strictly causal, permutation-equivariant architecture that computes all conditional probabilities across denoising steps in a single parallel forward pass, supporting both left-to-right and random token orderings during training. Experimental results show that ARMD achieves state-of-the-art performance on standard language modeling benchmarks, outperforming diffusion baselines with significantly fewer training steps, while also setting a new benchmark for parallel text generation through a novel strided parallel generation strategy.</div>
<div class="mono" style="margin-top:8px">本研究针对掩码扩散模型在语言建模中与自回归模型存在性能差距且训练迭代次数较多的问题，提出了自回归掩码扩散模型，旨在将自回归模型的训练效率与扩散模型的并行生成能力相统一。该方法将掩码扩散过程重构为块级因果模型，设计了一个严格因果、置换等变的架构，可在单次并行前向传播中计算所有去噪步骤的条件概率，支持高效的自回归式解码和渐进置换训练。实验结果表明，该模型在标准语言建模基准上取得了最先进的性能，以更少的训练步骤超越了现有扩散基线，并通过一种新颖的跨步并行生成策略，为并行文本生成设立了新基准，有效弥合了并行与顺序解码之间的性能差距。</div>
</details>
</div>
<div class="card">
<div class="title">On Fine-Grained I/O Complexity of Attention Backward Passes</div>
<div class="meta-line">Authors: Xiaoyu Li, Yingyu Liang, Zhenmei Shi, Zhao Song, Song Yue, Jiahao Zhang</div>
<div class="meta-line">First: 2024-10-12T07:01:30+00:00 · Latest: 2026-01-23T18:42:16+00:00</div>
<div class="links" style="margin-top:8px"><a href="https://arxiv.org/abs/2410.09397v2">Abs</a> · <a href="https://arxiv.org/pdf/2410.09397v2">PDF</a> · <a href="https://huggingface.co/huggingface">Code1</a> · <a href="https://huggingface.co/docs/hub/spaces">Code2</a></div>
<details class="detail"><summary>Abstract</summary>
<div class="mono">Large Language Models (LLMs) exhibit exceptional proficiency in handling extensive context windows in natural language. Nevertheless, the quadratic scaling of attention computation relative to sequence length creates substantial efficiency bottlenecks, necessitating the development of I/O-optimized algorithms. In this work, we conduct a systematic examination of the I/O complexity inherent in attention mechanisms, with a specific emphasis on the backward pass under both small and large cache settings. By leveraging the red-blue pebble game framework, we derive tight bounds for I/O complexity across the full spectrum of cache sizes. We validate that FlashAttention, one of the current industry standards, achieves optimality in the large-cache scenario for both forward and backward passes. Conversely, for small-cache environments, we introduce a novel algorithm that outperforms contemporary methods and successfully attains theoretical tight bounds. Furthermore, we expand our investigation to include sparse attention by establishing granular lower bounds for both forward and backward passes across all cache configurations. Ultimately, our results solidify the theoretical framework regarding I/O complexity in attention mechanisms, providing critical guidance for the development of efficient LLM training and inference systems.</div></details>
<details class="detail"><summary>中文标题/摘要</summary>
<div class="mono"><b>标题：</b>注意力机制反向传播的细粒度I/O复杂度研究</div>
<div class="mono" style="margin-top:8px">大语言模型在处理自然语言长上下文窗口方面展现出卓越能力，但注意力计算随序列长度呈二次方增长的特性导致显著效率瓶颈，亟需开发I/O优化算法。本研究系统分析了注意力机制固有的I/O复杂度，重点探究小缓存与大缓存配置下的反向传播过程。通过红蓝卵石博弈框架，我们推导出全缓存规模范围内的紧致I/O复杂度边界。验证表明当前业界标准算法FlashAttention在大缓存场景的前向与反向传播中均达到最优；针对小缓存环境，我们提出新型算法超越现有方法并实现理论紧致边界。进一步将研究拓展至稀疏注意力机制，建立全缓存配置下双向传播的细粒度下界。最终成果夯实了注意力机制I/O复杂度的理论框架，为高效大语言模型训练与推理系统开发提供关键指引。</div>
</details>
<details class="detail"><summary>Summary / 总结</summary>
<div class="mono">The quadratic scaling of attention computation with sequence length in Large Language Models creates significant efficiency bottlenecks, motivating a systematic analysis of I/O complexity, particularly for the backward pass under varying cache sizes. Using the red-blue pebble game framework, the work derives tight I/O complexity bounds across all cache sizes, validating that FlashAttention is optimal for large caches and introducing a novel algorithm that achieves theoretical tight bounds for small caches. The study also extends to sparse attention, establishing fine-grained lower bounds, thereby solidifying the theoretical foundation for efficient LLM training and inference systems.</div>
<div class="mono" style="margin-top:8px">大型语言模型中注意力计算随序列长度的二次缩放造成了显著的效率瓶颈，这促使了对I/O复杂性的系统分析，特别是在不同缓存大小下的反向传播过程。该研究利用红蓝卵石游戏框架，推导了完整缓存范围内的紧致I/O复杂度界限，验证了FlashAttention在大缓存场景下的最优性，并针对小缓存环境提出了一种达到理论紧致界限的新算法。研究还扩展到稀疏注意力，建立了所有缓存配置下的细粒度下界，从而为高效LLM训练和推理系统的开发奠定了坚实的理论基础。</div>
</details>
</div>
<div class="card">
<div class="title">Q-learning with Adjoint Matching</div>
<div class="meta-line">Authors: Qiyang Li, Sergey Levine</div>
<div class="meta-line">First: 2026-01-20T18:45:34+00:00 · Latest: 2026-01-23T18:40:14+00:00</div>
<div class="meta-line">Comments: 32 pages, 8 figures, 7 tables</div>
<div class="links" style="margin-top:8px"><a href="https://arxiv.org/abs/2601.14234v2">Abs</a> · <a href="https://arxiv.org/pdf/2601.14234v2">PDF</a> · <a href="https://huggingface.co/huggingface">Code1</a> · <a href="https://huggingface.co/docs/hub/spaces">Code2</a></div>
<details class="detail"><summary>Abstract</summary>
<div class="mono">We propose Q-learning with Adjoint Matching (QAM), a novel TD-based reinforcement learning (RL) algorithm that tackles a long-standing challenge in continuous-action RL: efficient optimization of an expressive diffusion or flow-matching policy with respect to a parameterized Q-function. Effective optimization requires exploiting the first-order information of the critic, but it is challenging to do so for flow or diffusion policies because direct gradient-based optimization via backpropagation through their multi-step denoising process is numerically unstable. Existing methods work around this either by only using the value and discarding the gradient information, or by relying on approximations that sacrifice policy expressivity or bias the learned policy. QAM sidesteps both of these challenges by leveraging adjoint matching, a recently proposed technique in generative modeling, which transforms the critic&#x27;s action gradient to form a step-wise objective function that is free from unstable backpropagation, while providing an unbiased, expressive policy at the optimum. Combined with temporal-difference backup for critic learning, QAM consistently outperforms prior approaches on hard, sparse reward tasks in both offline and offline-to-online RL.</div></details>
<details class="detail"><summary>中文标题/摘要</summary>
<div class="mono"><b>标题：</b>伴随匹配Q学习</div>
<div class="mono" style="margin-top:8px">我们提出伴随匹配Q学习（QAM），这是一种基于时序差分的新型强化学习算法，解决了连续动作强化学习中长期存在的挑战：针对参数化Q函数高效优化表达能力强的扩散或流匹配策略。有效优化需要利用评论家的一阶信息，但对流或扩散策略而言，通过多步去噪过程进行基于梯度的反向传播优化存在数值不稳定性。现有方法要么仅使用价值函数而丢弃梯度信息，要么依赖近似方法牺牲策略表达能力或引入偏差。QAM通过运用生成建模中最新提出的伴随匹配技术，将评论家的动作梯度转化为逐步目标函数，既避免了不稳定的反向传播，又在最优解处提供无偏且表达能力强的策略。结合评论家学习的时序差分更新，QAM在离线及离线到在线强化学习的困难稀疏奖励任务中持续超越现有方法。</div>
</details>
<details class="detail"><summary>Summary / 总结</summary>
<div class="mono">The research addresses the challenge of efficiently optimizing expressive diffusion or flow-matching policies in continuous-action reinforcement learning, where direct gradient-based optimization through multi-step denoising is numerically unstable. The proposed method, Q-learning with Adjoint Matching (QAM), leverages adjoint matching to transform the critic&#x27;s action gradient into a step-wise objective, avoiding unstable backpropagation while maintaining an unbiased and expressive policy. Experimental results demonstrate that QAM consistently outperforms prior methods on hard, sparse reward tasks in both offline and offline-to-online RL settings.</div>
<div class="mono" style="margin-top:8px">该研究旨在解决连续动作强化学习中高效优化扩散或流匹配策略的长期挑战，其中通过多步去噪的直接梯度优化存在数值不稳定性。所提出的方法——伴随匹配Q学习（QAM）——利用伴随匹配技术将评论者的动作梯度转换为逐步目标函数，避免了不稳定的反向传播，同时保持了无偏且表达能力强的策略。实验结果表明，在离线及离线到在线强化学习的困难稀疏奖励任务上，QAM一致优于现有方法。</div>
</details>
</div>
<div class="card">
<div class="title">Provable Differentially Private Computation of the Cross-Attention Mechanism</div>
<div class="meta-line">Authors: Yekun Ke, Yingyu Liang, Zhenmei Shi, Zhao Song, Jiahao Zhang</div>
<div class="meta-line">First: 2024-07-20T01:02:27+00:00 · Latest: 2026-01-23T18:38:40+00:00</div>
<div class="links" style="margin-top:8px"><a href="https://arxiv.org/abs/2407.14717v3">Abs</a> · <a href="https://arxiv.org/pdf/2407.14717v3">PDF</a> · <a href="https://huggingface.co/huggingface">Code1</a> · <a href="https://huggingface.co/docs/hub/spaces">Code2</a></div>
<details class="detail"><summary>Abstract</summary>
<div class="mono">Cross-attention has emerged as a cornerstone module in modern artificial intelligence, underpinning critical applications such as retrieval-augmented generation (RAG), system prompting, and guided stable diffusion. However, this is a rising concern about securing the privacy of cross-attention, as the underlying key and value matrices frequently encode sensitive data or private user information. In this work, we introduce a novel data structure designed to enforce differential privacy (DP) for cross-attention mechanisms, accompanied by provable theoretical guarantees. Specifically, letting $n$ denote the input sequence length, $d$ the feature dimension, $R$ the maximum magnitude of query and key matrices, $R_w$ the maximum magnitude of the value matrix, and $r, s, ε_s$ the parameters for polynomial kernel methods, our proposed structure achieves $\widetilde{O}(ndr^2)$ space and initialization complexity, with a query time of $\widetilde{O}(d r^2)$ per token. Moreover, we demonstrate that our mechanism satisfies $(ε, δ)$-DP, incurring an additive error of $\widetilde{O}((1-ε_s)^{-1} n^{-1} ε^{-1} R^{2s} R_w r^2)$ and a relative error of $2ε_s/(1-ε_s)$ with respect to the ground truth. Crucially, our framework maintains robustness against adaptive queries, ensuring security even in adversarial settings. To the best of our knowledge, this constitutes the first approach providing provable differential privacy for cross-attention, establishing a foundation for future privacy-preserving algorithms in large generative models (LGMs).</div></details>
<details class="detail"><summary>中文标题/摘要</summary>
<div class="mono"><b>标题：</b>可证明差分隐私的交叉注意力机制计算</div>
<div class="mono" style="margin-top:8px">交叉注意力已成为现代人工智能的基石模块，支撑着检索增强生成（RAG）、系统提示和引导式稳定扩散等关键应用。然而，由于底层的键值矩阵常编码敏感数据或用户隐私信息，其隐私保护问题日益受到关注。本研究提出一种新颖的数据结构，旨在为交叉注意力机制实施差分隐私（DP），并提供可证明的理论保证。具体而言，设输入序列长度为$n$，特征维度为$d$，查询与键矩阵的最大幅值为$R$，值矩阵的最大幅值为$R_w$，多项式核方法参数为$r, s, ε_s$，所提结构实现了$\widetilde{O}(ndr^2)$的空间与初始化复杂度，单令牌查询时间为$\widetilde{O}(d r^2)$。进一步证明该机制满足$(ε, δ)$-DP，其绝对误差为$\widetilde{O}((1-ε_s)^{-1} n^{-1} ε^{-1} R^{2s} R_w r^2)$，相对真实值的相对误差为$2ε_s/(1-ε_s)$。该框架能抵御自适应查询攻击，确保在对抗环境下的安全性。据我们所知，这是首个为交叉注意力提供可证明差分隐私的方法，为大型生成模型（LGMs）的隐私保护算法奠定了理论基础。</div>
</details>
<details class="detail"><summary>Summary / 总结</summary>
<div class="mono">The research is motivated by the widespread use of cross-attention in AI applications like retrieval-augmented generation, where key and value matrices often contain sensitive data, raising privacy concerns. The method introduces a novel data structure that enforces differential privacy for cross-attention, with provable guarantees, achieving space and initialization complexity of Õ(ndr²) and query time of Õ(dr²) per token. Experimental results show the mechanism satisfies (ε, δ)-differential privacy, introducing an additive error of Õ((1-ε_s)⁻¹ n⁻¹ ε⁻¹ R²ˢ R_w r²) and a relative error of 2ε_s/(1-ε_s), while remaining robust against adaptive queries, marking the first provably private approach for cross-attention.</div>
<div class="mono" style="margin-top:8px">该研究的动机在于交叉注意力机制在检索增强生成等人工智能应用中的广泛使用，其键值矩阵常包含敏感数据，引发了隐私担忧。方法提出了一种新颖的数据结构，为交叉注意力机制提供可证明的差分隐私保护，实现了Õ(ndr²)的空间和初始化复杂度以及每个令牌Õ(dr²)的查询时间。实验结果表明，该机制满足(ε, δ)-差分隐私，引入了Õ((1-ε_s)⁻¹ n⁻¹ ε⁻¹ R²ˢ R_w r²)的加性误差和2ε_s/(1-ε_s)的相对误差，同时能抵抗自适应查询，这是首个为交叉注意力提供可证明隐私保护的方法。</div>
</details>
</div>
<div class="card">
<div class="title">3D Molecule Generation from Rigid Motifs via SE(3) Flows</div>
<div class="meta-line">Authors: Roman Poletukhin, Marcel Kollovieh, Eike Eberhard, Stephan Günnemann</div>
<div class="meta-line">First: 2026-01-23T18:24:57+00:00 · Latest: 2026-01-23T18:24:57+00:00</div>
<div class="links" style="margin-top:8px"><a href="https://arxiv.org/abs/2601.16955v1">Abs</a> · <a href="https://arxiv.org/pdf/2601.16955v1">PDF</a> · <a href="https://huggingface.co/huggingface">Code1</a> · <a href="https://huggingface.co/docs/hub/spaces">Code2</a></div>
<details class="detail"><summary>Abstract</summary>
<div class="mono">Three-dimensional molecular structure generation is typically performed at the level of individual atoms, yet molecular graph generation techniques often consider fragments as their structural units. Building on the advances in frame-based protein structure generation, we extend these fragmentation ideas to 3D, treating general molecules as sets of rigid-body motifs. Utilising this representation, we employ SE(3)-equivariant generative modelling for de novo 3D molecule generation from rigid motifs. In our evaluations, we observe comparable or superior results to state-of-the-art across benchmarks, surpassing it in atom stability on GEOM-Drugs, while yielding a 2x to 10x reduction in generation steps and offering 3.5x compression in molecular representations compared to the standard atom-based methods.</div></details>
<details class="detail"><summary>中文标题/摘要</summary>
<div class="mono"><b>标题：</b>基于刚性基元与SE(3)流的三维分子生成</div>
<div class="mono" style="margin-top:8px">三维分子结构生成通常在原子层面进行，而分子图生成技术常将片段作为结构单元。基于帧式蛋白质结构生成的研究进展，我们将片段化思想拓展至三维领域，将普通分子视为刚性基元集合。利用该表征方法，我们采用SE(3)等变生成模型实现从刚性基元出发的从头三维分子生成。评估结果显示，在多项基准测试中取得与当前最优方法相当或更优的结果，在GEOM-Drugs数据集上原子稳定性表现更佳，同时生成步骤减少2至10倍，分子表征压缩率达到基于原子标准方法的3.5倍。</div>
</details>
<details class="detail"><summary>Summary / 总结</summary>
<div class="mono">The research addresses the challenge of generating three-dimensional molecular structures by moving beyond atom-level approaches to incorporate molecular fragments as rigid motifs, inspired by fragment-based graph generation and frame-based protein structure methods. The method employs SE(3)-equivariant generative modeling to generate molecules from these rigid-body units, ensuring spatial equivariance. Experimental results show performance comparable to or better than state-of-the-art methods on benchmarks, with improved atom stability on GEOM-Drugs, alongside a 2x to 10x reduction in generation steps and a 3.5x compression in representation size compared to atom-based techniques.</div>
<div class="mono" style="margin-top:8px">本研究旨在改进三维分子结构生成，通过超越计算密集的原子级建模，转而利用更大、更有意义的结构单元。该方法将分子表示为刚性基序的集合，并采用SE(3)等变的基于流的生成模型在三维空间中组装这些基序。实验结果表明，该方法在基准测试中取得了与最先进方法相当或更优的性能，特别是在GEOM-Drugs数据集上显著提高了原子稳定性，同时与标准的原子级方法相比，生成步骤减少了2到10倍，分子表示压缩了3.5倍。</div>
</details>
</div>
<div class="card">
<div class="title">Efficient semantic uncertainty quantification in language models via diversity-steered sampling</div>
<div class="meta-line">Authors: Ji Won Park, Kyunghyun Cho</div>
<div class="meta-line">Venue: NeurIPS 2025</div>
<div class="meta-line">First: 2025-10-24T10:06:21+00:00 · Latest: 2026-01-23T18:02:21+00:00</div>
<div class="meta-line">Comments: 10 pages (+7 appendix), 7 figures. Accepted at NeurIPS 2025</div>
<div class="links" style="margin-top:8px"><a href="https://arxiv.org/abs/2510.21310v2">Abs</a> · <a href="https://arxiv.org/pdf/2510.21310v2">PDF</a> · <a href="https://huggingface.co/huggingface">Code1</a> · <a href="https://huggingface.co/docs/hub/spaces">Code2</a></div>
<details class="detail"><summary>Abstract</summary>
<div class="mono">Accurately estimating semantic aleatoric and epistemic uncertainties in large language models (LLMs) is particularly challenging in free-form question answering (QA), where obtaining stable estimates often requires many expensive generations. We introduce a diversity-steered sampler that discourages semantically redundant outputs during decoding, covers both autoregressive and masked diffusion paradigms, and yields substantial sample-efficiency gains. The key idea is to inject a continuous semantic-similarity penalty into the model&#x27;s proposal distribution using a natural language inference (NLI) model lightly finetuned on partial prefixes or intermediate diffusion states. We debias downstream uncertainty estimates with importance reweighting and shrink their variance with control variates. Across four QA benchmarks, our method matches or surpasses baselines while covering more semantic clusters with the same number of samples. Being modular and requiring no gradient access to the base LLM, the framework promises to serve as a drop-in enhancement for uncertainty estimation in risk-sensitive model deployments.</div></details>
<details class="detail"><summary>中文标题/摘要</summary>
<div class="mono"><b>标题：</b>通过多样性引导采样实现语言模型的高效语义不确定性量化</div>
<div class="mono" style="margin-top:8px">在自由形式问答任务中，准确估计大语言模型的语义偶然性和认知不确定性尤为困难，通常需要大量昂贵的生成才能获得稳定估计。我们提出一种多样性引导采样器，在解码过程中抑制语义冗余输出，同时适用于自回归和掩码扩散范式，显著提升采样效率。其核心思想是使用经部分前缀或中间扩散状态轻量微调的自然语言推理模型，将连续语义相似度惩罚注入模型的提议分布中。我们通过重要性重加权修正下游不确定性估计的偏差，并利用控制变量法缩减其方差。在四个问答基准测试中，本方法在相同样本量下覆盖更多语义簇，性能达到或超越基线。该框架具有模块化特性，无需访问基础大语言模型的梯度，可作为风险敏感模型部署中不确定性估计的即插即用增强方案。</div>
</details>
<details class="detail"><summary>Summary / 总结</summary>
<div class="mono">Accurately estimating semantic uncertainty in large language models for free-form question answering is challenging due to the high computational cost of generating many samples. To address this, the authors propose a diversity-steered sampler that injects a semantic-similarity penalty into the model&#x27;s proposal distribution using a lightly finetuned natural language inference model, covering both autoregressive and masked diffusion paradigms; downstream uncertainty estimates are debiased with importance reweighting and variance is reduced with control variates. Experimental results on four QA benchmarks show the method matches or surpasses baseline performance, covering more semantic clusters with the same sample budget, offering a modular, gradient-free enhancement for risk-sensitive deployments.</div>
<div class="mono" style="margin-top:8px">本研究旨在解决大型语言模型在开放式问答中语义偶然和认知不确定性估计效率低下的问题，传统方法需要大量昂贵的生成才能获得稳定估计。提出的方法是一种多样性引导的采样器，通过在解码过程中向模型的提议分布注入连续的语义相似性惩罚来实现，该过程使用一个在部分前缀或中间扩散状态上微调的自然语言推理模型进行评估，适用于自回归和掩码扩散两种范式。在四个问答基准测试上的实验结果表明，该方法在不确定性估计上达到或超越了基线性能，并在相同样本数量下覆盖了更多的语义簇，其模块化且无需访问基础模型梯度的特点，使其适合作为风险敏感部署中的即插即用增强工具。</div>
</details>
</div>
<div class="card">
<div class="title">Is BatchEnsemble a Single Model? On Calibration and Diversity of Efficient Ensembles</div>
<div class="meta-line">Authors: Anton Zamyatin, Patrick Indri, Sagar Malhotra, Thomas Gärtner</div>
<div class="meta-line">First: 2026-01-23T17:50:50+00:00 · Latest: 2026-01-23T17:50:50+00:00</div>
<div class="meta-line">Comments: Accepted at the 1st workshop on Epistemic Intelligence in Machine Learning at EurIPS 2025</div>
<div class="links" style="margin-top:8px"><a href="https://arxiv.org/abs/2601.16936v1">Abs</a> · <a href="https://arxiv.org/pdf/2601.16936v1">PDF</a> · <a href="https://huggingface.co/huggingface">Code1</a> · <a href="https://huggingface.co/docs/hub/spaces">Code2</a></div>
<details class="detail"><summary>Abstract</summary>
<div class="mono">In resource-constrained and low-latency settings, uncertainty estimates must be efficiently obtained. Deep Ensembles provide robust epistemic uncertainty (EU) but require training multiple full-size models. BatchEnsemble aims to deliver ensemble-like EU at far lower parameter and memory cost by applying learned rank-1 perturbations to a shared base network. We show that BatchEnsemble not only underperforms Deep Ensembles but closely tracks a single model baseline in terms of accuracy, calibration and out-of-distribution (OOD) detection on CIFAR10/10C/SVHN. A controlled study on MNIST finds members are near-identical in function and parameter space, indicating limited capacity to realize distinct predictive modes. Thus, BatchEnsemble behaves more like a single model than a true ensemble.</div></details>
<details class="detail"><summary>中文标题/摘要</summary>
<div class="mono"><b>标题：</b>BatchEnsemble是单一模型吗？论高效集成方法的校准性与多样性</div>
<div class="mono" style="margin-top:8px">在资源受限和低延迟场景中，需高效获取不确定性估计。深度集成方法能提供稳健的认知不确定性，但需训练多个全尺寸模型。BatchEnsemble通过对共享基础网络应用学习得到的秩-1扰动，旨在以极低的参数量和内存成本实现类集成认知不确定性。我们证明BatchEnsemble不仅在CIFAR10/10C/SVHN数据集上的准确率、校准性和分布外检测方面表现不及深度集成方法，且与单一模型基线高度趋同。在MNIST上的对照研究发现，其成员在函数空间和参数空间近乎一致，表明其实现差异化预测模式的能力有限。因此，BatchEnsemble更接近单一模型而非真正的集成方法。</div>
</details>
<details class="detail"><summary>Summary / 总结</summary>
<div class="mono">The study investigates whether BatchEnsemble, an efficient ensemble method designed to reduce computational costs compared to Deep Ensembles, truly functions as a diverse ensemble for uncertainty estimation. Through empirical evaluation on CIFAR10, CIFAR10-C, and SVHN, the method&#x27;s performance is compared to Deep Ensembles and a single model baseline in terms of accuracy, calibration, and out-of-distribution detection. Results show that BatchEnsemble underperforms Deep Ensembles and closely resembles a single model, with a controlled MNIST analysis revealing near-identical member functions and parameters, indicating limited predictive diversity.</div>
<div class="mono" style="margin-top:8px">本研究针对资源受限环境中高效不确定性估计的需求，其中深度集成方法有效但计算成本高昂。方法研究了BatchEnsemble，该技术通过对共享基础网络应用学习的秩-1扰动，以较低成本近似集成行为。在CIFAR10、CIFAR10-C和SVHN上的实验结果表明，BatchEnsemble在准确性、校准和分布外检测方面表现不及深度集成，且与单一模型基线接近；在MNIST上的受控研究进一步发现其成员函数近乎相同，表明其缺乏真正集成的多样性。</div>
</details>
</div>
<div class="card">
<div class="title">Reward-Forcing: Autoregressive Video Generation with Reward Feedback</div>
<div class="meta-line">Authors: Jingran Zhang, Ning Li, Yuanhao Ban, Andrew Bai, Justin Cui</div>
<div class="meta-line">First: 2026-01-23T17:47:56+00:00 · Latest: 2026-01-23T17:47:56+00:00</div>
<div class="meta-line">Comments: preprint</div>
<div class="links" style="margin-top:8px"><a href="https://arxiv.org/abs/2601.16933v1">Abs</a> · <a href="https://arxiv.org/pdf/2601.16933v1">PDF</a> · <a href="https://huggingface.co/huggingface">Code1</a> · <a href="https://huggingface.co/docs/hub/spaces">Code2</a></div>
<details class="detail"><summary>Abstract</summary>
<div class="mono">While most prior work in video generation relies on bidirectional architectures, recent efforts have sought to adapt these models into autoregressive variants to support near real-time generation. However, such adaptations often depend heavily on teacher models, which can limit performance, particularly in the absence of a strong autoregressive teacher, resulting in output quality that typically lags behind their bidirectional counterparts. In this paper, we explore an alternative approach that uses reward signals to guide the generation process, enabling more efficient and scalable autoregressive generation. By using reward signals to guide the model, our method simplifies training while preserving high visual fidelity and temporal consistency. Through extensive experiments on standard benchmarks, we find that our approach performs comparably to existing autoregressive models and, in some cases, surpasses similarly sized bidirectional models by avoiding constraints imposed by teacher architectures. For example, on VBench, our method achieves a total score of 84.92, closely matching state-of-the-art autoregressive methods that score 84.31 but require significant heterogeneous distillation.</div></details>
<details class="detail"><summary>中文标题/摘要</summary>
<div class="mono"><b>标题：</b>奖励驱动：基于奖励反馈的自回归视频生成</div>
<div class="mono" style="margin-top:8px">现有视频生成研究多采用双向架构，近期工作尝试将其改造为自回归变体以实现近实时生成。然而此类改造通常严重依赖教师模型，在缺乏强自回归教师时性能受限，导致输出质量普遍落后于双向模型。本文提出一种利用奖励信号引导生成过程的替代方案，实现更高效可扩展的自回归生成。该方法通过奖励信号指导模型，在保持高视觉保真度与时序一致性的同时简化训练流程。在标准基准测试中的大量实验表明，本方法性能与现有自回归模型相当，且通过规避教师架构的约束，在某些情况下超越了同等规模的双向模型。例如在VBench基准上，本方法获得84.92总分，与需复杂异构蒸馏的先进自回归方法（84.31分）表现接近。</div>
</details>
<details class="detail"><summary>Summary / 总结</summary>
<div class="mono">This research addresses the performance gap in autoregressive video generation, which often relies on teacher models and underperforms compared to bidirectional approaches. The proposed method, Reward-Forcing, guides the autoregressive generation process using reward signals to enhance training efficiency and scalability without dependence on a teacher model. Experimental results on benchmarks like VBench show that the method achieves a total score of 84.92, closely matching state-of-the-art autoregressive models and even surpassing similarly sized bidirectional models in some cases, while maintaining high visual fidelity and temporal consistency.</div>
<div class="mono" style="margin-top:8px">本研究针对自回归视频生成模型因依赖教师模型而导致输出质量受限、通常落后于双向模型的问题。提出的Reward-Forcing方法利用奖励信号引导自回归生成过程，简化训练的同时保持高视觉保真度和时间一致性。在VBench等标准基准测试中，该方法获得84.92的总分，与最先进的自回归方法相当，并通过避免教师架构限制，在某些情况下超越了类似规模的双向模型。</div>
</details>
</div>
<div class="card">
<div class="title">Differentiable Cyclic Causal Discovery Under Unmeasured Confounders</div>
<div class="meta-line">Authors: Muralikrishnna G. Sethuraman, Faramarz Fekri</div>
<div class="meta-line">First: 2025-08-11T20:13:34+00:00 · Latest: 2026-01-23T17:34:59+00:00</div>
<div class="links" style="margin-top:8px"><a href="https://arxiv.org/abs/2508.08450v3">Abs</a> · <a href="https://arxiv.org/pdf/2508.08450v3">PDF</a> · <a href="https://huggingface.co/huggingface">Code1</a> · <a href="https://huggingface.co/docs/hub/spaces">Code2</a></div>
<details class="detail"><summary>Abstract</summary>
<div class="mono">Understanding causal relationships between variables is fundamental across scientific disciplines. Most causal discovery algorithms rely on two key assumptions: (i) all variables are observed, and (ii) the underlying causal graph is acyclic. While these assumptions simplify theoretical analysis, they are often violated in real-world systems, such as biological networks. Existing methods that account for confounders either assume linearity or struggle with scalability. To address these limitations, we propose DCCD-CONF, a novel framework for differentiable learning of nonlinear cyclic causal graphs in the presence of unmeasured confounders using interventional data. Our approach alternates between optimizing the graph structure and estimating the confounder distribution by maximizing the log-likelihood of the data. Through experiments on synthetic data and real-world gene perturbation datasets, we show that DCCD-CONF outperforms state-of-the-art methods in both causal graph recovery and confounder identification. Additionally, we also provide consistency guarantees for our framework, reinforcing its theoretical soundness.</div></details>
<details class="detail"><summary>中文标题/摘要</summary>
<div class="mono"><b>标题：</b>未测量混杂因素下的可微分循环因果发现</div>
<div class="mono" style="margin-top:8px">理解变量间的因果关系是科学领域的核心问题。多数因果发现算法依赖两个关键假设：(i) 所有变量均可观测，(ii) 基础因果图为无环结构。尽管这些假设简化了理论分析，但在生物网络等现实系统中常被违背。现有处理混杂因素的方法要么假设线性关系，要么面临可扩展性挑战。为突破这些局限，我们提出DCCD-CONF框架，利用干预数据实现未测量混杂因素下非线性循环因果图的可微分学习。该方法通过交替优化图结构与最大化数据对数似然来估计混杂因素分布。在合成数据和真实基因扰动数据集上的实验表明，DCCD-CONF在因果图恢复和混杂因素识别方面均优于现有先进方法。此外，我们还为该框架提供了理论一致性保证，强化了其理论严谨性。</div>
</details>
<details class="detail"><summary>Summary / 总结</summary>
<div class="mono">Causal discovery often assumes fully observed variables and acyclic graphs, but real-world systems like biological networks may violate these with unmeasured confounders and cycles. To address this, we propose DCCD-CONF, a differentiable framework that learns nonlinear cyclic causal graphs from interventional data by alternating between optimizing graph structure and estimating confounder distribution via log-likelihood maximization. Experiments on synthetic and gene perturbation datasets show DCCD-CONF outperforms state-of-the-art methods in recovering causal graphs and identifying confounders, supported by consistency guarantees.</div>
<div class="mono" style="margin-top:8px">因果发现通常假设所有变量均可观测且因果图无环，但这些假设在生物网络等现实系统中常被违背，而现有处理未测量混杂因子的方法受限于线性假设或可扩展性问题。为克服这些挑战，作者提出了DCCD-CONF，这是一个可微分框架，利用干预数据通过交替优化图结构和基于对数似然最大化估计混杂因子分布，来学习非线性循环因果图。在合成数据和真实基因扰动数据集上的实验表明，DCCD-CONF在因果图恢复和混杂因子识别方面优于现有先进方法，且该框架具有一致性保证。</div>
</details>
</div>
<div class="card">
<div class="title">Group-realizable multi-group learning by minimizing empirical risk</div>
<div class="meta-line">Authors: Navid Ardeshir, Samuel Deng, Daniel Hsu, Jingwen Liu</div>
<div class="meta-line">First: 2026-01-23T17:30:13+00:00 · Latest: 2026-01-23T17:30:13+00:00</div>
<div class="links" style="margin-top:8px"><a href="https://arxiv.org/abs/2601.16922v1">Abs</a> · <a href="https://arxiv.org/pdf/2601.16922v1">PDF</a> · <a href="https://huggingface.co/huggingface">Code1</a> · <a href="https://huggingface.co/docs/hub/spaces">Code2</a></div>
<details class="detail"><summary>Abstract</summary>
<div class="mono">The sample complexity of multi-group learning is shown to improve in the group-realizable setting over the agnostic setting, even when the family of groups is infinite so long as it has finite VC dimension. The improved sample complexity is obtained by empirical risk minimization over the class of group-realizable concepts, which itself could have infinite VC dimension. Implementing this approach is also shown to be computationally intractable, and an alternative approach is suggested based on improper learning.</div></details>
<details class="detail"><summary>中文标题/摘要</summary>
<div class="mono"><b>标题：</b>通过最小化经验风险实现群组可实现的多元群组学习</div>
<div class="mono" style="margin-top:8px">研究表明，在群组可实现设定下，即使群组族是无限的（只要其VC维有限），多元群组学习的样本复杂度相较于不可知设定有所提升。这一改进的样本复杂度是通过在群组可实现概念类上进行经验风险最小化获得的，而该类本身可能具有无限VC维。同时，该方法的实现被证明在计算上是不可行的，因此提出了一种基于非恰当学习的替代方案。</div>
</details>
<details class="detail"><summary>Summary / 总结</summary>
<div class="mono">This work investigates multi-group learning in the group-realizable setting, motivated by the potential for improved sample complexity compared to the agnostic setting, even for infinite families of groups with finite VC dimension. The proposed method employs empirical risk minimization over the class of group-realizable concepts, which may have infinite VC dimension. The main findings are that this approach achieves the improved sample complexity but is computationally intractable to implement, leading to the suggestion of an alternative improper learning strategy.</div>
<div class="mono" style="margin-top:8px">本研究探讨了组可实现设定下的多组学习，其动机在于，即使组族是无限的但具有有限VC维，其样本复杂度相比不可知设定仍有提升潜力。核心方法是针对组可实现概念类进行经验风险最小化，该类本身可能具有无限VC维。主要实验结果表明，该方法确实能获得改进的样本复杂度，但同时也证明实现这种精确的经验风险最小化在计算上是不可行的，因此研究建议采用一种非适当学习的替代方案。</div>
</details>
</div>
<div class="card">
<div class="title">HEIGHT: Heterogeneous Interaction Graph Transformer for Robot Navigation in Crowded and Constrained Environments</div>
<div class="meta-line">Authors: Shuijing Liu, Haochen Xia, Fatemeh Cheraghi Pouria, Kaiwen Hong, Neeloy Chakraborty, Zichao Hu, Joydeep Biswas, Katherine Driggs-Campbell</div>
<div class="meta-line">First: 2024-11-19T00:56:35+00:00 · Latest: 2026-01-23T17:24:19+00:00</div>
<div class="meta-line">Comments: Accepted to IEEE Transactions of Automation Science and Engineering (T-ASE)</div>
<div class="links" style="margin-top:8px"><a href="https://arxiv.org/abs/2411.12150v4">Abs</a> · <a href="https://arxiv.org/pdf/2411.12150v4">PDF</a> · <a href="https://huggingface.co/huggingface">Code1</a> · <a href="https://huggingface.co/docs/hub/spaces">Code2</a> · <a href="https://sites.google.com/view/crowdnav-height/home">Project1</a></div>
<details class="detail"><summary>Abstract</summary>
<div class="mono">We study the problem of robot navigation in dense and interactive crowds with static constraints such as corridors and furniture. Previous methods fail to consider all types of spatial and temporal interactions among agents and obstacles, leading to unsafe and inefficient robot paths. In this article, we leverage a graph-based representation of crowded and constrained scenarios and propose a structured framework to learn robot navigation policies with deep reinforcement learning. We first split the representations of different inputs and propose a heterogeneous spatio-temporal graph to model distinct interactions among humans, robots, and obstacles. Based on the heterogeneous spatio-temporal graph, we propose HEIGHT, a novel navigation policy network architecture with different components to capture heterogeneous interactions through space and time. HEIGHT utilizes attention mechanisms to prioritize important interactions and a recurrent network to track changes in the dynamic scene over time, encouraging the robot to avoid collisions adaptively. Through extensive simulation and real-world experiments, we demonstrate that HEIGHT outperforms state-of-the-art baselines in terms of success, navigation time, and generalization to domain shifts in challenging navigation scenarios. More information is available at https://sites.google.com/view/crowdnav-height/home.</div></details>
<details class="detail"><summary>中文标题/摘要</summary>
<div class="mono"><b>标题：</b>HEIGHT：面向拥挤受限环境下机器人导航的异质交互图变换器</div>
<div class="mono" style="margin-top:8px">本研究针对存在走廊、家具等静态约束的密集交互人群环境中的机器人导航问题展开。现有方法未能全面考虑智能体与障碍物间的时空交互关系，导致机器人路径规划存在安全风险与效率瓶颈。本文提出基于图结构的拥挤受限场景表征框架，采用深度强化学习构建结构化导航策略。首先通过分离不同输入特征的表示方式，构建异质时空图以建模人、机器人、障碍物间的差异化交互关系。基于此，我们提出HEIGHT——一种新型导航策略网络架构，其通过多组件设计捕获时空维度的异质交互特征。该模型利用注意力机制动态评估交互重要性，结合循环网络追踪动态场景时序变化，实现机器人自适应避障。大量仿真与实物实验表明，在挑战性导航场景中，HEIGHT在成功率、导航耗时及领域迁移泛化能力方面均优于现有先进基线模型。更多信息详见：https://sites.google.com/view/crowdnav-height/home。</div>
</details>
<details class="detail"><summary>Summary / 总结</summary>
<div class="mono">This research addresses robot navigation in dense crowds with static constraints, where prior methods inadequately model spatial and temporal interactions, resulting in unsafe and inefficient paths. The authors propose HEIGHT, a framework that uses a heterogeneous spatio-temporal graph to separately represent interactions among humans, robots, and obstacles, and employs deep reinforcement learning with attention mechanisms and a recurrent network to adaptively prioritize and track dynamic interactions. Experimental results in simulation and real-world settings show that HEIGHT surpasses state-of-the-art baselines in success rate, navigation time, and generalization to domain shifts.</div>
<div class="mono" style="margin-top:8px">本研究针对机器人在密集人群和静态约束环境中的导航问题，现有方法因未能充分考虑各类时空交互而导致路径不安全且低效。作者提出HEIGHT框架，通过异质时空图分别建模人、机器人与障碍物之间的交互，并利用深度强化学习结合注意力机制和循环网络来动态优先处理并跟踪交互变化。在仿真和真实环境中的大量实验表明，HEIGHT在成功率、导航时间和对领域迁移的泛化能力上均优于现有先进方法。</div>
</details>
</div>
<div class="card">
<div class="title">Calibrated Similarity for Reliable Geometric Analysis of Embedding Spaces</div>
<div class="meta-line">Authors: Nicolas Tacheny</div>
<div class="meta-line">First: 2026-01-23T17:14:44+00:00 · Latest: 2026-01-23T17:14:44+00:00</div>
<div class="meta-line">Comments: arXiv admin note: substantial text overlap with arXiv:2512.10350</div>
<div class="links" style="margin-top:8px"><a href="https://arxiv.org/abs/2601.16907v1">Abs</a> · <a href="https://arxiv.org/pdf/2601.16907v1">PDF</a> · <a href="https://huggingface.co/huggingface">Code1</a> · <a href="https://huggingface.co/docs/hub/spaces">Code2</a></div>
<details class="detail"><summary>Abstract</summary>
<div class="mono">While raw cosine similarity in pretrained embedding spaces exhibits strong rank correlation with human judgments, anisotropy induces systematic miscalibration of absolute values: scores concentrate in a narrow high-similarity band regardless of actual semantic relatedness, limiting interpretability as a quantitative measure. Prior work addresses this by modifying the embedding space (whitening, contrastive fine tuning), but such transformations alter geometric structure and require recomputing all embeddings.
  Using isotonic regression trained on human similarity judgments, we construct a monotonic transformation that achieves near-perfect calibration while preserving rank correlation and local stability(98% across seven perturbation types). Our contribution is not to replace cosine similarity, but to restore interpretability of its absolute values through monotone calibration, without altering its ranking properties.
  We characterize isotonic calibration as an order-preserving reparameterization and prove that all order-based constructions (angular ordering, nearest neighbors, threshold graphs and quantile-based decisions) are invariant under this transformation.</div></details>
<details class="detail"><summary>中文标题/摘要</summary>
<div class="mono"><b>标题：</b>面向嵌入空间可靠几何分析的校准相似度方法</div>
<div class="mono" style="margin-top:8px">预训练嵌入空间中的原始余弦相似度虽与人类判断具有强秩相关性，但各向异性会导致绝对值的系统性失准：无论实际语义相关性如何，得分均集中在狭窄的高相似度区间，限制了其作为定量度量的可解释性。先前研究通过修改嵌入空间（白化处理、对比微调）解决此问题，但此类变换会改变几何结构且需重新计算所有嵌入。
  基于人类相似度判断训练等渗回归，我们构建了一种单调变换，在保持秩相关性与局部稳定性（七类扰动下达98%）的同时实现近乎完美的校准。本研究的贡献并非替代余弦相似度，而是通过单调校准恢复其绝对值的可解释性，且不改变其排序特性。
  我们将等渗校准表征为保序重参数化过程，并证明所有基于序关系的构造（角度排序、最近邻、阈值图及分位数决策）在此变换下均保持不变。</div>
</details>
<details class="detail"><summary>Summary / 总结</summary>
<div class="mono">The research addresses the issue that raw cosine similarity in pretrained embedding spaces, despite having strong rank correlation with human judgments, suffers from miscalibration where scores are concentrated in a narrow high-similarity band, limiting their interpretability as absolute quantitative measures. The method introduces a monotonic transformation using isotonic regression trained on human similarity judgments to calibrate the scores, which preserves the original rank correlation and local geometric stability without altering the embedding space itself. Key experimental results show that this calibration achieves near-perfect alignment with human judgments while maintaining 98% stability across various perturbation types, and it is proven to preserve invariance for all order-based geometric constructions like nearest neighbors and threshold graphs.</div>
<div class="mono" style="margin-top:8px">本研究针对预训练嵌入空间中原始余弦相似度的问题：尽管与人类判断具有强秩相关性，但其绝对值存在误校准，得分集中在狭窄的高相似度区间，限制了其作为定量度量的可解释性。方法上，利用基于人类相似度判断训练的等渗回归构建单调变换来校准得分，该方法不改变嵌入空间本身，保留了原始的秩相关性和局部几何稳定性。主要实验结果表明，该校准实现了近乎完美的校准，同时在七种扰动类型下保持了98%的稳定性，并被证明能保持所有基于顺序的几何构造（如角度排序和最近邻）的不变性。</div>
</details>
</div>
<div class="card">
<div class="title">The Trajectory Alignment Coefficient in Two Acts: From Reward Tuning to Reward Learning</div>
<div class="meta-line">Authors: Calarina Muslimani, Yunshu Du, Kenta Kawamoto, Kaushik Subramanian, Peter Stone, Peter Wurman</div>
<div class="meta-line">First: 2026-01-23T17:13:54+00:00 · Latest: 2026-01-23T17:13:54+00:00</div>
<div class="links" style="margin-top:8px"><a href="https://arxiv.org/abs/2601.16906v1">Abs</a> · <a href="https://arxiv.org/pdf/2601.16906v1">PDF</a> · <a href="https://huggingface.co/huggingface">Code1</a> · <a href="https://huggingface.co/docs/hub/spaces">Code2</a></div>
<details class="detail"><summary>Abstract</summary>
<div class="mono">The success of reinforcement learning (RL) is fundamentally tied to having a reward function that accurately reflects the task objective. Yet, designing reward functions is notoriously time-consuming and prone to misspecification. To address this issue, our first goal is to understand how to support RL practitioners in specifying appropriate weights for a reward function. We leverage the Trajectory Alignment Coefficient (TAC), a metric that evaluates how closely a reward function&#x27;s induced preferences match those of a domain expert. To evaluate whether TAC provides effective support in practice, we conducted a human-subject study in which RL practitioners tuned reward weights for Lunar Lander. We found that providing TAC during reward tuning led participants to produce more performant reward functions and report lower cognitive workload relative to standard tuning without TAC. However, the study also underscored that manual reward design, even with TAC, remains labor-intensive. This limitation motivated our second goal: to learn a reward model that maximizes TAC directly. Specifically, we propose Soft-TAC, a differentiable approximation of TAC that can be used as a loss function to train reward models from human preference data. Validated in the racing simulator Gran Turismo 7, reward models trained using Soft-TAC successfully captured preference-specific objectives, resulting in policies with qualitatively more distinct behaviors than models trained with standard Cross-Entropy loss. This work demonstrates that TAC can serve as both a practical tool for guiding reward tuning and a reward learning objective in complex domains.</div></details>
<details class="detail"><summary>中文标题/摘要</summary>
<div class="mono"><b>标题：</b>轨迹对齐系数的双重奏：从奖励调优到奖励学习</div>
<div class="mono" style="margin-top:8px">强化学习（RL）的成功根本上取决于能否获得准确反映任务目标的奖励函数。然而，设计奖励函数不仅耗时且易产生设定偏差。为解决此问题，我们的首要目标是探索如何帮助RL从业者为奖励函数设定合适的权重。我们采用轨迹对齐系数（TAC）这一指标，用于评估奖励函数所诱导的偏好与领域专家偏好的匹配程度。为验证TAC在实际应用中的有效性，我们开展了以RL从业者为对象的人因研究，要求参与者在《月球着陆器》环境中调整奖励权重。研究发现：在奖励调优过程中提供TAC反馈，能使参与者设计出性能更优的奖励函数，同时其自我报告的认知负荷低于未使用TAC的标准调优组。但研究也揭示，即使借助TAC，人工设计奖励函数仍属劳动密集型工作。这一局限性促使我们确立第二个目标：直接学习能最大化TAC的奖励模型。具体而言，我们提出Soft-TAC——一种可微分的TAC近似方法，可作为损失函数利用人类偏好数据训练奖励模型。在竞速模拟游戏《GT赛车7》中的验证表明，基于Soft-TAC训练的奖励模型能有效捕捉特定偏好目标，所产生的策略行为在质性上比标准交叉熵损失训练的模型具有更显著的差异性。本研究表明，TAC既能作为指导奖励调优的实用工具，也可成为复杂领域中奖励学习的目标函数。</div>
</details>
<details class="detail"><summary>Summary / 总结</summary>
<div class="mono">The research addresses the challenge of designing accurate reward functions in reinforcement learning, which is often time-consuming and prone to misspecification. The method first employs the Trajectory Alignment Coefficient (TAC) as a metric to align reward-induced preferences with expert judgments, evaluating its utility through a human-subject study where practitioners tuned reward weights for Lunar Lander. Experimental results showed that providing TAC led to more performant reward functions and lower cognitive workload compared to standard tuning, though manual design remained laborious. This limitation motivated a second approach, Soft-TAC, a differentiable approximation used as a loss function to train reward models from human preference data; in Gran Turismo 7, models trained with Soft-TAC captured preference-specific objectives and produced policies with more distinct behaviors than those trained with Cross-Entropy loss.</div>
<div class="mono" style="margin-top:8px">本研究针对强化学习中奖励函数设计耗时且易出错的问题展开。首先，研究探讨了利用轨迹对齐系数（TAC）来辅助从业者手动调整奖励权重，以使奖励诱导的偏好与专家判断一致；在Lunar Lander平台上的人体实验表明，TAC指导能帮助参与者设计出性能更优的奖励函数并降低认知负荷。鉴于手动调整仍费时费力，研究进一步提出了Soft-TAC，即TAC的可微分近似，用于直接从人类偏好数据中学习奖励模型；在Gran Turismo 7模拟器中的验证显示，基于Soft-TAC训练的模型能捕捉偏好特定目标，并产生比交叉熵损失训练模型行为差异更显著的策略。</div>
</details>
</div>
<div class="card">
<div class="title">GRIP: Algorithm-Agnostic Machine Unlearning for Mixture-of-Experts via Geometric Router Constraints</div>
<div class="meta-line">Authors: Andy Zhu, Rongzhe Wei, Yupu Gu, Pan Li</div>
<div class="meta-line">First: 2026-01-23T17:13:54+00:00 · Latest: 2026-01-23T17:13:54+00:00</div>
<div class="links" style="margin-top:8px"><a href="https://arxiv.org/abs/2601.16905v1">Abs</a> · <a href="https://arxiv.org/pdf/2601.16905v1">PDF</a> · <a href="https://huggingface.co/huggingface">Code1</a> · <a href="https://huggingface.co/docs/hub/spaces">Code2</a></div>
<details class="detail"><summary>Abstract</summary>
<div class="mono">Machine unlearning (MU) for large language models has become critical for AI safety, yet existing methods fail to generalize to Mixture-of-Experts (MoE) architectures. We identify that traditional unlearning methods exploit MoE&#x27;s architectural vulnerability: they manipulate routers to redirect queries away from knowledgeable experts rather than erasing knowledge, causing a loss of model utility and superficial forgetting. We propose Geometric Routing Invariance Preservation (GRIP), an algorithm-agnostic framework for unlearning for MoE. Our core contribution is a geometric constraint, implemented by projecting router gradient updates into an expert-specific null-space. Crucially, this decouples routing stability from parameter rigidity: while discrete expert selections remain stable for retained knowledge, the continuous router parameters remain plastic within the null space, allowing the model to undergo necessary internal reconfiguration to satisfy unlearning objectives. This forces the unlearning optimization to erase knowledge directly from expert parameters rather than exploiting the superficial router manipulation shortcut. GRIP functions as an adapter, constraining router parameter updates without modifying the underlying unlearning algorithm. Extensive experiments on large-scale MoE models demonstrate that our adapter eliminates expert selection shift (achieving over 95% routing stability) across all tested unlearning methods while preserving their utility. By preventing existing algorithms from exploiting MoE model&#x27;s router vulnerability, GRIP adapts existing unlearning research from dense architectures to MoEs.</div></details>
<details class="detail"><summary>中文标题/摘要</summary>
<div class="mono"><b>标题：</b>GRIP：面向专家混合模型的几何路由约束式算法无关机器遗忘框架</div>
<div class="mono" style="margin-top:8px">大语言模型的机器遗忘对AI安全至关重要，但现有方法无法推广至专家混合架构。我们发现传统遗忘方法利用了MoE的结构脆弱性：通过操纵路由器将查询从知识丰富的专家处转移，而非真正擦除知识，导致模型效用损失和表面遗忘。本文提出几何路由不变性保持框架GRIP，这是一种面向MoE的算法无关遗忘框架。核心贡献是几何约束机制，通过将路由器梯度更新投影至专家特定零空间实现。该设计关键解耦了路由稳定性与参数刚性：离散专家选择对保留知识保持稳定，而连续路由器参数在零空间内保持可塑性，使模型能通过内部重构实现遗忘目标。这迫使遗忘优化直接擦除专家参数中的知识，而非利用路由器操纵的捷径。GRIP作为适配器，在不修改底层遗忘算法的前提下约束路由器参数更新。大规模MoE模型实验表明，该适配器能在所有测试方法中消除专家选择偏移（路由稳定性超95%），同时保持模型效用。通过阻断现有算法对MoE路由器脆弱性的利用，GRIP将稠密架构的遗忘研究成功适配至MoE模型。</div>
</details>
<details class="detail"><summary>Summary / 总结</summary>
<div class="mono">The research addresses the challenge of machine unlearning in Mixture-of-Experts (MoE) models, where existing methods fail by superficially manipulating routers to redirect queries instead of erasing knowledge, leading to utility loss. The proposed method, GRIP, is an algorithm-agnostic framework that imposes a geometric constraint by projecting router gradient updates into an expert-specific null-space, thereby stabilizing expert selection while allowing continuous router parameters to adapt for unlearning. Experimental results on large-scale MoE models show that GRIP achieves over 95% routing stability across various unlearning methods, effectively preventing router exploitation and preserving model utility.</div>
<div class="mono" style="margin-top:8px">该研究的动机是大型语言模型，特别是混合专家架构中机器遗忘的需求，现有方法因肤浅地操纵路由器来重定向查询而非擦除知识而失效，损害了模型效用。该方法提出了GRIP，一个算法无关的框架，通过将路由器梯度更新投影到专家特定的零空间来施加几何约束，解耦路由稳定性和参数刚性，从而迫使知识直接从专家参数中擦除。在大型混合专家模型上的实验结果表明，GRIP消除了专家选择偏移，在各种遗忘方法中实现了超过95%的路由稳定性，同时保持了模型效用，从而将现有的遗忘研究适配到混合专家架构。</div>
</details>
</div>
<div class="card">
<div class="title">Embedding -based Crop Type Classification in the Groundnut Basin of Senegal</div>
<div class="meta-line">Authors: Madeline C. Lisaius, Srinivasan Keshav, Andrew Blake, Clement Atzberger</div>
<div class="meta-line">First: 2026-01-23T17:05:40+00:00 · Latest: 2026-01-23T17:05:40+00:00</div>
<div class="links" style="margin-top:8px"><a href="https://arxiv.org/abs/2601.16900v1">Abs</a> · <a href="https://arxiv.org/pdf/2601.16900v1">PDF</a> · <a href="https://huggingface.co/huggingface">Code1</a> · <a href="https://huggingface.co/docs/hub/spaces">Code2</a></div>
<details class="detail"><summary>Abstract</summary>
<div class="mono">Crop type maps from satellite remote sensing are important tools for food security, local livelihood support and climate change mitigation in smallholder regions of the world, but most satellite-based methods are not well suited to smallholder conditions. To address this gap, we establish a four-part criteria for a useful embedding-based approach consisting of 1) performance, 2) plausibility, 3) transferability and 4) accessibility and evaluate geospatial foundation model (FM) embeddings -based approaches using TESSERA and AlphaEarth against current baseline methods for a region in the groundnut basin of Senegal. We find that the TESSERA -based approach to land cover and crop type mapping fulfills the selection criteria best, and in one temporal transfer example shows 28% higher accuracy compared to the next best method. These results indicate that TESSERA embeddings are an effective approach for crop type classification and mapping tasks in Senegal.</div></details>
<details class="detail"><summary>中文标题/摘要</summary>
<div class="mono"><b>标题：</b>基于嵌入的塞内加尔花生盆地作物类型分类</div>
<div class="mono" style="margin-top:8px">卫星遥感作物类型图是全球小农地区粮食安全、生计支持与气候变化应对的重要工具，但多数卫星方法难以适配小农耕作条件。为填补这一空白，本研究建立了包含性能、合理性、可迁移性与可访问性四要素的嵌入方法评价标准，并基于地理空间基础模型嵌入方法（TESSERA与AlphaEarth），在塞内加尔花生盆地与现有基线方法进行对比评估。研究发现，基于TESSERA的土地覆盖与作物类型制图方法最符合筛选标准，在时序迁移案例中其精度较次优方法提升28%。结果表明，TESSERA嵌入是塞内加尔作物分类与制图任务的有效解决方案。</div>
</details>
<details class="detail"><summary>Summary / 总结</summary>
<div class="mono">Crop type maps from satellite data are crucial for food security and climate adaptation in smallholder regions, but existing methods often underperform in these complex agricultural landscapes. To bridge this gap, the study proposes a four-part evaluation framework—assessing performance, plausibility, transferability, and accessibility—and compares geospatial foundation model embeddings from TESSERA and AlphaEarth against baseline methods in Senegal&#x27;s Groundnut Basin. Experimental results show that the TESSERA-based approach best meets all criteria, achieving a 28% higher accuracy in one temporal transfer test compared to the next best method, demonstrating its effectiveness for crop classification in the region.</div>
<div class="mono" style="margin-top:8px">卫星遥感作物类型图对于小农地区的粮食安全和气候适应至关重要，但现有方法往往不适用于小农农业的破碎化景观。为弥补这一不足，本研究提出了一个四部分评估框架——涵盖性能、合理性、可迁移性和可访问性——并比较了地理空间基础模型（TESSERA和AlphaEarth）的嵌入表示与基线方法在塞内加尔花生盆地作物分类中的应用。实验结果表明，基于TESSERA的方法最能满足所有标准，在一次时间迁移示例中，其准确率比次优方法高出28%，证明了其在小农环境下作物分类与制图任务中的有效性。</div>
</details>
</div>
<div class="card">
<div class="title">FedSGM: A Unified Framework for Constraint Aware, Bidirectionally Compressed, Multi-Step Federated Optimization</div>
<div class="meta-line">Authors: Antesh Upadhyay, Sang Bin Moon, Abolfazl Hashemi</div>
<div class="meta-line">First: 2026-01-23T17:03:06+00:00 · Latest: 2026-01-23T17:03:06+00:00</div>
<div class="links" style="margin-top:8px"><a href="https://arxiv.org/abs/2601.16897v1">Abs</a> · <a href="https://arxiv.org/pdf/2601.16897v1">PDF</a> · <a href="https://huggingface.co/huggingface">Code1</a> · <a href="https://huggingface.co/docs/hub/spaces">Code2</a></div>
<details class="detail"><summary>Abstract</summary>
<div class="mono">We introduce FedSGM, a unified framework for federated constrained optimization that addresses four major challenges in federated learning (FL): functional constraints, communication bottlenecks, local updates, and partial client participation. Building on the switching gradient method, FedSGM provides projection-free, primal-only updates, avoiding expensive dual-variable tuning or inner solvers. To handle communication limits, FedSGM incorporates bi-directional error feedback, correcting the bias introduced by compression while explicitly understanding the interaction between compression noise and multi-step local updates. We derive convergence guarantees showing that the averaged iterate achieves the canonical $\boldsymbol{\mathcal{O}}(1/\sqrt{T})$ rate, with additional high-probability bounds that decouple optimization progress from sampling noise due to partial participation. Additionally, we introduce a soft switching version of FedSGM to stabilize updates near the feasibility boundary. To our knowledge, FedSGM is the first framework to unify functional constraints, compression, multiple local updates, and partial client participation, establishing a theoretically grounded foundation for constrained federated learning. Finally, we validate the theoretical guarantees of FedSGM via experimentation on Neyman-Pearson classification and constrained Markov decision process (CMDP) tasks.</div></details>
<details class="detail"><summary>中文标题/摘要</summary>
<div class="mono"><b>标题：</b>FedSGM：面向约束感知、双向压缩、多步联邦优化的统一框架</div>
<div class="mono" style="margin-top:8px">本文提出FedSGM，一个用于联邦约束优化的统一框架，旨在解决联邦学习中的四大挑战：函数约束、通信瓶颈、本地更新与部分客户端参与。基于切换梯度法，FedSGM提供无需投影、仅需原始变量更新的方法，避免了昂贵的对偶变量调优或内部求解器。为应对通信限制，FedSGM引入双向误差反馈机制，在修正压缩引入偏差的同时，显式解析压缩噪声与多步本地更新间的交互作用。我们推导出收敛性保证，证明平均迭代可达经典$\boldsymbol{\mathcal{O}}(1/\sqrt{T})$收敛速率，并给出额外的高概率边界，将优化进程与部分参与导致的采样噪声解耦。此外，我们提出FedSGM的软切换版本以稳定可行性边界附近的更新。据我们所知，FedSGM是首个统一处理函数约束、压缩、多步本地更新与部分客户端参与的框架，为约束联邦学习奠定了理论基础。最后，通过在Neyman-Pearson分类与约束马尔可夫决策过程任务上的实验，验证了FedSGM的理论保证。</div>
</details>
<details class="detail"><summary>Summary / 总结</summary>
<div class="mono">The research is motivated by the need to address four key challenges in federated learning: functional constraints, communication bottlenecks, multiple local updates, and partial client participation. The proposed method, FedSGM, is a unified framework based on the switching gradient method, offering projection-free, primal-only updates and incorporating bi-directional error feedback to correct compression bias while explicitly modeling the interaction between compression noise and multi-step local updates. Experimental validation on Neyman-Pearson classification and constrained Markov decision process tasks confirms the theoretical convergence guarantees, showing that the averaged iterate achieves an O(1/√T) rate with high-probability bounds that decouple optimization progress from sampling noise.</div>
<div class="mono" style="margin-top:8px">本研究旨在解决联邦学习中的四个关键挑战：函数约束、通信瓶颈、多步本地更新和部分客户端参与。提出的FedSGM框架基于切换梯度方法，提供无需投影的纯原始变量更新，避免了复杂的对偶变量调优。该框架结合双向误差反馈来校正压缩偏差，同时显式建模压缩噪声与多步本地更新之间的相互作用。理论分析表明平均迭代达到O(1/√T)收敛速率，其高概率边界将优化进展与采样噪声解耦。在Neyman-Pearson分类和约束马尔可夫决策过程任务上的实验验证了理论保证。</div>
</details>
</div>
<div class="card">
<div class="title">LLM-Based Adversarial Persuasion Attacks on Fact-Checking Systems</div>
<div class="meta-line">Authors: João A. Leite, Olesya Razuvayevskaya, Kalina Bontcheva, Carolina Scarton</div>
<div class="meta-line">First: 2026-01-23T16:57:16+00:00 · Latest: 2026-01-23T16:57:16+00:00</div>
<div class="links" style="margin-top:8px"><a href="https://arxiv.org/abs/2601.16890v1">Abs</a> · <a href="https://arxiv.org/pdf/2601.16890v1">PDF</a> · <a href="https://huggingface.co/huggingface">Code1</a> · <a href="https://huggingface.co/docs/hub/spaces">Code2</a></div>
<details class="detail"><summary>Abstract</summary>
<div class="mono">Automated fact-checking (AFC) systems are susceptible to adversarial attacks, enabling false claims to evade detection. Existing adversarial frameworks typically rely on injecting noise or altering semantics, yet no existing framework exploits the adversarial potential of persuasion techniques, which are widely used in disinformation campaigns to manipulate audiences. In this paper, we introduce a novel class of persuasive adversarial attacks on AFCs by employing a generative LLM to rephrase claims using persuasion techniques. Considering 15 techniques grouped into 6 categories, we study the effects of persuasion on both claim verification and evidence retrieval using a decoupled evaluation strategy. Experiments on the FEVER and FEVEROUS benchmarks show that persuasion attacks can substantially degrade both verification performance and evidence retrieval. Our analysis identifies persuasion techniques as a potent class of adversarial attacks, highlighting the need for more robust AFC systems.</div></details>
<details class="detail"><summary>中文标题/摘要</summary>
<div class="mono"><b>标题：</b>基于大语言模型的事实核查系统对抗性说服攻击</div>
<div class="mono" style="margin-top:8px">自动化事实核查系统易受对抗攻击，使虚假声明得以规避检测。现有对抗框架多依赖注入噪声或改变语义，尚未有框架利用说服技术的对抗潜力——该技术广泛用于虚假信息传播以操纵受众。本文通过使用生成式大语言模型，采用说服技术重述声明，提出一类针对事实核查系统的新型说服性对抗攻击。基于6大类15种说服技术，我们采用解耦评估策略研究说服对声明验证与证据检索的影响。在FEVER和FEVEROUS基准测试上的实验表明，说服攻击能显著降低验证性能与证据检索效果。分析证实说服技术构成一类强效对抗攻击，凸显了构建更鲁棒事实核查系统的必要性。</div>
</details>
<details class="detail"><summary>Summary / 总结</summary>
<div class="mono">Automated fact-checking systems are vulnerable to adversarial attacks that allow false claims to bypass detection, but existing methods often rely on noise injection or semantic alterations without exploring persuasion techniques commonly used in disinformation. To address this, the authors propose a novel adversarial attack framework that employs a generative large language model to rephrase claims using 15 persuasion techniques across six categories, evaluating their impact on both claim verification and evidence retrieval through a decoupled strategy. Experiments on the FEVER and FEVEROUS benchmarks demonstrate that these persuasion attacks significantly degrade verification performance and evidence retrieval, revealing persuasion as a potent class of adversarial threats and underscoring the need for more robust fact-checking systems.</div>
<div class="mono" style="margin-top:8px">自动事实核查系统易受对抗性攻击影响，导致虚假声明逃避检测，但现有方法多依赖噪声注入或语义修改，未利用虚假信息活动中常见的说服技术。为此，研究者提出一种新颖的对抗攻击框架，使用生成式大语言模型，基于六类共15种说服技术对声明进行重述，并通过解耦评估策略分析其对声明验证和证据检索的影响。在FEVER和FEVEROUS基准上的实验表明，说服攻击能显著降低验证性能和证据检索效果，揭示了说服技术作为一类强效对抗攻击的威胁，强调了构建更鲁棒的事实核查系统的必要性。</div>
</details>
</div>
<div class="card">
<div class="title">Equivariant Flow Matching for Symmetry-Breaking Bifurcation Problems</div>
<div class="meta-line">Authors: Fleur Hendriks, Ondřej Rokoš, Martin Doškář, Marc G. D. Geers, Vlado Menkovski</div>
<div class="meta-line">Venue: NeurIPS 2025</div>
<div class="meta-line">First: 2025-09-03T14:18:05+00:00 · Latest: 2026-01-23T16:51:17+00:00</div>
<div class="meta-line">Comments: 9 pages, 7 figures including appendices. Accepted to Machine Learning and the Physical Sciences Workshop, NeurIPS 2025 (https://ml4physicalsciences.github.io/2025/). Repository with corresponding code: https://github.com/FHendriks11/bifurcationML/. Video explanation: https://www.youtube.com/watch?v=wsL3h17KtjY</div>
<div class="links" style="margin-top:8px"><a href="https://arxiv.org/abs/2509.03340v3">Abs</a> · <a href="https://arxiv.org/pdf/2509.03340v3">PDF</a> · <a href="https://github.com/FHendriks11/bifurcationML/">Code1</a> · <a href="https://huggingface.co/huggingface">Code2</a> · <a href="https://huggingface.co/docs/hub/spaces">Code3</a> · <a href="https://ml4physicalsciences.github.io/2025/">Project1</a></div>
<details class="detail"><summary>Abstract</summary>
<div class="mono">Bifurcation phenomena in nonlinear dynamical systems often lead to multiple coexisting stable solutions, particularly in the presence of symmetry breaking. Deterministic machine learning models are unable to capture this multiplicity, averaging over solutions and failing to represent lower-symmetry outcomes. In this work, we formalize the use of generative AI, specifically flow matching, as a principled way to model the full probability distribution over bifurcation outcomes. Our approach builds on existing techniques by combining flow matching with equivariant architectures and an optimal-transport-based coupling mechanism. We generalize equivariant flow matching to a symmetric coupling strategy that aligns predicted and target outputs under group actions, allowing accurate learning in equivariant settings. We validate our approach on a range of systems, from simple conceptual systems to physical problems such as buckling beams and the Allen--Cahn equation. The results demonstrate that the approach accurately captures multimodal distributions and symmetry-breaking bifurcations. Moreover, our results demonstrate that flow matching significantly outperforms non-probabilistic and variational methods. This offers a principled and scalable solution for modeling multistability in high-dimensional systems.</div></details>
<details class="detail"><summary>中文标题/摘要</summary>
<div class="mono"><b>标题：</b>面向对称破缺分岔问题的等变流匹配方法</div>
<div class="mono" style="margin-top:8px">非线性动力系统中的分岔现象常导致多个稳定解共存，尤其在对称破缺情形下。确定性机器学习模型无法捕捉这种多重性，会因对不同解取平均而无法表征低对称性结果。本研究将生成式人工智能（特别是流匹配）形式化为一种建模分岔结果全概率分布的原则性方法。该方法基于现有技术，将流匹配与等变架构及基于最优传输的耦合机制相结合。我们将等变流匹配推广至对称耦合策略，使预测输出与目标输出在群作用下对齐，从而在等变设定中实现精确学习。通过从简单概念系统到物理问题（如屈曲梁和Allen-Cahn方程）的一系列系统验证，结果表明该方法能准确捕捉多峰分布与对称破缺分岔现象，且流匹配显著优于非概率方法与变分方法。这为高维系统多稳态建模提供了原则性可扩展的解决方案。</div>
</details>
<details class="detail"><summary>Summary / 总结</summary>
<div class="mono">This research addresses the inability of deterministic machine learning models to capture multiple coexisting stable solutions in nonlinear dynamical systems undergoing symmetry-breaking bifurcations, where such models average over solutions and fail to represent lower-symmetry outcomes. The method formalizes the use of generative AI, specifically flow matching, as a principled approach to model the full probability distribution over bifurcation outcomes by combining flow matching with equivariant architectures and an optimal-transport-based coupling mechanism; it generalizes equivariant flow matching with a symmetric coupling strategy that aligns predicted and target outputs under group actions. Experimental validation on systems ranging from simple conceptual models to physical problems like buckling beams and the Allen-Cahn equation demonstrates that the approach accurately captures multimodal distributions and symmetry-breaking bifurcations, significantly outperforming non-probabilistic and variational methods.</div>
<div class="mono" style="margin-top:8px">本研究针对确定性机器学习模型在捕捉具有对称破缺分岔的非线性动力系统中多个共存稳定解时的局限性，这些模型会对解进行平均而无法表示低对称性结果。该方法通过将流匹配与等变架构以及基于最优传输的对称耦合策略相结合，形式化了生成式AI（特别是流匹配）的使用，该策略在群作用下对齐预测与目标输出，以建模分岔结果的完整概率分布。在从简单概念系统到物理问题（如屈曲梁和Allen-Cahn方程）的一系列系统上的实验验证表明，该方法能准确捕捉多峰分布和对称破缺分岔，显著优于非概率性和变分方法。</div>
</details>
</div>
<div class="card">
<div class="title">Multi-scale Graph Autoregressive Modeling: Molecular Property Prediction via Next Token Prediction</div>
<div class="meta-line">Authors: Zhuoyang Jiang, Yaosen Min, Peiran Jin, Lei Chen</div>
<div class="meta-line">First: 2026-01-05T20:06:11+00:00 · Latest: 2026-01-23T16:49:47+00:00</div>
<div class="links" style="margin-top:8px"><a href="https://arxiv.org/abs/2601.02530v3">Abs</a> · <a href="https://arxiv.org/pdf/2601.02530v3">PDF</a> · <a href="https://huggingface.co/huggingface">Code1</a> · <a href="https://huggingface.co/docs/hub/spaces">Code2</a></div>
<details class="detail"><summary>Abstract</summary>
<div class="mono">We present Connection-Aware Motif Sequencing (CamS), a graph-to-sequence representation that enables decoder-only Transformers to learn molecular graphs via standard next-token prediction (NTP). For molecular property prediction, SMILES-based NTP scales well but lacks explicit topology, whereas graph-native masked modeling captures connectivity but risks disrupting the pivotal chemical details (e.g., activity cliffs). CamS bridges this gap by serializing molecular graphs into structure-rich causal sequences. CamS first mines data-driven connection-aware motifs. It then serializes motifs via scaffold-rooted breadth-first search (BFS) to establish a stable core-to-periphery order. Crucially, CamS enables hierarchical modeling by concatenating sequences from fine to coarse motif scales, allowing the model to condition global scaffolds on dense, uncorrupted local structural evidence. We instantiate CamS-LLaMA by pre-training a vanilla LLaMA backbone on CamS sequences. It achieves state-of-the-art performance on MoleculeNet and the activity-cliff benchmark MoleculeACE, outperforming both SMILES-based language models and strong graph baselines. Interpretability analysis confirms that our multi-scale causal serialization effectively drives attention toward cliff-determining differences.</div></details>
<details class="detail"><summary>中文标题/摘要</summary>
<div class="mono"><b>标题：</b>多尺度图自回归建模：通过下一标记预测实现分子性质预测</div>
<div class="mono" style="margin-top:8px">我们提出连接感知基序序列化方法（CamS），这是一种图到序列的表征方法，使仅解码器Transformer能够通过标准下一标记预测（NTP）学习分子图。对于分子性质预测，基于SMILES的NTP扩展性良好但缺乏显式拓扑结构，而图原生掩码建模能捕捉连接性却可能破坏关键化学细节（如活性悬崖）。CamS通过将分子图序列化为结构丰富的因果序列来弥合这一差距。该方法首先挖掘数据驱动的连接感知基序，随后通过基于骨架的广度优先搜索（BFS）对基序进行序列化，建立稳定的从核心到外围的顺序。关键的是，CamS通过串联从细粒度到粗粒度的多尺度基序序列实现分层建模，使模型能够基于密集且未破坏的局部结构证据来调整全局骨架。我们通过在CamS序列上预训练标准LLaMA主干网络实例化CamS-LLaMA模型。该模型在MoleculeNet和活性悬崖基准MoleculeACE上取得最先进性能，优于基于SMILES的语言模型和强图基线。可解释性分析证实，我们的多尺度因果序列化能有效驱动注意力聚焦于决定活性悬崖的关键差异。</div>
</details>
<details class="detail"><summary>Summary / 总结</summary>
<div class="mono">The research aims to improve molecular property prediction by addressing the limitations of existing methods: SMILES-based next-token prediction lacks explicit molecular topology, while graph-native masked modeling can disrupt critical chemical details like activity cliffs. The proposed method, Connection-Aware Motif Sequencing (CamS), serializes molecular graphs into causal sequences by first mining data-driven, connection-aware motifs and then ordering them via a scaffold-rooted breadth-first search to create a stable core-to-periphery sequence; it further enables hierarchical modeling by concatenating sequences from fine to coarse motif scales. Experimental results show that CamS-LLaMA, a model pre-trained with this approach, achieves state-of-the-art performance on MoleculeNet and the activity-cliff benchmark MoleculeACE, outperforming both SMILES-based language models and graph baselines, with interpretability analysis confirming its effectiveness in focusing on cliff-determining structural differences.</div>
<div class="mono" style="margin-top:8px">本研究旨在改进分子性质预测，以解决现有方法的局限：基于SMILES的下一标记预测缺乏明确的拓扑信息，而基于图结构的掩码建模可能破坏如活性悬崖等关键化学细节。所提出的方法——连接感知基序序列化（CamS）——通过首先挖掘数据驱动的连接感知基序，然后通过基于骨架的广度优先搜索对其进行排序，以创建稳定的从核心到外围的序列，从而将分子图序列化为因果序列；该方法还通过串联从精细到粗糙的基序尺度序列来实现分层建模。实验结果表明，使用该方法预训练的CamS-LLaMA模型在MoleculeNet和MoleculeACE活性悬崖基准测试中取得了最先进的性能，优于基于SMILES的语言模型和图基线方法，可解释性分析证实了其能有效聚焦于决定活性悬崖的结构差异。</div>
</details>
</div>
<div class="card">
<div class="title">Gradient-Based Neuroplastic Adaptation for Concurrent Optimization of Neuro-Fuzzy Networks</div>
<div class="meta-line">Authors: John Wesley Hostetter, Min Chi</div>
<div class="meta-line">First: 2025-06-26T21:08:11+00:00 · Latest: 2026-01-23T16:49:40+00:00</div>
<div class="meta-line">Comments: 52 pages</div>
<div class="links" style="margin-top:8px"><a href="https://arxiv.org/abs/2506.21771v2">Abs</a> · <a href="https://arxiv.org/pdf/2506.21771v2">PDF</a> · <a href="https://huggingface.co/huggingface">Code1</a> · <a href="https://huggingface.co/docs/hub/spaces">Code2</a></div>
<details class="detail"><summary>Abstract</summary>
<div class="mono">Neuro-fuzzy networks (NFNs) are transparent, symbolic, and universal function approximations that perform as well as conventional neural architectures, but their knowledge is expressed as linguistic IF-THEN rules. Despite these advantages, their systematic design process remains a challenge. Existing work will often sequentially build NFNs by inefficiently isolating parametric and structural identification, leading to a premature commitment to brittle and subpar architecture. We propose a novel application-independent approach called gradient-based neuroplastic adaptation for the concurrent optimization of NFNs&#x27; parameters and structure. By recognizing that NFNs&#x27; parameters and structure should be optimized simultaneously as they are deeply conjoined, settings previously unapproachable for NFNs are now accessible, such as the online reinforcement learning of NFNs for vision-based tasks. The effectiveness of concurrently optimizing NFNs is empirically shown as it is trained by online reinforcement learning to proficiently play challenging scenarios from a vision-based video game called DOOM.</div></details>
<details class="detail"><summary>中文标题/摘要</summary>
<div class="mono"><b>标题：</b>基于梯度的神经可塑性适应方法用于神经模糊网络的协同优化</div>
<div class="mono" style="margin-top:8px">神经模糊网络（NFNs）是透明、符号化且通用的函数逼近器，其性能与传统神经架构相当，但其知识以语言化的IF-THEN规则表达。尽管具备这些优势，其系统化设计过程仍面临挑战。现有研究常通过低效地分离参数与结构识别来顺序构建NFNs，导致过早固化于脆弱且次优的架构。我们提出一种独立于应用的新方法——基于梯度的神经可塑性适应，用于协同优化NFNs的参数与结构。该方法认识到NFNs的参数与结构因深度耦合而需同步优化，从而使得NFNs能够应用于以往难以触及的场景，例如基于视觉任务的NFNs在线强化学习。通过在线强化学习训练NFNs熟练应对基于视觉的游戏《DOOM》中的挑战性场景，实验验证了协同优化NFNs的有效性。</div>
</details>
<details class="detail"><summary>Summary / 总结</summary>
<div class="mono">The research addresses the challenge of systematically designing neuro-fuzzy networks (NFNs), which are transparent and universal approximators but often suffer from inefficient sequential optimization of parameters and structure, leading to brittle architectures. The proposed method, gradient-based neuroplastic adaptation, concurrently optimizes both parameters and structure by leveraging their deep interconnection, enabling applications like online reinforcement learning for vision-based tasks. Experimental results demonstrate that this approach allows NFNs to be effectively trained via online reinforcement learning to proficiently handle challenging scenarios in the vision-based video game DOOM.</div>
<div class="mono" style="margin-top:8px">本研究针对神经模糊网络（NFNs）系统化设计中的挑战，这类网络虽具有透明性和通用逼近能力，但现有方法常低效地分离参数与结构识别，导致架构脆弱且性能不佳。所提出的方法——基于梯度的神经可塑性适应——实现了参数与结构的并发优化，认识到两者的深度关联，从而使NFNs能够应用于先前难以处理的场景，如基于视觉任务的在线强化学习。实验结果表明，该方法有效，通过在线强化学习训练的NFNs在基于视觉的视频游戏DOOM中能熟练应对具有挑战性的场景。</div>
</details>
</div>
<div class="card">
<div class="title">Multigrade Neural Network Approximation</div>
<div class="meta-line">Authors: Shijun Zhang, Zuowei Shen, Yuesheng Xu</div>
<div class="meta-line">First: 2026-01-23T16:46:25+00:00 · Latest: 2026-01-23T16:46:25+00:00</div>
<div class="links" style="margin-top:8px"><a href="https://arxiv.org/abs/2601.16884v1">Abs</a> · <a href="https://arxiv.org/pdf/2601.16884v1">PDF</a> · <a href="https://huggingface.co/huggingface">Code1</a> · <a href="https://huggingface.co/docs/hub/spaces">Code2</a></div>
<details class="detail"><summary>Abstract</summary>
<div class="mono">We study multigrade deep learning (MGDL) as a principled framework for structured error refinement in deep neural networks. While the approximation power of neural networks is now relatively well understood, training very deep architectures remains challenging due to highly non-convex and often ill-conditioned optimization landscapes. In contrast, for relatively shallow networks, most notably one-hidden-layer $\texttt{ReLU}$ models, training admits convex reformulations with global guarantees, motivating learning paradigms that improve stability while scaling to depth. MGDL builds upon this insight by training deep networks grade by grade: previously learned grades are frozen, and each new residual block is trained solely to reduce the remaining approximation error, yielding an interpretable and stable hierarchical refinement process. We develop an operator-theoretic foundation for MGDL and prove that, for any continuous target function, there exists a fixed-width multigrade $\texttt{ReLU}$ scheme whose residuals decrease strictly across grades and converge uniformly to zero. To the best of our knowledge, this work provides the first rigorous theoretical guarantee that grade-wise training yields provable vanishing approximation error in deep networks. Numerical experiments further illustrate the theoretical results.</div></details>
<details class="detail"><summary>中文标题/摘要</summary>
<div class="mono"><b>标题：</b>多级神经网络逼近</div>
<div class="mono" style="margin-top:8px">本研究将多级深度学习（MGDL）作为深度神经网络结构化误差修正的原理性框架进行探讨。尽管神经网络的逼近能力已得到较好理解，但极深架构的训练仍因高度非凸且常呈病态的优化空间而面临挑战。相比之下，较浅层网络（尤其是单隐层$\texttt{ReLU}$模型）可通过凸优化重构获得全局收敛保证，这启发了在扩展深度时提升稳定性的学习范式。MGDL基于此洞见实施逐级训练：已习得层级参数被冻结，每个新增残差块仅针对剩余逼近误差进行训练，形成可解释且稳定的层次化修正过程。我们建立了MGDL的算子理论基础，并证明对任意连续目标函数，存在固定宽度的多级$\texttt{ReLU}$方案，其残差严格逐级递减且一致收敛至零。据我们所知，该研究首次为深度网络中逐级训练可证明实现逼近误差消失提供了严格理论保证。数值实验进一步验证了理论结果。</div>
</details>
<details class="detail"><summary>Summary / 总结</summary>
<div class="mono">This research addresses the challenge of training deep neural networks, which often face non-convex and ill-conditioned optimization landscapes, by leveraging the more stable training properties of shallow networks, particularly one-hidden-layer ReLU models that admit convex reformulations. The proposed method, Multigrade Deep Learning (MGDL), trains deep networks in a structured, grade-by-grade manner: each new residual block is trained to reduce the remaining approximation error while previously learned grades are frozen, creating an interpretable hierarchical refinement process. Theoretically, the authors prove that for any continuous target function, a fixed-width multigrade ReLU scheme exists where residuals strictly decrease and converge uniformly to zero, providing the first rigorous guarantee that grade-wise training yields provable vanishing approximation error, which is further supported by numerical experiments.</div>
<div class="mono" style="margin-top:8px">本研究针对深度神经网络训练中常见的非凸和病态优化难题，提出了一种结构化误差精炼框架。该方法称为多层级深度学习（MGDL），通过逐级训练深度网络：冻结先前学习的浅层网络（层级），并顺序训练新的残差块以减少剩余近似误差，从而利用浅层ReLU网络凸训练的优势。理论上，作者证明了对于任意连续目标函数，存在一个固定宽度的多层级ReLU方案，其残差严格递减并一致收敛到零，这为通过逐级训练实现可证明的逼近误差消失提供了首个严格理论保证。数值实验进一步验证了理论结果，展示了该方法的稳定性和可解释的层次精炼过程。</div>
</details>
</div>
<div class="card">
<div class="title">Theory of Minimal Weight Perturbations in Deep Networks and its Applications for Low-Rank Activated Backdoor Attacks</div>
<div class="meta-line">Authors: Bethan Evans, Jared Tanner</div>
<div class="meta-line">First: 2026-01-23T16:41:58+00:00 · Latest: 2026-01-23T16:41:58+00:00</div>
<div class="links" style="margin-top:8px"><a href="https://arxiv.org/abs/2601.16880v1">Abs</a> · <a href="https://arxiv.org/pdf/2601.16880v1">PDF</a> · <a href="https://huggingface.co/huggingface">Code1</a> · <a href="https://huggingface.co/docs/hub/spaces">Code2</a></div>
<details class="detail"><summary>Abstract</summary>
<div class="mono">The minimal norm weight perturbations of DNNs required to achieve a specified change in output are derived and the factors determining its size are discussed. These single-layer exact formulae are contrasted with more generic multi-layer Lipschitz constant based robustness guarantees; both are observed to be of the same order which indicates similar efficacy in their guarantees. These results are applied to precision-modification-activated backdoor attacks, establishing provable compression thresholds below which such attacks cannot succeed, and show empirically that low-rank compression can reliably activate latent backdoors while preserving full-precision accuracy. These expressions reveal how back-propagated margins govern layer-wise sensitivity and provide certifiable guarantees on the smallest parameter updates consistent with a desired output shift.</div></details>
<details class="detail"><summary>中文标题/摘要</summary>
<div class="mono"><b>标题：</b>深度网络最小权重扰动理论及其在低秩激活后门攻击中的应用</div>
<div class="mono" style="margin-top:8px">本文推导了深度神经网络为实现指定输出变化所需的最小范数权重扰动，并讨论了决定其大小的因素。这些单层精确公式与基于多层Lipschitz常数的通用鲁棒性保证进行了对比，两者被证明具有相同量级，表明其保证效果相似。研究结果应用于精度修改激活的后门攻击，建立了可证明的压缩阈值，低于该阈值此类攻击无法成功，并通过实验证明低秩压缩能在保持全精度准确性的同时可靠激活潜在后门。这些表达式揭示了反向传播的边界如何控制逐层敏感性，并为符合期望输出变化的最小参数更新提供了可验证的保证。</div>
</details>
<details class="detail"><summary>Summary / 总结</summary>
<div class="mono">This research aims to understand the minimal weight perturbations needed to alter a deep neural network&#x27;s output, providing a theoretical foundation for analyzing network sensitivity and security. The method derives exact formulas for single-layer perturbations and compares them with multi-layer Lipschitz-based robustness bounds, finding both guarantees to be of similar order. Key experimental findings include establishing provable compression thresholds that prevent precision-modification-activated backdoor attacks and demonstrating empirically that low-rank compression can reliably trigger latent backdoors without compromising full-precision accuracy, while also revealing how back-propagated margins govern layer-wise sensitivity.</div>
<div class="mono" style="margin-top:8px">本研究旨在推导改变深度神经网络输出所需的最小权重扰动，为分析网络鲁棒性和安全性提供理论基础。方法上推导了单层扰动的精确公式，并与基于多层Lipschitz常数的保证进行了对比，发现两者具有相似量级。关键实验结果包括建立了可证明的压缩阈值以防止精度修改激活的后门攻击，并实证表明低秩压缩能在保持全精度准确性的同时可靠激活潜在后门，同时揭示了反向传播的边界如何控制逐层敏感性。</div>
</details>
</div>
<div class="card">
<div class="title">Kernel Embeddings and the Separation of Measure Phenomenon</div>
<div class="meta-line">Authors: Leonardo V. Santoro, Kartik G. Waghmare, Victor M. Panaretos</div>
<div class="meta-line">First: 2025-05-07T17:56:19+00:00 · Latest: 2026-01-23T16:38:50+00:00</div>
<div class="links" style="margin-top:8px"><a href="https://arxiv.org/abs/2505.04613v3">Abs</a> · <a href="https://arxiv.org/pdf/2505.04613v3">PDF</a> · <a href="https://huggingface.co/huggingface">Code1</a> · <a href="https://huggingface.co/docs/hub/spaces">Code2</a></div>
<details class="detail"><summary>Abstract</summary>
<div class="mono">We prove that kernel covariance embeddings lead to information-theoretically perfect separation of distinct continuous probability distributions. In statistical terms, we establish that testing for the \emph{equality} of two non-atomic (Borel) probability measures on a locally compact Polish space is \emph{equivalent} to testing for the \emph{singularity} between two centered Gaussian measures on a reproducing kernel Hilbert space. The corresponding Gaussians are defined via the notion of kernel covariance embedding of a probability measure, and the Hilbert space is that generated by the embedding kernel. Distinguishing singular Gaussians is structurally simpler from an information-theoretic perspective than non-parametric two-sample testing, particularly in complex or high-dimensional domains. This is because singular Gaussians are supported on essentially separate and affine subspaces. Our proof leverages the classical Feldman-Hájek dichotomy, and shows that even a small perturbation of a continuous distribution will be maximally magnified through its Gaussian embedding. This ``separation of measure phenomenon&#x27;&#x27; appears to be a blessing of infinite dimensionality, by means of embedding, with the potential to inform the design of efficient inference tools in considerable generality. The elicitation of this phenomenon also appears to crystallize, in a precise and simple mathematical statement, a core mechanism underpinning the empirical effectiveness of kernel methods.</div></details>
<details class="detail"><summary>中文标题/摘要</summary>
<div class="mono"><b>标题：</b>核嵌入与测度分离现象</div>
<div class="mono" style="margin-top:8px">我们证明了核协方差嵌入能够实现不同连续概率分布在信息论意义上的完美分离。从统计角度，我们建立了以下等价关系：在局部紧波兰空间上检验两个非原子（Borel）概率测度的相等性，等价于在再生核希尔伯特空间中检验两个中心化高斯测度之间的奇异性。对应的高斯测度通过概率测度的核协方差嵌入概念定义，而希尔伯特空间则由嵌入核生成。从信息论视角看，区分奇异高斯测度在结构上比非参数双样本检验更简单，尤其在复杂或高维领域，因为奇异高斯测度本质上支撑于分离的仿射子空间。我们的证明利用了经典的Feldman-Hájek二分定理，并表明即使对连续分布进行微小扰动，也会通过其高斯嵌入被极大放大。这种“测度分离现象”似乎是无限维通过嵌入带来的优势，有望为广泛的高效推断工具设计提供启示。该现象的揭示也通过精确简洁的数学表述，凝练了支撑核方法经验有效性的核心机制。</div>
</details>
<details class="detail"><summary>Summary / 总结</summary>
<div class="mono">The research is motivated by the challenge of distinguishing between continuous probability distributions in complex or high-dimensional domains, where non-parametric two-sample testing can be difficult. The method establishes an equivalence between testing for equality of two non-atomic probability measures and testing for singularity of two centered Gaussian measures in a reproducing kernel Hilbert space, using kernel covariance embeddings to construct these Gaussians. Key experimental findings demonstrate that this embedding leads to information-theoretically perfect separation, as even small perturbations in the original distributions are maximally magnified, resulting in singular Gaussians supported on essentially separate subspaces, which simplifies the testing problem.</div>
<div class="mono" style="margin-top:8px">该研究的动机源于在复杂或高维领域中区分连续概率分布的挑战，其中非参数双样本检验可能较为困难。方法通过核协方差算子嵌入原始测度，建立了检验两个非原子概率测度相等性与检验再生核希尔伯特空间中两个中心化高斯测度奇异性之间的等价性。关键实验结果表明，这种嵌入导致信息理论上完美的分离，即使原始分布的微小扰动也会被极大放大，从而产生支撑在本质分离子空间上的奇异高斯测度，这简化了推断过程，并阐明了核方法经验有效性背后的核心机制。</div>
</details>
</div>
<div class="card">
<div class="title">Provably Learning Attention with Queries</div>
<div class="meta-line">Authors: Satwik Bhattamishra, Kulin Shah, Michael Hahn, Varun Kanade</div>
<div class="meta-line">First: 2026-01-23T16:28:22+00:00 · Latest: 2026-01-23T16:28:22+00:00</div>
<div class="meta-line">Comments: Preprint</div>
<div class="links" style="margin-top:8px"><a href="https://arxiv.org/abs/2601.16873v1">Abs</a> · <a href="https://arxiv.org/pdf/2601.16873v1">PDF</a> · <a href="https://huggingface.co/huggingface">Code1</a> · <a href="https://huggingface.co/docs/hub/spaces">Code2</a></div>
<details class="detail"><summary>Abstract</summary>
<div class="mono">We study the problem of learning Transformer-based sequence models with black-box access to their outputs. In this setting, a learner may adaptively query the oracle with any sequence of vectors and observe the corresponding real-valued output. We begin with the simplest case, a single-head softmax-attention regressor. We show that for a model with width $d$, there is an elementary algorithm to learn the parameters of single-head attention exactly with $O(d^2)$ queries. Further, we show that if there exists an algorithm to learn ReLU feedforward networks (FFNs), then the single-head algorithm can be easily adapted to learn one-layer Transformers with single-head attention. Next, motivated by the regime where the head dimension $r \ll d$, we provide a randomised algorithm that learns single-head attention-based models with $O(rd)$ queries via compressed sensing arguments. We also study robustness to noisy oracle access, proving that under mild norm and margin conditions, the parameters can be estimated to $\varepsilon$ accuracy with a polynomial number of queries even when outputs are only provided up to additive tolerance. Finally, we show that multi-head attention parameters are not identifiable from value queries in general -- distinct parameterisations can induce the same input-output map. Hence, guarantees analogous to the single-head setting are impossible without additional structural assumptions.</div></details>
<details class="detail"><summary>中文标题/摘要</summary>
<div class="mono"><b>标题：</b>可证明的基于查询的注意力机制学习</div>
<div class="mono" style="margin-top:8px">本研究探讨在仅能黑盒访问输出的条件下学习基于Transformer的序列模型。学习者可自适应地向预言机输入任意向量序列并观察对应的实值输出。我们从最简单的单头softmax注意力回归器入手，证明对于宽度为$d$的模型，存在基础算法能以$O(d^2)$次查询精确学习单头注意力参数。进一步证明：若存在学习ReLU前馈网络（FFN）的算法，则单头算法可轻松扩展至学习带单头注意力的单层Transformer。针对头维度$r \ll d$的场景，我们提出随机算法通过压缩感知论证以$O(rd)$次查询学习基于单头注意力的模型。同时研究噪声预言机访问的鲁棒性，证明在温和的范数和边界条件下，即使输出仅提供加性容差，仍可通过多项式次查询将参数估计至$\varepsilon$精度。最后证明多头注意力参数通常无法通过值查询唯一确定——不同参数化可能产生相同的输入输出映射，因此在缺乏额外结构假设时无法获得类似单头场景的理论保证。</div>
</details>
<details class="detail"><summary>Summary / 总结</summary>
<div class="mono">This work investigates the problem of learning Transformer-based sequence models through black-box query access to their outputs, aiming to establish query-efficient algorithms with provable guarantees. The authors first present an elementary algorithm that exactly learns the parameters of a single-head softmax-attention regressor using O(d²) queries, where d is the model width. They then extend this to show that learning one-layer Transformers reduces to learning feedforward networks, and provide a randomized algorithm requiring only O(rd) queries when the head dimension r is much smaller than d, leveraging compressed sensing techniques. Experimental analysis confirms these query complexities and demonstrates robustness to noisy oracle outputs under mild conditions, while also proving that multi-head attention parameters are generally not identifiable from value queries alone without additional structural assumptions.</div>
<div class="mono" style="margin-top:8px">本研究探讨了通过黑盒访问模型输出来学习Transformer参数的问题，其动机在于理解逆向工程注意力机制的查询复杂度。方法涉及设计对预言机的自适应查询序列；对于单头softmax注意力回归器，作者提出了一种基础算法，使用O(d²)次查询即可精确学习参数，并证明如果存在学习ReLU前馈网络的算法，则可将其扩展至学习单层Transformer。关键的实验发现包括：当头部维度r远小于宽度d时，利用压缩感知的随机化算法仅需O(rd)次查询即可学习；在温和条件下，从带噪声的预言机学习具有鲁棒性保证；以及一个根本性的可识别性结果，表明在没有额外结构假设的情况下，无法仅通过值查询唯一确定多头注意力的参数。</div>
</details>
</div>
<div class="card">
<div class="title">MACTAS: Self-Attention-Based Inter-Agent Communication in Multi-Agent Reinforcement Learning with Action-Value Function Decomposition</div>
<div class="meta-line">Authors: Maciej Wojtala, Bogusz Stefańczyk, Dominik Bogucki, Łukasz Lepak, Jakub Strykowski, Paweł Wawrzyński</div>
<div class="meta-line">Venue: IJCAI 2026</div>
<div class="meta-line">First: 2025-08-19T09:08:48+00:00 · Latest: 2026-01-23T16:26:59+00:00</div>
<div class="meta-line">Comments: Submitted for IJCAI 2026</div>
<div class="links" style="margin-top:8px"><a href="https://arxiv.org/abs/2508.13661v3">Abs</a> · <a href="https://arxiv.org/pdf/2508.13661v3">PDF</a> · <a href="https://huggingface.co/huggingface">Code1</a> · <a href="https://huggingface.co/docs/hub/spaces">Code2</a></div>
<details class="detail"><summary>Abstract</summary>
<div class="mono">Communication is essential for the collective execution of complex tasks by human agents, motivating interest in communication mechanisms for multi-agent reinforcement learning (MARL). However, existing communication protocols in MARL are often complex and non-differentiable. In this work, we introduce a self-attention-based communication method that exchanges information between the agents in MARL. Our proposed approach is fully differentiable, allowing agents to learn to generate messages in a reward-driven manner. The method can be seamlessly integrated with any action-value function decomposition algorithm and can be viewed as an orthogonal extension of such decompositions. Notably, it includes a fixed number of trainable parameters, independent of the number of agents, which makes it scalable to large systems. Experimental results on the SMACv2 benchmark demonstrate the effectiveness of our approach, which achieves state-of-the-art performance on a number of maps. makes it scalable to large systems. Experimental results on the SMACv2 benchmark demonstrate the effectiveness of our approach, which achieves state-of-the-art performance on a number of maps.</div></details>
<details class="detail"><summary>中文标题/摘要</summary>
<div class="mono"><b>标题：</b>MACTAS：基于自注意力的多智能体强化学习中动作价值函数分解的智能体间通信</div>
<div class="mono" style="margin-top:8px">通信对于人类智能体协同执行复杂任务至关重要，这推动了对多智能体强化学习（MARL）通信机制的研究兴趣。然而，现有MARL通信协议通常复杂且不可微分。本文提出一种基于自注意力的通信方法，实现MARL智能体间的信息交换。该方法完全可微分，使智能体能够以奖励驱动的方式学习生成消息。该方法可与任何动作价值函数分解算法无缝集成，可视为此类分解的正交扩展。值得注意的是，其包含固定数量的可训练参数，与智能体数量无关，因此可扩展至大规模系统。在SMACv2基准测试中的实验结果表明，该方法在多个地图上取得了最先进的性能。</div>
</details>
<details class="detail"><summary>Summary / 总结</summary>
<div class="mono">Motivated by the need for effective and learnable communication in multi-agent systems, this paper introduces MACTAS, a self-attention-based communication method for multi-agent reinforcement learning. The method is designed as a fully differentiable, reward-driven communication protocol that can be integrated with any action-value function decomposition algorithm, featuring a parameter count independent of the number of agents for scalability. Experiments on the SMACv2 benchmark show that the approach achieves state-of-the-art performance on several maps.</div>
<div class="mono" style="margin-top:8px">受多智能体系统中对有效且可微分通信的需求驱动，本文提出了MACTAS，一种基于自注意力的多智能体强化学习通信方法。该方法与动作价值函数分解算法集成，采用完全可微分的协议，使智能体以奖励驱动的方式学习生成消息；其参数数量固定，不随智能体数量增加，确保了可扩展性。在SMACv2基准测试上的实验结果表明，该方法在多个地图上实现了最先进的性能。</div>
</details>
</div></div>
    <details style="margin-top:16px" class="detail"><summary>History</summary>
      <div class="history-list"><a href="archive/20260127_0439.html">20260127_0439</a>
<a href="archive/20260127_0333.html">20260127_0333</a>
<a href="archive/20260126_0626.html">20260126_0626</a>
<a href="archive/20260126_0526.html">20260126_0526</a>
<a href="archive/20260126_0327.html">20260126_0327</a>
<a href="archive/20260125_0624.html">20260125_0624</a>
<a href="archive/20260125_0524.html">20260125_0524</a>
<a href="archive/20260125_0440.html">20260125_0440</a>
<a href="archive/20260125_0325.html">20260125_0325</a>
<a href="archive/20260124_0627.html">20260124_0627</a>
<a href="archive/20260124_0526.html">20260124_0526</a>
<a href="archive/20260124_0444.html">20260124_0444</a>
<a href="archive/20260124_0334.html">20260124_0334</a>
<a href="archive/20260123_0627.html">20260123_0627</a>
<a href="archive/20260123_0529.html">20260123_0529</a>
<a href="archive/20260123_0446.html">20260123_0446</a>
<a href="archive/20260123_0334.html">20260123_0334</a>
<a href="archive/20260122_2019.html">20260122_2019</a>
<a href="archive/20260122_2013.html">20260122_2013</a>
<a href="archive/20260122_2008.html">20260122_2008</a>
<a href="archive/20260122_2001.html">20260122_2001</a>
<a href="archive/20260122_0629.html">20260122_0629</a>
<a href="archive/20260122_0535.html">20260122_0535</a>
<a href="archive/20260122_0449.html">20260122_0449</a>
<a href="archive/20260122_0336.html">20260122_0336</a>
<a href="archive/20260121_0625.html">20260121_0625</a>
<a href="archive/20260121_0529.html">20260121_0529</a>
<a href="archive/20260121_0450.html">20260121_0450</a>
<a href="archive/20260121_0423.html">20260121_0423</a>
<a href="archive/20260120_0626.html">20260120_0626</a>
<a href="archive/20260120_0528.html">20260120_0528</a>
<a href="archive/20260120_0443.html">20260120_0443</a>
<a href="archive/20260120_0330.html">20260120_0330</a>
<a href="archive/20260119_0624.html">20260119_0624</a>
<a href="archive/20260119_0525.html">20260119_0525</a>
<a href="archive/20260119_0440.html">20260119_0440</a>
<a href="archive/20260119_0325.html">20260119_0325</a>
<a href="archive/20260118_2225.html">20260118_2225</a>
<a href="archive/20260118_2159.html">20260118_2159</a>
<a href="archive/20260118_2135.html">20260118_2135</a>
<a href="archive/20260118_2040.html">20260118_2040</a>
<a href="archive/20260118_1953.html">20260118_1953</a>
<a href="archive/20260118_1907.html">20260118_1907</a>
<a href="archive/20260118_0327.html">20260118_0327</a>
<a href="archive/20260117_0332.html">20260117_0332</a>
<a href="archive/20260116_0339.html">20260116_0339</a>
<a href="archive/20260115_0334.html">20260115_0334</a>
<a href="archive/20260114_0333.html">20260114_0333</a>
<a href="archive/20260113_0334.html">20260113_0334</a>
<a href="archive/20260112_0331.html">20260112_0331</a>
<a href="archive/20260111_0329.html">20260111_0329</a>
<a href="archive/20260110_0333.html">20260110_0333</a>
<a href="archive/20260109_0334.html">20260109_0334</a>
<a href="archive/20260108_0335.html">20260108_0335</a>
<a href="archive/20260107_0330.html">20260107_0330</a>
<a href="archive/20260106_0336.html">20260106_0336</a>
<a href="archive/20260105_0328.html">20260105_0328</a>
<a href="archive/20260104_0328.html">20260104_0328</a>
<a href="archive/20260103_0325.html">20260103_0325</a>
<a href="archive/20260102_0339.html">20260102_0339</a>
<a href="archive/20260101_0329.html">20260101_0329</a>
<a href="archive/20251231_0333.html">20251231_0333</a>
<a href="archive/20251230_0332.html">20251230_0332</a>
<a href="archive/20251229_0329.html">20251229_0329</a>
<a href="archive/20251228_0332.html">20251228_0332</a>
<a href="archive/20251227_0329.html">20251227_0329</a>
<a href="archive/20251226_0330.html">20251226_0330</a>
<a href="archive/20251225_0329.html">20251225_0329</a>
<a href="archive/20251224_0331.html">20251224_0331</a>
<a href="archive/20251223_0332.html">20251223_0332</a>
<a href="archive/20251222_0328.html">20251222_0328</a>
<a href="archive/20251221_0329.html">20251221_0329</a>
<a href="archive/20251220_0330.html">20251220_0330</a>
<a href="archive/20251219_0330.html">20251219_0330</a>
<a href="archive/20251218_0345.html">20251218_0345</a>
<a href="archive/20251217_0332.html">20251217_0332</a>
<a href="archive/20251216_0333.html">20251216_0333</a>
<a href="archive/20251215_0333.html">20251215_0333</a>
<a href="archive/20251214_0327.html">20251214_0327</a>
<a href="archive/20251212_0333.html">20251212_0333</a>
<a href="archive/20251211_0331.html">20251211_0331</a>
<a href="archive/20251210_0332.html">20251210_0332</a>
<a href="archive/20251209_0331.html">20251209_0331</a>
<a href="archive/20251208_0328.html">20251208_0328</a>
<a href="archive/20251207_0327.html">20251207_0327</a>
<a href="archive/20251206_0330.html">20251206_0330</a>
<a href="archive/20251205_0331.html">20251205_0331</a>
<a href="archive/20251204_0331.html">20251204_0331</a>
<a href="archive/20251203_0333.html">20251203_0333</a>
<a href="archive/20251202_0335.html">20251202_0335</a>
<a href="archive/20251201_0328.html">20251201_0328</a>
<a href="archive/20251130_0327.html">20251130_0327</a>
<a href="archive/20251129_0328.html">20251129_0328</a>
<a href="archive/20251128_0327.html">20251128_0327</a>
<a href="archive/20251127_0327.html">20251127_0327</a>
<a href="archive/20251126_0329.html">20251126_0329</a>
<a href="archive/20251125_0327.html">20251125_0327</a>
<a href="archive/20251124_0327.html">20251124_0327</a>
<a href="archive/20251123_0326.html">20251123_0326</a>
<a href="archive/20251122_0328.html">20251122_0328</a></div>
    </details>
    <div class="footer">Generated by arxiv-tracker</div>
  </div>
</body></html>
