<!doctype html>
<html><head><meta charset="utf-8"><meta name="viewport" content="width=device-width,initial-scale=1">
<title>arXiv 论文速递</title><style>
:root {
  --bg:#f8fafc; --card:#ffffff; --text:#0f172a; --muted:#667085; --border:#e5e7eb; --acc:#2563eb;
}
:root[data-theme="dark"] {
  --bg:#0b0f17; --card:#111827; --text:#e5e7eb; --muted:#9ca3af; --border:#1f2937; --acc:#2563eb;
}
*{box-sizing:border-box} body{margin:0;background:var(--bg);color:var(--text);
  font-family:ui-sans-serif,system-ui,-apple-system,Segoe UI,Roboto,Helvetica,Arial;line-height:1.6;}
.container{max-width:900px;margin:0 auto;padding:18px;}
.header{display:flex;gap:10px;justify-content:space-between;align-items:center;margin:8px 0 16px;flex-wrap:wrap}
h1{font-size:22px;margin:0}
.badge{font-size:12px;color:#111827;background:var(--acc);padding:2px 8px;border-radius:999px}
.card{background:var(--card);border:1px solid var(--border);border-radius:16px;padding:16px 18px;margin:14px 0;box-shadow:0 1px 2px rgba(0,0,0,.04)}
.title{font-weight:700;margin:0 0 6px 0;font-size:18px}
.meta-line{color:var(--muted);font-size:13px;margin:2px 0}
.links a{color:var(--acc);text-decoration:none;margin-right:12px}
.detail{margin-top:10px;background:rgba(2,6,23,.03);border:1px solid var(--border);border-radius:10px;padding:8px 10px}
summary{cursor:pointer;color:var(--acc)}
.mono{white-space:pre-wrap;background:rgba(2,6,23,.03);border:1px solid var(--border);padding:10px;border-radius:10px}
.row{display:grid;grid-template-columns:1fr;gap:12px}
@media (min-width: 860px) {
  .row-2{grid-template-columns:1fr 1fr}
}
.footer{color:var(--muted);font-size:13px;margin:20px 0 10px}
.hr{height:1px;background:var(--border);margin:14px 0}
.history-list a{display:block;color:var(--acc);text-decoration:none;margin:4px 0}
.controls{display:flex;gap:8px;align-items:center}
.btn{border:1px solid var(--border);background:var(--card);padding:6px 10px;border-radius:10px;cursor:pointer;color:var(--text)}
.btn:hover{border-color:var(--acc)}
</style>
<script>
(function() {
  const root = document.documentElement;
  function apply(t) {
    if (t==='dark') root.setAttribute('data-theme','dark');
    else if (t==='light') root.removeAttribute('data-theme');
    else {
      if (window.matchMedia && window.matchMedia('(prefers-color-scheme: dark)').matches)
        root.setAttribute('data-theme','dark');
      else root.removeAttribute('data-theme');
    }
  }
  let t = localStorage.getItem('theme') || 'light';
  if (!['light','dark','auto'].includes(t)) t='light';
  apply(t);
  window.__toggleTheme = function() {
    let cur = localStorage.getItem('theme') || 'light';
    if (cur==='light') cur='dark';
    else if (cur==='dark') cur='auto';
    else cur='light';
    localStorage.setItem('theme', cur);
    apply(cur);
    const el=document.getElementById('theme-label');
    if(el) el.textContent = cur.toUpperCase();
  }
  window.__expandAll = function(open) {
    document.querySelectorAll('details').forEach(d => d.open = !!open);
  }
})();
</script>
</head>
<body>
  <div class="container">
    <div class="header">
      <h1>arXiv 论文速递</h1>
      <div style="display:flex;gap:10px;align-items:center">
        
<div class="controls">
  <button class="btn" onclick="__toggleTheme()">Theme: <span id="theme-label" style="margin-left:6px">AUTO</span></button>
  <button class="btn" onclick="__expandAll(true)">Expand All</button>
  <button class="btn" onclick="__expandAll(false)">Collapse All</button>
</div>

        <span class="badge">2026-02-05 05:37</span>
      </div>
    </div>
    <div class="hr"></div>
    <div>Snapshot: 20260205_0537</div>
    <div class="row"><div class="card">
<div class="title">PLATE: Plasticity-Tunable Efficient Adapters for Geometry-Aware Continual Learning</div>
<div class="meta-line">Authors: Romain Cosentino</div>
<div class="meta-line">First: 2026-02-03T18:59:42+00:00 · Latest: 2026-02-03T18:59:42+00:00</div>
<div class="links" style="margin-top:8px"><a href="https://arxiv.org/abs/2602.03846v1">Abs</a> · <a href="https://arxiv.org/pdf/2602.03846v1">PDF</a> · <a href="https://github.com/SalesforceAIResearch/PLATE">Code1</a> · <a href="https://huggingface.co/huggingface">Code2</a> · <a href="https://huggingface.co/docs/hub/spaces">Code3</a></div>
<details class="detail"><summary>Abstract</summary>
<div class="mono">We develop a continual learning method for pretrained models that \emph{requires no access to old-task data}, addressing a practical barrier in foundation model adaptation where pretraining distributions are often unavailable. Our key observation is that pretrained networks exhibit substantial \emph{geometric redundancy}, and that this redundancy can be exploited in two complementary ways. First, redundant neurons provide a proxy for dominant pretraining-era feature directions, enabling the construction of approximately protected update subspaces directly from pretrained weights. Second, redundancy offers a natural bias for \emph{where} to place plasticity: by restricting updates to a subset of redundant neurons and constraining the remaining degrees of freedom, we obtain update families with reduced functional drift on the old-data distribution and improved worst-case retention guarantees. These insights lead to \textsc{PLATE} (\textbf{Pla}sticity-\textbf{T}unable \textbf{E}fficient Adapters), a continual learning method requiring no past-task data that provides explicit control over the plasticity-retention trade-off. PLATE parameterizes each layer with a structured low-rank update $ΔW = B A Q^\top$, where $B$ and $Q$ are computed once from pretrained weights and kept frozen, and only $A$ is trained on the new task. The code is available at https://github.com/SalesforceAIResearch/PLATE.</div></details>
<details class="detail"><summary>中文标题/摘要</summary>
<div class="mono"><b>标题：</b>PLATE：面向几何感知持续学习的可塑性可调高效适配器</div>
<div class="mono" style="margin-top:8px">我们为预训练模型开发了一种无需访问旧任务数据的持续学习方法，解决了基础模型适配中预训练分布常不可用的实际障碍。核心发现是预训练网络存在显著的几何冗余，可通过两种互补方式利用：首先，冗余神经元为预训练阶段主导特征方向提供代理，支持直接从预训练权重构建近似受保护的更新子空间；其次，冗余性为可塑性布局提供自然偏置——通过将更新限制在冗余神经元子集并约束剩余自由度，获得在旧数据分布上功能漂移更小、最坏情况保留保证更强的更新族。这些洞见催生了PLATE（可塑性可调高效适配器），这是一种无需历史任务数据、能显式控制可塑性-保留权衡的持续学习方法。PLATE通过结构化低秩更新$ΔW = B A Q^\top$参数化各层，其中$B$和$Q$从预训练权重一次性计算并冻结，仅$A$在新任务上训练。代码发布于https://github.com/SalesforceAIResearch/PLATE。</div>
</details>
<details class="detail"><summary>Summary / 总结</summary>
<div class="mono">This work addresses the practical challenge of adapting pretrained foundation models to new tasks without access to old-task data, a common constraint when pretraining distributions are unavailable. The method, named PLATE, exploits the geometric redundancy observed in pretrained networks by constructing protected update subspaces directly from the pretrained weights and strategically restricting plasticity to a subset of redundant neurons. It implements this through a structured low-rank update per layer, ΔW = B A Q^⊤, where B and Q are frozen matrices derived from the pretrained model, and only the small matrix A is trained on the new task. Experimental results demonstrate that PLATE effectively controls the plasticity-retention trade-off, reducing functional drift on the old-data distribution and providing improved worst-case retention guarantees compared to prior methods.</div>
<div class="mono" style="margin-top:8px">本研究针对持续学习中一个实际挑战：在无法获取原始预训练数据的情况下，使预训练基础模型适应新任务。该方法名为PLATE，它利用预训练网络中观察到的几何冗余，为每个层构建结构化低秩更新ΔW = B A Q^⊤，其中矩阵B和Q从预训练权重中一次性计算并冻结，仅小型矩阵A在新任务上训练。这种设计创建了近似受保护的子空间，最大程度减少了对旧任务的功能漂移，实现了对可塑性-保持权衡的显式控制，并在无需任何旧任务数据的情况下提供了改进的最坏情况保持保证。</div>
</details>
</div>
<div class="card">
<div class="title">Reuse your FLOPs: Scaling RL on Hard Problems by Conditioning on Very Off-Policy Prefixes</div>
<div class="meta-line">Authors: Amrith Setlur, Zijian Wang, Andrew Cohen, Paria Rashidinejad, Sang Michael Xie</div>
<div class="meta-line">First: 2026-01-26T18:57:00+00:00 · Latest: 2026-02-03T18:58:52+00:00</div>
<div class="links" style="margin-top:8px"><a href="https://arxiv.org/abs/2601.18795v2">Abs</a> · <a href="https://arxiv.org/pdf/2601.18795v2">PDF</a> · <a href="https://huggingface.co/huggingface">Code1</a> · <a href="https://huggingface.co/docs/hub/spaces">Code2</a></div>
<details class="detail"><summary>Abstract</summary>
<div class="mono">Typical reinforcement learning (RL) methods for LLM reasoning waste compute on hard problems, where correct on-policy traces are rare, policy gradients vanish, and learning stalls. To bootstrap more efficient RL, we consider reusing old sampling FLOPs (from prior inference or RL training) in the form of off-policy traces. Standard off-policy methods supervise against off-policy data, causing instabilities during RL optimization. We introduce PrefixRL, where we condition on the prefix of successful off-policy traces and run on-policy RL to complete them, side-stepping off-policy instabilities. PrefixRL boosts the learning signal on hard problems by modulating the difficulty of the problem through the off-policy prefix length. We prove that the PrefixRL objective is not only consistent with the standard RL objective but also more sample efficient. Empirically, we discover back-generalization: training only on prefixed problems generalizes to out-of-distribution unprefixed performance, with learned strategies often differing from those in the prefix. In our experiments, we source the off-policy traces by rejection sampling with the base model, creating a self-improvement loop. On hard reasoning problems, PrefixRL reaches the same training reward 2x faster than the strongest baseline (SFT on off-policy data then RL), even after accounting for the compute spent on the initial rejection sampling, and increases the final reward by 3x. The gains transfer to held-out benchmarks, and PrefixRL is still effective when off-policy traces are derived from a different model family, validating its flexibility in practical settings.</div></details>
<details class="detail"><summary>中文标题/摘要</summary>
<div class="mono"><b>标题：</b>复用你的浮点运算：通过基于极离策略前缀的条件化实现困难问题上的强化学习扩展</div>
<div class="mono" style="margin-top:8px">传统用于大语言模型推理的强化学习方法在困难问题上浪费算力，因为正确的同策略轨迹稀少、策略梯度消失且学习停滞。为引导更高效的强化学习，我们考虑以离策略轨迹的形式复用旧采样浮点运算（来自先前的推理或强化学习训练）。标准离策略方法基于离策略数据进行监督，导致强化学习优化期间的不稳定性。我们提出PrefixRL方法：基于成功离策略轨迹的前缀进行条件化，并运行同策略强化学习来完成轨迹，从而规避离策略不稳定性。PrefixRL通过调节离策略前缀长度来调整问题难度，从而增强困难问题上的学习信号。我们证明PrefixRL目标不仅与标准强化学习目标一致，且样本效率更高。实证中，我们发现了反向泛化现象：仅在前缀化问题上训练可泛化至分布外无前缀性能，且习得策略常与前缀中的策略不同。实验中，我们通过基础模型的拒绝采样获取离策略轨迹，形成自我改进循环。在困难推理问题上，即使计入初始拒绝采样的算力消耗，PrefixRL达到相同训练奖励的速度仍比最强基线（离策略数据监督微调后强化学习）快2倍，并将最终奖励提升3倍。这些增益可迁移至保留基准测试，且当离策略轨迹源自不同模型家族时PrefixRL依然有效，验证了其在实际场景中的灵活性。</div>
</details>
<details class="detail"><summary>Summary / 总结</summary>
<div class="mono">The research addresses the inefficiency of standard reinforcement learning (RL) methods for large language models on hard reasoning problems, where on-policy traces are scarce and policy gradients vanish, leading to stalled learning. To overcome this, the authors propose PrefixRL, a method that conditions on the prefixes of successful off-policy traces—sourced via rejection sampling from a base model—and then performs on-policy RL to complete them, thereby avoiding the instabilities of direct off-policy supervision while modulating problem difficulty via prefix length. Experiments demonstrate that PrefixRL achieves the same training reward twice as fast as strong baselines like supervised fine-tuning followed by RL, even after accounting for initial rejection sampling compute, and triples the final reward, with gains transferring to held-out benchmarks and showing effectiveness even with off-policy traces from different model families.</div>
<div class="mono" style="margin-top:8px">本研究针对大型语言模型在困难推理问题上标准强化学习方法效率低下的问题，即正确策略轨迹稀少、策略梯度消失导致学习停滞。提出的PrefixRL方法通过复用先前推理或训练中的离策略轨迹，以其前缀为条件进行在策略强化学习来完成轨迹，从而避免直接离策略监督的不稳定性，并通过前缀长度调节问题难度。实验结果表明，PrefixRL在考虑初始拒绝采样计算后，达到相同训练奖励的速度比基于离策略数据的监督微调再强化学习等强基线快两倍，并将最终奖励提高三倍，其增益可迁移到保留基准测试中，且在不同模型家族来源的离策略轨迹上仍有效，验证了其实用灵活性。</div>
</details>
</div>
<div class="card">
<div class="title">Investigating Quantum Circuit Designs Using Neuro-Evolution</div>
<div class="meta-line">Authors: Devroop Kar, Daniel Krutz, Travis Desell</div>
<div class="meta-line">First: 2026-02-03T18:57:39+00:00 · Latest: 2026-02-03T18:57:39+00:00</div>
<div class="meta-line">Comments: Submitted to The Genetic and Evolutionary Computation Conference (GECCO) 2026. Under Review</div>
<div class="links" style="margin-top:8px"><a href="https://arxiv.org/abs/2602.03840v1">Abs</a> · <a href="https://arxiv.org/pdf/2602.03840v1">PDF</a> · <a href="https://huggingface.co/huggingface">Code1</a> · <a href="https://huggingface.co/docs/hub/spaces">Code2</a></div>
<details class="detail"><summary>Abstract</summary>
<div class="mono">Designing effective quantum circuits remains a central challenge in quantum computing, as circuit structure strongly influences expressivity, trainability, and hardware feasibility. Current approaches, whether using manually designed circuit templates, fixed heuristics, or automated rules, face limitations in scalability, flexibility, and adaptability, often producing circuits that are poorly matched to the specific problem or quantum hardware. In this work, we propose the Evolutionary eXploration of Augmenting Quantum Circuits (EXAQC), an evolutionary approach to the automated design and training of parameterized quantum circuits (PQCs) which leverages and extends on strategies from neuroevolution and genetic programming. The proposed method jointly searches over gate types, qubit connectivity, parameterization, and circuit depth while respecting hardware and noise constraints. The method supports both Qiskit and Pennylane libraries, allowing the user to configure every aspect. This work highlights evolutionary search as a critical tool for advancing quantum machine learning and variational quantum algorithms, providing a principled pathway toward scalable, problem-aware, and hardware-efficient quantum circuit design. Preliminary results demonstrate that circuits evolved on classification tasks are able to achieve over 90% accuracy on most of the benchmark datasets with a limited computational budget, and are able to emulate target circuit quantum states with high fidelity scores.</div></details>
<details class="detail"><summary>中文标题/摘要</summary>
<div class="mono"><b>标题：</b>基于神经进化的量子电路设计研究</div>
<div class="mono" style="margin-top:8px">设计有效的量子电路仍是量子计算的核心挑战，因为电路结构强烈影响表达能力、可训练性和硬件可行性。当前方法——无论是使用手动设计的电路模板、固定启发式规则还是自动化规则——在可扩展性、灵活性和适应性方面均存在局限，常产生与具体问题或量子硬件匹配不佳的电路。本研究提出增强量子电路的进化探索方法（EXAQC），这是一种利用并拓展神经进化和遗传编程策略的参数化量子电路（PQC）自动化设计与训练的进化方法。该方法在遵循硬件和噪声约束的同时，联合搜索门类型、量子比特连接性、参数化方案和电路深度，支持Qiskit和Pennylane库，允许用户配置所有环节。本工作强调进化搜索是推进量子机器学习和变分量子算法的关键工具，为可扩展、问题感知且硬件高效的量子电路设计提供了原则性路径。初步结果表明，在有限计算资源下，针对分类任务进化的电路在多数基准数据集上能达到超过90%的准确率，并能以高保真度模拟目标电路的量子态。</div>
</details>
<details class="detail"><summary>Summary / 总结</summary>
<div class="mono">The research addresses the challenge of designing effective quantum circuits, where current manual, heuristic, or rule-based methods often yield circuits that are not well-suited to specific problems or hardware constraints. The proposed method, EXAQC, is an evolutionary approach that automates the design and training of parameterized quantum circuits by jointly searching over gate types, qubit connectivity, parameterization, and circuit depth while adhering to hardware and noise limitations. Preliminary experimental results show that circuits evolved for classification tasks achieve over 90% accuracy on most benchmark datasets with limited computational resources and can emulate target quantum states with high fidelity.</div>
<div class="mono" style="margin-top:8px">本研究针对量子电路中设计有效电路的核心挑战，现有手动或启发式方法在可扩展性和适应性上存在不足，影响了电路的表达能力、可训练性和硬件可行性。提出的方法EXAQC采用受神经进化和遗传编程启发的进化方法，在硬件和噪声约束下自动搜索和优化门类型、量子比特连接性、参数化和电路深度。初步实验结果表明，进化出的电路在有限计算资源下，在多数基准分类任务上实现了超过90%的准确率，并以高保真度模拟了目标量子态。</div>
</details>
</div>
<div class="card">
<div class="title">Polynomial Neural Sheaf Diffusion: A Spectral Filtering Approach on Cellular Sheaves</div>
<div class="meta-line">Authors: Alessio Borgi, Fabrizio Silvestri, Pietro Liò</div>
<div class="meta-line">Venue: ICML 2026</div>
<div class="meta-line">First: 2025-11-28T23:10:54+00:00 · Latest: 2026-02-03T18:57:37+00:00</div>
<div class="meta-line">Comments: Under Review at ICML 2026</div>
<div class="links" style="margin-top:8px"><a href="https://arxiv.org/abs/2512.00242v2">Abs</a> · <a href="https://arxiv.org/pdf/2512.00242v2">PDF</a> · <a href="https://huggingface.co/huggingface">Code1</a> · <a href="https://huggingface.co/docs/hub/spaces">Code2</a></div>
<details class="detail"><summary>Abstract</summary>
<div class="mono">Sheaf Neural Networks equip graph structures with a cellular sheaf: a geometric structure which assigns local vector spaces (stalks) and a linear learnable restriction/transport maps to nodes and edges, yielding an edge-aware inductive bias that handles heterophily and limits oversmoothing. However, common Neural Sheaf Diffusion implementations rely on SVD-based sheaf normalization and dense per-edge restriction maps, which scale with stalk dimension, require frequent Laplacian rebuilds, and yield brittle gradients. To address these limitations, we introduce Polynomial Neural Sheaf Diffusion (PolyNSD), a new sheaf diffusion approach whose propagation operator is a degree-K polynomial in a normalised sheaf Laplacian, evaluated via a stable three-term recurrence on a spectrally rescaled operator. This provides an explicit K-hop receptive field in a single layer (independently of the stalk dimension), with a trainable spectral response obtained as a convex mixture of K+1 orthogonal polynomial basis responses. PolyNSD enforces stability via convex mixtures, spectral rescaling, and residual/gated paths, reaching new state-of-the-art results on both homophilic and heterophilic benchmarks, inverting the Neural Sheaf Diffusion trend by obtaining these results with just diagonal restriction maps, decoupling performance from large stalk dimension, while reducing runtime and memory requirements.</div></details>
<details class="detail"><summary>中文标题/摘要</summary>
<div class="mono"><b>标题：</b>多项式神经层扩散：胞腔层上的谱滤波方法</div>
<div class="mono" style="margin-top:8px">层神经网络为图结构配备胞腔层：一种几何结构，为节点和边分配局部向量空间（茎）及可学习的线性限制/传输映射，形成具有边感知能力的归纳偏置，可处理异配性并抑制过平滑。然而，现有神经层扩散实现依赖基于SVD的层归一化和稠密的逐边限制映射，其计算复杂度随茎维度增长，需频繁重建拉普拉斯矩阵，且产生脆弱梯度。为突破这些局限，我们提出多项式神经层扩散（PolyNSD）——一种新型层扩散方法，其传播算子为归一化层拉普拉斯算子的K次多项式，通过谱重缩放算子的稳定三项递推求值。该方法在单层内提供显式的K跳感受野（与茎维度无关），并通过K+1个正交多项式基响应的凸组合获得可训练的谱响应。PolyNSD通过凸组合、谱重缩放及残差/门控路径确保稳定性，在同配与异配基准测试中均达到最新最优性能，仅使用对角限制映射即逆转神经层扩散的性能趋势，使性能与高茎维度解耦，同时降低运行时内存需求。</div>
</details>
<details class="detail"><summary>Summary / 总结</summary>
<div class="mono">To overcome the computational inefficiency and instability of existing Neural Sheaf Diffusion methods, which rely on SVD-based normalization and dense per-edge restriction maps, this work introduces Polynomial Neural Sheaf Diffusion (PolyNSD). The method defines a propagation operator as a degree-K polynomial in a normalized sheaf Laplacian, computed via a stable recurrence on a spectrally rescaled operator, which provides an explicit K-hop receptive field and a trainable spectral response as a convex mixture of orthogonal polynomial bases. Experiments show that PolyNSD achieves state-of-the-art results on homophilic and heterophilic graph benchmarks using only diagonal restriction maps, thereby decoupling performance from large stalk dimensions while reducing runtime and memory costs.</div>
<div class="mono" style="margin-top:8px">本研究旨在解决现有神经层扩散模型的计算和稳定性限制，这些模型依赖基于SVD的归一化和密集的每边限制映射，导致可扩展性问题和梯度脆弱性。提出的方法——多项式神经层扩散（PolyNSD）——引入了一个传播算子，定义为归一化层拉普拉斯矩阵的K次多项式，通过谱重缩放算子的稳定三项递推进行评估，以实现显式的K跳感受野和作为正交多项式基凸组合的可训练谱响应。实验结果表明，PolyNSD在同质性和异质性图基准测试中均达到了最先进的性能，仅使用对角限制映射将性能与大维数解耦，同时降低了运行时间和内存需求。</div>
</details>
</div>
<div class="card">
<div class="title">Understanding and Exploiting Weight Update Sparsity for Communication-Efficient Distributed RL</div>
<div class="meta-line">Authors: Erfan Miahi, Eugene Belilovsky</div>
<div class="meta-line">First: 2026-02-03T18:56:48+00:00 · Latest: 2026-02-03T18:56:48+00:00</div>
<div class="meta-line">Comments: 32 pages, 14 figures</div>
<div class="links" style="margin-top:8px"><a href="https://arxiv.org/abs/2602.03839v1">Abs</a> · <a href="https://arxiv.org/pdf/2602.03839v1">PDF</a> · <a href="https://huggingface.co/huggingface">Code1</a> · <a href="https://huggingface.co/docs/hub/spaces">Code2</a></div>
<details class="detail"><summary>Abstract</summary>
<div class="mono">Reinforcement learning (RL) is a critical component for post-training large language models (LLMs). However, in bandwidth-constrained distributed RL, scalability is often bottlenecked by the synchronization of policy weights from trainers to inference workers, particularly over commodity networks or in decentralized settings. While recent studies suggest that RL updates modify only a small fraction of model parameters, these observations are typically based on coarse checkpoint differences. We present a systematic empirical study of weight-update sparsity at both step-level and multi-step granularities, examining its evolution across training dynamics, off-policy delay, and model scale. We find that update sparsity is consistently high, frequently exceeding 99% across practically relevant settings. Leveraging this structure, we propose PULSE (Patch Updates via Lossless Sparse Encoding), a simple yet highly efficient lossless weight synchronization method that transmits only the indices and values of modified parameters. PULSE is robust to transmission errors and avoids floating-point drift inherent in additive delta schemes. In bandwidth-constrained decentralized environments, our approach achieves over 100x (14 GB to ~108 MB) communication reduction while maintaining bit-identical training dynamics and performance compared to full weight synchronization. By exploiting this structure, PULSE enables decentralized RL training to approach centralized throughput, reducing the bandwidth required for weight synchronization from 20 Gbit/s to 0.2 Gbit/s to maintain high GPU utilization.</div></details>
<details class="detail"><summary>中文标题/摘要</summary>
<div class="mono"><b>标题：</b>理解并利用权重更新稀疏性实现通信高效的分布式强化学习</div>
<div class="mono" style="margin-top:8px">强化学习（RL）是大型语言模型（LLM）后训练的关键组成部分。然而，在带宽受限的分布式RL中，可扩展性常受限于策略权重从训练器到推理工作节点的同步过程，尤其是在商用网络或去中心化环境中。尽管近期研究表明RL更新仅修改模型参数的极小部分，但这些观察通常基于粗略的检查点差异。本文系统实证研究了步级与多步粒度下的权重更新稀疏性，分析了其在训练动态、离策略延迟和模型规模中的演变规律。我们发现更新稀疏性始终保持在较高水平，在实际相关设置中常超过99%。利用这一结构，我们提出了PULSE（基于无损稀疏编码的补丁更新），一种简单高效的无损权重同步方法，仅传输修改参数的索引和数值。PULSE对传输错误具有鲁棒性，并避免了加法增量方案固有的浮点数漂移问题。在带宽受限的去中心化环境中，相比全权重同步，该方法实现了超过100倍（从14 GB降至约108 MB）的通信压缩，同时保持比特级一致的训练动态与性能。通过利用此结构，PULSE使去中心化RL训练接近中心化吞吐量，将维持高GPU利用率所需的权重同步带宽从20 Gbit/s降至0.2 Gbit/s。</div>
</details>
<details class="detail"><summary>Summary / 总结</summary>
<div class="mono">The research is motivated by the communication bottleneck in distributed reinforcement learning (RL) for large language models, where synchronizing full policy weights between trainers and inference workers consumes excessive bandwidth. The method involves a systematic empirical analysis of weight-update sparsity, revealing that over 99% of parameters remain unchanged per update, and introduces PULSE, a lossless sparse encoding technique that transmits only the indices and values of modified weights. Key experimental results show that PULSE reduces communication volume by over 100x (from 14 GB to ~108 MB) in bandwidth-constrained decentralized settings, maintains bit-identical training performance, and lowers the required synchronization bandwidth from 20 Gbit/s to 0.2 Gbit/s to sustain high GPU utilization.</div>
<div class="mono" style="margin-top:8px">本研究旨在解决大型语言模型分布式强化学习中的通信瓶颈问题，即训练器与推理节点间同步完整策略权重会消耗大量带宽。方法上，首先对权重更新稀疏性进行了系统性实证分析，发现每次更新中超过99%的参数保持不变，据此提出了PULSE——一种无损稀疏编码技术，仅传输被修改参数的索引和数值。主要实验结果表明，PULSE在保持训练动态和性能完全一致的前提下，将通信量降低了100倍以上（从14 GB降至约108 MB），使去中心化训练所需的同步带宽从20 Gbit/s降至0.2 Gbit/s，从而维持了GPU的高利用率。</div>
</details>
</div>
<div class="card">
<div class="title">ME-IGM: Individual-Global-Max in Maximum Entropy Multi-Agent Reinforcement Learning</div>
<div class="meta-line">Authors: Wen-Tse Chen, Yuxuan Li, Shiyu Huang, Jiayu Chen, Jeff Schneider</div>
<div class="meta-line">Venue: Proc. of the 25th International Conference on Autonomous Agents and Multiagent Systems (AAMAS 2026), Paphos, Cyprus, May 25 - 29, 2026, IFAAMAS, 19 pages</div>
<div class="meta-line">First: 2024-06-20T01:55:08+00:00 · Latest: 2026-02-03T18:35:29+00:00</div>
<div class="meta-line">Comments: Published in the Proceedings of the 25th International Conference on Autonomous Agents and Multiagent Systems (AAMAS 2026)</div>
<div class="links" style="margin-top:8px"><a href="https://arxiv.org/abs/2406.13930v4">Abs</a> · <a href="https://arxiv.org/pdf/2406.13930v4">PDF</a> · <a href="https://huggingface.co/huggingface">Code1</a> · <a href="https://huggingface.co/docs/hub/spaces">Code2</a></div>
<details class="detail"><summary>Abstract</summary>
<div class="mono">Multi-agent credit assignment is a fundamental challenge for cooperative multi-agent reinforcement learning (MARL), where a team of agents learn from shared reward signals. The Individual-Global-Max (IGM) condition is a widely used principle for multi-agent credit assignment, requiring that the joint action determined by individual Q-functions maximizes the global Q-value. Meanwhile, the principle of maximum entropy has been leveraged to enhance exploration in MARL. However, we identify a critical limitation in existing maximum entropy MARL methods: a misalignment arises between local policies and the joint policy that maximizes the global Q-value, leading to violations of the IGM condition. To address this misalignment, we propose an order-preserving transformation. Building on it, we introduce ME-IGM, a novel maximum entropy MARL algorithm compatible with any credit assignment mechanism that satisfies the IGM condition while enjoying the benefits of maximum entropy exploration. We empirically evaluate two variants of ME-IGM: ME-QMIX and ME-QPLEX, in non-monotonic matrix games, and demonstrate their state-of-the-art performance across 17 scenarios in SMAC-v2 and Overcooked.</div></details>
<details class="detail"><summary>中文标题/摘要</summary>
<div class="mono"><b>标题：</b>ME-IGM：最大熵多智能体强化学习中的个体-全局最大化准则</div>
<div class="mono" style="margin-top:8px">多智能体信用分配是合作式多智能体强化学习（MARL）的核心挑战，即智能体团队需从共享奖励信号中学习。个体-全局最大化（IGM）条件是信用分配的常用原则，要求由个体Q函数确定的联合动作能最大化全局Q值。最大熵原则已被用于增强MARL的探索能力，但现有最大熵MARL方法存在关键缺陷：局部策略与最大化全局Q值的联合策略间存在错位，导致违反IGM条件。为解决此问题，我们提出保序变换方法，并在此基础上构建ME-IGM算法——该新型最大熵MARL算法兼容所有满足IGM条件的信用分配机制，同时保留最大熵探索优势。我们在非单调矩阵游戏中实证评估ME-IGM的两种变体（ME-QMIX与ME-QPLEX），并在SMAC-v2和Overcooked的17个场景中验证其领先性能。</div>
</details>
<details class="detail"><summary>Summary / 总结</summary>
<div class="mono">The research addresses a misalignment between local policies and the joint policy in maximum entropy multi-agent reinforcement learning (MARL), which violates the fundamental Individual-Global-Max (IGM) condition for credit assignment and hinders effective learning. To resolve this, the authors propose an order-preserving transformation and introduce the ME-IGM algorithm, which integrates maximum entropy exploration with any IGM-compliant credit assignment method. Experimental results on non-monotonic matrix games, SMAC-v2, and Overcooked show that the ME-IGM variants, ME-QMIX and ME-QPLEX, achieve state-of-the-art performance across 17 scenarios.</div>
<div class="mono" style="margin-top:8px">本研究解决了最大熵多智能体强化学习中局部策略与联合策略之间的错位问题，该问题破坏了信用分配所依赖的个体-全局最大值条件。方法上，提出了一种保序变换，以确保最大熵探索与基于IGM的信用分配机制兼容，从而形成了ME-IGM算法。实验结果表明，其变体ME-QMIX和ME-QPLEX在非单调矩阵游戏以及SMAC-v2和Overcooked的17个场景中均取得了最先进的性能。</div>
</details>
</div>
<div class="card">
<div class="title">Robust Intervention Learning from Emergency Stop Interventions</div>
<div class="meta-line">Authors: Ethan Pronovost, Khimya Khetarpal, Siddhartha Srinivasa</div>
<div class="meta-line">First: 2026-02-03T18:33:21+00:00 · Latest: 2026-02-03T18:33:21+00:00</div>
<div class="links" style="margin-top:8px"><a href="https://arxiv.org/abs/2602.03825v1">Abs</a> · <a href="https://arxiv.org/pdf/2602.03825v1">PDF</a> · <a href="https://huggingface.co/huggingface">Code1</a> · <a href="https://huggingface.co/docs/hub/spaces">Code2</a></div>
<details class="detail"><summary>Abstract</summary>
<div class="mono">Human interventions are a common source of data in autonomous systems during testing. These interventions provide an important signal about where the current policy needs improvement, but are often noisy and incomplete. We define Robust Intervention Learning (RIL) as the problem of learning from intervention data while remaining robust to the quality and informativeness of the intervention signal. In the best case, interventions are precise and avoiding them is sufficient to solve the task, but in many realistic settings avoiding interventions is necessary but not sufficient for achieving good performance. We study robust intervention learning in the context of emergency stop interventions and propose Residual Intervention Fine-Tuning (RIFT), a residual fine-tuning algorithm that treats intervention feedback as an incomplete learning signal and explicitly combines it with a prior policy. By framing intervention learning as a fine-tuning problem, our approach leverages structure encoded in the prior policy to resolve ambiguity when intervention signals under-specify the task. We provide theoretical analysis characterizing conditions under which this formulation yields principled policy improvement, and identify regimes where intervention learning is expected to fail. Our experiments reveal that residual fine-tuning enables robust and consistent policy improvement across a range of intervention strategies and prior policy qualities, and highlight robust intervention learning as a promising direction for future work.</div></details>
<details class="detail"><summary>中文标题/摘要</summary>
<div class="mono"><b>标题：</b>基于紧急停止干预的鲁棒干预学习</div>
<div class="mono" style="margin-top:8px">在自主系统测试中，人工干预是常见的数据来源。这些干预为当前策略的改进提供了重要信号，但通常存在噪声且不完整。我们定义鲁棒干预学习（RIL）为从干预数据中学习，同时对干预信号的质量和信息量保持鲁棒性的问题。在理想情况下，干预是精确的，避免干预足以完成任务；但在许多实际场景中，避免干预是必要的，却不足以实现良好性能。我们在紧急停止干预的背景下研究鲁棒干预学习，并提出残差干预微调（RIFT）算法，该算法将干预反馈视为不完整的学习信号，并明确将其与先验策略结合。通过将干预学习构建为微调问题，我们的方法利用先验策略中编码的结构来消除干预信号未充分指定任务时的歧义。我们提供了理论分析，描述了该框架实现原则性策略改进的条件，并识别了干预学习可能失效的机制。实验表明，残差微调能在多种干预策略和先验策略质量下实现鲁棒且一致的策略改进，凸显了鲁棒干预学习作为未来研究方向的潜力。</div>
</details>
<details class="detail"><summary>Summary / 总结</summary>
<div class="mono">The research addresses the challenge of learning from human interventions in autonomous systems, which are often noisy and incomplete, by defining Robust Intervention Learning (RIL) to improve policies while remaining robust to signal quality. The method introduces Residual Intervention Fine-Tuning (RIFT), a residual fine-tuning algorithm that treats intervention feedback as an incomplete signal and explicitly combines it with a prior policy to resolve ambiguity. Experimental results demonstrate that RIFT enables robust and consistent policy improvement across various intervention strategies and prior policy qualities, with theoretical analysis identifying conditions for principled improvement and failure regimes.</div>
<div class="mono" style="margin-top:8px">该研究针对自主系统中人类干预信号通常存在噪声和不完整的问题，提出了鲁棒干预学习（RIL），旨在从干预中学习并保持对信号质量的鲁棒性。方法上引入了残差干预微调（RIFT），这是一种残差微调算法，将干预反馈视为不完整信号，并与先验策略显式结合以解决任务歧义。实验结果表明，RIFT能在多种干预策略和先验策略质量下实现鲁棒且一致的策略改进，理论分析则明确了实现原则性改进的条件以及可能失败的机制。</div>
</details>
</div>
<div class="card">
<div class="title">Preference-based Conditional Treatment Effects and Policy Learning</div>
<div class="meta-line">Authors: Dovid Parnas, Mathieu Even, Julie Josse, Uri Shalit</div>
<div class="meta-line">First: 2026-02-03T18:31:26+00:00 · Latest: 2026-02-03T18:31:26+00:00</div>
<div class="meta-line">Comments: Accepted to AISTATS 2026; 10 pages + appendix</div>
<div class="links" style="margin-top:8px"><a href="https://arxiv.org/abs/2602.03823v1">Abs</a> · <a href="https://arxiv.org/pdf/2602.03823v1">PDF</a> · <a href="https://huggingface.co/huggingface">Code1</a> · <a href="https://huggingface.co/docs/hub/spaces">Code2</a></div>
<details class="detail"><summary>Abstract</summary>
<div class="mono">We introduce a new preference-based framework for conditional treatment effect estimation and policy learning, built on the Conditional Preference-based Treatment Effect (CPTE). CPTE requires only that outcomes be ranked under a preference rule, unlocking flexible modeling of heterogeneous effects with multivariate, ordinal, or preference-driven outcomes. This unifies applications such as conditional probability of necessity and sufficiency, conditional Win Ratio, and Generalized Pairwise Comparisons. Despite the intrinsic non-identifiability of comparison-based estimands, CPTE provides interpretable targets and delivers new identifiability conditions for previous unidentifiable estimands. We present estimation strategies via matching, quantile, and distributional regression, and further design efficient influence-function estimators to correct plug-in bias and maximize policy value. Synthetic and semi-synthetic experiments demonstrate clear performance gains and practical impact.</div></details>
<details class="detail"><summary>中文标题/摘要</summary>
<div class="mono"><b>标题：</b>基于偏好的条件处理效应与策略学习</div>
<div class="mono" style="margin-top:8px">本文提出一种新的基于偏好的条件处理效应估计与策略学习框架，其核心为条件偏好处理效应（CPTE）。CPTE仅要求结果在偏好规则下可排序，从而能够灵活建模具有多元、有序或偏好驱动结果的异质性效应。该框架统一了诸如条件必要性与充分性概率、条件胜率比及广义成对比较等应用场景。尽管基于比较的估计量存在固有的不可识别性，CPTE提供了可解释的目标，并为先前不可识别的估计量提出了新的可识别条件。我们通过匹配、分位数和分布回归提出估计策略，并进一步设计高效影响函数估计量以校正插件偏差并最大化策略价值。合成与半合成实验展示了显著的性能提升与实际应用价值。</div>
</details>
<details class="detail"><summary>Summary / 总结</summary>
<div class="mono">The research addresses the need for flexible treatment effect estimation when outcomes are multivariate, ordinal, or preference-driven, where traditional mean-based effects are insufficient. The authors propose the Conditional Preference-based Treatment Effect (CPTE) framework, which requires only outcome rankings under a preference rule, and develop estimation strategies using matching, quantile, and distributional regression, along with efficient influence-function estimators to correct plug-in bias and optimize policy value. Experimental results on synthetic and semi-synthetic data demonstrate that the proposed methods achieve clear performance improvements and offer practical impact for policy learning.</div>
<div class="mono" style="margin-top:8px">本研究旨在解决当结果为多变量、有序或由偏好定义时，传统基于均值的效应估计不足，需要灵活估计异质性处理效应的问题。方法引入了基于条件的偏好处理效应（CPTE）框架，该框架仅依赖于偏好规则下的结果排序，统一了如条件必要性与充分性概率等多种应用。它为先前不可识别的估计量提供了新的可识别性条件，并提出了包括匹配、回归和基于高效影响函数的偏差校正等估计策略，以进行策略学习。在合成和半合成数据上的实验结果表明，该方法取得了明显的性能提升和实际影响。</div>
</details>
</div>
<div class="card">
<div class="title">SymPlex: A Structure-Aware Transformer for Symbolic PDE Solving</div>
<div class="meta-line">Authors: Yesom Park, Annie C. Lu, Shao-Ching Huang, Qiyang Hu, Y. Sungtaek Ju, Stanley Osher</div>
<div class="meta-line">First: 2026-02-03T18:18:30+00:00 · Latest: 2026-02-03T18:18:30+00:00</div>
<div class="meta-line">Comments: 27 pages</div>
<div class="links" style="margin-top:8px"><a href="https://arxiv.org/abs/2602.03816v1">Abs</a> · <a href="https://arxiv.org/pdf/2602.03816v1">PDF</a> · <a href="https://huggingface.co/huggingface">Code1</a> · <a href="https://huggingface.co/docs/hub/spaces">Code2</a></div>
<details class="detail"><summary>Abstract</summary>
<div class="mono">We propose SymPlex, a reinforcement learning framework for discovering analytical symbolic solutions to partial differential equations (PDEs) without access to ground-truth expressions. SymPlex formulates symbolic PDE solving as tree-structured decision-making and optimizes candidate solutions using only the PDE and its boundary conditions. At its core is SymFormer, a structure-aware Transformer that models hierarchical symbolic dependencies via tree-relative self-attention and enforces syntactic validity through grammar-constrained autoregressive decoding, overcoming the limited expressivity of sequence-based generators. Unlike numerical and neural approaches that approximate solutions in discretized or implicit function spaces, SymPlex operates directly in symbolic expression space, enabling interpretable and human-readable solutions that naturally represent non-smooth behavior and explicit parametric dependence. Empirical results demonstrate exact recovery of non-smooth and parametric PDE solutions using deep learning-based symbolic methods.</div></details>
<details class="detail"><summary>中文标题/摘要</summary>
<div class="mono"><b>标题：</b>SymPlex：面向符号偏微分方程求解的结构感知Transformer</div>
<div class="mono" style="margin-top:8px">本文提出SymPlex——一种无需真实表达式即可发现偏微分方程解析符号解的强化学习框架。该框架将符号PDE求解建模为树结构决策过程，仅利用PDE及其边界条件优化候选解。其核心组件SymFormer是一种结构感知Transformer，通过树相对自注意力机制建模层次化符号依赖关系，并借助语法约束的自回归解码确保句法有效性，克服了基于序列生成器的表达能力局限。与在离散化或隐函数空间逼近解的传统数值及神经网络方法不同，SymPlex直接在符号表达式空间操作，可生成自然表征非光滑行为及显式参数依赖性的可解释、人类可读解。实验结果表明，该基于深度学习的符号方法能精确还原非光滑及参数化PDE解。</div>
</details>
<details class="detail"><summary>Summary / 总结</summary>
<div class="mono">The research aims to discover analytical symbolic solutions to partial differential equations (PDEs) without relying on ground-truth expressions, addressing the limitations of numerical approximations and implicit neural representations. The method introduces SymPlex, a reinforcement learning framework that formulates symbolic solving as tree-structured decision-making, and SymFormer, a structure-aware Transformer employing tree-relative self-attention and grammar-constrained decoding to generate syntactically valid expressions. Experimental results show that the approach can exactly recover non-smooth and parametric PDE solutions, demonstrating the capability of deep learning-based symbolic methods to produce interpretable, human-readable solutions.</div>
<div class="mono" style="margin-top:8px">本研究旨在无需依赖真实表达式的情况下，为偏微分方程（PDE）发现解析符号解，以解决数值近似和隐式神经表示的局限性。方法提出了SymPlex，一个将符号求解构建为树形决策过程的强化学习框架，以及SymFormer，一个通过树相对自注意力和语法约束解码来生成语法有效表达式的结构感知Transformer。实验结果表明，该方法能够精确恢复非光滑和参数化的PDE解，证明了基于深度学习的符号方法能够产生可解释、人类可读的解决方案。</div>
</details>
</div>
<div class="card">
<div class="title">Fast-Slow Efficient Training for Multimodal Large Language Models via Visual Token Pruning</div>
<div class="meta-line">Authors: Dingkun Zhang, Shuhan Qi, Yulin Wu, Xinyu Xiao, Xuan Wang, Long Chen</div>
<div class="meta-line">First: 2026-02-03T18:18:11+00:00 · Latest: 2026-02-03T18:18:11+00:00</div>
<div class="links" style="margin-top:8px"><a href="https://arxiv.org/abs/2602.03815v1">Abs</a> · <a href="https://arxiv.org/pdf/2602.03815v1">PDF</a> · <a href="https://github.com/dingkun-zhang/DualSpeed">Code1</a> · <a href="https://huggingface.co/huggingface">Code2</a> · <a href="https://huggingface.co/docs/hub/spaces">Code3</a></div>
<details class="detail"><summary>Abstract</summary>
<div class="mono">Multimodal Large Language Models (MLLMs) suffer from severe training inefficiency issue, which is associated with their massive model sizes and visual token numbers. Existing efforts in efficient training focus on reducing model sizes or trainable parameters. Inspired by the success of Visual Token Pruning (VTP) in improving inference efficiency, we are exploring another substantial research direction for efficient training by reducing visual tokens. However, applying VTP at the training stage results in a training-inference mismatch: pruning-trained models perform poorly when inferring on non-pruned full visual token sequences. To close this gap, we propose DualSpeed, a fast-slow framework for efficient training of MLLMs. The fast-mode is the primary mode, which incorporates existing VTP methods as plugins to reduce visual tokens, along with a mode isolator to isolate the model&#x27;s behaviors. The slow-mode is the auxiliary mode, where the model is trained on full visual sequences to retain training-inference consistency. To boost its training, it further leverages self-distillation to learn from the sufficiently trained fast-mode. Together, DualSpeed can achieve both training efficiency and non-degraded performance. Experiments show DualSpeed accelerates the training of LLaVA-1.5 by 2.1$\times$ and LLaVA-NeXT by 4.0$\times$, retaining over 99% performance. Code: https://github.com/dingkun-zhang/DualSpeed</div></details>
<details class="detail"><summary>中文标题/摘要</summary>
<div class="mono"><b>标题：</b>基于视觉令牌剪枝的多模态大语言模型快慢双速高效训练方法</div>
<div class="mono" style="margin-top:8px">多模态大语言模型（MLLMs）因其庞大的模型规模和视觉令牌数量而存在严重的训练效率问题。现有高效训练研究主要集中于缩减模型规模或可训练参数。受视觉令牌剪枝（VTP）在提升推理效率方面成功的启发，本研究探索通过减少视觉令牌实现高效训练的新方向。然而，在训练阶段直接应用VTP会导致训练-推理失配：经剪枝训练的模型在完整视觉令牌序列上进行推理时性能显著下降。为弥合这一差距，我们提出DualSpeed——一种用于MLLMs高效训练的快慢双速框架。快速模式作为主模式，将现有VTP方法作为插件来减少视觉令牌，并通过模式隔离器分离模型行为；慢速模式作为辅助模式，在完整视觉序列上进行训练以保持训练-推理一致性。为增强训练效果，该模式进一步利用自蒸馏技术从充分训练的快速模式中学习。DualSpeed能同时实现训练效率提升与性能无损保持。实验表明，DualSpeed将LLaVA-1.5训练速度提升2.1倍，LLaVA-NeXT提升4.0倍，性能保持率超过99%。代码地址：https://github.com/dingkun-zhang/DualSpeed</div>
</details>
<details class="detail"><summary>Summary / 总结</summary>
<div class="mono">To address the severe training inefficiency of Multimodal Large Language Models (MLLMs) caused by massive visual token numbers, this work explores visual token pruning for efficient training. The proposed DualSpeed framework employs a fast-slow training approach: the primary fast mode uses visual token pruning to reduce tokens, while an auxiliary slow mode trains on full token sequences to prevent a training-inference mismatch, further enhanced by self-distillation from the fast mode. Experiments demonstrate that DualSpeed accelerates training for LLaVA-1.5 by 2.1× and LLaVA-NeXT by 4.0× while maintaining over 99% of the original model performance.</div>
<div class="mono" style="margin-top:8px">为解决多模态大语言模型因海量视觉令牌导致的严重训练低效问题，本研究探索通过视觉令牌剪枝实现高效训练。提出的DualSpeed框架采用快速模式剪枝视觉令牌以提升效率，同时使用慢速模式处理完整令牌序列以保持训练-推理一致性，并通过从快速模式进行自蒸馏来增强训练。实验表明，DualSpeed将LLaVA-1.5和LLaVA-NeXT的训练分别加速2.1倍和4.0倍，同时保持超过99%的原始模型性能。</div>
</details>
</div>
<div class="card">
<div class="title">Conformal Thinking: Risk Control for Reasoning on a Compute Budget</div>
<div class="meta-line">Authors: Xi Wang, Anushri Suresh, Alvin Zhang, Rishi More, William Jurayj, Benjamin Van Durme, Mehrdad Farajtabar, Daniel Khashabi, Eric Nalisnick</div>
<div class="meta-line">First: 2026-02-03T18:17:22+00:00 · Latest: 2026-02-03T18:17:22+00:00</div>
<div class="links" style="margin-top:8px"><a href="https://arxiv.org/abs/2602.03814v1">Abs</a> · <a href="https://arxiv.org/pdf/2602.03814v1">PDF</a> · <a href="https://huggingface.co/huggingface">Code1</a> · <a href="https://huggingface.co/docs/hub/spaces">Code2</a></div>
<details class="detail"><summary>Abstract</summary>
<div class="mono">Reasoning Large Language Models (LLMs) enable test-time scaling, with dataset-level accuracy improving as the token budget increases, motivating adaptive reasoning -- spending tokens when they improve reliability and stopping early when additional computation is unlikely to help. However, setting the token budget, as well as the threshold for adaptive reasoning, is a practical challenge that entails a fundamental risk-accuracy trade-off. We re-frame the budget setting problem as risk control, limiting the error rate while minimizing compute. Our framework introduces an upper threshold that stops reasoning when the model is confident (risking incorrect output) and a novel parametric lower threshold that preemptively stops unsolvable instances (risking premature stoppage). Given a target risk and a validation set, we use distribution-free risk control to optimally specify these stopping mechanisms. For scenarios with multiple budget controlling criteria, we incorporate an efficiency loss to select the most computationally efficient exiting mechanism. Empirical results across diverse reasoning tasks and models demonstrate the effectiveness of our risk control approach, demonstrating computational efficiency gains from the lower threshold and ensemble stopping mechanisms while adhering to the user-specified risk target.</div></details>
<details class="detail"><summary>中文标题/摘要</summary>
<div class="mono"><b>标题：</b>保形思维：计算预算约束下的推理风险控制</div>
<div class="mono" style="margin-top:8px">推理型大语言模型（LLMs）支持测试时扩展，其数据集级准确率随计算令牌预算增加而提升，这催生了自适应推理机制——在能提升可靠性时消耗令牌，而在额外计算可能无效时提前终止。然而，设定令牌预算及自适应推理阈值存在实际挑战，涉及风险与准确率间的根本权衡。我们将预算设定问题重构为风险控制问题，在最小化计算量的同时限制错误率。该框架引入双重阈值：上阈值在模型置信时停止推理（可能产生错误输出），创新的参数化下阈值则主动终止不可解实例（可能过早停止）。给定目标风险与验证集，我们采用无分布风险控制方法优化配置这些停止机制。针对多预算控制标准的场景，通过引入效率损失函数选择计算效率最高的退出机制。跨多种推理任务与模型的实证结果表明，该风险控制方法在遵循用户指定风险目标的同时，通过下阈值与集成停止机制显著提升了计算效率。</div>
</details>
<details class="detail"><summary>Summary / 总结</summary>
<div class="mono">The research addresses the practical challenge of setting token budgets and thresholds for adaptive reasoning in Large Language Models (LLMs), where accuracy improves with increased computation but entails a risk-accuracy trade-off. The method reframes budget setting as a risk control problem, introducing an upper threshold to stop when confident and a novel parametric lower threshold to preemptively stop unsolvable instances, using distribution-free risk control on a validation set to optimally specify these mechanisms and incorporating an efficiency loss for scenarios with multiple criteria. Experimental results across diverse reasoning tasks and models show the approach effectively controls error rates to user-specified targets while achieving computational efficiency gains from the lower threshold and ensemble stopping mechanisms.</div>
<div class="mono" style="margin-top:8px">该研究针对大型语言模型自适应推理中设置令牌预算和阈值的实际挑战，即增加计算量可提高准确性但涉及风险-准确性权衡。方法将预算设置重新定义为风险控制问题，引入用于自信输出的上限阈值和用于预先停止不可解实例的新型参数化下限阈值，利用无分布风险控制根据目标风险和验证集优化指定这些机制，并为多标准场景纳入效率损失选择。在不同推理任务和模型上的实验结果表明，该方法通过下限阈值和集成停止机制实现了计算效率提升，同时遵守用户指定的风险目标。</div>
</details>
</div>
<div class="card">
<div class="title">Antidistillation Fingerprinting</div>
<div class="meta-line">Authors: Yixuan Even Xu, John Kirchenbauer, Yash Savani, Asher Trockman, Alexander Robey, Tom Goldstein, Fei Fang, J. Zico Kolter</div>
<div class="meta-line">First: 2026-02-03T18:15:50+00:00 · Latest: 2026-02-03T18:15:50+00:00</div>
<div class="meta-line">Comments: 26 pages, 11 figures</div>
<div class="links" style="margin-top:8px"><a href="https://arxiv.org/abs/2602.03812v1">Abs</a> · <a href="https://arxiv.org/pdf/2602.03812v1">PDF</a> · <a href="https://huggingface.co/huggingface">Code1</a> · <a href="https://huggingface.co/docs/hub/spaces">Code2</a></div>
<details class="detail"><summary>Abstract</summary>
<div class="mono">Model distillation enables efficient emulation of frontier large language models (LLMs), creating a need for robust mechanisms to detect when a third-party student model has trained on a teacher model&#x27;s outputs. However, existing fingerprinting techniques that could be used to detect such distillation rely on heuristic perturbations that impose a steep trade-off between generation quality and fingerprinting strength, often requiring significant degradation of utility to ensure the fingerprint is effectively internalized by the student. We introduce antidistillation fingerprinting (ADFP), a principled approach that aligns the fingerprinting objective with the student&#x27;s learning dynamics. Building upon the gradient-based framework of antidistillation sampling, ADFP utilizes a proxy model to identify and sample tokens that directly maximize the expected detectability of the fingerprint in the student after fine-tuning, rather than relying on the incidental absorption of the un-targeted biases of a more naive watermark. Experiments on GSM8K and OASST1 benchmarks demonstrate that ADFP achieves a significant Pareto improvement over state-of-the-art baselines, yielding stronger detection confidence with minimal impact on utility, even when the student model&#x27;s architecture is unknown.</div></details>
<details class="detail"><summary>中文标题/摘要</summary>
<div class="mono"><b>标题：</b>抗蒸馏指纹识别</div>
<div class="mono" style="margin-top:8px">模型蒸馏技术能够高效模拟前沿大语言模型（LLM），这催生了检测第三方学生模型是否基于教师模型输出进行训练的鲁棒机制需求。然而，现有可用于检测此类蒸馏的指纹识别技术依赖启发式扰动，导致生成质量与指纹强度之间存在显著权衡——通常需要大幅降低模型效用才能确保指纹被学生模型有效内化。本文提出抗蒸馏指纹识别（ADFP），这是一种将指纹识别目标与学生模型学习动态对齐的原理性方法。基于抗蒸馏采样的梯度框架，ADFP利用代理模型识别并采样能直接最大化微调后学生模型中指纹预期可检测性的词元，而非依赖朴素水印中非针对性偏差的偶然吸收。在GSM8K和OASST1基准测试上的实验表明，ADFP较现有先进基线实现了显著的帕累托改进，即使学生模型架构未知，仍能以最小效用代价获得更强的检测置信度。</div>
</details>
<details class="detail"><summary>Summary / 总结</summary>
<div class="mono">The need to detect when a third-party student model has been trained on a teacher model&#x27;s outputs via distillation motivates this work, as existing fingerprinting techniques impose a steep trade-off between generation quality and detection strength. The proposed method, antidistillation fingerprinting (ADFP), uses a proxy model to identify and sample tokens that directly maximize the expected detectability of the fingerprint in the student after fine-tuning, aligning the fingerprinting objective with the student&#x27;s learning dynamics. Experimental results on GSM8K and OASST1 benchmarks show that ADFP achieves a significant Pareto improvement over state-of-the-art baselines, providing stronger detection confidence with minimal impact on utility, even when the student model&#x27;s architecture is unknown.</div>
<div class="mono" style="margin-top:8px">模型蒸馏使得高效模仿前沿大语言模型成为可能，因此需要可靠的机制来检测第三方学生模型是否基于教师模型的输出进行了训练，而现有指纹技术依赖启发式扰动，导致生成质量与检测强度之间存在严重权衡。本研究提出的抗蒸馏指纹方法采用了一种原则性方法，利用代理模型识别并采样能直接最大化学生模型微调后指纹可检测性的标记，使指纹目标与学生的学习动态对齐。在GSM8K和OASST1基准上的实验结果表明，该方法相比现有基线实现了显著的帕累托改进，即使学生模型架构未知，也能以对效用最小的影响获得更强的检测置信度。</div>
</details>
</div>
<div class="card">
<div class="title">Enhancing Imbalanced Node Classification via Curriculum-Guided Feature Learning and Three-Stage Attention Network</div>
<div class="meta-line">Authors: Abdul Joseph Fofanah, Lian Wen, David Chen, Shaoyang Zhang</div>
<div class="meta-line">First: 2026-02-03T18:10:40+00:00 · Latest: 2026-02-03T18:10:40+00:00</div>
<div class="links" style="margin-top:8px"><a href="https://arxiv.org/abs/2602.03808v1">Abs</a> · <a href="https://arxiv.org/pdf/2602.03808v1">PDF</a> · <a href="https://huggingface.co/huggingface">Code1</a> · <a href="https://huggingface.co/docs/hub/spaces">Code2</a></div>
<details class="detail"><summary>Abstract</summary>
<div class="mono">Imbalanced node classification in graph neural networks (GNNs) happens when some labels are much more common than others, which causes the model to learn unfairly and perform badly on the less common classes. To solve this problem, we propose a Curriculum-Guided Feature Learning and Three-Stage Attention Network (CL3AN-GNN), a learning network that uses a three-step attention system (Engage, Enact, Embed) similar to how humans learn. The model begins by engaging with structurally simpler features, defined as (1) local neighbourhood patterns (1-hop), (2) low-degree node attributes, and (3) class-separable node pairs identified via initial graph convolutional networks and graph attention networks (GCN and GAT) embeddings. This foundation enables stable early learning despite label skew. The Enact stage then addresses complicated aspects: (1) connections that require multiple steps, (2) edges that connect different types of nodes, and (3) nodes at the edges of minority classes by using adjustable attention weights. Finally, Embed consolidates these features via iterative message passing and curriculum-aligned loss weighting. We evaluate CL3AN-GNN on eight Open Graph Benchmark datasets spanning social, biological, and citation networks. Experiments show consistent improvements across all datasets in accuracy, F1-score, and AUC over recent state-of-the-art methods. The model&#x27;s step-by-step method works well with different types of graph datasets, showing quicker results than training everything at once, better performance on new, imbalanced graphs, and clear explanations of each step using gradient stability and attention correlation learning curves. This work provides both a theoretically grounded framework for curriculum learning in GNNs and practical evidence of its effectiveness against imbalances, validated through metrics, convergence speeds, and generalisation tests.</div></details>
<details class="detail"><summary>中文标题/摘要</summary>
<div class="mono"><b>标题：</b>基于课程引导特征学习与三阶段注意力网络的非均衡节点分类增强方法</div>
<div class="mono" style="margin-top:8px">图神经网络中的非均衡节点分类问题指某些标签远多于其他标签，导致模型学习偏倚且在少数类上表现不佳。为解决该问题，我们提出课程引导特征学习与三阶段注意力网络（CL3AN-GNN），该网络采用模拟人类学习过程的三步注意力机制（Engage、Enact、Embed）。模型首先从结构简单的特征入手，包括：（1）局部邻域模式（1跳），（2）低度节点属性，（3）通过初始图卷积网络与图注意力网络嵌入识别的类可分节点对。该基础设计确保在标签倾斜情况下实现稳定早期学习。Enact阶段通过可调注意力权重处理复杂特征：（1）多步连接关系，（2）异质节点间边连接，（3）少数类边界节点。最后，Embed阶段通过迭代消息传递与课程对齐损失加权整合特征。我们在涵盖社交、生物和引文网络的八个开放图基准数据集上评估CL3AN-GNN。实验表明，该模型在准确率、F1分数和AUC指标上均优于当前最优方法。这种渐进式方法能适配不同类型的图数据集，相比整体训练具有更快收敛速度，在新非均衡图上表现更优，并通过梯度稳定性与注意力相关性学习曲线提供清晰的步骤解释。本研究不仅为图神经网络课程学习提供了理论框架，还通过性能指标、收敛速度与泛化测试验证了其应对非均衡问题的实际有效性。</div>
</details>
<details class="detail"><summary>Summary / 总结</summary>
<div class="mono">The research addresses the challenge of imbalanced node classification in graph neural networks, where models often underperform on minority classes due to skewed label distributions. The proposed method, CL3AN-GNN, employs a curriculum-guided three-stage attention network (Engage, Enact, Embed) that progressively learns from simpler to more complex graph features, utilizing local patterns, low-degree nodes, and class-separable pairs initially, then handling multi-hop connections, heterogeneous edges, and minority-class boundaries with adaptive attention weights. Experimental evaluation on eight Open Graph Benchmark datasets demonstrates consistent improvements in accuracy, F1-score, and AUC over state-of-the-art methods, along with faster convergence, better generalization to unseen imbalanced graphs, and interpretable learning dynamics through gradient stability and attention correlation analysis.</div>
<div class="mono" style="margin-top:8px">本研究针对图神经网络中节点分类的类别不平衡问题，即标签分布不均导致模型在少数类上性能下降。提出的CL3AN-GNN方法采用课程引导的三阶段注意力网络（Engage、Enact、Embed），通过从简单到复杂的特征渐进学习，利用注意力机制聚焦局部模式、低度节点和少数类边界。在八个Open Graph Benchmark数据集上的实验表明，该方法在准确率、F1分数和AUC指标上均优于现有先进方法，同时具有更快的收敛速度和对未见不平衡图更好的泛化能力。</div>
</details>
</div>
<div class="card">
<div class="title">Bridging Online and Offline RL: Contextual Bandit Learning for Multi-Turn Code Generation</div>
<div class="meta-line">Authors: Ziru Chen, Dongdong Chen, Ruinan Jin, Yingbin Liang, Yujia Xie, Huan Sun</div>
<div class="meta-line">First: 2026-02-03T18:08:41+00:00 · Latest: 2026-02-03T18:08:41+00:00</div>
<div class="links" style="margin-top:8px"><a href="https://arxiv.org/abs/2602.03806v1">Abs</a> · <a href="https://arxiv.org/pdf/2602.03806v1">PDF</a> · <a href="https://github.com/OSU-NLP-Group/cobalt">Code1</a> · <a href="https://huggingface.co/huggingface">Code2</a> · <a href="https://huggingface.co/docs/hub/spaces">Code3</a></div>
<details class="detail"><summary>Abstract</summary>
<div class="mono">Recently, there have been significant research interests in training large language models (LLMs) with reinforcement learning (RL) on real-world tasks, such as multi-turn code generation. While online RL tends to perform better than offline RL, its higher training cost and instability hinders wide adoption. In this paper, we build on the observation that multi-turn code generation can be formulated as a one-step recoverable Markov decision process and propose contextual bandit learning with offline trajectories (Cobalt), a new method that combines the benefits of online and offline RL. Cobalt first collects code generation trajectories using a reference LLM and divides them into partial trajectories as contextual prompts. Then, during online bandit learning, the LLM is trained to complete each partial trajectory prompt through single-step code generation. Cobalt outperforms two multi-turn online RL baselines based on GRPO and VeRPO, and substantially improves R1-Distill 8B and Qwen3 8B by up to 9.0 and 6.2 absolute Pass@1 scores on LiveCodeBench. Also, we analyze LLMs&#x27; in-context reward hacking behaviors and augment Cobalt training with perturbed trajectories to mitigate this issue. Overall, our results demonstrate Cobalt as a promising solution for iterative decision-making tasks like multi-turn code generation. Our code and data are available at https://github.com/OSU-NLP-Group/cobalt.</div></details>
<details class="detail"><summary>中文标题/摘要</summary>
<div class="mono"><b>标题：</b>连接在线与离线强化学习：面向多轮代码生成的上下文赌博机学习</div>
<div class="mono" style="margin-top:8px">近期，利用强化学习在真实世界任务（如多轮代码生成）上训练大语言模型的研究备受关注。虽然在线强化学习通常表现优于离线强化学习，但其较高的训练成本和不稳定性限制了广泛应用。本文基于多轮代码生成可建模为单步可恢复马尔可夫决策过程的观察，提出了基于离线轨迹的上下文赌博机学习方法（Cobalt），该方法融合了在线与离线强化学习的优势。Cobalt首先使用参考大语言模型收集代码生成轨迹，并将其分割为作为上下文提示的部分轨迹；随后在在线赌博机学习阶段，通过单步代码生成训练大语言模型完成每个部分轨迹提示。Cobalt在LiveCodeBench基准上显著优于基于GRPO和VeRPO的两种多轮在线强化学习基线，将R1-Distill 8B和Qwen3 8B模型的Pass@1分数分别提升高达9.0和6.2个绝对百分点。此外，我们分析了大语言模型的上下文奖励攻击行为，并通过扰动轨迹增强Cobalt训练以缓解该问题。总体而言，我们的结果表明Cobalt为多轮代码生成等迭代决策任务提供了有前景的解决方案。代码与数据已开源：https://github.com/OSU-NLP-Group/cobalt。</div>
</details>
<details class="detail"><summary>Summary / 总结</summary>
<div class="mono">This research addresses the challenge of applying reinforcement learning to large language models for multi-turn code generation, where online RL is effective but costly and unstable, while offline RL is more stable but less performant. The proposed method, Contextual Bandit Learning with Offline Trajectories (Cobalt), formulates the task as a one-step recoverable Markov decision process, first collecting trajectories from a reference LLM and using partial trajectories as contextual prompts, then training the LLM through online bandit learning to complete these prompts in single-step generations. Experiments show that Cobalt outperforms online RL baselines like GRPO and VeRPO, improving models such as R1-Distill 8B and Qwen3 8B by up to 9.0 and 6.2 absolute Pass@1 scores on LiveCodeBench, while also mitigating in-context reward hacking via perturbed trajectory augmentation.</div>
<div class="mono" style="margin-top:8px">针对在线强化学习训练大语言模型进行多轮代码生成时成本高、不稳定的问题，本研究将任务建模为一步可恢复马尔可夫决策过程，提出了基于离线轨迹的上下文赌博机学习方法。该方法首先使用参考模型收集完整的代码生成轨迹，将其分割为部分轨迹作为上下文提示，然后通过在线单步赌博机学习训练模型完成这些提示。实验结果表明，该方法优于GRPO和VeRPO等在线强化学习基线，在LiveCodeBench上将R1-Distill 8B和Qwen3 8B模型的Pass@1分数分别提升了最高9.0和6.2分，并通过使用扰动轨迹进行数据增强，缓解了模型在上下文中的奖励黑客行为。</div>
</details>
</div>
<div class="card">
<div class="title">Measuring Agents in Production</div>
<div class="meta-line">Authors: Melissa Z. Pan, Negar Arabzadeh, Riccardo Cogo, Yuxuan Zhu, Alexander Xiong, Lakshya A Agrawal, Huanzhi Mao, Emma Shen, Sid Pallerla, Liana Patel, Shu Liu, Tianneng Shi, Xiaoyuan Liu, Jared Quincy Davis, Emmanuele Lacavalla, Alessandro Basile, Shuyi Yang, Paul Castro, Daniel Kang, Joseph E. Gonzalez, Koushik Sen, Dawn Song, Ion Stoica, Matei Zaharia, Marquita Ellis</div>
<div class="meta-line">First: 2025-12-02T16:45:10+00:00 · Latest: 2026-02-03T18:06:26+00:00</div>
<div class="links" style="margin-top:8px"><a href="https://arxiv.org/abs/2512.04123v3">Abs</a> · <a href="https://arxiv.org/pdf/2512.04123v3">PDF</a> · <a href="https://huggingface.co/huggingface">Code1</a> · <a href="https://huggingface.co/docs/hub/spaces">Code2</a></div>
<details class="detail"><summary>Abstract</summary>
<div class="mono">LLM-based agents already operate in production across many industries, yet we lack an understanding of what technical methods make deployments successful. We present the first systematic study of Measuring Agents in Production, MAP, using first-hand data from agent developers. We conducted 20 case studies via in-depth interviews and surveyed 306 practitioners across 26 domains. We investigate why organizations build agents, how they build them, how they evaluate them, and their top development challenges. Our study finds that production agents are built using simple, controllable approaches: 68% execute at most 10 steps before human intervention, 70% rely on prompting off-the-shelf models instead of weight tuning, and 74% depend primarily on human evaluation. Reliability (consistent correct behavior over time) remains the top development challenge, which practitioners currently address through systems-level design. MAP documents the current state of production agents, providing the research community with visibility into deployment realities and under-explored research avenues.</div></details>
<details class="detail"><summary>中文标题/摘要</summary>
<div class="mono"><b>标题：</b>生产环境中智能体的度量研究</div>
<div class="mono" style="margin-top:8px">基于大语言模型的智能体已在多行业投入生产应用，但关于何种技术方法能确保部署成功仍缺乏系统认知。本研究通过开发者一手数据，首次对生产环境中的智能体度量（MAP）展开系统性研究：通过深度访谈完成20个案例研究，并调研了涵盖26个领域的306名从业者。我们探究了企业开发智能体的动因、构建方式、评估体系及核心挑战。研究发现，生产级智能体普遍采用简洁可控的实现方案：68%的智能体在人工干预前最多执行10步操作，70%依赖现成模型的提示工程而非权重调优，74%主要依靠人工评估。可靠性（长期保持行为一致性与正确性）仍是首要挑战，从业者目前通过系统级设计应对。MAP研究记录了生产智能体的现状，为学界揭示实际部署情况与尚待探索的研究路径。</div>
</details>
<details class="detail"><summary>Summary / 总结</summary>
<div class="mono">The research is motivated by the widespread deployment of LLM-based agents in production across industries, yet a lack of systematic understanding of what technical methods lead to successful deployments. The method involves the first systematic study, Measuring Agents in Production (MAP), which collects first-hand data through 20 in-depth case study interviews and a survey of 306 practitioners across 26 domains to investigate why and how organizations build agents, how they evaluate them, and their key challenges. The main experimental findings reveal that production agents are predominantly built using simple, controllable approaches: 68% execute at most 10 steps before requiring human intervention, 70% rely on prompting off-the-shelf models rather than weight tuning, and 74% depend primarily on human evaluation, with reliability being the top development challenge addressed through systems-level design.</div>
<div class="mono" style="margin-top:8px">本研究的动机在于，尽管基于大语言模型的智能体已在各行业的生产环境中广泛部署，但对其成功部署的技术方法仍缺乏系统性理解。研究方法上，首次通过测量生产环境中的智能体（MAP）进行系统性研究，收集了一手数据，包括20个深度案例访谈和对26个领域的306名从业者的调查，以探究组织构建智能体的原因、方法、评估方式及主要挑战。主要实验结果表明，生产环境中的智能体主要采用简单、可控的方法构建：68%的智能体在执行最多10步后就需要人工干预，70%依赖提示现成模型而非权重调优，74%主要依靠人工评估，而可靠性（随时间保持一致的正确行为）是首要的开发挑战，目前通过系统级设计来解决。</div>
</details>
</div>
<div class="card">
<div class="title">Prediction of Critical Heat Flux in Rod Bundles Using Tube-Based Hybrid Machine Learning Models in CTF</div>
<div class="meta-line">Authors: Aidan Furlong, Robert Salko, Xingang Zhao, Xu Wu</div>
<div class="meta-line">First: 2026-02-03T18:05:16+00:00 · Latest: 2026-02-03T18:05:16+00:00</div>
<div class="meta-line">Comments: Submitted to the 2026 American Nuclear Society Annual Meeting</div>
<div class="links" style="margin-top:8px"><a href="https://arxiv.org/abs/2602.03805v1">Abs</a> · <a href="https://arxiv.org/pdf/2602.03805v1">PDF</a> · <a href="https://huggingface.co/huggingface">Code1</a> · <a href="https://huggingface.co/docs/hub/spaces">Code2</a></div>
<details class="detail"><summary>Abstract</summary>
<div class="mono">The prediction of critical heat flux (CHF) using machine learning (ML) approaches has become a highly active research activity in recent years, the goal of which is to build models more accurate than current conventional approaches such as empirical correlations or lookup tables (LUTs). Previous work developed and deployed tube-based pure and hybrid ML models in the CTF subchannel code, however, full-scale reactor core simulations require the use of rod bundle geometries. Unlike isolated subchannels, rod bundles experience complex thermal hydraulic phenomena such as channel crossflow, spacer grid losses, and effects from unheated conductors. This study investigates the generalization of ML-based CHF prediction models in rod bundles after being trained on tube-based CHF data. A purely data-driven DNN and two hybrid bias-correction models were implemented in the CTF subchannel code and used to predict CHF location and magnitude in the Combustion Engineering 5-by-5 bundle CHF test series. The W-3 correlation, Bowring correlation, and Groeneveld LUT were used as baseline comparators. On average, all three ML-based approaches produced magnitude and location predictions more accurate than the baseline models, with the hybrid LUT model exhibiting the most favorable performance metrics.</div></details>
<details class="detail"><summary>中文标题/摘要</summary>
<div class="mono"><b>标题：</b>基于管状混合机器学习模型的CTF棒束临界热流密度预测研究</div>
<div class="mono" style="margin-top:8px">近年来，采用机器学习方法预测临界热流密度已成为高度活跃的研究领域，其目标是构建比当前经验关联式或查值表等传统方法更精确的模型。先前研究已在CTF子通道程序中开发并部署了基于管状数据的纯机器学习及混合模型，但全尺寸堆芯模拟需采用棒束几何结构。与孤立子通道不同，棒束会经历通道横流、定位格架损失及未加热导体影响等复杂热工水力现象。本研究探讨了基于管状临界热流密度数据训练的机器学习模型在棒束中的泛化能力。在CTF子通道程序中实现了纯数据驱动的深度神经网络和两种混合偏差校正模型，用于预测燃烧工程5×5棒束临界热流密度测试序列中的临界热流密度位置与幅值。研究以W-3关联式、鲍林关联式和格罗内维尔德查值表作为基准对比模型。平均而言，三种机器学习方法在幅值与位置预测上均优于基准模型，其中混合查值表模型展现出最优的性能指标。</div>
</details>
<details class="detail"><summary>Summary / 总结</summary>
<div class="mono">This study addresses the need to extend machine learning (ML) models for critical heat flux (CHF) prediction from simple tube geometries to complex rod bundles, which involve crossflow and spacer grid effects, for full-core reactor simulations. The method implements a purely data-driven deep neural network (DNN) and two hybrid bias-correction models within the CTF subchannel code, applying them to a 5-by-5 rod bundle test series after training on tube-based data. Experimental results show that all three ML-based approaches, benchmarked against the W-3 correlation, Bowring correlation, and Groeneveld lookup table, achieved more accurate predictions of both CHF magnitude and location on average, with the hybrid lookup table model performing best.</div>
<div class="mono" style="margin-top:8px">本研究旨在解决将用于预测临界热流密度（CHF）的机器学习模型从简单的管状几何结构推广到复杂棒束几何结构的需求，因为棒束涉及横流和定位格架效应等现象，这对于全堆芯反应堆模拟是必要的。方法是在CTF子通道程序中实现了一个纯数据驱动的深度神经网络和两个混合偏差校正模型，将其应用于预测燃烧工程5x5棒束测试系列中的CHF，并与传统的W-3关联式、Bowring关联式以及Groeneveld查表法进行对比。主要的实验结果表明，平均而言，所有三种基于机器学习的方法在CHF大小和位置预测上都比基线模型更准确，其中混合查表模型显示出最优的性能指标。</div>
</details>
</div>
<div class="card">
<div class="title">Manifold Random Features</div>
<div class="meta-line">Authors: Ananya Parashar, Derek Long, Dwaipayan Saha, Krzysztof Choromanski</div>
<div class="meta-line">First: 2026-02-03T18:00:01+00:00 · Latest: 2026-02-03T18:00:01+00:00</div>
<div class="links" style="margin-top:8px"><a href="https://arxiv.org/abs/2602.03797v1">Abs</a> · <a href="https://arxiv.org/pdf/2602.03797v1">PDF</a> · <a href="https://huggingface.co/huggingface">Code1</a> · <a href="https://huggingface.co/docs/hub/spaces">Code2</a></div>
<details class="detail"><summary>Abstract</summary>
<div class="mono">We present a new paradigm for creating random features to approximate bi-variate functions (in particular, kernels) defined on general manifolds. This new mechanism of Manifold Random Features (MRFs) leverages discretization of the manifold and the recently introduced technique of Graph Random Features (GRFs) to learn continuous fields on manifolds. Those fields are used to find continuous approximation mechanisms that otherwise, in general scenarios, cannot be derived analytically. MRFs provide positive and bounded features, a key property for accurate, low-variance approximation. We show deep asymptotic connection between GRFs, defined on discrete graph objects, and continuous random features used for regular kernels. As a by-product of our method, we re-discover recently introduced mechanism of Gaussian kernel approximation applied in particular to improve linear-attention Transformers, considering simple random walks on graphs and by-passing original complex mathematical computations. We complement our algorithm with a rigorous theoretical analysis and verify in thorough experimental studies.</div></details>
<details class="detail"><summary>中文标题/摘要</summary>
<div class="mono"><b>标题：</b>流形随机特征</div>
<div class="mono" style="margin-top:8px">我们提出了一种新范式，用于创建随机特征以逼近定义在一般流形上的双变量函数（特别是核函数）。这种流形随机特征（MRFs）的新机制利用流形的离散化及近期提出的图随机特征（GRFs）技术，学习流形上的连续场。这些场用于寻找连续逼近机制，而在一般场景下，这些机制通常无法通过解析方法推导。MRFs提供正且有界的特征，这是实现精确、低方差逼近的关键特性。我们揭示了定义在离散图对象上的GRFs与用于常规核的连续随机特征之间的深层渐近联系。作为方法的副产品，我们重新发现了近期提出的高斯核逼近机制，该机制特别应用于改进线性注意力Transformer，通过考虑图上的简单随机游走，绕过了原始复杂的数学计算。我们通过严格的理论分析补充算法，并在详尽的实验研究中进行了验证。</div>
</details>
<details class="detail"><summary>Summary / 总结</summary>
<div class="mono">This research addresses the challenge of approximating bi-variate functions, particularly kernels, on general manifolds where analytical continuous approximations are often unavailable. The method introduces Manifold Random Features (MRFs), which discretize the manifold and apply Graph Random Features (GRFs) to learn continuous fields, thereby enabling kernel approximation. Key experimental findings demonstrate that MRFs produce positive and bounded features, leading to accurate and low-variance approximations, and reveal a deep asymptotic connection between discrete GRFs and continuous random features for regular kernels. As a byproduct, the method independently rediscovers a Gaussian kernel approximation mechanism used to enhance linear-attention Transformers, achieved through simple random walks on graphs, bypassing original complex computations.</div>
<div class="mono" style="margin-top:8px">该研究旨在近似一般流形上的双变量函数（如核函数），这些场景通常无法解析地获得连续逼近。方法提出了流形随机特征（MRFs），通过离散化流形并应用图随机特征（GRFs）来学习连续场，从而以正定有界特征实现低方差的核近似。实验验证了MRFs的有效性，同时该方法还重新发现了用于改进线性注意力Transformer的高斯核近似机制，建立了离散图基与连续随机特征之间的深层联系。</div>
</details>
</div>
<div class="card">
<div class="title">Understanding Agent Scaling in LLM-Based Multi-Agent Systems via Diversity</div>
<div class="meta-line">Authors: Yingxuan Yang, Chengrui Qu, Muning Wen, Laixi Shi, Ying Wen, Weinan Zhang, Adam Wierman, Shangding Gu</div>
<div class="meta-line">First: 2026-02-03T17:58:10+00:00 · Latest: 2026-02-03T17:58:10+00:00</div>
<div class="links" style="margin-top:8px"><a href="https://arxiv.org/abs/2602.03794v1">Abs</a> · <a href="https://arxiv.org/pdf/2602.03794v1">PDF</a> · <a href="https://github.com/SafeRL-Lab/Agent-Scaling">Code1</a> · <a href="https://huggingface.co/huggingface">Code2</a> · <a href="https://huggingface.co/docs/hub/spaces">Code3</a></div>
<details class="detail"><summary>Abstract</summary>
<div class="mono">LLM-based multi-agent systems (MAS) have emerged as a promising approach to tackle complex tasks that are difficult for individual LLMs. A natural strategy is to scale performance by increasing the number of agents; however, we find that such scaling exhibits strong diminishing returns in homogeneous settings, while introducing heterogeneity (e.g., different models, prompts, or tools) continues to yield substantial gains. This raises a fundamental question: what limits scaling, and why does diversity help? We present an information-theoretic framework showing that MAS performance is bounded by the intrinsic task uncertainty, not by agent count. We derive architecture-agnostic bounds demonstrating that improvements depend on how many effective channels the system accesses. Homogeneous agents saturate early because their outputs are strongly correlated, whereas heterogeneous agents contribute complementary evidence. We further introduce $K^*$, an effective channel count that quantifies the number of effective channels without ground-truth labels. Empirically, we show that heterogeneous configurations consistently outperform homogeneous scaling: 2 diverse agents can match or exceed the performance of 16 homogeneous agents. Our results provide principled guidelines for building efficient and robust MAS through diversity-aware design. Code and Dataset are available at the link: https://github.com/SafeRL-Lab/Agent-Scaling.</div></details>
<details class="detail"><summary>中文标题/摘要</summary>
<div class="mono"><b>标题：</b>基于多样性的LLM多智能体系统规模扩展机制解析</div>
<div class="mono" style="margin-top:8px">基于大语言模型的多智能体系统已成为解决单一模型难以应对复杂任务的有效途径。通过增加智能体数量来提升性能是常见策略，但研究发现：在智能体同质化场景中，规模扩展会迅速遭遇收益递减；而引入异质性（如采用不同模型、提示词或工具）则能持续带来显著增益。这引出一个核心问题：规模扩展的瓶颈何在？多样性为何有效？我们提出一个信息论框架，证明系统性能受限于任务内在不确定性，而非智能体数量。通过推导架构无关的边界条件，发现性能提升取决于系统可调用的有效信息通道数量。同质智能体因输出高度相关而快速饱和，异质智能体则能提供互补证据。我们进一步提出$K^*$指标——一种无需真实标签即可量化有效通道数量的方法。实验表明：异质配置始终优于同质扩展，仅需2个异质智能体即可达到甚至超越16个同质智能体的性能。本研究为通过多样性感知设计构建高效鲁棒的多智能体系统提供了理论指导。代码与数据集已开源：https://github.com/SafeRL-Lab/Agent-Scaling。</div>
</details>
<details class="detail"><summary>Summary / 总结</summary>
<div class="mono">This research investigates why scaling the number of agents in LLM-based multi-agent systems (MAS) often yields diminishing returns, and how diversity mitigates this. The authors propose an information-theoretic framework showing that MAS performance is bounded by intrinsic task uncertainty and the number of effective information channels, not by agent count. They introduce $K^*$, a metric to quantify effective channels without ground-truth labels. Experimental results demonstrate that heterogeneous agent configurations (using different models, prompts, or tools) substantially outperform homogeneous scaling, with just two diverse agents matching or exceeding the performance of sixteen homogeneous agents.</div>
<div class="mono" style="margin-top:8px">本研究旨在探究为何在基于大语言模型的多智能体系统中单纯增加智能体数量往往收益递减，以及多样性如何突破这一限制。作者提出了一个信息论框架，证明多智能体系统的性能根本上受限于任务本身的内在不确定性，而非智能体数量，性能提升取决于系统能否访问更多有效且不相关的信息通道。实验结果表明，采用不同模型或提示词的异构智能体配置显著优于同构扩展，仅需两个异构智能体的性能即可匹配甚至超过十六个同构智能体。</div>
</details>
</div>
<div class="card">
<div class="title">Admissibility of Stein Shrinkage for Batch Normalization in the Presence of Adversarial Attacks</div>
<div class="meta-line">Authors: Sofia Ivolgina, P. Thomas Fletcher, Baba C. Vemuri</div>
<div class="meta-line">First: 2025-07-11T02:13:42+00:00 · Latest: 2026-02-03T17:54:39+00:00</div>
<div class="links" style="margin-top:8px"><a href="https://arxiv.org/abs/2507.08261v2">Abs</a> · <a href="https://arxiv.org/pdf/2507.08261v2">PDF</a> · <a href="https://huggingface.co/huggingface">Code1</a> · <a href="https://huggingface.co/docs/hub/spaces">Code2</a></div>
<details class="detail"><summary>Abstract</summary>
<div class="mono">Batch normalization (BN) is a ubiquitous operation in deep neural networks, primarily used to improve stability and regularization during training. BN centers and scales feature maps using sample means and variances, which are naturally suited for Stein&#x27;s shrinkage estimation. Applying such shrinkage yields more accurate mean and variance estimates of the batch in the mean-squared-error sense. In this paper, we prove that the Stein shrinkage estimator of the mean and variance dominates over the sample mean and variance estimators, respectively, in the presence of adversarial attacks modeled using sub-Gaussian distributions. Furthermore, by construction, the James-Stein (JS) BN yields a smaller local Lipschitz constant compared to the vanilla BN, implying better regularity properties and potentially improved robustness. This facilitates and justifies the application of Stein shrinkage to estimate the mean and variance parameters in BN and the use of it in image classification and segmentation tasks with and without adversarial attacks. We present SOTA performance results using this Stein-corrected BN in a standard ResNet architecture applied to the task of image classification using CIFAR-10 data, 3D CNN on PPMI (neuroimaging) data, and image segmentation using HRNet on Cityscape data with and without adversarial attacks.</div></details>
<details class="detail"><summary>中文标题/摘要</summary>
<div class="mono"><b>标题：</b>对抗攻击下Stein收缩在批归一化中的适用性</div>
<div class="mono" style="margin-top:8px">批归一化（BN）是深度神经网络中普遍采用的操作，主要用于提升训练稳定性和正则化效果。BN利用样本均值和方差对特征图进行中心化与缩放，这自然适用于Stein收缩估计。应用此类收缩能在均方误差意义上获得更精确的批次均值与方差估计。本文证明，在采用亚高斯分布建模的对抗攻击存在时，均值与方差的Stein收缩估计量分别优于样本均值与方差估计量。此外，通过结构设计，James-Stein（JS）BN相比原始BN具有更小的局部Lipschitz常数，意味着更好的正则特性及潜在的鲁棒性提升。这为Stein收缩应用于BN的均值方差参数估计提供了理论依据，并支持其在有无对抗攻击的图像分类与分割任务中的使用。我们在标准ResNet架构中应用Stein修正BN，在CIFAR-10数据图像分类、PPMI（神经影像）数据的3D CNN分析，以及Cityscape数据上采用HRNet进行图像分割（含/不含对抗攻击）的任务中，均取得了当前最优的性能结果。</div>
</details>
<details class="detail"><summary>Summary / 总结</summary>
<div class="mono">This research addresses the vulnerability of batch normalization (BN) to adversarial attacks by proposing a more robust estimation method for its mean and variance parameters. The method applies Stein shrinkage, specifically the James-Stein estimator, to the sample statistics used in BN, theoretically proving its dominance over standard estimators under adversarial conditions modeled by sub-Gaussian distributions. Experimental results demonstrate state-of-the-art performance, including improved robustness and a reduced local Lipschitz constant, in image classification tasks on CIFAR-10 and neuroimaging data, as well as in image segmentation on Cityscapes data.</div>
<div class="mono" style="margin-top:8px">本研究针对深度神经网络中批归一化（BN）对对抗性攻击的脆弱性，提出了一种更鲁棒的估计方法。作者应用斯坦因收缩估计，特别是詹姆斯-斯坦因估计器，来改进BN内部的样本均值和方差计算，并从理论上证明了在子高斯分布建模的对抗条件下，该估计器优于标准估计器。实验结果表明，这种斯坦因校正的BN降低了局部利普希茨常数，从而具有更好的正则性，并在CIFAR-10图像分类、神经影像数据分类以及Cityscape数据图像分割任务中，无论是否存在对抗性攻击，均展现出先进的性能，提升了模型的鲁棒性。</div>
</details>
</div>
<div class="card">
<div class="title">Should I use Synthetic Data for That? An Analysis of the Suitability of Synthetic Data for Data Sharing and Augmentation</div>
<div class="meta-line">Authors: Bogdan Kulynych, Theresa Stadler, Jean Louis Raisaro, Carmela Troncoso</div>
<div class="meta-line">First: 2026-02-03T17:52:57+00:00 · Latest: 2026-02-03T17:52:57+00:00</div>
<div class="meta-line">Comments: BK and TS contributed equally</div>
<div class="links" style="margin-top:8px"><a href="https://arxiv.org/abs/2602.03791v1">Abs</a> · <a href="https://arxiv.org/pdf/2602.03791v1">PDF</a> · <a href="https://huggingface.co/huggingface">Code1</a> · <a href="https://huggingface.co/docs/hub/spaces">Code2</a></div>
<details class="detail"><summary>Abstract</summary>
<div class="mono">Recent advances in generative modelling have led many to see synthetic data as the go-to solution for a range of problems around data access, scarcity, and under-representation. In this paper, we study three prominent use cases: (1) Sharing synthetic data as a proxy for proprietary datasets to enable statistical analyses while protecting privacy, (2) Augmenting machine learning training sets with synthetic data to improve model performance, and (3) Augmenting datasets with synthetic data to reduce variance in statistical estimation. For each use case, we formalise the problem setting and study, through formal analysis and case studies, under which conditions synthetic data can achieve its intended objectives. We identify fundamental and practical limits that constrain when synthetic data can serve as an effective solution for a particular problem. Our analysis reveals that due to these limits many existing or envisioned use cases of synthetic data are a poor problem fit. Our formalisations and classification of synthetic data use cases enable decision makers to assess whether synthetic data is a suitable approach for their specific data availability problem.</div></details>
<details class="detail"><summary>中文标题/摘要</summary>
<div class="mono"><b>标题：</b>是否应使用合成数据？——合成数据在数据共享与增强中的适用性分析</div>
<div class="mono" style="margin-top:8px">生成建模的最新进展使许多人将合成数据视为解决数据访问、稀缺性和代表性不足等问题的首选方案。本文研究了三个主要应用场景：(1) 将合成数据作为专有数据集的替代进行共享，以在保护隐私的同时支持统计分析；(2) 通过合成数据增强机器学习训练集以提升模型性能；(3) 利用合成数据扩充数据集以降低统计估计的方差。针对每个场景，我们通过形式化分析和案例研究，明确了问题设定，并探讨了合成数据在何种条件下能实现其预期目标。研究揭示了制约合成数据在特定问题中有效性的根本性与实践性限制，指出由于这些限制，许多现有或设想中的合成数据应用场景与实际问题匹配度较低。本文对合成数据应用场景的形式化分类，可帮助决策者评估合成数据是否适合解决其特定的数据可用性问题。</div>
</details>
<details class="detail"><summary>Summary / 总结</summary>
<div class="mono">Motivated by the growing perception of synthetic data as a universal solution for data access, scarcity, and under-representation issues, this paper systematically analyzes its suitability for three prominent use cases: sharing as a privacy-preserving proxy for proprietary data, augmenting machine learning training sets, and reducing variance in statistical estimation. The method involves formalizing each problem setting and conducting formal analyses and case studies to determine the conditions under which synthetic data can meet its objectives. The key experimental findings reveal fundamental and practical limits, indicating that many existing or envisioned applications of synthetic data are poorly suited, thereby providing a framework to help decision-makers assess its appropriateness for specific data availability problems.</div>
<div class="mono" style="margin-top:8px">鉴于合成数据日益被视为解决数据访问、稀缺性和代表性不足等问题的通用方案，本文系统分析了其在三个主要应用场景中的适用性：作为专有数据的隐私保护代理进行共享、用于增强机器学习训练集以及减少统计估计的方差。研究方法包括形式化每个问题设置，并通过形式化分析和案例研究来确定合成数据能够实现其目标的条件。关键的实验结果表明，合成数据存在根本性和实践性的限制，这表明许多现有或设想的合成数据应用并不合适，从而为决策者评估其针对特定数据可用性问题的适用性提供了一个框架。</div>
</details>
</div>
<div class="card">
<div class="title">Fast Sampling for Flows and Diffusions with Lazy and Point Mass Stochastic Interpolants</div>
<div class="meta-line">Authors: Gabriel Damsholt, Jes Frellsen, Susanne Ditlevsen</div>
<div class="meta-line">First: 2026-02-03T17:48:34+00:00 · Latest: 2026-02-03T17:48:34+00:00</div>
<div class="links" style="margin-top:8px"><a href="https://arxiv.org/abs/2602.03789v1">Abs</a> · <a href="https://arxiv.org/pdf/2602.03789v1">PDF</a> · <a href="https://huggingface.co/huggingface">Code1</a> · <a href="https://huggingface.co/docs/hub/spaces">Code2</a></div>
<details class="detail"><summary>Abstract</summary>
<div class="mono">Stochastic interpolants unify flows and diffusions, popular generative modeling frameworks. A primary hyperparameter in these methods is the interpolation schedule that determines how to bridge a standard Gaussian base measure to an arbitrary target measure. We prove how to convert a sample path of a stochastic differential equation (SDE) with arbitrary diffusion coefficient under any schedule into the unique sample path under another arbitrary schedule and diffusion coefficient. We then extend the stochastic interpolant framework to admit a larger class of point mass schedules in which the Gaussian base measure collapses to a point mass measure. Under the assumption of Gaussian data, we identify lazy schedule families that make the drift identically zero and show that with deterministic sampling one gets a variance-preserving schedule commonly used in diffusion models, whereas with statistically optimal SDE sampling one gets our point mass schedule. Finally, to demonstrate the usefulness of our theoretical results on realistic highly non-Gaussian data, we apply our lazy schedule conversion to a state-of-the-art pretrained flow model and show that this allows for generating images in fewer steps without retraining the model.</div></details>
<details class="detail"><summary>中文标题/摘要</summary>
<div class="mono"><b>标题：</b>基于惰性与点质量随机插值的流与扩散快速采样方法</div>
<div class="mono" style="margin-top:8px">随机插值统一了流与扩散这两种主流生成建模框架。这些方法的核心超参数是插值调度，它决定了如何将标准高斯基测度与任意目标测度相连接。我们证明了如何将任意扩散系数下、任意调度对应的随机微分方程样本路径，转换为另一任意调度与扩散系数下的唯一样本路径。随后，我们将随机插值框架扩展至允许更广泛的点质量调度类别，其中高斯基测度坍缩为点质量测度。在高斯数据假设下，我们识别出使漂移项恒为零的惰性调度族，并证明：采用确定性采样时可得到扩散模型中常用的方差保持调度，而采用统计最优的随机微分方程采样时则得到我们的点质量调度。最后，为验证理论结果在现实高度非高斯数据上的实用性，我们将惰性调度转换应用于先进的预训练流模型，结果表明无需重新训练模型即可用更少步骤生成图像。</div>
</details>
<details class="detail"><summary>Summary / 总结</summary>
<div class="mono">This research addresses the need for flexible sampling schedules in generative models based on stochastic interpolants, which unify flow and diffusion methods. The authors develop a theoretical framework to convert sample paths between arbitrary stochastic differential equation schedules and diffusion coefficients, and extend the interpolant framework to include point mass schedules where the Gaussian base collapses to a point. Key experimental findings show that with Gaussian data, lazy schedules produce zero drift, yielding variance-preserving schedules with deterministic sampling and point mass schedules with optimal SDE sampling; applying lazy schedule conversion to a pretrained flow model enables faster image generation without retraining.</div>
<div class="mono" style="margin-top:8px">本研究针对基于随机插值的生成模型（统一了流模型和扩散方法）中采样调度灵活性不足的问题，提出了一个理论框架。作者开发了在任意随机微分方程调度和扩散系数之间转换样本路径的方法，并将框架扩展到包含高斯基坍缩为点质量的点质量调度。实验结果表明，在高斯数据假设下，惰性调度族产生零漂移，确定性采样产生方差保持调度，而最优随机微分方程采样产生点质量调度。将惰性调度转换应用于预训练流模型处理非高斯图像数据时，可在不重新训练模型的情况下实现更快的图像生成。</div>
</details>
</div>
<div class="card">
<div class="title">Inference-time Unlearning Using Conformal Prediction</div>
<div class="meta-line">Authors: Somnath Basu Roy Chowdhury, Rahul Kidambi, Avinava Dubey, David Wang, Gokhan Mergen, Amr Ahmed, Aranyak Mehta</div>
<div class="meta-line">First: 2026-02-03T17:46:50+00:00 · Latest: 2026-02-03T17:46:50+00:00</div>
<div class="links" style="margin-top:8px"><a href="https://arxiv.org/abs/2602.03787v1">Abs</a> · <a href="https://arxiv.org/pdf/2602.03787v1">PDF</a> · <a href="https://huggingface.co/huggingface">Code1</a> · <a href="https://huggingface.co/docs/hub/spaces">Code2</a></div>
<details class="detail"><summary>Abstract</summary>
<div class="mono">Machine unlearning is the process of efficiently removing specific information from a trained machine learning model without retraining from scratch. Existing unlearning methods, which often provide provable guarantees, typically involve retraining a subset of model parameters based on a forget set. While these approaches show promise in certain scenarios, their underlying assumptions are often challenged in real-world applications -- particularly when applied to generative models. Furthermore, updating parameters using these unlearning procedures often degrades the general-purpose capabilities the model acquired during pre-training. Motivated by these shortcomings, this paper considers the paradigm of inference time unlearning -- wherein, the generative model is equipped with an (approximately correct) verifier that judges whether the model&#x27;s response satisfies appropriate unlearning guarantees. This paper introduces a framework that iteratively refines the quality of the generated responses using feedback from the verifier without updating the model parameters. The proposed framework leverages conformal prediction to reduce computational overhead and provide distribution-free unlearning guarantees. This paper&#x27;s approach significantly outperforms existing state-of-the-art methods, reducing unlearning error by up to 93% across challenging unlearning benchmarks.</div></details>
<details class="detail"><summary>中文标题/摘要</summary>
<div class="mono"><b>标题：</b>基于共形预测的推理时遗忘学习</div>
<div class="mono" style="margin-top:8px">机器学习遗忘是指在不从头重新训练的情况下，从已训练的机器学习模型中高效移除特定信息的过程。现有遗忘方法通常基于遗忘集对模型参数子集进行重训练，并提供可证明的保证。尽管这些方法在某些场景中表现出潜力，但其基本假设在实际应用中常面临挑战——尤其是在生成模型中应用时。此外，使用这些遗忘流程更新参数往往会削弱模型在预训练阶段获得的通用能力。针对这些不足，本文探讨推理时遗忘范式：为生成模型配备一个（近似正确的）验证器，用于判断模型响应是否符合适当的遗忘保证。本文提出一种框架，利用验证器的反馈迭代优化生成响应质量，而无需更新模型参数。该框架通过共形预测降低计算开销，并提供无分布依赖的遗忘保证。实验表明，该方法在多个高难度遗忘基准测试中显著优于现有最优技术，最高可降低93%的遗忘误差。</div>
</details>
<details class="detail"><summary>Summary / 总结</summary>
<div class="mono">This paper addresses limitations in existing machine unlearning methods, which often require retraining model parameters and can degrade general model capabilities, especially in generative models. The authors propose an inference-time unlearning framework that uses a verifier to judge whether generated responses meet unlearning guarantees, iteratively refining outputs without updating model parameters. By leveraging conformal prediction, the method reduces computational overhead and provides distribution-free guarantees, achieving up to 93% reduction in unlearning error across benchmarks compared to state-of-the-art approaches.</div>
<div class="mono" style="margin-top:8px">针对现有机器遗忘方法通常需要重新训练且可能损害模型性能的局限，本研究提出了一种无需更新参数的推理时遗忘框架。该方法利用验证器评估生成响应是否符合遗忘标准，并采用共形预测迭代优化输出，在降低计算开销的同时提供分布无关的保证。实验结果表明，该方法在多个挑战性遗忘基准上显著优于现有技术，将遗忘误差降低了高达93%。</div>
</details>
</div>
<div class="card">
<div class="title">Efficient Estimation of Kernel Surrogate Models for Task Attribution</div>
<div class="meta-line">Authors: Zhenshuo Zhang, Minxuan Duan, Hongyang R. Zhang</div>
<div class="meta-line">Venue: ICLR 2026</div>
<div class="meta-line">First: 2026-02-03T17:43:48+00:00 · Latest: 2026-02-03T17:43:48+00:00</div>
<div class="meta-line">Comments: 27 pages. To appear in ICLR 2026</div>
<div class="links" style="margin-top:8px"><a href="https://arxiv.org/abs/2602.03783v1">Abs</a> · <a href="https://arxiv.org/pdf/2602.03783v1">PDF</a> · <a href="https://huggingface.co/huggingface">Code1</a> · <a href="https://huggingface.co/docs/hub/spaces">Code2</a></div>
<details class="detail"><summary>Abstract</summary>
<div class="mono">Modern AI agents such as large language models are trained on diverse tasks -- translation, code generation, mathematical reasoning, and text prediction -- simultaneously. A key question is to quantify how each individual training task influences performance on a target task, a problem we refer to as task attribution. The direct approach, leave-one-out retraining, measures the effect of removing each task, but is computationally infeasible at scale. An alternative approach that builds surrogate models to predict a target task&#x27;s performance for any subset of training tasks has emerged in recent literature. Prior work focuses on linear surrogate models, which capture first-order relationships, but miss nonlinear interactions such as synergy, antagonism, or XOR-type effects. In this paper, we first consider a unified task weighting framework for analyzing task attribution methods, and show a new connection between linear surrogate models and influence functions through a second-order analysis. Then, we introduce kernel surrogate models, which more effectively represent second-order task interactions. To efficiently learn the kernel surrogate, we develop a gradient-based estimation procedure that leverages a first-order approximation of pretrained models; empirically, this yields accurate estimates with less than $2\%$ relative error without repeated retraining. Experiments across multiple domains -- including math reasoning in transformers, in-context learning, and multi-objective reinforcement learning -- demonstrate the effectiveness of kernel surrogate models. They achieve a $25\%$ higher correlation with the leave-one-out ground truth than linear surrogates and influence-function baselines. When used for downstream task selection, kernel surrogate models yield a $40\%$ improvement in demonstration selection for in-context learning and multi-objective reinforcement learning benchmarks.</div></details>
<details class="detail"><summary>中文标题/摘要</summary>
<div class="mono"><b>标题：</b>面向任务归因的核代理模型高效估计方法</div>
<div class="mono" style="margin-top:8px">现代人工智能代理（如大语言模型）通常在翻译、代码生成、数学推理和文本预测等多样化任务上同时训练。核心问题在于量化每个独立训练任务对目标任务性能的影响，即任务归因问题。直接方法（留一重训练法）通过移除各任务来测量影响，但计算成本过高难以规模化。近期研究提出构建代理模型来预测任意训练任务子集对目标任务性能的影响。现有工作主要聚焦线性代理模型，这类模型虽能捕捉一阶关系，却无法表征非线性交互作用（如协同效应、拮抗效应或异或型效应）。本文首先提出统一的任务加权框架来分析任务归因方法，并通过二阶分析揭示线性代理模型与影响函数之间的新关联。进而引入能更有效表征二阶任务交互的核代理模型。为高效学习核代理模型，我们开发了基于梯度的估计方法，该方法利用预训练模型的一阶近似；实证表明，该方法无需重复训练即可实现低于2%相对误差的精确估计。在多个领域的实验（包括Transformer数学推理、上下文学习及多目标强化学习）均验证了核代理模型的有效性：相较于线性代理模型和影响函数基线，其与留一法基准真相的相关系数提升25%；应用于下游任务选择时，在上下文学习和多目标强化学习基准测试中，演示样本选择性能提升40%。</div>
</details>
<details class="detail"><summary>Summary / 总结</summary>
<div class="mono">To address the computational infeasibility of leave-one-out retraining for quantifying how individual training tasks influence a target task&#x27;s performance in modern AI agents, this paper introduces kernel surrogate models that capture nonlinear task interactions. The method develops a gradient-based estimation procedure leveraging a first-order approximation of pretrained models to efficiently learn these surrogates. Experimental results across domains like math reasoning in transformers, in-context learning, and multi-objective reinforcement learning show the kernel surrogate achieves less than 2% relative error without retraining, a 25% higher correlation with ground truth than linear baselines, and yields a 40% improvement in downstream task selection.</div>
<div class="mono" style="margin-top:8px">为解决现代AI智能体中留一重训练进行任务归因的计算不可行性问题，本文引入核代理模型以捕捉任务间的非线性交互作用，如协同与拮抗。该方法采用基于梯度的估计程序，利用预训练模型的一阶近似来高效学习核代理模型，无需重复训练即可实现低于2%的相对误差。在数学推理、上下文学习和多目标强化学习等多个领域的实验结果表明，核代理模型与真实值的相关性比线性基线和影响函数方法高25%，并在下游任务选择中实现了40%的性能提升。</div>
</details>
</div>
<div class="card">
<div class="title">Reward Redistribution for CVaR MDPs using a Bellman Operator on L-infinity</div>
<div class="meta-line">Authors: Aneri Muni, Vincent Taboga, Esther Derman, Pierre-Luc Bacon, Erick Delage</div>
<div class="meta-line">First: 2026-02-03T17:39:45+00:00 · Latest: 2026-02-03T17:39:45+00:00</div>
<div class="links" style="margin-top:8px"><a href="https://arxiv.org/abs/2602.03778v1">Abs</a> · <a href="https://arxiv.org/pdf/2602.03778v1">PDF</a> · <a href="https://huggingface.co/huggingface">Code1</a> · <a href="https://huggingface.co/docs/hub/spaces">Code2</a></div>
<details class="detail"><summary>Abstract</summary>
<div class="mono">Tail-end risk measures such as static conditional value-at-risk (CVaR) are used in safety-critical applications to prevent rare, yet catastrophic events. Unlike risk-neutral objectives, the static CVaR of the return depends on entire trajectories without admitting a recursive Bellman decomposition in the underlying Markov decision process. A classical resolution relies on state augmentation with a continuous variable. However, unless restricted to a specialized class of admissible value functions, this formulation induces sparse rewards and degenerate fixed points. In this work, we propose a novel formulation of the static CVaR objective based on augmentation. Our alternative approach leads to a Bellman operator with: (1) dense per-step rewards; (2) contracting properties on the full space of bounded value functions. Building on this theoretical foundation, we develop risk-averse value iteration and model-free Q-learning algorithms that rely on discretized augmented states. We further provide convergence guarantees and approximation error bounds due to discretization. Empirical results demonstrate that our algorithms successfully learn CVaR-sensitive policies and achieve effective performance-safety trade-offs.</div></details>
<details class="detail"><summary>中文标题/摘要</summary>
<div class="mono"><b>标题：</b>基于L-无穷范数贝尔曼算子的CVaR MDP奖励重分配</div>
<div class="mono" style="margin-top:8px">在安全关键应用中，常采用静态条件风险价值（CVaR）等尾部风险度量来预防罕见但灾难性的事件。与风险中性目标不同，回报的静态CVaR依赖于完整轨迹，无法在底层马尔可夫决策过程中进行递归贝尔曼分解。经典解决方案通过引入连续变量进行状态增广，但除非限制在特定可容许值函数类，否则该形式会导致稀疏奖励和退化不动点。本文提出一种基于增广的静态CVaR目标新形式，其构建的贝尔曼算子具有：（1）密集的逐步奖励；（2）在有界值函数全空间上的压缩特性。基于此理论框架，我们开发了依赖离散化增广状态的风险规避值迭代与无模型Q学习算法，并提供了收敛性保证及离散化导致的近似误差界。实验结果表明，所提算法能有效学习CVaR敏感策略，实现性能与安全性的均衡权衡。</div>
</details>
<details class="detail"><summary>Summary / 总结</summary>
<div class="mono">The research addresses the challenge of optimizing conditional value-at-risk (CVaR) in Markov decision processes, which is crucial for safety-critical applications but lacks a recursive Bellman decomposition. The authors propose a novel state-augmentation formulation that yields a Bellman operator with dense per-step rewards and contraction properties on bounded value functions. Experimental results show that their risk-averse value iteration and Q-learning algorithms with discretized augmented states successfully learn CVaR-sensitive policies and achieve effective performance-safety trade-offs, supported by convergence guarantees and approximation error bounds.</div>
<div class="mono" style="margin-top:8px">本研究针对马尔可夫决策过程中条件风险价值（CVaR）的优化挑战，这对于安全关键应用至关重要，旨在减轻罕见但严重的后果。作者提出了一种新颖的状态增强公式，产生了一个具有密集每步奖励和在有界值函数空间上收缩性质的贝尔曼算子，从而开发了基于离散化增强状态的风险规避值迭代和Q学习算法。实验结果表明，所提方法能够学习对CVaR敏感的策略，并在性能与安全性之间实现有效权衡，同时提供了收敛保证和离散化误差界。</div>
</details>
</div>
<div class="card">
<div class="title">Reasoning Cache: Continual Improvement Over Long Horizons via Short-Horizon RL</div>
<div class="meta-line">Authors: Ian Wu, Yuxiao Qu, Amrith Setlur, Aviral Kumar</div>
<div class="meta-line">First: 2026-02-03T17:34:04+00:00 · Latest: 2026-02-03T17:34:04+00:00</div>
<div class="meta-line">Comments: preprint</div>
<div class="links" style="margin-top:8px"><a href="https://arxiv.org/abs/2602.03773v1">Abs</a> · <a href="https://arxiv.org/pdf/2602.03773v1">PDF</a> · <a href="https://huggingface.co/huggingface">Code1</a> · <a href="https://huggingface.co/docs/hub/spaces">Code2</a></div>
<details class="detail"><summary>Abstract</summary>
<div class="mono">Large Language Models (LLMs) that can continually improve beyond their training budgets are able to solve increasingly difficult problems by adapting at test time, a property we refer to as extrapolation. However, standard reinforcement learning (RL) operates over fixed problem distributions and training budgets, which limits extrapolation amidst distribution shift at test time. To address this, we introduce RC, an iterative decoding algorithm that replaces standard autoregressive decoding during both training and inference. RC exploits an asymmetry between the response generation and summarization capabilities of LLMs to construct reasoning chains that consistently improve across iterations. Models trained to use RC can extrapolate and continually improve over reasoning horizons more than an order of magnitude longer than those seen during training. Empirically, training a 4B model with RC using a 16k-token training budget improves performance on HMMT 2025 from 40% to nearly 70% with 0.5m tokens at test time, outperforming both comparably sized models and many larger reasoning LLMs. Finally, we also show that models trained with RC can more effectively leverage existing scaffolds to further scale test-time performance, due to the improved summary-conditioned generation abilities learned through training.</div></details>
<details class="detail"><summary>中文标题/摘要</summary>
<div class="mono"><b>标题：</b>推理缓存：通过短视界强化学习实现长视界持续改进</div>
<div class="mono" style="margin-top:8px">能够持续超越训练预算进行改进的大语言模型（LLMs）可通过测试时自适应解决日益复杂的问题，这一特性我们称为外推。然而，标准强化学习（RL）在固定的问题分布和训练预算下运行，限制了其在测试时分布变化中的外推能力。为此，我们提出RC，一种迭代解码算法，在训练和推理阶段替代标准的自回归解码。RC利用LLMs在响应生成与摘要能力间的不对称性，构建在迭代中持续改进的推理链。经RC训练的模型能够外推并在推理视界上持续改进，其视界长度可超过训练所见的一个数量级以上。实证表明，使用16k词元训练预算对4B模型进行RC训练，在测试时使用0.5百万词元可将HMMT 2025任务性能从40%提升至近70%，优于同等规模模型及许多更大的推理LLMs。最后，我们还证明，由于训练中习得的摘要条件生成能力得到提升，经RC训练的模型能更有效地利用现有框架进一步扩展测试时性能。</div>
</details>
<details class="detail"><summary>Summary / 总结</summary>
<div class="mono">The research aims to enable large language models to continually improve beyond their fixed training budgets and distributions, a capability termed extrapolation, which is limited by standard reinforcement learning. The method introduces Reasoning Cache (RC), an iterative decoding algorithm that replaces standard autoregressive decoding by exploiting an asymmetry in LLMs&#x27; generation and summarization abilities to construct progressively improving reasoning chains. Experimental results show that a 4B model trained with RC using a 16k-token budget improved performance on HMMT 2025 from 40% to nearly 70% with 0.5 million test-time tokens, outperforming comparable and larger models, and demonstrated enhanced ability to leverage existing scaffolds for further performance scaling.</div>
<div class="mono" style="margin-top:8px">本研究旨在使大语言模型能够在固定的训练预算和分布之外持续改进，这种称为外推的能力受限于标准的强化学习方法。该方法引入了推理缓存（RC），这是一种迭代解码算法，通过利用大语言模型能力的不对称性来构建跨迭代改进的推理链，从而替代标准的自回归解码。实验结果表明，一个40亿参数的模型使用16k令牌的训练预算通过RC训练后，在HMMT 2025任务上的性能从40%提升至近70%，仅使用50万测试令牌，超越了同类规模及更大的模型，并展现出利用现有框架进一步扩展性能的增强能力。</div>
</details>
</div>
<div class="card">
<div class="title">UniGeM: Unifying Data Mixing and Selection via Geometric Exploration and Mining</div>
<div class="meta-line">Authors: Changhao Wang, Yunfei Yu, Xinhao Yao, Jiaolong Yang, Riccardo Cantoro, Chaobo Li, Qing Cui, Jun Zhou</div>
<div class="meta-line">First: 2026-02-03T17:32:56+00:00 · Latest: 2026-02-03T17:32:56+00:00</div>
<div class="links" style="margin-top:8px"><a href="https://arxiv.org/abs/2602.03772v1">Abs</a> · <a href="https://arxiv.org/pdf/2602.03772v1">PDF</a> · <a href="https://huggingface.co/huggingface">Code1</a> · <a href="https://huggingface.co/docs/hub/spaces">Code2</a></div>
<details class="detail"><summary>Abstract</summary>
<div class="mono">The scaling of Large Language Models (LLMs) is increasingly limited by data quality. Most methods handle data mixing and sample selection separately, which can break the structure in code corpora. We introduce \textbf{UniGeM}, a framework that unifies mixing and selection by treating data curation as a \textit{manifold approximation} problem without training proxy models or relying on external reference datasets. UniGeM operates hierarchically: \textbf{Macro-Exploration} learns mixing weights with stability-based clustering; \textbf{Micro-Mining} filters high-quality instances by their geometric distribution to ensure logical consistency. Validated by training 8B and 16B MoE models on 100B tokens, UniGeM achieves \textbf{2.0$\times$ data efficiency} over a random baseline and further improves overall performance compared to SOTA methods in reasoning-heavy evaluations and multilingual generalization.</div></details>
<details class="detail"><summary>中文标题/摘要</summary>
<div class="mono"><b>标题：</b>UniGeM：通过几何探索与挖掘统一数据混合与选择</div>
<div class="mono" style="margin-top:8px">大语言模型（LLM）的扩展日益受限于数据质量。现有方法大多将数据混合与样本选择分开处理，可能破坏代码语料库的结构。我们提出\textbf{UniGeM}框架，将数据治理视为\textit{流形逼近}问题，无需训练代理模型或依赖外部参考数据集，从而统一混合与选择过程。UniGeM采用分层架构：\textbf{宏观探索}通过基于稳定性的聚类学习混合权重；\textbf{微观挖掘}依据几何分布筛选高质量实例以确保逻辑一致性。通过在1000亿token上训练80亿和160亿参数的混合专家模型验证，UniGeM相比随机基线实现\textbf{2.0倍数据效率提升}，在强推理评估与多语言泛化任务中进一步超越现有最优方法的整体性能。</div>
</details>
<details class="detail"><summary>Summary / 总结</summary>
<div class="mono">To address the data quality bottleneck in scaling large language models, where existing methods treat data mixing and sample selection separately and risk disrupting structural patterns in code corpora, this paper proposes UniGeM, a unified framework that formulates data curation as a manifold approximation problem without requiring proxy models or external datasets. The method hierarchically combines macro-exploration, which learns mixing weights via stability-based clustering, with micro-mining, which filters instances based on geometric distribution to maintain logical consistency. Experiments training 8B and 16B mixture-of-experts models on 100B tokens show UniGeM achieves 2.0× data efficiency over a random baseline and outperforms state-of-the-art methods in reasoning-heavy and multilingual generalization evaluations.</div>
<div class="mono" style="margin-top:8px">针对大语言模型规模化中数据质量成为瓶颈、现有方法将数据混合与样本选择分离处理可能破坏代码语料结构的问题，本研究提出了UniGeM框架，将数据整理统一为流形逼近问题。该方法无需训练代理模型或依赖外部数据集，通过分层操作实现：宏观探索通过基于稳定性的聚类学习混合权重，微观挖掘则依据几何分布筛选实例以保证逻辑一致性。在100B token上训练8B和16B混合专家模型的实验结果表明，UniGeM相比随机基线实现了2.0倍的数据效率提升，并在推理密集型评估和多语言泛化任务中超越了现有最优方法。</div>
</details>
</div>
<div class="card">
<div class="title">Reasoning with Latent Tokens in Diffusion Language Models</div>
<div class="meta-line">Authors: Andre He, Sean Welleck, Daniel Fried</div>
<div class="meta-line">First: 2026-02-03T17:27:46+00:00 · Latest: 2026-02-03T17:27:46+00:00</div>
<div class="links" style="margin-top:8px"><a href="https://arxiv.org/abs/2602.03769v1">Abs</a> · <a href="https://arxiv.org/pdf/2602.03769v1">PDF</a> · <a href="https://huggingface.co/huggingface">Code1</a> · <a href="https://huggingface.co/docs/hub/spaces">Code2</a></div>
<details class="detail"><summary>Abstract</summary>
<div class="mono">Discrete diffusion models have recently become competitive with autoregressive models for language modeling, even outperforming them on reasoning tasks requiring planning and global coherence, but they require more computation at inference time. We trace this trade-off to a key mechanism: diffusion models are trained to jointly predict a distribution over all unknown tokens, including those that will not actually be decoded in the current step. Ablating this joint prediction yields faster inference but degrades performance, revealing that accurate prediction at the decoded position relies on joint reasoning about the distribution of undecoded tokens. We interpret these as latent tokens and introduce a method for modulating their number, demonstrating empirically that this enables a smooth tradeoff between inference speed and sample quality. Furthermore, we demonstrate that latent tokens can be introduced into autoregressive models through an auxiliary multi-token prediction objective, yielding substantial improvements on the same reasoning tasks where they have traditionally struggled. Our results suggest that latent tokens, while arising naturally in diffusion, represent a general mechanism for improving performance on tasks requiring global coherence or lookahead.</div></details>
<details class="detail"><summary>中文标题/摘要</summary>
<div class="mono"><b>标题：</b>扩散语言模型中基于潜在标记的推理</div>
<div class="mono" style="margin-top:8px">离散扩散模型近期在语言建模任务中已能与自回归模型竞争，甚至在需要规划与全局一致性的推理任务上表现更优，但其推理阶段计算成本更高。研究发现这一权衡源于关键机制：扩散模型被训练为联合预测所有未知标记（包括当前步不实际解码的标记）的分布。若消除这种联合预测，可加速推理但性能下降，表明解码位置的准确预测依赖于对未解码标记分布的联合推理。我们将这些标记解释为潜在标记，并提出一种调节其数量的方法，实证表明该方法能在推理速度与样本质量间实现平滑权衡。此外，我们证明可通过辅助多标记预测目标将潜在标记引入自回归模型，从而在其传统表现薄弱的相同推理任务上取得显著提升。研究结果表明，潜在标记虽自然产生于扩散过程，但可作为一种通用机制提升需要全局一致性或前瞻能力的任务性能。</div>
</details>
<details class="detail"><summary>Summary / 总结</summary>
<div class="mono">The study investigates why discrete diffusion models outperform autoregressive models on reasoning tasks despite slower inference, attributing it to their joint prediction of all unknown tokens, including undecoded ones. The authors propose modulating the number of these latent tokens to balance speed and quality, and introduce a multi-token prediction objective into autoregressive models to enhance their reasoning performance. Experiments show this approach enables a smooth trade-off between inference efficiency and sample quality in diffusion models, and significantly improves autoregressive models on tasks requiring global coherence.</div>
<div class="mono" style="margin-top:8px">本研究旨在探究离散扩散语言模型在推理任务上优于自回归模型但推理速度较慢的原因，发现其优势源于训练时对所有未知标记的联合预测。作者将这些未解码标记识别为潜在标记，并引入一种调节其数量的方法，实现了推理速度与样本质量之间的可控权衡。实验表明，通过辅助的多标记预测目标将潜在标记引入自回归模型，能显著提升其在传统上表现不佳、需要全局连贯性和前瞻性的推理任务上的性能。</div>
</details>
</div>
<div class="card">
<div class="title">Decision-oriented benchmarking to transform AI weather forecast access: Application to the Indian monsoon</div>
<div class="meta-line">Authors: Rajat Masiwal, Colin Aitken, Adam Marchakitus, Mayank Gupta, Katherine Kowal, Hamid A. Pahlavan, Tyler Yang, Y. Qiang Sun, Michael Kremer, Amir Jina, William R. Boos, Pedram Hassanzadeh</div>
<div class="meta-line">First: 2026-02-03T17:27:22+00:00 · Latest: 2026-02-03T17:27:22+00:00</div>
<div class="links" style="margin-top:8px"><a href="https://arxiv.org/abs/2602.03767v1">Abs</a> · <a href="https://arxiv.org/pdf/2602.03767v1">PDF</a> · <a href="https://huggingface.co/huggingface">Code1</a> · <a href="https://huggingface.co/docs/hub/spaces">Code2</a></div>
<details class="detail"><summary>Abstract</summary>
<div class="mono">Artificial intelligence weather prediction (AIWP) models now often outperform traditional physics-based models on common metrics while requiring orders-of-magnitude less computing resources and time. Open-access AIWP models thus hold promise as transformational tools for helping low- and middle-income populations make decisions in the face of high-impact weather shocks. Yet, current approaches to evaluating AIWP models focus mainly on aggregated meteorological metrics without considering local stakeholders&#x27; needs in decision-oriented, operational frameworks. Here, we introduce such a framework that connects meteorology, AI, and social sciences. As an example, we apply it to the 150-year-old problem of Indian monsoon forecasting, focusing on benefits to rain-fed agriculture, which is highly susceptible to climate change. AIWP models skillfully predict an agriculturally relevant onset index at regional scales weeks in advance when evaluated out-of-sample using deterministic and probabilistic metrics. This framework informed a government-led effort in 2025 to send 38 million Indian farmers AI-based monsoon onset forecasts, which captured an unusual weeks-long pause in monsoon progression. This decision-oriented benchmarking framework provides a key component of a blueprint for harnessing the power of AIWP models to help large vulnerable populations adapt to weather shocks in the face of climate variability and change.</div></details>
<details class="detail"><summary>中文标题/摘要</summary>
<div class="mono"><b>标题：</b>面向决策的基准测试变革AI天气预报获取：以印度季风为例的应用</div>
<div class="mono" style="margin-top:8px">人工智能天气预测模型目前在常用指标上已常超越传统物理模型，且所需计算资源与时间呈数量级减少。开放获取的AI天气预测模型有望成为变革性工具，帮助中低收入人群应对高影响天气冲击的决策。然而，现有评估方法主要关注聚合气象指标，未在面向决策的业务框架中考虑本地利益相关者的需求。本文提出融合气象学、人工智能与社会科学的评估框架，并以印度季风预报这一延续150年的难题为例，聚焦对气候变化高度敏感的雨养农业效益。通过确定性及概率性指标的样本外评估，AI天气预测模型能提前数周在区域尺度精准预测农业相关季风爆发指数。该框架支撑了2025年政府主导的向3800万印度农户发送AI季风爆发预报的举措，成功捕捉到季风进程中罕见的数周停滞现象。这一面向决策的基准测试框架为利用AI天气预测模型助力大规模脆弱群体适应气候变率与变化的蓝图提供了关键组成部分。</div>
</details>
<details class="detail"><summary>Summary / 总结</summary>
<div class="mono">The research is motivated by the need to move beyond aggregated meteorological metrics and evaluate AI weather prediction (AIWP) models based on their utility for specific, high-impact decisions faced by vulnerable populations, such as rain-fed farmers in India. The method introduces a decision-oriented benchmarking framework that integrates meteorology, AI, and social sciences, applying it to the long-standing challenge of forecasting the Indian monsoon onset for agricultural benefit. Key experimental results show that AIWP models skillfully predict an agriculturally relevant monsoon onset index at regional scales weeks in advance in out-of-sample evaluations, a capability that directly informed a 2025 government initiative to provide AI-based forecasts to 38 million farmers, successfully capturing an unusual pause in monsoon progression.</div>
<div class="mono" style="margin-top:8px">本研究的动机是，需要超越评估人工智能天气预测模型时使用的聚合气象指标，转而评估其对特定现实世界决策的价值，特别是对中低收入国家的脆弱人群。该方法引入了一个融合气象学、人工智能和社会科学的决策导向基准测试框架，并将其应用于印度季风预测，重点关注对雨养农业的效益。关键的实验结果表明，在样本外评估中，人工智能天气预测模型能够提前数周熟练预测区域尺度上与农业相关的季风爆发指数，该框架直接为2025年一项政府倡议提供了信息，该倡议向3800万农民提供了基于人工智能的季风爆发预报，并成功捕捉到一次异常的季风暂停。</div>
</details>
</div>
<div class="card">
<div class="title">Conditional Flow Matching for Visually-Guided Acoustic Highlighting</div>
<div class="meta-line">Authors: Hugo Malard, Gael Le Lan, Daniel Wong, David Lou Alon, Yi-Chiao Wu, Sanjeel Parekh</div>
<div class="meta-line">First: 2026-02-03T17:24:47+00:00 · Latest: 2026-02-03T17:24:47+00:00</div>
<div class="links" style="margin-top:8px"><a href="https://arxiv.org/abs/2602.03762v1">Abs</a> · <a href="https://arxiv.org/pdf/2602.03762v1">PDF</a> · <a href="https://huggingface.co/huggingface">Code1</a> · <a href="https://huggingface.co/docs/hub/spaces">Code2</a></div>
<details class="detail"><summary>Abstract</summary>
<div class="mono">Visually-guided acoustic highlighting seeks to rebalance audio in alignment with the accompanying video, creating a coherent audio-visual experience. While visual saliency and enhancement have been widely studied, acoustic highlighting remains underexplored, often leading to misalignment between visual and auditory focus. Existing approaches use discriminative models, which struggle with the inherent ambiguity in audio remixing, where no natural one-to-one mapping exists between poorly-balanced and well-balanced audio mixes. To address this limitation, we reframe this task as a generative problem and introduce a Conditional Flow Matching (CFM) framework. A key challenge in iterative flow-based generation is that early prediction errors -- in selecting the correct source to enhance -- compound over steps and push trajectories off-manifold. To address this, we introduce a rollout loss that penalizes drift at the final step, encouraging self-correcting trajectories and stabilizing long-range flow integration. We further propose a conditioning module that fuses audio and visual cues before vector field regression, enabling explicit cross-modal source selection. Extensive quantitative and qualitative evaluations show that our method consistently surpasses the previous state-of-the-art discriminative approach, establishing that visually-guided audio remixing is best addressed through generative modeling.</div></details>
<details class="detail"><summary>中文标题/摘要</summary>
<div class="mono"><b>标题：</b>面向视觉引导声学增强的条件流匹配方法</div>
<div class="mono" style="margin-top:8px">视觉引导声学增强旨在根据伴随视频重新平衡音频，以创建连贯的视听体验。尽管视觉显著性与增强已得到广泛研究，声学增强领域仍探索不足，常导致视觉焦点与听觉焦点错位。现有方法采用判别式模型，难以处理音频混音中固有的模糊性——在平衡失调与平衡良好的音频混音间不存在天然的一一映射关系。为突破此局限，我们将该任务重构为生成式问题，并提出条件流匹配框架。基于迭代流生成的核心挑战在于：早期预测误差（选择正确增强声源）会在多步迭代中累积，导致轨迹偏离流形。为此，我们引入滚动损失函数，通过惩罚最终步的轨迹漂移来促进自校正轨迹，从而稳定长程流集成。进一步提出融合视听线索的条件模块，在向量场回归前实现显式的跨模态声源选择。大量定量与定性实验表明，本方法持续超越现有最佳判别式方法，证实视觉引导音频混音任务最适合通过生成式建模解决。</div>
</details>
<details class="detail"><summary>Summary / 总结</summary>
<div class="mono">The study addresses the underexplored task of visually-guided acoustic highlighting, which aims to rebalance audio to align with video focus, as existing discriminative models struggle with the inherent ambiguity in audio remixing due to the lack of a natural one-to-one mapping between poorly-balanced and well-balanced mixes. To overcome this, the authors reframe the problem as generative and propose a Conditional Flow Matching (CFM) framework, incorporating a rollout loss to penalize drift in iterative flow-based generation and a conditioning module that fuses audio and visual cues for explicit cross-modal source selection. Experimental results demonstrate that this generative approach consistently outperforms the previous state-of-the-art discriminative method, establishing the superiority of generative modeling for this task.</div>
<div class="mono" style="margin-top:8px">本研究针对视觉引导的声学高亮这一探索不足的任务，其目标是根据视觉焦点重新平衡音频以创造一致的视听体验。作者将该问题重新定义为生成式而非判别式任务，并引入了条件流匹配框架；为了缓解迭代式基于流的生成中误差累积的问题，他们提出了一个惩罚最终步漂移的展开损失，以及一个融合视听线索以实现显式跨模态源选择的调节模块。实验结果表明，这种生成式方法在性能上持续超越了先前最先进的判别式方法。</div>
</details>
</div>
<div class="card">
<div class="title">Toward Learning POMDPs Beyond Full-Rank Actions and State Observability</div>
<div class="meta-line">Authors: Seiji Shaw, Travis Manderson, Chad Kessens, Nicholas Roy</div>
<div class="meta-line">First: 2026-01-26T20:06:41+00:00 · Latest: 2026-02-03T17:03:44+00:00</div>
<div class="meta-line">Comments: Update abstract</div>
<div class="links" style="margin-top:8px"><a href="https://arxiv.org/abs/2601.18930v3">Abs</a> · <a href="https://arxiv.org/pdf/2601.18930v3">PDF</a> · <a href="https://huggingface.co/huggingface">Code1</a> · <a href="https://huggingface.co/docs/hub/spaces">Code2</a></div>
<details class="detail"><summary>Abstract</summary>
<div class="mono">We are interested in enabling autonomous agents to learn and reason about systems with hidden states, such as locking mechanisms. We cast this problem as learning the parameters of a discrete Partially Observable Markov Decision Process (POMDP). The agent begins with knowledge of the POMDP&#x27;s actions and observation spaces, but not its state space, transitions, or observation models. These properties must be constructed from a sequence of actions and observations. Spectral approaches to learning models of partially observable domains, such as Predictive State Representations (PSRs), learn representations of state that are sufficient to predict future outcomes. PSR models, however, do not have explicit transition and observation system models that can be used with different reward functions to solve different planning problems. Under a mild set of rankness assumptions on the products of transition and observation matrices, we show how PSRs learn POMDP matrices up to a similarity transform, and this transform may be estimated via tensor decomposition methods. Our method learns observation matrices and transition matrices up to a partition of states, where the states in a single partition have the same observation distributions corresponding to actions whose transition matrices are full-rank. Our experiments suggest that explicit observation and transition likelihoods can be leveraged to generate new plans for different goals and reward functions after the model has been learned. We also show that learning a POMDP beyond a partition of states is impossible from sequential data by constructing two POMDPs that agree on all observation distributions but differ in their transition dynamics.</div></details>
<details class="detail"><summary>中文标题/摘要</summary>
<div class="mono"><b>标题：</b>面向超越满秩动作与状态可观测性的POMDP学习研究</div>
<div class="mono" style="margin-top:8px">本研究致力于使自主智能体能够学习和推理具有隐藏状态的系统（如锁定机制）。我们将该问题建模为离散部分可观测马尔可夫决策过程（POMDP）的参数学习问题。智能体初始已知POMDP的动作空间和观测空间，但未知其状态空间、转移模型及观测模型，这些属性需通过动作-观测序列构建。针对部分可观测领域模型学习的光谱方法（如预测状态表示PSR）可学习足以预测未来结果的状态表示，但PSR模型缺乏可用于不同奖励函数以解决不同规划问题的显式转移与观测系统模型。在转移矩阵与观测矩阵乘积满足温和秩假设条件下，我们证明PSR可通过相似变换学习POMDP矩阵，且该变换可通过张量分解方法估计。本方法学习的观测矩阵和转移矩阵存在状态划分的模糊性——同一划分内的状态具有相同观测分布，对应转移矩阵满秩的动作。实验表明，学习模型后可利用显式观测与转移似然为不同目标和奖励函数生成新规划。我们还通过构建两个观测分布完全一致但转移动态不同的POMDP，证明仅凭序列数据无法学习超越状态划分层级的POMDP模型。</div>
</details>
<details class="detail"><summary>Summary / 总结</summary>
<div class="mono">The research aims to enable autonomous agents to learn and reason about systems with hidden states, such as locking mechanisms, by learning the parameters of a discrete Partially Observable Markov Decision Process (POMDP) from sequences of actions and observations. The method builds on spectral approaches like Predictive State Representations (PSRs) but, under mild rank assumptions, shows how to recover explicit POMDP transition and observation matrices up to a similarity transform using tensor decomposition, though states are only identifiable up to partitions where they share observation distributions for actions with full-rank transitions. Experimental results indicate that these recovered explicit models can be leveraged for planning with new reward functions, while a theoretical finding demonstrates that learning a POMDP beyond such state partitions is impossible from sequential data alone, as proven by constructing observationally equivalent POMDPs with different dynamics.</div>
<div class="mono" style="margin-top:8px">本研究旨在使自主智能体能够通过从动作和观察序列中学习离散部分可观测马尔可夫决策过程（POMDP）的参数，来学习和推理具有隐藏状态的系统（如锁定机制）。该方法扩展了谱学习方法（如预测状态表示PSR），表明在温和的秩假设下，PSR可以恢复POMDP的转移矩阵和观测矩阵至一个相似变换，该变换可通过张量分解估计，但状态仅可识别至分区级别，其中同一分区内的状态对于具有满秩转移矩阵的动作共享观测分布。实验结果表明，学习到的显式似然模型可用于针对新目标和奖励函数进行规划，同时理论构造证明，仅从序列数据中学习超越此类状态分区是不可能的。</div>
</details>
</div></div>
    <details style="margin-top:16px" class="detail"><summary>History</summary>
      <div class="history-list"><a href="archive/20260205_0450.html">20260205_0450</a>
<a href="archive/20260205_0346.html">20260205_0346</a>
<a href="archive/20260204_0633.html">20260204_0633</a>
<a href="archive/20260204_0541.html">20260204_0541</a>
<a href="archive/20260204_0456.html">20260204_0456</a>
<a href="archive/20260204_0354.html">20260204_0354</a>
<a href="archive/20260202_0623.html">20260202_0623</a>
<a href="archive/20260202_0525.html">20260202_0525</a>
<a href="archive/20260202_0441.html">20260202_0441</a>
<a href="archive/20260202_0331.html">20260202_0331</a>
<a href="archive/20260201_0625.html">20260201_0625</a>
<a href="archive/20260201_0527.html">20260201_0527</a>
<a href="archive/20260201_0443.html">20260201_0443</a>
<a href="archive/20260201_0331.html">20260201_0331</a>
<a href="archive/20260131_0628.html">20260131_0628</a>
<a href="archive/20260131_0535.html">20260131_0535</a>
<a href="archive/20260131_0449.html">20260131_0449</a>
<a href="archive/20260131_0342.html">20260131_0342</a>
<a href="archive/20260130_0631.html">20260130_0631</a>
<a href="archive/20260130_0533.html">20260130_0533</a>
<a href="archive/20260130_0449.html">20260130_0449</a>
<a href="archive/20260130_0341.html">20260130_0341</a>
<a href="archive/20260129_0630.html">20260129_0630</a>
<a href="archive/20260129_0536.html">20260129_0536</a>
<a href="archive/20260129_0450.html">20260129_0450</a>
<a href="archive/20260129_0336.html">20260129_0336</a>
<a href="archive/20260128_0625.html">20260128_0625</a>
<a href="archive/20260128_0439.html">20260128_0439</a>
<a href="archive/20260128_0334.html">20260128_0334</a>
<a href="archive/20260127_0627.html">20260127_0627</a>
<a href="archive/20260127_0529.html">20260127_0529</a>
<a href="archive/20260127_0439.html">20260127_0439</a>
<a href="archive/20260127_0333.html">20260127_0333</a>
<a href="archive/20260126_0626.html">20260126_0626</a>
<a href="archive/20260126_0526.html">20260126_0526</a>
<a href="archive/20260126_0327.html">20260126_0327</a>
<a href="archive/20260125_0624.html">20260125_0624</a>
<a href="archive/20260125_0524.html">20260125_0524</a>
<a href="archive/20260125_0440.html">20260125_0440</a>
<a href="archive/20260125_0325.html">20260125_0325</a>
<a href="archive/20260124_0627.html">20260124_0627</a>
<a href="archive/20260124_0526.html">20260124_0526</a>
<a href="archive/20260124_0444.html">20260124_0444</a>
<a href="archive/20260124_0334.html">20260124_0334</a>
<a href="archive/20260123_0627.html">20260123_0627</a>
<a href="archive/20260123_0529.html">20260123_0529</a>
<a href="archive/20260123_0446.html">20260123_0446</a>
<a href="archive/20260123_0334.html">20260123_0334</a>
<a href="archive/20260122_2019.html">20260122_2019</a>
<a href="archive/20260122_2013.html">20260122_2013</a>
<a href="archive/20260122_2008.html">20260122_2008</a>
<a href="archive/20260122_2001.html">20260122_2001</a>
<a href="archive/20260122_0629.html">20260122_0629</a>
<a href="archive/20260122_0535.html">20260122_0535</a>
<a href="archive/20260122_0449.html">20260122_0449</a>
<a href="archive/20260122_0336.html">20260122_0336</a>
<a href="archive/20260121_0625.html">20260121_0625</a>
<a href="archive/20260121_0529.html">20260121_0529</a>
<a href="archive/20260121_0450.html">20260121_0450</a>
<a href="archive/20260121_0423.html">20260121_0423</a>
<a href="archive/20260120_0626.html">20260120_0626</a>
<a href="archive/20260120_0528.html">20260120_0528</a>
<a href="archive/20260120_0443.html">20260120_0443</a>
<a href="archive/20260120_0330.html">20260120_0330</a>
<a href="archive/20260119_0624.html">20260119_0624</a>
<a href="archive/20260119_0525.html">20260119_0525</a>
<a href="archive/20260119_0440.html">20260119_0440</a>
<a href="archive/20260119_0325.html">20260119_0325</a>
<a href="archive/20260118_2225.html">20260118_2225</a>
<a href="archive/20260118_2159.html">20260118_2159</a>
<a href="archive/20260118_2135.html">20260118_2135</a>
<a href="archive/20260118_2040.html">20260118_2040</a>
<a href="archive/20260118_1953.html">20260118_1953</a>
<a href="archive/20260118_1907.html">20260118_1907</a>
<a href="archive/20260118_0327.html">20260118_0327</a>
<a href="archive/20260117_0332.html">20260117_0332</a>
<a href="archive/20260116_0339.html">20260116_0339</a>
<a href="archive/20260115_0334.html">20260115_0334</a>
<a href="archive/20260114_0333.html">20260114_0333</a>
<a href="archive/20260113_0334.html">20260113_0334</a>
<a href="archive/20260112_0331.html">20260112_0331</a>
<a href="archive/20260111_0329.html">20260111_0329</a>
<a href="archive/20260110_0333.html">20260110_0333</a>
<a href="archive/20260109_0334.html">20260109_0334</a>
<a href="archive/20260108_0335.html">20260108_0335</a>
<a href="archive/20260107_0330.html">20260107_0330</a>
<a href="archive/20260106_0336.html">20260106_0336</a>
<a href="archive/20260105_0328.html">20260105_0328</a>
<a href="archive/20260104_0328.html">20260104_0328</a>
<a href="archive/20260103_0325.html">20260103_0325</a>
<a href="archive/20260102_0339.html">20260102_0339</a>
<a href="archive/20260101_0329.html">20260101_0329</a>
<a href="archive/20251231_0333.html">20251231_0333</a>
<a href="archive/20251230_0332.html">20251230_0332</a>
<a href="archive/20251229_0329.html">20251229_0329</a>
<a href="archive/20251228_0332.html">20251228_0332</a>
<a href="archive/20251227_0329.html">20251227_0329</a>
<a href="archive/20251226_0330.html">20251226_0330</a>
<a href="archive/20251225_0329.html">20251225_0329</a>
<a href="archive/20251224_0331.html">20251224_0331</a></div>
    </details>
    <div class="footer">Generated by arxiv-tracker</div>
  </div>
</body></html>
