<!doctype html>
<html><head><meta charset="utf-8"><meta name="viewport" content="width=device-width,initial-scale=1">
<title>arXiv 论文速递</title><style>
:root {
  --bg:#f8fafc; --card:#ffffff; --text:#0f172a; --muted:#667085; --border:#e5e7eb; --acc:#2563eb;
}
:root[data-theme="dark"] {
  --bg:#0b0f17; --card:#111827; --text:#e5e7eb; --muted:#9ca3af; --border:#1f2937; --acc:#2563eb;
}
*{box-sizing:border-box} body{margin:0;background:var(--bg);color:var(--text);
  font-family:ui-sans-serif,system-ui,-apple-system,Segoe UI,Roboto,Helvetica,Arial;line-height:1.6;}
.container{max-width:900px;margin:0 auto;padding:18px;}
.header{display:flex;gap:10px;justify-content:space-between;align-items:center;margin:8px 0 16px;flex-wrap:wrap}
h1{font-size:22px;margin:0}
.badge{font-size:12px;color:#111827;background:var(--acc);padding:2px 8px;border-radius:999px}
.card{background:var(--card);border:1px solid var(--border);border-radius:16px;padding:16px 18px;margin:14px 0;box-shadow:0 1px 2px rgba(0,0,0,.04)}
.title{font-weight:700;margin:0 0 6px 0;font-size:18px}
.meta-line{color:var(--muted);font-size:13px;margin:2px 0}
.links a{color:var(--acc);text-decoration:none;margin-right:12px}
.detail{margin-top:10px;background:rgba(2,6,23,.03);border:1px solid var(--border);border-radius:10px;padding:8px 10px}
summary{cursor:pointer;color:var(--acc)}
.mono{white-space:pre-wrap;background:rgba(2,6,23,.03);border:1px solid var(--border);padding:10px;border-radius:10px}
.row{display:grid;grid-template-columns:1fr;gap:12px}
@media (min-width: 860px) {
  .row-2{grid-template-columns:1fr 1fr}
}
.footer{color:var(--muted);font-size:13px;margin:20px 0 10px}
.hr{height:1px;background:var(--border);margin:14px 0}
.history-list a{display:block;color:var(--acc);text-decoration:none;margin:4px 0}
.controls{display:flex;gap:8px;align-items:center}
.btn{border:1px solid var(--border);background:var(--card);padding:6px 10px;border-radius:10px;cursor:pointer;color:var(--text)}
.btn:hover{border-color:var(--acc)}
</style>
<script>
(function() {
  const root = document.documentElement;
  function apply(t) {
    if (t==='dark') root.setAttribute('data-theme','dark');
    else if (t==='light') root.removeAttribute('data-theme');
    else {
      if (window.matchMedia && window.matchMedia('(prefers-color-scheme: dark)').matches)
        root.setAttribute('data-theme','dark');
      else root.removeAttribute('data-theme');
    }
  }
  let t = localStorage.getItem('theme') || 'light';
  if (!['light','dark','auto'].includes(t)) t='light';
  apply(t);
  window.__toggleTheme = function() {
    let cur = localStorage.getItem('theme') || 'light';
    if (cur==='light') cur='dark';
    else if (cur==='dark') cur='auto';
    else cur='light';
    localStorage.setItem('theme', cur);
    apply(cur);
    const el=document.getElementById('theme-label');
    if(el) el.textContent = cur.toUpperCase();
  }
  window.__expandAll = function(open) {
    document.querySelectorAll('details').forEach(d => d.open = !!open);
  }
})();
</script>
</head>
<body>
  <div class="container">
    <div class="header">
      <h1>arXiv 论文速递</h1>
      <div style="display:flex;gap:10px;align-items:center">
        
<div class="controls">
  <button class="btn" onclick="__toggleTheme()">Theme: <span id="theme-label" style="margin-left:6px">AUTO</span></button>
  <button class="btn" onclick="__expandAll(true)">Expand All</button>
  <button class="btn" onclick="__expandAll(false)">Collapse All</button>
</div>

        <span class="badge">2026-01-27 03:33</span>
      </div>
    </div>
    <div class="hr"></div>
    <div>Snapshot: 20260127_0333</div>
    <div class="row"><div class="card">
<div class="title">A Scalable Measure of Loss Landscape Curvature for Analyzing the Training Dynamics of LLMs</div>
<div class="meta-line">Authors: Dayal Singh Kalra, Jean-Christophe Gagnon-Audet, Andrey Gromov, Ishita Mediratta, Kelvin Niu, Alexander H Miller, Michael Shvartsman</div>
<div class="meta-line">First: 2026-01-23T18:59:40+00:00 · Latest: 2026-01-23T18:59:40+00:00</div>
<div class="meta-line">Comments: 9 pages, 6 figures</div>
<div class="links" style="margin-top:8px"><a href="https://arxiv.org/abs/2601.16979v1">Abs</a> · <a href="https://arxiv.org/pdf/2601.16979v1">PDF</a> · <a href="https://huggingface.co/huggingface">Code1</a> · <a href="https://huggingface.co/docs/hub/spaces">Code2</a></div>
<details class="detail"><summary>Abstract</summary>
<div class="mono">Understanding the curvature evolution of the loss landscape is fundamental to analyzing the training dynamics of neural networks. The most commonly studied measure, Hessian sharpness ($λ_{\max}^H$) -- the largest eigenvalue of the loss Hessian -- determines local training stability and interacts with the learning rate throughout training. Despite its significance in analyzing training dynamics, direct measurement of Hessian sharpness remains prohibitive for Large Language Models (LLMs) due to high computational cost. We analyze $\textit{critical sharpness}$ ($λ_c$), a computationally efficient measure requiring fewer than $10$ forward passes given the update direction $Δ\mathbfθ$. Critically, this measure captures well-documented Hessian sharpness phenomena, including progressive sharpening and Edge of Stability. Using this measure, we provide the first demonstration of these sharpness phenomena at scale, up to $7$B parameters, spanning both pre-training and mid-training of OLMo-2 models. We further introduce $\textit{relative critical sharpness}$ ($λ_c^{1\to 2}$), which quantifies the curvature of one loss landscape while optimizing another, to analyze the transition from pre-training to fine-tuning and guide data mixing strategies. Critical sharpness provides practitioners with a practical tool for diagnosing curvature dynamics and informing data composition choices at scale. More broadly, our work shows that scalable curvature measures can provide actionable insights for large-scale training.</div></details>
<details class="detail"><summary>中文标题/摘要</summary>
<div class="mono"><b>标题：</b>一种可扩展的损失景观曲率度量方法，用于分析大语言模型的训练动态</div>
<div class="mono" style="margin-top:8px">理解损失景观曲率的演化是分析神经网络训练动态的基础。最常研究的度量指标——Hessian锐度（$λ_{\max}^H$，即损失Hessian矩阵的最大特征值）决定了局部训练的稳定性，并在整个训练过程中与学习率相互作用。尽管该指标对分析训练动态至关重要，但由于计算成本高昂，直接测量Hessian锐度对于大语言模型（LLMs）仍不可行。我们分析了$\textit{临界锐度}$（$λ_c$），这是一种计算高效的度量方法，在给定更新方向$Δ\mathbfθ$时仅需少于$10$次前向传播。关键在于，该度量能捕捉到已有充分文献记载的Hessian锐度现象，包括渐进锐化和稳定性边缘。利用此度量，我们首次在大规模（高达$70$亿参数）上展示了这些锐度现象，涵盖OLMo-2模型的预训练和中期训练全过程。我们进一步引入$\textit{相对临界锐度}$（$λ_c^{1\to 2}$），该指标可在优化一个损失景观时量化另一个损失景观的曲率，用于分析从预训练到微调的过渡过程，并指导数据混合策略。临界锐度为实践者提供了一个实用工具，可用于诊断曲率动态并为大规模数据组合选择提供依据。更广泛而言，我们的研究表明可扩展的曲率度量方法能为大规模训练提供可操作的见解。</div>
</details>
<details class="detail"><summary>Summary / 总结</summary>
<div class="mono">To understand the training dynamics of large language models (LLMs), analyzing the curvature of the loss landscape is essential, but directly computing the Hessian sharpness is computationally prohibitive. The authors propose a scalable measure called critical sharpness, which approximates the largest Hessian eigenvalue efficiently using fewer than ten forward passes given a parameter update direction. Experiments on OLMo-2 models up to 7B parameters demonstrate that this measure successfully captures known curvature phenomena like progressive sharpening and the Edge of Stability during both pre-training and mid-training, and its extension, relative critical sharpness, provides insights for fine-tuning transitions and data mixing strategies.</div>
<div class="mono" style="margin-top:8px">为分析大语言模型（LLM）的训练动态，其中直接计算海森矩阵锐度计算成本过高，本研究提出了一种可扩展的度量方法——临界锐度，它利用参数更新方向，通过少于10次前向传播来近似曲率。该方法捕捉了渐进锐化和稳定性边缘等已知的海森矩阵现象，并在高达70亿参数的OLMo-2模型的预训练和中期训练中进行了大规模验证。主要实验结果包括首次大规模观测到这些锐度动态，并引入了相对临界锐度来分析任务间损失景观的转换，从而为微调的数据混合策略提供指导。</div>
</details>
</div>
<div class="card">
<div class="title">MapAnything: Universal Feed-Forward Metric 3D Reconstruction</div>
<div class="meta-line">Authors: Nikhil Keetha, Norman Müller, Johannes Schönberger, Lorenzo Porzi, Yuchen Zhang, Tobias Fischer, Arno Knapitsch, Duncan Zauss, Ethan Weber, Nelson Antunes, Jonathon Luiten, Manuel Lopez-Antequera, Samuel Rota Bulò, Christian Richardt, Deva Ramanan, Sebastian Scherer, Peter Kontschieder</div>
<div class="meta-line">First: 2025-09-16T18:00:14+00:00 · Latest: 2026-01-23T18:59:33+00:00</div>
<div class="meta-line">Comments: 3DV 2026. Project Page: https://map-anything.github.io/</div>
<div class="links" style="margin-top:8px"><a href="https://arxiv.org/abs/2509.13414v3">Abs</a> · <a href="https://arxiv.org/pdf/2509.13414v3">PDF</a> · <a href="https://huggingface.co/huggingface">Code1</a> · <a href="https://huggingface.co/docs/hub/spaces">Code2</a> · <a href="https://map-anything.github.io/">Project1</a></div>
<details class="detail"><summary>Abstract</summary>
<div class="mono">We introduce MapAnything, a unified transformer-based feed-forward model that ingests one or more images along with optional geometric inputs such as camera intrinsics, poses, depth, or partial reconstructions, and then directly regresses the metric 3D scene geometry and cameras. MapAnything leverages a factored representation of multi-view scene geometry, i.e., a collection of depth maps, local ray maps, camera poses, and a metric scale factor that effectively upgrades local reconstructions into a globally consistent metric frame. Standardizing the supervision and training across diverse datasets, along with flexible input augmentation, enables MapAnything to address a broad range of 3D vision tasks in a single feed-forward pass, including uncalibrated structure-from-motion, calibrated multi-view stereo, monocular depth estimation, camera localization, depth completion, and more. We provide extensive experimental analyses and model ablations demonstrating that MapAnything outperforms or matches specialist feed-forward models while offering more efficient joint training behavior, thus paving the way toward a universal 3D reconstruction backbone.</div></details>
<details class="detail"><summary>中文标题/摘要</summary>
<div class="mono"><b>标题：</b>MapAnything：通用前馈式度量三维重建</div>
<div class="mono" style="margin-top:8px">本文提出MapAnything，一种基于Transformer的统一前馈模型。该模型可接收单张或多张图像，以及相机内参、位姿、深度或部分重建结果等可选几何输入，直接回归出度量化的三维场景几何与相机参数。MapAnything采用多视角场景几何的分解表示——即深度图集合、局部光线图、相机位姿及度量尺度因子——将局部重建有效升级至全局一致的度量坐标系。通过跨数据集的标准化监督训练与灵活输入增强，MapAnything能在单次前馈计算中处理广泛的三维视觉任务，包括未标定运动恢复结构、已标定多视角立体视觉、单目深度估计、相机定位、深度补全等。大量实验分析与模型消融研究表明，MapAnything在保持高效联合训练特性的同时，性能优于或匹配专用前馈模型，为构建通用三维重建基础模型开辟了新路径。</div>
</details>
<details class="detail"><summary>Summary / 总结</summary>
<div class="mono">The research aims to develop a universal model for diverse 3D vision tasks, which are typically addressed by separate specialized models. The method introduces MapAnything, a unified transformer-based feed-forward model that ingests images with optional geometric inputs and directly regresses metric 3D geometry and cameras using a factored representation of multi-view scene geometry. Experimental results show that MapAnything outperforms or matches specialist feed-forward models across tasks like structure-from-motion and monocular depth estimation while enabling more efficient joint training.</div>
<div class="mono" style="margin-top:8px">本研究旨在为通常由专门、独立的模型处理的各种3D视觉任务开发一个通用模型。该方法引入了MapAnything，这是一个基于Transformer的统一前馈模型，它处理图像和可选的几何输入，以直接回归度量3D几何和相机，并使用多视图场景几何的分解表示来实现全局一致性。实验结果表明，在运动恢复结构和深度估计等任务上，MapAnything的性能优于或匹配专门的前馈模型，同时实现了更高效的联合训练。</div>
</details>
</div>
<div class="card">
<div class="title">LLM Reasoning for Cold-Start Item Recommendation</div>
<div class="meta-line">Authors: Shijun Li, Yu Wang, Jin Wang, Ying Li, Joydeep Ghosh, Anne Cocos</div>
<div class="meta-line">Venue: WWW 2026</div>
<div class="meta-line">First: 2025-11-23T03:22:53+00:00 · Latest: 2026-01-23T18:51:39+00:00</div>
<div class="meta-line">Comments: Published on Proceedings of the ACM on Web Conference 2026 (WWW 2026)</div>
<div class="links" style="margin-top:8px"><a href="https://arxiv.org/abs/2511.18261v3">Abs</a> · <a href="https://arxiv.org/pdf/2511.18261v3">PDF</a> · <a href="https://huggingface.co/huggingface">Code1</a> · <a href="https://huggingface.co/docs/hub/spaces">Code2</a></div>
<details class="detail"><summary>Abstract</summary>
<div class="mono">Large Language Models (LLMs) have shown significant potential for improving recommendation systems through their inherent reasoning capabilities and extensive knowledge base. Yet, existing studies predominantly address warm-start scenarios with abundant user-item interaction data, leaving the more challenging cold-start scenarios, where sparse interactions hinder traditional collaborative filtering methods, underexplored. To address this limitation, we propose novel reasoning strategies designed for cold-start item recommendations within the Netflix domain. Our method utilizes the advanced reasoning capabilities of LLMs to effectively infer user preferences, particularly for newly introduced or rarely interacted items. We systematically evaluate supervised fine-tuning, reinforcement learning-based fine-tuning, and hybrid approaches that combine both methods to optimize recommendation performance. Extensive experiments on real-world data demonstrate significant improvements in both methodological efficacy and practical performance in cold-start recommendation contexts. Remarkably, our reasoning-based fine-tuned models outperform Netflix&#x27;s production ranking model by up to 8% in certain cases.</div></details>
<details class="detail"><summary>中文标题/摘要</summary>
<div class="mono"><b>标题：</b>面向冷启动物品推荐的LLM推理方法</div>
<div class="mono" style="margin-top:8px">大型语言模型（LLMs）凭借其内在推理能力和广泛知识库，在改进推荐系统方面展现出巨大潜力。然而现有研究主要关注具有丰富用户-物品交互数据的温启动场景，对交互稀疏导致传统协同过滤方法失效的冷启动场景探索不足。为突破这一局限，我们针对Netflix领域提出创新的冷启动物品推荐推理策略。该方法利用LLMs的高级推理能力有效推断用户偏好，尤其适用于新引入或交互稀少的物品。我们系统评估了监督微调、基于强化学习的微调以及融合两种方法的混合策略，以优化推荐性能。基于真实数据的大量实验表明，该方法在冷启动推荐场景中显著提升了方法效能与实际表现。值得注意的是，我们基于推理的微调模型在特定情况下比Netflix生产级排序模型性能提升高达8%。</div>
</details>
<details class="detail"><summary>Summary / 总结</summary>
<div class="mono">The research addresses the underexplored challenge of cold-start item recommendation, where sparse user-item interactions hinder traditional collaborative filtering methods, by leveraging the reasoning capabilities of Large Language Models (LLMs). The proposed method develops novel reasoning strategies for the Netflix domain, employing supervised fine-tuning, reinforcement learning-based fine-tuning, and hybrid approaches to optimize LLMs for inferring user preferences towards new or rarely interacted items. Experimental evaluation on real-world data shows that these reasoning-based fine-tuned models achieve significant performance improvements in cold-start scenarios, outperforming Netflix&#x27;s production ranking model by up to 8% in certain cases.</div>
<div class="mono" style="margin-top:8px">本研究针对冷启动物品推荐中用户-物品交互稀疏、传统协同过滤方法效果受限的挑战，利用大语言模型的推理能力来探索这一未充分研究的领域。所提出的方法为Netflix领域设计了新颖的推理策略，通过监督微调、基于强化学习的微调以及两者结合的混合方法来优化模型，以推断用户对新引入或极少交互物品的偏好。在真实数据上的大量实验表明，基于推理的微调模型在冷启动场景下取得了显著的性能提升，在某些情况下甚至能超越Netflix的生产排序模型达8%。</div>
</details>
</div>
<div class="card">
<div class="title">BONO-Bench: A Comprehensive Test Suite for Bi-objective Numerical Optimization with Traceable Pareto Sets</div>
<div class="meta-line">Authors: Lennart Schäpermeier, Pascal Kerschke</div>
<div class="meta-line">First: 2026-01-23T18:42:20+00:00 · Latest: 2026-01-23T18:42:20+00:00</div>
<div class="meta-line">Comments: Accepted for publication in the Special Issue on Benchmarking in Multi-Criteria Optimization at ACM TELO</div>
<div class="links" style="margin-top:8px"><a href="https://arxiv.org/abs/2601.16970v1">Abs</a> · <a href="https://arxiv.org/pdf/2601.16970v1">PDF</a> · <a href="https://huggingface.co/huggingface">Code1</a> · <a href="https://huggingface.co/docs/hub/spaces">Code2</a></div>
<details class="detail"><summary>Abstract</summary>
<div class="mono">The evaluation of heuristic optimizers on test problems, better known as \emph{benchmarking}, is a cornerstone of research in multi-objective optimization.
  However, most test problems used in benchmarking numerical multi-objective black-box optimizers come from one of two flawed approaches: On the one hand, problems are constructed manually, which result in problems with well-understood optimal solutions, but unrealistic properties and biases.
  On the other hand, more realistic and complex single-objective problems are composited into multi-objective problems, but with a lack of control and understanding of problem properties.
  This paper proposes an extensive problem generation approach for bi-objective numerical optimization problems consisting of the combination of theoretically well-understood convex-quadratic functions into unimodal and multimodal landscapes with and without global structure.
  It supports configuration of test problem properties, such as the number of decision variables, local optima, Pareto front shape, plateaus in the objective space, or degree of conditioning, while maintaining theoretical tractability: The optimal front can be approximated to an arbitrary degree of precision regarding Pareto-compliant performance indicators such as the hypervolume or the exact R2 indicator.
  To demonstrate the generator&#x27;s capabilities, a test suite of 20 problem categories, called \emph{BONO-Bench}, is created and subsequently used as a basis of an illustrative benchmark study.
  Finally, the general approach underlying our proposed generator, together with the associated test suite, is publicly released in the Python package \texttt{bonobench} to facilitate reproducible benchmarking.</div></details>
<details class="detail"><summary>中文标题/摘要</summary>
<div class="mono"><b>标题：</b>BONO-Bench：具有可追踪帕累托前沿的双目标数值优化综合测试套件</div>
<div class="mono" style="margin-top:8px">在测试问题上评估启发式优化器（通常称为基准测试）是多目标优化研究的基石。然而，当前用于评估数值多目标黑盒优化器的测试问题大多源于两种有缺陷的方法：一方面，人工构造的问题虽具有明确的最优解，却存在不现实的特性与偏差；另一方面，将更真实复杂的单目标问题组合成多目标问题时，往往缺乏对问题特性的控制与理解。本文提出一种面向双目标数值优化问题的扩展问题生成方法，通过组合理论清晰的凸二次函数，构建具有/无全局结构的单峰与多峰地形。该方法支持配置测试问题特性（如决策变量数量、局部最优解数量、帕累托前沿形状、目标空间平台区域、条件数等），同时保持理论可追踪性：针对帕累托兼容性能指标（如超体积或精确R2指标），可实现对最优前沿任意精度的逼近。为展示生成器的能力，我们创建了包含20个问题类别的测试套件（称为BONO-Bench），并以此为基础开展示范性基准研究。最后，我们将所提生成器的通用方法及相关测试套件通过Python软件包bonobench公开发布，以促进可复现的基准测试。</div>
</details>
<details class="detail"><summary>Summary / 总结</summary>
<div class="mono">The research is motivated by the limitations of existing test problems for benchmarking multi-objective optimizers, which are either manually constructed with unrealistic biases or composited from single-objective problems without controlled properties. The method proposes a generation approach for bi-objective numerical optimization problems by combining convex-quadratic functions to create unimodal and multimodal landscapes, allowing configurable properties like the number of variables, local optima, Pareto front shape, and conditioning while maintaining theoretical tractability of the optimal front. Experimental results demonstrate the generator&#x27;s capabilities through a test suite of 20 problem categories, BONO-Bench, used in an illustrative benchmark study, with the approach and suite released as a Python package for reproducible benchmarking.</div>
<div class="mono" style="margin-top:8px">该研究针对现有多目标优化基准的局限性，即手动构建的问题不现实，而复合问题缺乏可控属性。方法通过组合凸二次函数来创建单峰和多峰景观，提出了一种双目标数值优化问题生成器，允许配置变量数量、帕累托前沿形状和条件化等属性，同时保持最优前沿的理论可追踪性。实验结果通过一个包含20个问题类别的测试套件BONO-Bench展示了生成器的能力，并用于说明性基准研究，该方法已作为Python包发布以促进可复现的基准测试。</div>
</details>
</div>
<div class="card">
<div class="title">On Fine-Grained I/O Complexity of Attention Backward Passes</div>
<div class="meta-line">Authors: Xiaoyu Li, Yingyu Liang, Zhenmei Shi, Zhao Song, Song Yue, Jiahao Zhang</div>
<div class="meta-line">First: 2024-10-12T07:01:30+00:00 · Latest: 2026-01-23T18:42:16+00:00</div>
<div class="links" style="margin-top:8px"><a href="https://arxiv.org/abs/2410.09397v2">Abs</a> · <a href="https://arxiv.org/pdf/2410.09397v2">PDF</a> · <a href="https://huggingface.co/huggingface">Code1</a> · <a href="https://huggingface.co/docs/hub/spaces">Code2</a></div>
<details class="detail"><summary>Abstract</summary>
<div class="mono">Large Language Models (LLMs) exhibit exceptional proficiency in handling extensive context windows in natural language. Nevertheless, the quadratic scaling of attention computation relative to sequence length creates substantial efficiency bottlenecks, necessitating the development of I/O-optimized algorithms. In this work, we conduct a systematic examination of the I/O complexity inherent in attention mechanisms, with a specific emphasis on the backward pass under both small and large cache settings. By leveraging the red-blue pebble game framework, we derive tight bounds for I/O complexity across the full spectrum of cache sizes. We validate that FlashAttention, one of the current industry standards, achieves optimality in the large-cache scenario for both forward and backward passes. Conversely, for small-cache environments, we introduce a novel algorithm that outperforms contemporary methods and successfully attains theoretical tight bounds. Furthermore, we expand our investigation to include sparse attention by establishing granular lower bounds for both forward and backward passes across all cache configurations. Ultimately, our results solidify the theoretical framework regarding I/O complexity in attention mechanisms, providing critical guidance for the development of efficient LLM training and inference systems.</div></details>
<details class="detail"><summary>中文标题/摘要</summary>
<div class="mono"><b>标题：</b>注意力机制反向传播的细粒度I/O复杂度研究</div>
<div class="mono" style="margin-top:8px">大语言模型在处理自然语言长上下文窗口方面展现出卓越能力，但注意力计算随序列长度呈二次方增长，导致显著效率瓶颈，亟需开发I/O优化算法。本研究系统分析了注意力机制固有的I/O复杂度，重点探究小缓存与大缓存配置下的反向传播过程。通过红蓝卵石博弈框架，我们推导出全缓存规模范围内的紧致I/O复杂度边界。验证表明当前业界标准FlashAttention在大缓存场景下实现前向与反向传播的最优性；针对小缓存环境，我们提出创新算法，其性能超越现有方法并达到理论紧致边界。此外，研究拓展至稀疏注意力机制，建立全缓存配置下前向与反向传播的细粒度下界。最终成果夯实了注意力机制I/O复杂度的理论框架，为高效大语言模型训练与推理系统开发提供关键指导。</div>
</details>
<details class="detail"><summary>Summary / 总结</summary>
<div class="mono">The quadratic scaling of attention computation with sequence length in Large Language Models creates significant efficiency bottlenecks, motivating a systematic analysis of I/O complexity, particularly for the backward pass under varying cache sizes. Using the red-blue pebble game framework, the work derives tight I/O complexity bounds across the full cache size spectrum, validating that FlashAttention is optimal for large caches and introducing a novel algorithm that attains theoretical tight bounds for small caches. The experimental findings confirm the new algorithm&#x27;s superiority over contemporary methods in small-cache settings and extend the analysis to establish granular lower bounds for sparse attention, solidifying the theoretical foundation for efficient LLM training and inference systems.</div>
<div class="mono" style="margin-top:8px">大型语言模型中注意力计算随序列长度的二次缩放导致了显著的效率瓶颈，这促使了对I/O复杂性的系统分析，特别是在不同缓存大小下的反向传播过程。该研究利用红蓝卵石游戏框架，推导了全缓存范围内的紧致I/O复杂度界限，验证了FlashAttention在大缓存场景下的最优性，并针对小缓存环境提出了一种达到理论紧致界限的新算法。研究还扩展到稀疏注意力，建立了所有缓存配置下的细粒度下界，从而巩固了高效LLM训练与推理系统的理论基础。</div>
</details>
</div>
<div class="card">
<div class="title">Q-learning with Adjoint Matching</div>
<div class="meta-line">Authors: Qiyang Li, Sergey Levine</div>
<div class="meta-line">First: 2026-01-20T18:45:34+00:00 · Latest: 2026-01-23T18:40:14+00:00</div>
<div class="meta-line">Comments: 32 pages, 8 figures, 7 tables</div>
<div class="links" style="margin-top:8px"><a href="https://arxiv.org/abs/2601.14234v2">Abs</a> · <a href="https://arxiv.org/pdf/2601.14234v2">PDF</a> · <a href="https://huggingface.co/huggingface">Code1</a> · <a href="https://huggingface.co/docs/hub/spaces">Code2</a></div>
<details class="detail"><summary>Abstract</summary>
<div class="mono">We propose Q-learning with Adjoint Matching (QAM), a novel TD-based reinforcement learning (RL) algorithm that tackles a long-standing challenge in continuous-action RL: efficient optimization of an expressive diffusion or flow-matching policy with respect to a parameterized Q-function. Effective optimization requires exploiting the first-order information of the critic, but it is challenging to do so for flow or diffusion policies because direct gradient-based optimization via backpropagation through their multi-step denoising process is numerically unstable. Existing methods work around this either by only using the value and discarding the gradient information, or by relying on approximations that sacrifice policy expressivity or bias the learned policy. QAM sidesteps both of these challenges by leveraging adjoint matching, a recently proposed technique in generative modeling, which transforms the critic&#x27;s action gradient to form a step-wise objective function that is free from unstable backpropagation, while providing an unbiased, expressive policy at the optimum. Combined with temporal-difference backup for critic learning, QAM consistently outperforms prior approaches on hard, sparse reward tasks in both offline and offline-to-online RL.</div></details>
<details class="detail"><summary>中文标题/摘要</summary>
<div class="mono"><b>标题：</b>伴随匹配Q学习</div>
<div class="mono" style="margin-top:8px">我们提出伴随匹配Q学习（QAM），这是一种基于时序差分的新型强化学习算法，解决了连续动作强化学习中长期存在的挑战：针对参数化Q函数高效优化表达能力强的扩散或流匹配策略。有效优化需要利用评论家的一阶信息，但对流或扩散策略而言，通过多步去噪过程进行基于梯度的直接反向传播优化存在数值不稳定性。现有方法要么仅使用价值函数而丢弃梯度信息，要么依赖牺牲策略表达能力或引入偏差的近似方法。QAM通过运用生成建模中最新提出的伴随匹配技术，巧妙规避了这两类挑战。该技术将评论家的动作梯度转化为分步目标函数，避免了不稳定的反向传播，同时在最优解处提供无偏且表达能力强的策略。结合评论家学习的时序差分更新，QAM在离线及离线到在线强化学习的困难稀疏奖励任务中持续超越现有方法。</div>
</details>
<details class="detail"><summary>Summary / 总结</summary>
<div class="mono">The research addresses the challenge of efficiently optimizing expressive diffusion or flow-matching policies in continuous-action reinforcement learning, where direct gradient-based optimization through multi-step denoising processes is numerically unstable. The proposed method, Q-learning with Adjoint Matching (QAM), leverages adjoint matching to transform the critic&#x27;s action gradient into a step-wise objective, avoiding unstable backpropagation while maintaining an unbiased and expressive policy. Experimental results show that QAM consistently outperforms prior methods on hard, sparse reward tasks in both offline and offline-to-online RL settings.</div>
<div class="mono" style="margin-top:8px">该研究旨在解决连续动作强化学习中高效优化表达性扩散或流匹配策略的长期挑战，其中通过多步去噪过程进行直接梯度优化存在数值不稳定性。所提出的方法——伴随匹配Q学习（QAM）——利用伴随匹配技术将评论者的动作梯度转化为逐步目标函数，从而避免了不稳定的反向传播，同时保持了无偏且表达性强的策略。实验结果表明，在离线及离线到在线强化学习的困难稀疏奖励任务上，QAM一致优于现有方法。</div>
</details>
</div>
<div class="card">
<div class="title">Empowering Medical Equipment Sustainability in Low-Resource Settings: An AI-Powered Diagnostic and Support Platform for Biomedical Technicians</div>
<div class="meta-line">Authors: Bernes Lorier Atabonfack, Ahmed Tahiru Issah, Mohammed Hardi Abdul Baaki, Clemence Ingabire, Tolulope Olusuyi, Maruf Adewole, Udunna C. Anazodo, Timothy X Brown</div>
<div class="meta-line">Venue: MICCAI 2025</div>
<div class="meta-line">First: 2026-01-23T18:39:55+00:00 · Latest: 2026-01-23T18:39:55+00:00</div>
<div class="meta-line">Comments: Accepted at the MIRASOL Workshop at MICCAI 2025. To appear in Lecture Notes in Computer Science (LNCS)</div>
<div class="links" style="margin-top:8px"><a href="https://arxiv.org/abs/2601.16967v1">Abs</a> · <a href="https://arxiv.org/pdf/2601.16967v1">PDF</a> · <a href="https://huggingface.co/huggingface">Code1</a> · <a href="https://huggingface.co/docs/hub/spaces">Code2</a></div>
<details class="detail"><summary>Abstract</summary>
<div class="mono">In low- and middle-income countries (LMICs), a significant proportion of medical diagnostic equipment remains underutilized or non-functional due to a lack of timely maintenance, limited access to technical expertise, and minimal support from manufacturers, particularly for devices acquired through third-party vendors or donations. This challenge contributes to increased equipment downtime, delayed diagnoses, and compromised patient care. This research explores the development and validation of an AI-powered support platform designed to assist biomedical technicians in diagnosing and repairing medical devices in real-time. The system integrates a large language model (LLM) with a user-friendly web interface, enabling imaging technologists/radiographers and biomedical technicians to input error codes or device symptoms and receive accurate, step-by-step troubleshooting guidance. The platform also includes a global peer-to-peer discussion forum to support knowledge exchange and provide additional context for rare or undocumented issues. A proof of concept was developed using the Philips HDI 5000 ultrasound machine, achieving 100% precision in error code interpretation and 80% accuracy in suggesting corrective actions. This study demonstrates the feasibility and potential of AI-driven systems to support medical device maintenance, with the aim of reducing equipment downtime to improve healthcare delivery in resource-constrained environments.</div></details>
<details class="detail"><summary>中文标题/摘要</summary>
<div class="mono"><b>标题：</b>赋能低资源环境下的医疗设备可持续性：面向生物医学技术人员的AI驱动诊断与支持平台</div>
<div class="mono" style="margin-top:8px">在中低收入国家，大量医疗诊断设备因缺乏及时维护、技术专家支持不足及制造商（特别是通过第三方或捐赠获得的设备）支持有限而处于闲置或故障状态，导致设备停机时间延长、诊断延误及患者护理质量下降。本研究开发并验证了一款AI支持平台，旨在实时协助生物医学技术人员诊断和修复医疗设备。该系统将大型语言模型与用户友好的Web界面结合，允许影像技师/放射师及生物医学技术人员输入错误代码或设备症状，获取精准的逐步故障排除指导。平台还设有全球同行讨论论坛，支持知识共享并为罕见或未记录问题提供补充信息。基于飞利浦HDI 5000超声设备的原型验证显示，错误代码解读准确率达100%，修复建议准确率达80%。本研究证实了AI驱动系统支持医疗设备维护的可行性与潜力，旨在通过减少设备停机时间改善资源受限环境的医疗服务。</div>
</details>
<details class="detail"><summary>Summary / 总结</summary>
<div class="mono">This research addresses the critical challenge of medical equipment downtime in low- and middle-income countries (LMICs), where devices often become non-functional due to maintenance and expertise shortages, compromising patient care. The proposed method is an AI-powered support platform that integrates a large language model (LLM) with a web interface and a peer-to-peer forum, enabling technicians to input error codes or symptoms and receive step-by-step troubleshooting guidance. In a proof-of-concept validation using a Philips HDI 5000 ultrasound machine, the system achieved 100% precision in interpreting error codes and 80% accuracy in suggesting corrective actions, demonstrating its feasibility for reducing equipment downtime in resource-constrained settings.</div>
<div class="mono" style="margin-top:8px">本研究旨在解决中低收入国家因维护困难导致的医疗设备利用率低和故障率高的问题，为此开发了一个人工智能驱动的诊断与支持平台。该方法将大型语言模型与网页界面及点对点论坛相结合，使技术人员能够输入错误代码或症状以获取故障排除指导。在基于飞利浦HDI 5000超声设备的原理验证中，该系统在错误代码解读上实现了100%的精确度，并在建议纠正措施上达到了80%的准确率，证明了其在减少设备停机时间方面的可行性。</div>
</details>
</div>
<div class="card">
<div class="title">Provable Differentially Private Computation of the Cross-Attention Mechanism</div>
<div class="meta-line">Authors: Yekun Ke, Yingyu Liang, Zhenmei Shi, Zhao Song, Jiahao Zhang</div>
<div class="meta-line">First: 2024-07-20T01:02:27+00:00 · Latest: 2026-01-23T18:38:40+00:00</div>
<div class="links" style="margin-top:8px"><a href="https://arxiv.org/abs/2407.14717v3">Abs</a> · <a href="https://arxiv.org/pdf/2407.14717v3">PDF</a> · <a href="https://huggingface.co/huggingface">Code1</a> · <a href="https://huggingface.co/docs/hub/spaces">Code2</a></div>
<details class="detail"><summary>Abstract</summary>
<div class="mono">Cross-attention has emerged as a cornerstone module in modern artificial intelligence, underpinning critical applications such as retrieval-augmented generation (RAG), system prompting, and guided stable diffusion. However, this is a rising concern about securing the privacy of cross-attention, as the underlying key and value matrices frequently encode sensitive data or private user information. In this work, we introduce a novel data structure designed to enforce differential privacy (DP) for cross-attention mechanisms, accompanied by provable theoretical guarantees. Specifically, letting $n$ denote the input sequence length, $d$ the feature dimension, $R$ the maximum magnitude of query and key matrices, $R_w$ the maximum magnitude of the value matrix, and $r, s, ε_s$ the parameters for polynomial kernel methods, our proposed structure achieves $\widetilde{O}(ndr^2)$ space and initialization complexity, with a query time of $\widetilde{O}(d r^2)$ per token. Moreover, we demonstrate that our mechanism satisfies $(ε, δ)$-DP, incurring an additive error of $\widetilde{O}((1-ε_s)^{-1} n^{-1} ε^{-1} R^{2s} R_w r^2)$ and a relative error of $2ε_s/(1-ε_s)$ with respect to the ground truth. Crucially, our framework maintains robustness against adaptive queries, ensuring security even in adversarial settings. To the best of our knowledge, this constitutes the first approach providing provable differential privacy for cross-attention, establishing a foundation for future privacy-preserving algorithms in large generative models (LGMs).</div></details>
<details class="detail"><summary>中文标题/摘要</summary>
<div class="mono"><b>标题：</b>可证明差分隐私的交叉注意力机制计算</div>
<div class="mono" style="margin-top:8px">交叉注意力已成为现代人工智能的基石模块，支撑着检索增强生成（RAG）、系统提示和引导式稳定扩散等关键应用。然而，由于底层键值矩阵常编码敏感数据或用户隐私信息，其隐私保护问题日益受到关注。本研究提出一种新颖的数据结构，旨在为交叉注意力机制实施差分隐私（DP），并提供可证明的理论保证。具体而言，设输入序列长度为$n$，特征维度为$d$，查询与键矩阵最大幅值为$R$，值矩阵最大幅值为$R_w$，多项式核方法参数为$r, s, ε_s$，所提结构实现$\widetilde{O}(ndr^2)$空间与初始化复杂度，单令牌查询时间为$\widetilde{O}(d r^2)$。该机制满足$(ε, δ)$-DP，其绝对误差为$\widetilde{O}((1-ε_s)^{-1} n^{-1} ε^{-1} R^{2s} R_w r^2)$，相对真实值的相对误差为$2ε_s/(1-ε_s)$。该框架对自适应查询保持鲁棒性，确保在对抗环境下的安全性。据我们所知，这是首个为交叉注意力提供可证明差分隐私的方法，为大型生成模型（LGMs）的隐私保护算法奠定了基础。</div>
</details>
<details class="detail"><summary>Summary / 总结</summary>
<div class="mono">Motivated by the widespread use of cross-attention in applications like retrieval-augmented generation and guided stable diffusion, where key and value matrices often contain sensitive user data, this work introduces a novel data structure to enforce differential privacy (DP) for cross-attention with provable guarantees. The method achieves space and initialization complexity of $\widetilde{O}(ndr^2)$ and query time of $\widetilde{O}(d r^2)$ per token, using parameters such as sequence length $n$, feature dimension $d$, and polynomial kernel parameters $r, s, ε_s$. Experimental results demonstrate that the mechanism satisfies $(ε, δ)$-DP, introducing an additive error of $\widetilde{O}((1-ε_s)^{-1} n^{-1} ε^{-1} R^{2s} R_w r^2)$ and a relative error of $2ε_s/(1-ε_s)$, while remaining robust against adaptive queries, thereby establishing a foundation for privacy-preserving large generative models.</div>
<div class="mono" style="margin-top:8px">该研究的动机在于交叉注意力机制在检索增强生成和引导稳定扩散等关键应用中的广泛使用，其键值矩阵常包含敏感数据，引发了隐私担忧。方法提出了一种新颖的数据结构，为交叉注意力机制提供可证明的差分隐私保证，实现了$\widetilde{O}(ndr^2)$的空间和初始化复杂度以及每令牌$\widetilde{O}(d r^2)$的查询时间。实验结果表明，该机制满足$(\epsilon, \delta)$-差分隐私，引入了$\widetilde{O}((1-\epsilon_s)^{-1} n^{-1} \epsilon^{-1} R^{2s} R_w r^2)$的加性误差和$2\epsilon_s/(1-\epsilon_s)$的相对误差，并能抵御自适应查询，这是首个为交叉注意力提供可证明隐私保护的方法。</div>
</details>
</div>
<div class="card">
<div class="title">Spatial-Agent: Agentic Geo-spatial Reasoning with Scientific Core Concepts</div>
<div class="meta-line">Authors: Riyang Bao, Cheng Yang, Dazhou Yu, Zhexiang Tang, Gengchen Mai, Liang Zhao</div>
<div class="meta-line">First: 2026-01-23T18:33:45+00:00 · Latest: 2026-01-23T18:33:45+00:00</div>
<div class="meta-line">Comments: 15pages, 4 figures</div>
<div class="links" style="margin-top:8px"><a href="https://arxiv.org/abs/2601.16965v1">Abs</a> · <a href="https://arxiv.org/pdf/2601.16965v1">PDF</a> · <a href="https://huggingface.co/huggingface">Code1</a> · <a href="https://huggingface.co/docs/hub/spaces">Code2</a></div>
<details class="detail"><summary>Abstract</summary>
<div class="mono">Geospatial reasoning is essential for real-world applications such as urban analytics, transportation planning, and disaster response. However, existing LLM-based agents often fail at genuine geospatial computation, relying instead on web search or pattern matching while hallucinating spatial relationships. We present Spatial-Agent, an AI agent grounded in foundational theories of spatial information science. Our approach formalizes geo-analytical question answering as a concept transformation problem, where natural-language questions are parsed into executable workflows represented as GeoFlow Graphs -- directed acyclic graphs with nodes corresponding to spatial concepts and edges representing transformations. Drawing on spatial information theory, Spatial-Agent extracts spatial concepts, assigns functional roles with principled ordering constraints, and composes transformation sequences through template-based generation. Extensive experiments on MapEval-API and MapQA benchmarks demonstrate that Spatial-Agent significantly outperforms existing baselines including ReAct and Reflexion, while producing interpretable and executable geospatial workflows.</div></details>
<details class="detail"><summary>中文标题/摘要</summary>
<div class="mono"><b>标题：</b>空间智能体：基于科学核心概念的自主地理空间推理</div>
<div class="mono" style="margin-top:8px">地理空间推理在城市分析、交通规划和灾害应对等实际应用中至关重要。然而，现有基于大语言模型的智能体往往无法进行真正的地理空间计算，而是依赖网络搜索或模式匹配，同时虚构空间关系。本文提出空间智能体，这是一种基于空间信息科学基础理论的AI智能体。我们的方法将地理分析问答形式化为概念转换问题：自然语言问题被解析为可执行的工作流，表示为GeoFlow图——一种有向无环图，其节点对应空间概念，边表示转换关系。依托空间信息理论，空间智能体提取空间概念，通过原则性排序约束分配功能角色，并基于模板生成转换序列。在MapEval-API和MapQA基准上的大量实验表明，空间智能体显著优于包括ReAct和Reflexion在内的现有基线方法，同时能生成可解释且可执行的地理空间工作流。</div>
</details>
<details class="detail"><summary>Summary / 总结</summary>
<div class="mono">The research addresses the limitation of existing LLM-based agents in performing genuine geospatial computation, as they often rely on web search or pattern matching while hallucinating spatial relationships. The proposed Spatial-Agent formalizes geo-analytical question answering as a concept transformation problem, parsing natural-language questions into executable workflows represented as GeoFlow Graphs—directed acyclic graphs where nodes correspond to spatial concepts and edges represent transformations, grounded in spatial information theory. Experimental results on MapEval-API and MapQA benchmarks show that Spatial-Agent significantly outperforms baselines like ReAct and Reflexion while producing interpretable and executable geospatial workflows.</div>
<div class="mono" style="margin-top:8px">地理空间推理对于城市分析和灾害响应等应用至关重要，但现有基于大语言模型的智能体常缺乏真正的计算能力，并产生空间关系幻觉。为此，研究者提出了Spatial-Agent，这是一种基于空间信息科学理论的AI智能体，它将地理分析问题形式化为概念转换问题，将自然语言问题解析为可执行的工作流，即GeoFlow图——一种有向无环图，其中节点对应空间概念，边表示转换关系。该方法提取空间概念，依据原则性顺序约束分配功能角色，并通过基于模板的生成组合转换序列。在MapEval-API和MapQA基准上的大量实验表明，Spatial-Agent显著优于ReAct和Reflexion等基线方法，同时能生成可解释且可执行的地理空间工作流。</div>
</details>
</div>
<div class="card">
<div class="title">AgentDrive: An Open Benchmark Dataset for Agentic AI Reasoning with LLM-Generated Scenarios in Autonomous Systems</div>
<div class="meta-line">Authors: Mohamed Amine Ferrag, Abderrahmane Lakas, Merouane Debbah</div>
<div class="meta-line">First: 2026-01-23T18:33:41+00:00 · Latest: 2026-01-23T18:33:41+00:00</div>
<div class="meta-line">Comments: 16 pages</div>
<div class="links" style="margin-top:8px"><a href="https://arxiv.org/abs/2601.16964v1">Abs</a> · <a href="https://arxiv.org/pdf/2601.16964v1">PDF</a> · <a href="https://github.com/maferrag/AgentDrive">Code1</a> · <a href="https://huggingface.co/huggingface">Code2</a> · <a href="https://huggingface.co/docs/hub/spaces">Code3</a></div>
<details class="detail"><summary>Abstract</summary>
<div class="mono">The rapid advancement of large language models (LLMs) has sparked growing interest in their integration into autonomous systems for reasoning-driven perception, planning, and decision-making. However, evaluating and training such agentic AI models remains challenging due to the lack of large-scale, structured, and safety-critical benchmarks. This paper introduces AgentDrive, an open benchmark dataset containing 300,000 LLM-generated driving scenarios designed for training, fine-tuning, and evaluating autonomous agents under diverse conditions. AgentDrive formalizes a factorized scenario space across seven orthogonal axes: scenario type, driver behavior, environment, road layout, objective, difficulty, and traffic density. An LLM-driven prompt-to-JSON pipeline generates semantically rich, simulation-ready specifications that are validated against physical and schema constraints. Each scenario undergoes simulation rollouts, surrogate safety metric computation, and rule-based outcome labeling. To complement simulation-based evaluation, we introduce AgentDrive-MCQ, a 100,000-question multiple-choice benchmark spanning five reasoning dimensions: physics, policy, hybrid, scenario, and comparative reasoning. We conduct a large-scale evaluation of fifty leading LLMs on AgentDrive-MCQ. Results show that while proprietary frontier models perform best in contextual and policy reasoning, advanced open models are rapidly closing the gap in structured and physics-grounded reasoning. We release the AgentDrive dataset, AgentDrive-MCQ benchmark, evaluation code, and related materials at https://github.com/maferrag/AgentDrive</div></details>
<details class="detail"><summary>中文标题/摘要</summary>
<div class="mono"><b>标题：</b>AgentDrive：面向自主系统中基于LLM生成场景的智能体AI推理的开放基准数据集</div>
<div class="mono" style="margin-top:8px">大语言模型（LLMs）的快速发展推动了其在自主系统中用于推理驱动的感知、规划与决策的集成研究。然而，由于缺乏大规模、结构化且安全关键的基准，评估和训练此类智能体AI模型仍具挑战。本文提出AgentDrive，一个包含30万个LLM生成驾驶场景的开放基准数据集，专为在不同条件下训练、微调和评估自主智能体而设计。AgentDrive将场景空间沿七个正交维度形式化：场景类型、驾驶员行为、环境、道路布局、目标、难度和交通密度。通过LLM驱动的提示到JSON流水线生成语义丰富、可直接仿真的规范，并依据物理与模式约束进行验证。每个场景均经过仿真推演、代理安全指标计算和基于规则的结果标注。为补充基于仿真的评估，我们引入AgentDrive-MCQ——一个包含10万道选择题的基准，涵盖物理推理、策略推理、混合推理、场景推理和比较推理五个维度。我们对五十个主流LLM在AgentDrive-MCQ上进行了大规模评估。结果显示，虽然专有前沿模型在上下文和策略推理中表现最佳，但先进开源模型在结构化和物理基础推理方面正迅速缩小差距。我们在https://github.com/maferrag/AgentDrive 发布了AgentDrive数据集、AgentDrive-MCQ基准、评估代码及相关材料。</div>
</details>
<details class="detail"><summary>Summary / 总结</summary>
<div class="mono">The integration of large language models (LLMs) into autonomous systems for reasoning tasks is hindered by a lack of large-scale, structured, and safety-critical benchmarks. To address this, the authors introduce AgentDrive, an open benchmark dataset of 300,000 LLM-generated driving scenarios, created via a prompt-to-JSON pipeline that formalizes scenarios across seven orthogonal axes and validates them against constraints. The dataset supports simulation rollouts and safety evaluations, and is complemented by AgentDrive-MCQ, a 100,000-question multiple-choice benchmark for assessing five reasoning dimensions. A large-scale evaluation of fifty LLMs on AgentDrive-MCQ reveals that while proprietary frontier models excel in contextual and policy reasoning, advanced open models are rapidly catching up in structured and physics-grounded reasoning.</div>
<div class="mono" style="margin-top:8px">将大语言模型（LLM）集成到自主系统中进行推理任务，目前因缺乏大规模、结构化且安全关键的基准而受阻。为此，研究者提出了AgentDrive，这是一个包含30万个LLM生成驾驶场景的开放基准数据集，通过一个提示词到JSON的流水线创建，该流水线基于七个正交维度形式化场景并依据约束进行验证。该数据集支持仿真推演和安全评估，并辅以AgentDrive-MCQ，一个包含10万个问题的多项选择题基准，用于评估五个推理维度。对五十个LLM在AgentDrive-MCQ上进行的大规模评估表明，虽然专有的前沿模型在情境和政策推理方面表现出色，但先进的开源模型在结构化和基于物理的推理方面正迅速缩小性能差距。</div>
</details>
</div>
<div class="card">
<div class="title">Efficient semantic uncertainty quantification in language models via diversity-steered sampling</div>
<div class="meta-line">Authors: Ji Won Park, Kyunghyun Cho</div>
<div class="meta-line">Venue: NeurIPS 2025</div>
<div class="meta-line">First: 2025-10-24T10:06:21+00:00 · Latest: 2026-01-23T18:02:21+00:00</div>
<div class="meta-line">Comments: 10 pages (+7 appendix), 7 figures. Accepted at NeurIPS 2025</div>
<div class="links" style="margin-top:8px"><a href="https://arxiv.org/abs/2510.21310v2">Abs</a> · <a href="https://arxiv.org/pdf/2510.21310v2">PDF</a> · <a href="https://huggingface.co/huggingface">Code1</a> · <a href="https://huggingface.co/docs/hub/spaces">Code2</a></div>
<details class="detail"><summary>Abstract</summary>
<div class="mono">Accurately estimating semantic aleatoric and epistemic uncertainties in large language models (LLMs) is particularly challenging in free-form question answering (QA), where obtaining stable estimates often requires many expensive generations. We introduce a diversity-steered sampler that discourages semantically redundant outputs during decoding, covers both autoregressive and masked diffusion paradigms, and yields substantial sample-efficiency gains. The key idea is to inject a continuous semantic-similarity penalty into the model&#x27;s proposal distribution using a natural language inference (NLI) model lightly finetuned on partial prefixes or intermediate diffusion states. We debias downstream uncertainty estimates with importance reweighting and shrink their variance with control variates. Across four QA benchmarks, our method matches or surpasses baselines while covering more semantic clusters with the same number of samples. Being modular and requiring no gradient access to the base LLM, the framework promises to serve as a drop-in enhancement for uncertainty estimation in risk-sensitive model deployments.</div></details>
<details class="detail"><summary>中文标题/摘要</summary>
<div class="mono"><b>标题：</b>通过多样性引导采样实现语言模型的高效语义不确定性量化</div>
<div class="mono" style="margin-top:8px">在自由形式问答任务中，准确估计大语言模型的语义偶然性和认知不确定性尤为困难，通常需要大量昂贵的生成才能获得稳定估计。我们提出一种多样性引导采样器，在解码过程中抑制语义冗余输出，同时适用于自回归和掩码扩散范式，显著提升采样效率。其核心思想是使用经部分前缀或中间扩散状态轻量微调的自然语言推理模型，向模型的提议分布注入连续语义相似度惩罚。我们通过重要性重加权修正下游不确定性估计的偏差，并利用控制变量法缩减其方差。在四个问答基准测试中，本方法在保持相同样本量的情况下，匹配或超越基线模型并覆盖更多语义簇。该框架具有模块化特性且无需访问基础大语言模型的梯度，有望作为风险敏感模型部署中不确定性估计的即插即用增强方案。</div>
</details>
<details class="detail"><summary>Summary / 总结</summary>
<div class="mono">This research addresses the challenge of efficiently estimating semantic uncertainty in large language models for free-form question answering, where traditional methods require many expensive generations. The authors introduce a diversity-steered sampler that injects a continuous semantic-similarity penalty into the proposal distribution using a lightly finetuned natural language inference model, covering both autoregressive and masked diffusion paradigms, and debiasing estimates with importance reweighting and control variates. Experimental results across four QA benchmarks show the method matches or surpasses baseline performance while covering more semantic clusters with the same number of samples, offering a modular drop-in enhancement for risk-sensitive deployments.</div>
<div class="mono" style="margin-top:8px">本研究针对大语言模型在开放式问答中语义不确定性估计效率低下的问题，传统方法需要大量昂贵生成才能获得稳定估计。作者提出了一种多样性引导的采样方法，使用微调后的自然语言推理模型向模型提议分布注入连续语义相似性惩罚，覆盖自回归和掩码扩散两种范式。在四个问答基准测试上的实验结果表明，该方法在相同样本数量下匹配或超越了基线性能，同时覆盖了更多语义簇，为风险敏感部署中的不确定性估计提供了一种模块化、无需梯度的增强方案。</div>
</details>
</div>
<div class="card">
<div class="title">Failures of Contingent Thinking</div>
<div class="meta-line">Authors: Evan Piermont, Peio Zuazo-Garin</div>
<div class="meta-line">First: 2020-07-15T14:21:16+00:00 · Latest: 2026-01-23T17:59:32+00:00</div>
<div class="links" style="margin-top:8px"><a href="https://arxiv.org/abs/2007.07703v4">Abs</a> · <a href="https://arxiv.org/pdf/2007.07703v4">PDF</a> · <a href="https://huggingface.co/huggingface">Code1</a> · <a href="https://huggingface.co/docs/hub/spaces">Code2</a></div>
<details class="detail"><summary>Abstract</summary>
<div class="mono">We present a behavioral definition of an agent&#x27;s perceived implication that uniquely identifies a subjective state-space representing her view of a decision problem, and which may differ from the modeler&#x27;s. By examining belief updating within this model, we formalize the recent empirical consensus that reducing uncertainty improves contingent thinking, and propose a novel form of updating corresponding to the agent &#x27;realizing&#x27; a flaw in her own thinking. Finally, we clarify the sense in which contingent thinking makes state-bystate dominance more cognitively demanding than obvious dominance.</div></details>
<details class="detail"><summary>中文标题/摘要</summary>
<div class="mono"><b>标题：</b>条件性思维的失败</div>
<div class="mono" style="margin-top:8px">本文提出了一种行为定义，用于刻画智能体感知到的隐含关系，该定义能唯一确定代表其决策问题观感的主观状态空间，且可能与建模者的视角不同。通过在此模型内检验信念更新过程，我们形式化了近期实证研究达成的共识——降低不确定性可改善条件性思维，并提出一种对应智能体&#x27;意识到&#x27;自身思维缺陷的新型更新形式。最后，我们阐明了条件性思维为何使逐状态支配性比显性支配性在认知上更具挑战性。</div>
</details>
<details class="detail"><summary>Summary / 总结</summary>
<div class="mono">The research addresses the gap between an agent&#x27;s subjective understanding of a decision problem and the modeler&#x27;s objective representation, motivated by the need to formalize failures in contingent thinking. The method introduces a behavioral definition of perceived implication to uniquely identify a subjective state-space and examines belief updating within this framework, including a novel form of updating where an agent realizes flaws in her own reasoning. Key findings formalize that reducing uncertainty improves contingent thinking, clarify why state-by-state dominance is more cognitively demanding than obvious dominance, and propose a model for how agents correct their subjective models.</div>
<div class="mono" style="margin-top:8px">本研究旨在解决决策者主观理解与建模者客观表征之间的差异，动机在于形式化或然思维的失败。方法上，通过引入感知蕴含的行为定义来唯一识别主观状态空间，并在此框架内检验信念更新，包括一种决策者意识到自身思维缺陷的新型更新形式。主要实验结果形式化了减少不确定性可改善或然思维的观点，并阐明了为何逐状态支配比明显支配更具认知挑战性。</div>
</details>
</div>
<div class="card">
<div class="title">Information Representation Fairness in Long-Document Embeddings: The Peculiar Interaction of Positional and Language Bias</div>
<div class="meta-line">Authors: Elias Schuhmacher, Andrianos Michail, Juri Opitz, Rico Sennrich, Simon Clematide</div>
<div class="meta-line">First: 2026-01-23T17:48:31+00:00 · Latest: 2026-01-23T17:48:31+00:00</div>
<div class="links" style="margin-top:8px"><a href="https://arxiv.org/abs/2601.16934v1">Abs</a> · <a href="https://arxiv.org/pdf/2601.16934v1">PDF</a> · <a href="https://github.com/impresso/fair-sentence-transformers">Code1</a> · <a href="https://huggingface.co/huggingface">Code2</a> · <a href="https://huggingface.co/docs/hub/spaces">Code3</a></div>
<details class="detail"><summary>Abstract</summary>
<div class="mono">To be discoverable in an embedding-based search process, each part of a document should be reflected in its embedding representation. To quantify any potential reflection biases, we introduce a permutation-based evaluation framework. With this, we observe that state-of-the-art embedding models exhibit systematic positional and language biases when documents are longer and consist of multiple segments. Specifically, early segments and segments in higher-resource languages like English are over-represented, while later segments and segments in lower-resource languages are marginalized. In our further analysis, we find that the positional bias stems from front-loaded attention distributions in pooling-token embeddings, where early tokens receive more attention. To mitigate this issue, we introduce an inference-time attention calibration method that redistributes attention more evenly across document positions, increasing discoverabiltiy of later segments. Our evaluation framework and attention calibration is available at https://github.com/impresso/fair-sentence-transformers</div></details>
<details class="detail"><summary>中文标题/摘要</summary>
<div class="mono"><b>标题：</b>长文档嵌入中的信息表征公平性：位置偏差与语言偏差的特殊交互</div>
<div class="mono" style="margin-top:8px">为使文档各部分在基于嵌入的检索过程中可被发现，其嵌入表征应完整反映文档内容。为量化潜在的表征偏差，我们提出一种基于排列的评估框架。通过该框架，我们发现当前先进的嵌入模型在处理由多段落构成的长文档时，会呈现系统性位置偏差与语言偏差：早期段落及英语等高资源语言段落被过度表征，而后期段落及低资源语言段落则被边缘化。进一步分析表明，位置偏差源于池化标记嵌入中前部集中的注意力分布，即早期标记获得更多关注。为缓解此问题，我们提出一种推理时注意力校准方法，通过更均衡地重新分配跨文档位置的注意力，提升后期段落的可发现性。评估框架与注意力校准代码已开源：https://github.com/impresso/fair-sentence-transformers</div>
</details>
<details class="detail"><summary>Summary / 总结</summary>
<div class="mono">This research addresses the problem of information representation fairness in long-document embeddings, motivated by the need for all document segments to be discoverable in embedding-based search. The authors introduce a permutation-based evaluation framework to quantify biases and find that state-of-the-art models systematically over-represent early segments and content in high-resource languages like English, while marginalizing later segments and lower-resource languages. They trace the positional bias to front-loaded attention distributions in pooling mechanisms and propose an inference-time attention calibration method to redistribute attention more evenly, which experimentally increases the discoverability of later segments.</div>
<div class="mono" style="margin-top:8px">本研究针对长文档嵌入中的信息表示公平性问题，旨在确保文档的所有部分在基于嵌入的搜索中都能被发现。作者引入了一种基于排列的评估框架来量化偏差，发现最先进的模型会系统性地过度表示文档前段和高资源语言（如英语）的内容，同时边缘化后段和低资源语言的内容。他们将位置偏差归因于池化令牌嵌入中注意力分布前倾的问题，并提出了一种推理时的注意力校准方法，以更均匀地重新分配注意力，实验证明该方法提高了文档后段的可发现性。</div>
</details>
</div>
<div class="card">
<div class="title">Nishpaksh: TEC Standard-Compliant Framework for Fairness Auditing and Certification of AI Models</div>
<div class="meta-line">Authors: Shashank Prakash, Ranjitha Prasad, Avinash Agarwal</div>
<div class="meta-line">First: 2026-01-23T17:35:05+00:00 · Latest: 2026-01-23T17:35:05+00:00</div>
<div class="meta-line">Comments: Accepted and presented at 2026 18th International Conference on COMmunication Systems and NETworks (COMSNETS)</div>
<div class="links" style="margin-top:8px"><a href="https://arxiv.org/abs/2601.16926v1">Abs</a> · <a href="https://arxiv.org/pdf/2601.16926v1">PDF</a> · <a href="https://huggingface.co/huggingface">Code1</a> · <a href="https://huggingface.co/docs/hub/spaces">Code2</a></div>
<details class="detail"><summary>Abstract</summary>
<div class="mono">The growing reliance on Artificial Intelligence (AI) models in high-stakes decision-making systems, particularly within emerging telecom and 6G applications, underscores the urgent need for transparent and standardized fairness assessment frameworks. While global toolkits such as IBM AI Fairness 360 and Microsoft Fairlearn have advanced bias detection, they often lack alignment with region-specific regulatory requirements and national priorities. To address this gap, we propose Nishpaksh, an indigenous fairness evaluation tool that operationalizes the Telecommunication Engineering Centre (TEC) Standard for the Evaluation and Rating of Artificial Intelligence Systems. Nishpaksh integrates survey-based risk quantification, contextual threshold determination, and quantitative fairness evaluation into a unified, web-based dashboard. The tool employs vectorized computation, reactive state management, and certification-ready reporting to enable reproducible, audit-grade assessments, thereby addressing a critical post-standardization implementation need. Experimental validation on the COMPAS dataset demonstrates Nishpaksh&#x27;s effectiveness in identifying attribute-specific bias and generating standardized fairness scores compliant with the TEC framework. The system bridges the gap between research-oriented fairness methodologies and regulatory AI governance in India, marking a significant step toward responsible and auditable AI deployment within critical infrastructure like telecommunications.</div></details>
<details class="detail"><summary>中文标题/摘要</summary>
<div class="mono"><b>标题：</b>Nishpaksh：符合TEC标准的AI模型公平性审计与认证框架</div>
<div class="mono" style="margin-top:8px">高风险决策系统（尤其是新兴电信与6G应用）对人工智能模型的日益依赖，凸显了对透明化、标准化公平性评估框架的迫切需求。尽管IBM AI Fairness 360和Microsoft Fairlearn等全球工具包已推进偏见检测，但其常与区域特定法规要求和国家优先事项脱节。为填补这一空白，我们提出本土化公平性评估工具Nishpaksh，该工具将电信工程中心人工智能系统评估与评级标准付诸实践。Nishpaksh将基于调查的风险量化、情境化阈值确定和定量公平性评估整合至统一的基于Web的仪表板中。该工具采用向量化计算、响应式状态管理和符合认证要求的报告生成，以实现可复现的审计级评估，从而满足标准化后关键的实施需求。在COMPAS数据集上的实验验证表明，Nishpaksh能有效识别属性特定偏见，并生成符合TEC框架的标准化公平性评分。该系统弥合了研究导向的公平性方法与印度监管性AI治理之间的鸿沟，标志着在电信等关键基础设施领域向负责任、可审计的AI部署迈出重要一步。</div>
</details>
<details class="detail"><summary>Summary / 总结</summary>
<div class="mono">The increasing use of AI models in high-stakes domains such as telecommunications and 6G necessitates transparent and standardized fairness auditing, but existing global toolkits often fail to meet region-specific regulatory standards. To address this, the authors introduce Nishpaksh, a framework designed to operationalize India&#x27;s Telecommunication Engineering Centre (TEC) Standard for AI evaluation by integrating survey-based risk quantification, contextual threshold setting, and quantitative fairness assessment into a unified web dashboard. Experiments on the COMPAS dataset show that Nishpaksh effectively identifies attribute-specific biases and produces standardized fairness scores compliant with the TEC framework, bridging the gap between research methodologies and regulatory AI governance for auditable deployment in critical infrastructure.</div>
<div class="mono" style="margin-top:8px">随着人工智能模型在高风险的电信和6G应用中的使用日益增加，亟需符合地区法规的标准化公平性审计框架，而现有的全球工具包往往缺乏这种针对性。为此，研究者提出了Nishpaksh框架，该框架通过整合基于调查的风险量化、上下文阈值确定和定量公平性评估，实现了印度电信工程中心（TEC）标准，并利用向量化计算和响应式状态管理构建了统一的网络仪表板。在COMPAS数据集上的实验验证表明，该工具能有效识别特定属性的偏见，并生成符合TEC标准的公平性评分，从而弥合了研究方法与监管性AI治理之间的差距，为关键基础设施中可审计的人工智能部署迈出了重要一步。</div>
</details>
</div>
<div class="card">
<div class="title">HEIGHT: Heterogeneous Interaction Graph Transformer for Robot Navigation in Crowded and Constrained Environments</div>
<div class="meta-line">Authors: Shuijing Liu, Haochen Xia, Fatemeh Cheraghi Pouria, Kaiwen Hong, Neeloy Chakraborty, Zichao Hu, Joydeep Biswas, Katherine Driggs-Campbell</div>
<div class="meta-line">First: 2024-11-19T00:56:35+00:00 · Latest: 2026-01-23T17:24:19+00:00</div>
<div class="meta-line">Comments: Accepted to IEEE Transactions of Automation Science and Engineering (T-ASE)</div>
<div class="links" style="margin-top:8px"><a href="https://arxiv.org/abs/2411.12150v4">Abs</a> · <a href="https://arxiv.org/pdf/2411.12150v4">PDF</a> · <a href="https://huggingface.co/huggingface">Code1</a> · <a href="https://huggingface.co/docs/hub/spaces">Code2</a> · <a href="https://sites.google.com/view/crowdnav-height/home">Project1</a></div>
<details class="detail"><summary>Abstract</summary>
<div class="mono">We study the problem of robot navigation in dense and interactive crowds with static constraints such as corridors and furniture. Previous methods fail to consider all types of spatial and temporal interactions among agents and obstacles, leading to unsafe and inefficient robot paths. In this article, we leverage a graph-based representation of crowded and constrained scenarios and propose a structured framework to learn robot navigation policies with deep reinforcement learning. We first split the representations of different inputs and propose a heterogeneous spatio-temporal graph to model distinct interactions among humans, robots, and obstacles. Based on the heterogeneous spatio-temporal graph, we propose HEIGHT, a novel navigation policy network architecture with different components to capture heterogeneous interactions through space and time. HEIGHT utilizes attention mechanisms to prioritize important interactions and a recurrent network to track changes in the dynamic scene over time, encouraging the robot to avoid collisions adaptively. Through extensive simulation and real-world experiments, we demonstrate that HEIGHT outperforms state-of-the-art baselines in terms of success, navigation time, and generalization to domain shifts in challenging navigation scenarios. More information is available at https://sites.google.com/view/crowdnav-height/home.</div></details>
<details class="detail"><summary>中文标题/摘要</summary>
<div class="mono"><b>标题：</b>HEIGHT：面向拥挤受限环境中机器人导航的异质交互图变换器</div>
<div class="mono" style="margin-top:8px">本文研究机器人在存在走廊、家具等静态约束的密集交互人群中的导航问题。现有方法未能全面考虑智能体与障碍物间的各类时空交互，导致机器人路径不安全且低效。为此，我们采用基于图的拥挤受限场景表示，提出一种结构化框架，通过深度强化学习训练机器人导航策略。首先对不同输入进行表征分离，构建异质时空图以建模人、机器人及障碍物间的差异化交互。基于该图，我们提出HEIGHT——一种新型导航策略网络架构，其通过不同组件捕捉时空异质交互。HEIGHT利用注意力机制对关键交互进行优先级排序，并采用循环网络追踪动态场景的时序变化，使机器人能自适应避障。通过大量仿真与真实实验验证，HEIGHT在挑战性导航场景中，于成功率、导航时间及领域偏移泛化能力方面均优于现有先进基线。更多信息详见：https://sites.google.com/view/crowdnav-height/home。</div>
</details>
<details class="detail"><summary>Summary / 总结</summary>
<div class="mono">This research addresses robot navigation in dense, interactive crowds with static constraints, where prior methods inadequately model spatial and temporal interactions, resulting in unsafe and inefficient paths. The authors propose HEIGHT, a framework that uses a heterogeneous spatio-temporal graph to separately represent interactions among humans, robots, and obstacles, and employs deep reinforcement learning with attention mechanisms and a recurrent network to capture these interactions over time, prioritizing critical ones for adaptive collision avoidance. Experimental results from simulations and real-world tests show that HEIGHT surpasses state-of-the-art baselines in success rate, navigation time, and generalization to domain shifts in challenging scenarios.</div>
<div class="mono" style="margin-top:8px">本研究针对机器人如何在密集、交互式人群及静态约束环境中导航的问题，先前方法未能充分考虑各类空间与时间交互，导致路径不安全且低效。作者提出HEIGHT框架，利用异构图分别建模人、机器人与障碍物之间的交互，并通过深度强化学习结合注意力机制和循环网络来优先处理关键交互并适应动态场景变化。仿真和真实环境实验表明，HEIGHT在成功率、导航时间和对挑战性场景的泛化能力上均优于现有先进方法。</div>
</details>
</div>
<div class="card">
<div class="title">LoL: Longer than Longer, Scaling Video Generation to Hour</div>
<div class="meta-line">Authors: Justin Cui, Jie Wu, Ming Li, Tao Yang, Xiaojie Li, Rui Wang, Andrew Bai, Yuanhao Ban, Cho-Jui Hsieh</div>
<div class="meta-line">First: 2026-01-23T17:21:35+00:00 · Latest: 2026-01-23T17:21:35+00:00</div>
<div class="meta-line">Comments: preprint</div>
<div class="links" style="margin-top:8px"><a href="https://arxiv.org/abs/2601.16914v1">Abs</a> · <a href="https://arxiv.org/pdf/2601.16914v1">PDF</a> · <a href="https://huggingface.co/huggingface">Code1</a> · <a href="https://huggingface.co/docs/hub/spaces">Code2</a></div>
<details class="detail"><summary>Abstract</summary>
<div class="mono">Recent research in long-form video generation has shifted from bidirectional to autoregressive models, yet these methods commonly suffer from error accumulation and a loss of long-term coherence. While attention sink frames have been introduced to mitigate this performance decay, they often induce a critical failure mode we term sink-collapse: the generated content repeatedly reverts to the sink frame, resulting in abrupt scene resets and cyclic motion patterns. Our analysis reveals that sink-collapse originates from an inherent conflict between the periodic structure of Rotary Position Embedding (RoPE) and the multi-head attention mechanisms prevalent in current generative models. To address it, we propose a lightweight, training-free approach that effectively suppresses this behavior by introducing multi-head RoPE jitter that breaks inter-head attention homogenization and mitigates long-horizon collapse. Extensive experiments show that our method successfully alleviates sink-collapse while preserving generation quality. To the best of our knowledge, this work achieves the first demonstration of real-time, streaming, and infinite-length video generation with little quality decay. As an illustration of this robustness, we generate continuous videos up to 12 hours in length, which, to our knowledge, is among the longest publicly demonstrated results in streaming video generation.</div></details>
<details class="detail"><summary>中文标题/摘要</summary>
<div class="mono"><b>标题：</b>LoL：更长更长，将视频生成扩展至小时级</div>
<div class="mono" style="margin-top:8px">近期长视频生成研究已从双向模型转向自回归模型，但这些方法普遍存在误差累积和长期连贯性丧失的问题。尽管已引入注意力汇帧以缓解性能衰减，但其常引发一种关键失效模式，我们称之为汇塌缩：生成内容反复回退至汇帧，导致场景突然重置和循环运动模式。我们的分析表明，汇塌缩源于旋转位置编码的周期性结构与当前生成模型中普遍采用的多头注意力机制之间的内在冲突。为解决此问题，我们提出一种轻量级、无需训练的方法，通过引入多头RoPE抖动来打破头间注意力同质化并缓解长程塌缩，从而有效抑制该行为。大量实验表明，我们的方法在保持生成质量的同时成功缓解了汇塌缩。据我们所知，这项工作首次实现了质量几乎无衰减的实时、流式、无限长度视频生成。为证明其鲁棒性，我们生成了长达12小时的连续视频，这据我们所知是流式视频生成领域公开演示的最长结果之一。</div>
</details>
<details class="detail"><summary>Summary / 总结</summary>
<div class="mono">Recent autoregressive models for long-form video generation suffer from error accumulation and loss of long-term coherence, with attention sink frames often causing a failure mode termed sink-collapse, where generated content repeatedly reverts to the sink frame. The authors identify that sink-collapse stems from a conflict between the periodic structure of Rotary Position Embedding (RoPE) and multi-head attention mechanisms. They propose a lightweight, training-free method that introduces multi-head RoPE jitter to break inter-head attention homogenization and mitigate collapse. Experiments demonstrate the method effectively alleviates sink-collapse while maintaining quality, enabling real-time, streaming, infinite-length video generation with minimal decay, including continuous videos up to 12 hours long.</div>
<div class="mono" style="margin-top:8px">本研究针对自回归长视频生成中的“汇点崩溃”问题，即生成内容反复回退到注意力汇点帧，导致场景突然重置和循环运动模式。作者发现其根本原因是旋转位置编码的周期结构与多头注意力机制之间的冲突。他们提出了一种轻量级、无需训练的方法，通过引入多头旋转位置编码抖动来打破注意力头间的同质化，从而缓解长时程崩溃。实验结果表明，该方法有效缓解了汇点崩溃问题并保持了生成质量，能够生成长达12小时的连续视频且质量衰减极小，这代表了当前公开演示中流式视频生成的最长结果之一。</div>
</details>
</div>
<div class="card">
<div class="title">Preventing the Collapse of Peer Review Requires Verification-First AI</div>
<div class="meta-line">Authors: Lei You, Lele Cao, Iryna Gurevych</div>
<div class="meta-line">First: 2026-01-23T17:17:32+00:00 · Latest: 2026-01-23T17:17:32+00:00</div>
<div class="links" style="margin-top:8px"><a href="https://arxiv.org/abs/2601.16909v1">Abs</a> · <a href="https://arxiv.org/pdf/2601.16909v1">PDF</a> · <a href="https://huggingface.co/huggingface">Code1</a> · <a href="https://huggingface.co/docs/hub/spaces">Code2</a></div>
<details class="detail"><summary>Abstract</summary>
<div class="mono">This paper argues that AI-assisted peer review should be verification-first rather than review-mimicking. We propose truth-coupling, i.e. how tightly venue scores track latent scientific truth, as the right objective for review tools. We formalize two forces that drive a phase transition toward proxy-sovereign evaluation: verification pressure, when claims outpace verification capacity, and signal shrinkage, when real improvements become hard to separate from noise. In a minimal model that mixes occasional high-fidelity checks with frequent proxy judgment, we derive an explicit coupling law and an incentive-collapse condition under which rational effort shifts from truth-seeking to proxy optimization, even when current decisions still appear reliable. These results motivate actions for tool builders and program chairs: deploy AI as an adversarial auditor that generates auditable verification artifacts and expands effective verification bandwidth, rather than as a score predictor that amplifies claim inflation.</div></details>
<details class="detail"><summary>中文标题/摘要</summary>
<div class="mono"><b>标题：</b>防止同行评审崩溃需要验证优先的人工智能</div>
<div class="mono" style="margin-top:8px">本文主张AI辅助的同行评审应采用验证优先而非模仿评审的模式。我们提出真理耦合——即学术平台评分与潜在科学真理的紧密度——作为评审工具的正确目标。通过形式化分析驱动评审向代理主权评估相变的两种力量：验证压力（当学术主张超出验证能力时）与信号收缩（当真实改进难以从噪声中分离时）。在一个混合高频代理判断与偶发高保真核查的最小模型中，我们推导出显式耦合定律与激励崩溃条件：即使当前决策仍显可靠，理性努力也会从追求真理转向优化代理指标。这些结论为工具开发者和程序委员会主席提出行动方向：应将AI部署为对抗性审计器——生成可审计的验证证据并扩展有效验证带宽，而非作为放大主张膨胀的评分预测器。</div>
</details>
<details class="detail"><summary>Summary / 总结</summary>
<div class="mono">This paper addresses the risk that AI-assisted peer review, if designed to mimic human scoring, could accelerate a collapse of scientific evaluation into proxy optimization rather than truth-seeking. The authors propose a verification-first AI approach, formalizing the problem through a model of truth-coupling—the alignment between venue scores and latent scientific truth—and identifying conditions like verification pressure and signal shrinkage that drive a phase transition. Their analysis yields a coupling law and an incentive-collapse condition, showing that rational effort can shift from truth-seeking to proxy optimization even when decisions appear reliable. The key experimental finding from the model motivates tool builders and program chairs to deploy AI as an adversarial auditor that generates verification artifacts to expand verification bandwidth, rather than as a score predictor that amplifies claim inflation.</div>
<div class="mono" style="margin-top:8px">本文探讨了人工智能辅助同行评议可能无意中加速科学评估体系崩溃的风险，即评审重点从验证真相转向模仿表面评审模式。研究提出了真相耦合作为正确目标，并将同行评议动态建模为一个受验证压力和信号收缩影响的系统，这两股力量可引发相变，使理性行为者转而优化代理指标而非科学真相。模型揭示了一个特定的激励崩溃条件，据此建议AI工具应充当对抗性审计员，生成可审计的验证工件并扩大验证能力，而非充当评审分数的预测器。</div>
</details>
</div>
<div class="card">
<div class="title">GRIP: Algorithm-Agnostic Machine Unlearning for Mixture-of-Experts via Geometric Router Constraints</div>
<div class="meta-line">Authors: Andy Zhu, Rongzhe Wei, Yupu Gu, Pan Li</div>
<div class="meta-line">First: 2026-01-23T17:13:54+00:00 · Latest: 2026-01-23T17:13:54+00:00</div>
<div class="links" style="margin-top:8px"><a href="https://arxiv.org/abs/2601.16905v1">Abs</a> · <a href="https://arxiv.org/pdf/2601.16905v1">PDF</a> · <a href="https://huggingface.co/huggingface">Code1</a> · <a href="https://huggingface.co/docs/hub/spaces">Code2</a></div>
<details class="detail"><summary>Abstract</summary>
<div class="mono">Machine unlearning (MU) for large language models has become critical for AI safety, yet existing methods fail to generalize to Mixture-of-Experts (MoE) architectures. We identify that traditional unlearning methods exploit MoE&#x27;s architectural vulnerability: they manipulate routers to redirect queries away from knowledgeable experts rather than erasing knowledge, causing a loss of model utility and superficial forgetting. We propose Geometric Routing Invariance Preservation (GRIP), an algorithm-agnostic framework for unlearning for MoE. Our core contribution is a geometric constraint, implemented by projecting router gradient updates into an expert-specific null-space. Crucially, this decouples routing stability from parameter rigidity: while discrete expert selections remain stable for retained knowledge, the continuous router parameters remain plastic within the null space, allowing the model to undergo necessary internal reconfiguration to satisfy unlearning objectives. This forces the unlearning optimization to erase knowledge directly from expert parameters rather than exploiting the superficial router manipulation shortcut. GRIP functions as an adapter, constraining router parameter updates without modifying the underlying unlearning algorithm. Extensive experiments on large-scale MoE models demonstrate that our adapter eliminates expert selection shift (achieving over 95% routing stability) across all tested unlearning methods while preserving their utility. By preventing existing algorithms from exploiting MoE model&#x27;s router vulnerability, GRIP adapts existing unlearning research from dense architectures to MoEs.</div></details>
<details class="detail"><summary>中文标题/摘要</summary>
<div class="mono"><b>标题：</b>GRIP：基于几何路由约束的专家混合模型算法无关机器遗忘框架</div>
<div class="mono" style="margin-top:8px">大语言模型的机器遗忘对AI安全至关重要，但现有方法无法推广至专家混合架构。我们发现传统遗忘方法利用了MoE的结构脆弱性：通过操纵路由将查询从知识专家处转移而非真正擦除知识，导致模型效用损失和表面遗忘。本文提出几何路由不变性保持框架——一种算法无关的MoE遗忘方案。核心贡献是几何约束机制，通过将路由梯度更新投影至专家特定零空间实现。关键创新在于解耦路由稳定性与参数刚性：离散专家选择对保留知识保持稳定，而连续路由参数在零空间内保持可塑性，使模型能通过内部重构实现遗忘目标。这迫使遗忘优化直接擦除专家参数知识，而非利用路由操纵捷径。GRIP作为适配器约束路由参数更新，无需修改底层遗忘算法。大规模MoE实验表明，该适配器在所有测试方法中消除专家选择偏移（路由稳定性超95%）并保持模型效用。通过阻止现有算法利用MoE路由脆弱性，GRIP将稠密架构的遗忘研究成功适配至MoE模型。</div>
</details>
<details class="detail"><summary>Summary / 总结</summary>
<div class="mono">The research addresses the challenge of machine unlearning for Mixture-of-Experts (MoE) models, where existing methods fail by superficially manipulating routers to redirect queries instead of erasing knowledge, which harms model utility. The proposed method, GRIP, is an algorithm-agnostic framework that imposes a geometric constraint by projecting router gradient updates into an expert-specific null-space, decoupling routing stability from parameter plasticity to force knowledge erasure directly from expert parameters. Experimental results on large-scale MoE models show that GRIP achieves over 95% routing stability across various unlearning methods while preserving model utility, effectively adapting dense architecture unlearning techniques to MoEs.</div>
<div class="mono" style="margin-top:8px">本研究针对混合专家模型中机器遗忘的挑战，现有方法会通过表面操纵路由器决策将查询从知识渊博的专家处重定向，而非真正擦除目标知识，从而损害模型效用。提出的GRIP框架引入了一种几何约束，将路由器梯度更新投影到专家特定的零空间中，解耦了路由稳定性与参数刚性，迫使遗忘优化直接修改专家参数。在大型混合专家模型上的实验表明，GRIP作为一种算法无关的适配器，能在各种遗忘方法中消除专家选择偏移，实现超过95%的路由稳定性，同时保持模型效用。</div>
</details>
</div>
<div class="card">
<div class="title">Evaluating Large Vision-language Models for Surgical Tool Detection</div>
<div class="meta-line">Authors: Nakul Poudel, Richard Simon, Cristian A. Linte</div>
<div class="meta-line">First: 2026-01-23T17:00:46+00:00 · Latest: 2026-01-23T17:00:46+00:00</div>
<div class="links" style="margin-top:8px"><a href="https://arxiv.org/abs/2601.16895v1">Abs</a> · <a href="https://arxiv.org/pdf/2601.16895v1">PDF</a> · <a href="https://huggingface.co/huggingface">Code1</a> · <a href="https://huggingface.co/docs/hub/spaces">Code2</a></div>
<details class="detail"><summary>Abstract</summary>
<div class="mono">Surgery is a highly complex process, and artificial intelligence has emerged as a transformative force in supporting surgical guidance and decision-making. However, the unimodal nature of most current AI systems limits their ability to achieve a holistic understanding of surgical workflows. This highlights the need for general-purpose surgical AI systems capable of comprehensively modeling the interrelated components of surgical scenes. Recent advances in large vision-language models that integrate multimodal data processing offer strong potential for modeling surgical tasks and providing human-like scene reasoning and understanding. Despite their promise, systematic investigations of VLMs in surgical applications remain limited. In this study, we evaluate the effectiveness of large VLMs for the fundamental surgical vision task of detecting surgical tools. Specifically, we investigate three state-of-the-art VLMs, Qwen2.5, LLaVA1.5, and InternVL3.5, on the GraSP robotic surgery dataset under both zero-shot and parameter-efficient LoRA fine-tuning settings. Our results demonstrate that Qwen2.5 consistently achieves superior detection performance in both configurations among the evaluated VLMs. Furthermore, compared with the open-set detection baseline Grounding DINO, Qwen2.5 exhibits stronger zero-shot generalization and comparable fine-tuned performance. Notably, Qwen2.5 shows superior instrument recognition, while Grounding DINO demonstrates stronger localization.</div></details>
<details class="detail"><summary>中文标题/摘要</summary>
<div class="mono"><b>标题：</b>评估大型视觉语言模型在外科手术工具检测中的应用</div>
<div class="mono" style="margin-top:8px">外科手术是高度复杂的过程，人工智能已成为支持手术引导与决策的变革性力量。然而，当前多数AI系统的单模态特性限制了其对手术流程的整体理解能力，这凸显了对能够全面建模手术场景中相互关联组件的通用手术AI系统的需求。近期整合多模态数据处理的大型视觉语言模型进展，为建模手术任务及提供类人场景推理与理解展现出巨大潜力。尽管前景广阔，针对VLMs在手术应用中的系统性研究仍显不足。本研究评估了大型VLMs在基础手术视觉任务——手术工具检测中的有效性。具体而言，我们在GraSP机器人手术数据集上，以零样本和参数高效LoRA微调两种设置，测试了Qwen2.5、LLaVA1.5和InternVL3.5三种前沿VLM。结果表明，在评估的VLMs中，Qwen2.5在两种配置下均持续取得最优检测性能。此外，与开放集检测基线Grounding DINO相比，Qwen2.5展现出更强的零样本泛化能力和相当的微调性能。值得注意的是，Qwen2.5在器械识别方面表现更优，而Grounding DINO则在定位能力上更为突出。</div>
</details>
<details class="detail"><summary>Summary / 总结</summary>
<div class="mono">Motivated by the need for general-purpose surgical AI systems that can holistically model surgical workflows beyond unimodal approaches, this study evaluates large vision-language models (VLMs) for surgical tool detection. The method involves testing three state-of-the-art VLMs—Qwen2.5, LLaVA1.5, and InternVL3.5—on the GraSP robotic surgery dataset under zero-shot and LoRA fine-tuning settings. Key experimental findings show that Qwen2.5 consistently achieves superior detection performance in both configurations, exhibits stronger zero-shot generalization than the open-set baseline Grounding DINO, and demonstrates comparable fine-tuned performance, with particular strengths in instrument recognition, while Grounding DINO excels in localization.</div>
<div class="mono" style="margin-top:8px">本研究旨在开发能够全面理解多模态手术工作流程的通用手术AI系统，为此系统评估了大型视觉语言模型在外科手术工具检测任务中的有效性。方法上，在GraSP机器人手术数据集上，以零样本和参数高效的LoRA微调两种设置，对Qwen2.5、LLaVA1.5和InternVL3.5三种先进模型进行了测试。主要实验结果表明，Qwen2.5在两种配置下均表现出最优的检测性能，其零样本泛化能力优于开放集检测基线Grounding DINO，且在器械识别方面更优，而Grounding DINO则在定位能力上更强。</div>
</details>
</div>
<div class="card">
<div class="title">LLM-Based Adversarial Persuasion Attacks on Fact-Checking Systems</div>
<div class="meta-line">Authors: João A. Leite, Olesya Razuvayevskaya, Kalina Bontcheva, Carolina Scarton</div>
<div class="meta-line">First: 2026-01-23T16:57:16+00:00 · Latest: 2026-01-23T16:57:16+00:00</div>
<div class="links" style="margin-top:8px"><a href="https://arxiv.org/abs/2601.16890v1">Abs</a> · <a href="https://arxiv.org/pdf/2601.16890v1">PDF</a> · <a href="https://huggingface.co/huggingface">Code1</a> · <a href="https://huggingface.co/docs/hub/spaces">Code2</a></div>
<details class="detail"><summary>Abstract</summary>
<div class="mono">Automated fact-checking (AFC) systems are susceptible to adversarial attacks, enabling false claims to evade detection. Existing adversarial frameworks typically rely on injecting noise or altering semantics, yet no existing framework exploits the adversarial potential of persuasion techniques, which are widely used in disinformation campaigns to manipulate audiences. In this paper, we introduce a novel class of persuasive adversarial attacks on AFCs by employing a generative LLM to rephrase claims using persuasion techniques. Considering 15 techniques grouped into 6 categories, we study the effects of persuasion on both claim verification and evidence retrieval using a decoupled evaluation strategy. Experiments on the FEVER and FEVEROUS benchmarks show that persuasion attacks can substantially degrade both verification performance and evidence retrieval. Our analysis identifies persuasion techniques as a potent class of adversarial attacks, highlighting the need for more robust AFC systems.</div></details>
<details class="detail"><summary>中文标题/摘要</summary>
<div class="mono"><b>标题：</b>基于大语言模型的事实核查系统对抗性说服攻击</div>
<div class="mono" style="margin-top:8px">自动化事实核查系统易受对抗攻击，使虚假声明得以规避检测。现有对抗框架多依赖注入噪声或改变语义，尚未有框架利用说服技术的对抗潜力——该技术广泛用于虚假信息活动中操纵受众。本文通过使用生成式大语言模型，采用说服技术重述声明，提出一类针对事实核查系统的新型说服性对抗攻击。基于6大类15种说服技术，我们采用解耦评估策略研究说服对声明验证和证据检索的影响。在FEVER和FEVEROUS基准测试上的实验表明，说服攻击能显著降低验证性能和证据检索效果。分析证实说服技术是一类强效对抗攻击手段，凸显了构建更鲁棒的事实核查系统的必要性。</div>
</details>
<details class="detail"><summary>Summary / 总结</summary>
<div class="mono">Automated fact-checking systems are vulnerable to adversarial attacks that allow false claims to bypass detection, but existing methods often rely on noise injection or semantic alterations without exploring persuasion techniques commonly used in disinformation. To address this, the authors propose a novel adversarial attack framework that employs a generative large language model to rephrase claims using 15 persuasion techniques across six categories, evaluating their impact on both claim verification and evidence retrieval through a decoupled strategy. Experiments on the FEVER and FEVEROUS benchmarks demonstrate that these persuasion attacks significantly degrade verification performance and evidence retrieval, revealing persuasion as a potent class of adversarial threats and underscoring the need for more robust fact-checking systems.</div>
<div class="mono" style="margin-top:8px">自动事实核查系统易受对抗性攻击，导致虚假声明逃避检测，但现有方法多依赖噪声注入或语义修改，未利用虚假信息活动中常见的说服技术的对抗潜力。为此，研究者提出一种新颖的说服性对抗攻击框架，利用生成式大语言模型，通过六类共15种说服技术重写声明，并采用解耦评估策略分析其对声明验证和证据检索的影响。在FEVER和FEVEROUS基准上的实验表明，说服攻击能显著降低验证性能和证据检索效果，揭示说服技术是一类有效的对抗攻击手段，强调了构建更鲁棒的事实核查系统的必要性。</div>
</details>
</div>
<div class="card">
<div class="title">Equivariant Flow Matching for Symmetry-Breaking Bifurcation Problems</div>
<div class="meta-line">Authors: Fleur Hendriks, Ondřej Rokoš, Martin Doškář, Marc G. D. Geers, Vlado Menkovski</div>
<div class="meta-line">Venue: NeurIPS 2025</div>
<div class="meta-line">First: 2025-09-03T14:18:05+00:00 · Latest: 2026-01-23T16:51:17+00:00</div>
<div class="meta-line">Comments: 9 pages, 7 figures including appendices. Accepted to Machine Learning and the Physical Sciences Workshop, NeurIPS 2025 (https://ml4physicalsciences.github.io/2025/). Repository with corresponding code: https://github.com/FHendriks11/bifurcationML/. Video explanation: https://www.youtube.com/watch?v=wsL3h17KtjY</div>
<div class="links" style="margin-top:8px"><a href="https://arxiv.org/abs/2509.03340v3">Abs</a> · <a href="https://arxiv.org/pdf/2509.03340v3">PDF</a> · <a href="https://github.com/FHendriks11/bifurcationML/">Code1</a> · <a href="https://huggingface.co/huggingface">Code2</a> · <a href="https://huggingface.co/docs/hub/spaces">Code3</a> · <a href="https://ml4physicalsciences.github.io/2025/">Project1</a></div>
<details class="detail"><summary>Abstract</summary>
<div class="mono">Bifurcation phenomena in nonlinear dynamical systems often lead to multiple coexisting stable solutions, particularly in the presence of symmetry breaking. Deterministic machine learning models are unable to capture this multiplicity, averaging over solutions and failing to represent lower-symmetry outcomes. In this work, we formalize the use of generative AI, specifically flow matching, as a principled way to model the full probability distribution over bifurcation outcomes. Our approach builds on existing techniques by combining flow matching with equivariant architectures and an optimal-transport-based coupling mechanism. We generalize equivariant flow matching to a symmetric coupling strategy that aligns predicted and target outputs under group actions, allowing accurate learning in equivariant settings. We validate our approach on a range of systems, from simple conceptual systems to physical problems such as buckling beams and the Allen--Cahn equation. The results demonstrate that the approach accurately captures multimodal distributions and symmetry-breaking bifurcations. Moreover, our results demonstrate that flow matching significantly outperforms non-probabilistic and variational methods. This offers a principled and scalable solution for modeling multistability in high-dimensional systems.</div></details>
<details class="detail"><summary>中文标题/摘要</summary>
<div class="mono"><b>标题：</b>面向对称破缺分岔问题的等变流匹配方法</div>
<div class="mono" style="margin-top:8px">非线性动力系统中的分岔现象常导致多个稳定解共存，尤其在对称破缺情形下。确定性机器学习模型无法捕捉这种多重性，其解的平均化过程会忽略低对称性结果。本研究将生成式人工智能（特别是流匹配）形式化为建模分岔结果全概率分布的原理性方法。该方法基于现有技术，将流匹配与等变架构及最优传输耦合机制相结合。我们将等变流匹配推广至对称耦合策略，使预测输出与目标输出在群作用下对齐，从而在等变设定中实现精确学习。通过从简单概念系统到物理问题（如屈曲梁和Allen-Cahn方程）的系列实验验证，结果表明该方法能准确捕捉多峰分布与对称破缺分岔，且流匹配显著优于非概率方法与变分方法。这为高维系统多稳态建模提供了原理性可扩展解决方案。</div>
</details>
<details class="detail"><summary>Summary / 总结</summary>
<div class="mono">This research addresses the limitation of deterministic machine learning models in capturing multiple coexisting stable solutions in nonlinear dynamical systems with symmetry-breaking bifurcations, as such models average over solutions. The method formalizes the use of generative AI through flow matching, specifically by combining it with equivariant architectures and an optimal-transport-based symmetric coupling strategy to model the full probability distribution of outcomes. Experimental validation on systems including conceptual models, buckling beams, and the Allen-Cahn equation demonstrates that the approach accurately captures multimodal distributions and symmetry-breaking bifurcations, significantly outperforming non-probabilistic and variational methods.</div>
<div class="mono" style="margin-top:8px">本研究针对确定性机器学习模型无法捕捉非线性动力系统中对称性破缺分岔产生的多个共存稳定解的问题，这类模型会对解进行平均而无法表示低对称性结果。该方法通过流匹配形式化地使用生成式AI来建模分岔结果的完整概率分布，将其与等变架构和基于最优传输的耦合机制相结合；它推广了等变流匹配，采用一种对称耦合策略，在群作用下对齐预测输出与目标输出。在从简单概念系统到物理问题（如屈曲梁和Allen-Cahn方程）的一系列系统上的实验验证表明，该方法能准确捕捉多峰分布和对称性破缺分岔，显著优于非概率方法和变分方法。</div>
</details>
</div>
<div class="card">
<div class="title">MAGE-KT: Multi-Agent Graph-Enhanced Knowledge Tracing with Subgraph Retrieval and Asymmetric Fusion</div>
<div class="meta-line">Authors: Chi Yu, Hongyu Yuan, Zhiyi Duan</div>
<div class="meta-line">First: 2026-01-23T16:51:08+00:00 · Latest: 2026-01-23T16:51:08+00:00</div>
<div class="links" style="margin-top:8px"><a href="https://arxiv.org/abs/2601.16886v1">Abs</a> · <a href="https://arxiv.org/pdf/2601.16886v1">PDF</a> · <a href="https://huggingface.co/huggingface">Code1</a> · <a href="https://huggingface.co/docs/hub/spaces">Code2</a></div>
<details class="detail"><summary>Abstract</summary>
<div class="mono">Knowledge Tracing (KT) aims to model a student&#x27;s learning trajectory and predict performance on the next question. A key challenge is how to better represent the relationships among students, questions, and knowledge concepts (KCs). Recently, graph-based KT paradigms have shown promise for this problem. However, existing methods have not sufficiently explored inter-concept relations, often inferred solely from interaction sequences. In addition, the scale and heterogeneity of KT graphs make full-graph encoding both computationally both costly and noise-prone, causing attention to bleed into student-irrelevant regions and degrading the fidelity of inter-KC relations. To address these issues, we propose a novel framework: Multi-Agent Graph-Enhanced Knowledge Tracing (MAGE-KT). It constructs a multi-view heterogeneous graph by combining a multi-agent KC relation extractor and a student-question interaction graph, capturing complementary semantic and behavioral signals. Conditioned on the target student&#x27;s history, it retrieves compact, high-value subgraphs and integrates them using an Asymmetric Cross-attention Fusion Module to enhance prediction while avoiding attention diffusion and irrelevant computation. Experiments on three widely used KT datasets show substantial improvements in KC-relation accuracy and clear gains in next-question prediction over existing methods.</div></details>
<details class="detail"><summary>中文标题/摘要</summary>
<div class="mono"><b>标题：</b>MAGE-KT：基于子图检索与非对称融合的多智能体图增强知识追踪</div>
<div class="mono" style="margin-top:8px">知识追踪（KT）旨在建模学生的学习轨迹并预测其下一题表现。核心挑战在于如何更好地表征学生、试题与知识点（KC）间的关联关系。近年来，基于图的KT方法在该问题上展现出潜力，但现有研究对知识点间关系的挖掘仍不充分——通常仅从交互序列推断，且KT图的规模与异质性使全图编码计算成本高、易受噪声干扰，导致注意力扩散至无关区域并降低知识点关系保真度。为此，我们提出多智能体图增强知识追踪框架（MAGE-KT）：通过多智能体知识点关系提取器与学生-试题交互图构建多视图异质图，捕获互补的语义与行为信号；基于目标学生历史检索紧凑高价值子图，并采用非对称交叉注意力融合模块进行集成，在避免注意力扩散与无关计算的同时提升预测性能。在三个常用KT数据集上的实验表明，本方法在知识点关系准确率与下一题预测性能上均显著优于现有方法。</div>
</details>
<details class="detail"><summary>Summary / 总结</summary>
<div class="mono">The research addresses limitations in existing graph-based knowledge tracing methods, which often inadequately capture inter-concept relations and suffer from computational inefficiency and noise due to full-graph encoding. The proposed MAGE-KT framework constructs a multi-view heterogeneous graph using a multi-agent knowledge concept relation extractor and a student-question interaction graph, then retrieves compact subgraphs based on student history and integrates them via an asymmetric cross-attention fusion module to enhance prediction. Experiments on three datasets demonstrate significant improvements in knowledge concept relation accuracy and next-question prediction performance over prior methods.</div>
<div class="mono" style="margin-top:8px">本研究针对现有基于图的知识追踪方法在捕捉概念间关系方面的不足，以及全图编码带来的计算效率低下和噪声问题。提出的MAGE-KT框架通过多智能体知识概念关系提取器和学生-问题交互图构建多视图异质图，然后根据目标学生的学习历史检索紧凑的高价值子图，并通过非对称交叉注意力融合模块进行集成。在三个常用数据集上的实验表明，MAGE-KT显著提升了知识概念关系的准确性，并在下一问题预测任务上明显优于现有方法。</div>
</details>
</div>
<div class="card">
<div class="title">Explaining Group Recommendations via Counterfactuals</div>
<div class="meta-line">Authors: Maria Stratigi, Nikos Bikakis</div>
<div class="meta-line">First: 2026-01-23T16:42:05+00:00 · Latest: 2026-01-23T16:42:05+00:00</div>
<div class="links" style="margin-top:8px"><a href="https://arxiv.org/abs/2601.16882v1">Abs</a> · <a href="https://arxiv.org/pdf/2601.16882v1">PDF</a> · <a href="https://huggingface.co/huggingface">Code1</a> · <a href="https://huggingface.co/docs/hub/spaces">Code2</a></div>
<details class="detail"><summary>Abstract</summary>
<div class="mono">Group recommender systems help users make collective choices but often lack transparency, leaving group members uncertain about why items are suggested. Existing explanation methods focus on individuals, offering limited support for groups where multiple preferences interact. In this paper, we propose a framework for group counterfactual explanations, which reveal how removing specific past interactions would change a group recommendation. We formalize this concept, introduce utility and fairness measures tailored to groups, and design heuristic algorithms, such as Pareto-based filtering and grow-and-prune strategies, for efficient explanation discovery. Experiments on MovieLens and Amazon datasets show clear trade-offs: low-cost methods produce larger, less fair explanations, while other approaches yield concise and balanced results at higher cost. Furthermore, the Pareto-filtering heuristic demonstrates significant efficiency improvements in sparse settings.</div></details>
<details class="detail"><summary>中文标题/摘要</summary>
<div class="mono"><b>标题：</b>通过反事实解释群体推荐</div>
<div class="mono" style="margin-top:8px">群体推荐系统帮助用户进行集体决策，但往往缺乏透明度，使成员难以理解推荐依据。现有解释方法主要针对个体，难以应对多偏好交互的群体场景。本文提出一种群体反事实解释框架，通过移除特定历史交互来揭示推荐结果的改变机制。我们形式化该概念，设计适用于群体的效用与公平性度量指标，并开发启发式算法（如基于帕累托的筛选和生长剪枝策略）以高效生成解释。在MovieLens和亚马逊数据集上的实验表明：低成本方法产生更广泛但公平性较差的解释，而其他方法能以更高成本生成简洁均衡的结果。帕累托筛选启发式在稀疏场景中展现出显著的效率提升。</div>
</details>
<details class="detail"><summary>Summary / 总结</summary>
<div class="mono">Group recommender systems often lack transparency, making it unclear why items are suggested to a collective. To address this, the authors propose a framework for generating counterfactual explanations that reveal how removing specific past interactions would alter a group recommendation, formalizing the concept and introducing group-tailored utility and fairness measures. They design heuristic algorithms, including Pareto-based filtering and grow-and-prune strategies, for efficient explanation discovery. Experiments on MovieLens and Amazon datasets demonstrate trade-offs: low-cost methods yield larger but less fair explanations, while other approaches produce concise and balanced results at higher computational cost, with Pareto-filtering showing significant efficiency gains in sparse data settings.</div>
<div class="mono" style="margin-top:8px">群组推荐系统通常缺乏透明度，导致成员难以理解推荐项目的缘由。为解决此问题，本文提出了一个群组反事实解释框架，通过揭示移除特定历史交互如何改变群组推荐来提供解释，形式化了这一概念并引入了针对群组的效用和公平性度量，同时设计了帕累托过滤和增长-剪枝等启发式算法以高效发现解释。在MovieLens和Amazon数据集上的实验表明存在明显权衡：低成本方法产生规模较大但公平性较差的解释，而其他方法则以更高计算成本生成简洁且平衡的结果，其中帕累托过滤在稀疏数据环境下显示出显著的效率提升。</div>
</details>
</div>
<div class="card">
<div class="title">Programming over Thinking: Efficient and Robust Multi-Constraint Planning</div>
<div class="meta-line">Authors: Derrick Goh Xin Deik, Quanyu Long, Zhengyuan Liu, Nancy F. Chen, Wenya Wang</div>
<div class="meta-line">First: 2026-01-14T02:58:07+00:00 · Latest: 2026-01-23T16:41:41+00:00</div>
<div class="meta-line">Comments: 8 pages of main text, 2 pages of references and and limitations, 37 pages of appendices</div>
<div class="links" style="margin-top:8px"><a href="https://arxiv.org/abs/2601.09097v2">Abs</a> · <a href="https://arxiv.org/pdf/2601.09097v2">PDF</a> · <a href="https://github.com/DerrickGXD/SCOPE">Code1</a> · <a href="https://huggingface.co/huggingface">Code2</a> · <a href="https://huggingface.co/docs/hub/spaces">Code3</a></div>
<details class="detail"><summary>Abstract</summary>
<div class="mono">Multi-constraint planning involves identifying, evaluating, and refining candidate plans while satisfying multiple, potentially conflicting constraints. Existing large language model (LLM) approaches face fundamental limitations in this domain. Pure reasoning paradigms, which rely on long natural language chains, are prone to inconsistency, error accumulation, and prohibitive cost as constraints compound. Conversely, LLMs combined with coding- or solver-based strategies lack flexibility: they often generate problem-specific code from scratch or depend on fixed solvers, failing to capture generalizable logic across diverse problems. To address these challenges, we introduce the Scalable COde Planning Engine (SCOPE), a framework that disentangles query-specific reasoning from generic code execution. By separating reasoning from execution, SCOPE produces solver functions that are consistent, deterministic, and reusable across queries while requiring only minimal changes to input parameters. SCOPE achieves state-of-the-art performance while lowering cost and latency. For example, with GPT-4o, it reaches 93.1% success on TravelPlanner, a 61.6% gain over the best baseline (CoT) while cutting inference cost by 1.4x and time by ~4.67x. Code is available at https://github.com/DerrickGXD/SCOPE.</div></details>
<details class="detail"><summary>中文标题/摘要</summary>
<div class="mono"><b>标题：</b>编程优于思考：高效且鲁棒的多约束规划</div>
<div class="mono" style="margin-top:8px">多约束规划涉及在满足多个可能相互冲突的约束条件下，识别、评估和优化候选方案。现有的大语言模型（LLM）方法在该领域面临根本性局限。纯推理范式依赖冗长的自然语言链，容易因约束叠加而产生不一致性、错误累积和过高成本。相反，结合编码或基于求解器策略的LLM缺乏灵活性：它们通常从头生成针对特定问题的代码，或依赖固定求解器，难以捕捉跨问题的可泛化逻辑。为应对这些挑战，我们提出了可扩展代码规划引擎（SCOPE），该框架将查询特定推理与通用代码执行解耦。通过分离推理与执行，SCOPE生成一致、确定且可跨查询复用的求解器函数，仅需对输入参数进行最小改动。SCOPE在降低成本和延迟的同时实现了最先进的性能。例如，在GPT-4o上，其在TravelPlanner任务中达到93.1%的成功率，较最佳基线（CoT）提升61.6%，同时将推理成本降低1.4倍，时间减少约4.67倍。代码发布于https://github.com/DerrickGXD/SCOPE。</div>
</details>
<details class="detail"><summary>Summary / 总结</summary>
<div class="mono">This research addresses the limitations of large language models (LLM) in multi-constraint planning, where pure reasoning paradigms suffer from inconsistency and high cost, and code-based strategies lack flexibility and generalizability. The authors propose the Scalable COde Planning Engine (SCOPE), a framework that separates query-specific reasoning from generic code execution to produce consistent, deterministic, and reusable solver functions. Experiments demonstrate that SCOPE achieves state-of-the-art performance; for instance, using GPT-4o, it attains 93.1% success on the TravelPlanner benchmark, a 61.6% improvement over the best baseline while reducing inference cost by 1.4x and time by approximately 4.67x.</div>
<div class="mono" style="margin-top:8px">本研究针对大语言模型在多约束规划任务中的局限性展开，现有纯推理范式存在不一致性和高成本问题，而基于代码的策略则缺乏灵活性和泛化能力。提出的方法——可扩展代码规划引擎（SCOPE）——引入了一个将特定查询推理与通用代码执行解耦的框架，从而生成可复用且确定性的求解器函数。关键实验结果表明，SCOPE实现了最先进的性能，例如在TravelPlanner基准测试上达到93.1%的成功率，相比最佳基线提升了61.6%，同时将推理成本降低了1.4倍，时间减少了约4.67倍。</div>
</details>
</div>
<div class="card">
<div class="title">No Validation, No Problem: Predicting Model Performance from a Single Gradient</div>
<div class="meta-line">Authors: Fangzheng Wu, Brian Summa</div>
<div class="meta-line">First: 2026-01-23T16:30:11+00:00 · Latest: 2026-01-23T16:30:11+00:00</div>
<div class="links" style="margin-top:8px"><a href="https://arxiv.org/abs/2601.16874v1">Abs</a> · <a href="https://arxiv.org/pdf/2601.16874v1">PDF</a> · <a href="https://huggingface.co/huggingface">Code1</a> · <a href="https://huggingface.co/docs/hub/spaces">Code2</a></div>
<details class="detail"><summary>Abstract</summary>
<div class="mono">We propose a validation-free checkpointing signal from a single forward-backward pass: the Frobenius norm of the classifier-head gradient on one detached-feature batch, ||g||_F = ||dL/dW||_F. Across ImageNet-1k CNNs and Transformers, this proxy is strongly negative with Top-1 and positive with loss. Selecting the checkpoint with the minimum head gradient in a short tail window closes most of the gap to the oracle (4.24% +/- 2.00% with a universal setup, about 1.12% with light per-family tuning). For practical deployment, a head-scale normalization is more stable within classic CNN families (e.g., ResNets), while a feature-scale normalization works well for Transformers and modern CNNs. The same one-batch probe also predicts COCO detection/segmentation mAP. In diffusion (UNet/DDPM on CIFAR-10), it tracks progress and enables near-oracle tail-window selection; it is positively correlated with same-distribution probe MSE and negatively with FID (lower is better), so it can be used as a lightweight, label-free monitor. Validation labels are never used beyond reporting. The probe adds much less than 0.1% of an epoch and works as a drop-in for validation-free checkpoint selection and early stopping.</div></details>
<details class="detail"><summary>中文标题/摘要</summary>
<div class="mono"><b>标题：</b>无需验证，亦无难题：基于单次梯度预测模型性能</div>
<div class="mono" style="margin-top:8px">我们提出一种无需验证的检查点信号，仅需单次前向-反向传播：在单批分离特征上计算分类头梯度的弗罗贝尼乌斯范数，即||g||_F = ||dL/dW||_F。在ImageNet-1k的CNN与Transformer模型中，该指标与Top-1准确率呈强负相关，与损失值呈正相关。通过在短尾窗口中选择梯度范数最小的检查点，可基本弥合与最优结果的差距（通用设置下差距为4.24%±2.00%，经轻量级家族调优后约1.12%）。实际部署中，经典CNN家族（如ResNet）采用头部尺度归一化更稳定，而Transformer与现代CNN适用特征尺度归一化。同一单批探测方法亦能预测COCO检测/分割的mAP。在扩散模型（CIFAR-10上的UNet/DDPM）中，该指标可追踪训练进程并实现近最优的尾窗选择；其与同分布探测MSE正相关，与FID负相关（值越低越好），因此可作为轻量级无标签监控工具。除结果报告外全程无需验证标签。该探测方法增加的计算量远低于0.1%训练周期，可直接替代传统验证流程用于检查点选择与早停。</div>
</details>
<details class="detail"><summary>Summary / 总结</summary>
<div class="mono">To enable efficient model checkpoint selection without validation data, this work introduces a lightweight proxy based on the Frobenius norm of the classifier-head gradient computed from a single batch of detached features. The method involves computing ||dL/dW||_F during training and using it to select checkpoints, with normalization strategies tailored for different architectures (e.g., head-scale for ResNets, feature-scale for Transformers). Experiments on ImageNet-1k show the proxy strongly correlates with final performance metrics, allowing checkpoint selection that closes most of the gap to an oracle, and it generalizes to tasks like COCO detection and diffusion model training, serving as a label-free monitor with minimal computational overhead.</div>
<div class="mono" style="margin-top:8px">为了在没有验证数据的情况下实现高效的模型检查点选择，本研究提出了一种轻量级代理指标，基于从单批分离特征计算出的分类器头梯度Frobenius范数||g||_F。该方法在ImageNet-1k的CNN和Transformer模型上进行了评估，结果显示该代理指标与Top-1准确率呈强负相关，与损失值呈正相关；在训练尾段窗口中选择梯度范数最小的检查点，可以基本弥合与最优选择之间的性能差距，在通用设置下平均差距为4.24%，经轻量级家族调优后可降至约1.12%。该方法还可推广至COCO检测/分割任务以及扩散模型（CIFAR-10上的UNet/DDPM），能有效追踪训练进度并实现接近最优的检查点选择，同时仅增加极小的计算开销。</div>
</details>
</div>
<div class="card">
<div class="title">Boosting Deep Reinforcement Learning with Semantic Knowledge for Robotic Manipulators</div>
<div class="meta-line">Authors: Lucía Güitta-López, Vincenzo Suriani, Jaime Boal, Álvaro J. López-López, Daniele Nardi</div>
<div class="meta-line">Venue: Robotics, published 24 June 2025</div>
<div class="meta-line">First: 2026-01-23T16:14:28+00:00 · Latest: 2026-01-23T16:14:28+00:00</div>
<div class="links" style="margin-top:8px"><a href="https://arxiv.org/abs/2601.16866v1">Abs</a> · <a href="https://arxiv.org/pdf/2601.16866v1">PDF</a> · <a href="https://huggingface.co/huggingface">Code1</a> · <a href="https://huggingface.co/docs/hub/spaces">Code2</a></div>
<details class="detail"><summary>Abstract</summary>
<div class="mono">Deep Reinforcement Learning (DRL) is a powerful framework for solving complex sequential decision-making problems, particularly in robotic control. However, its practical deployment is often hindered by the substantial amount of experience required for learning, which results in high computational and time costs. In this work, we propose a novel integration of DRL with semantic knowledge in the form of Knowledge Graph Embeddings (KGEs), aiming to enhance learning efficiency by providing contextual information to the agent. Our architecture combines KGEs with visual observations, enabling the agent to exploit environmental knowledge during training. Experimental validation with robotic manipulators in environments featuring both fixed and randomized target attributes demonstrates that our method achieves up to {60}{\%} reduction in learning time and improves task accuracy by approximately 15 percentage points, without increasing training time or computational complexity. These results highlight the potential of semantic knowledge to reduce sample complexity and improve the effectiveness of DRL in robotic applications.</div></details>
<details class="detail"><summary>中文标题/摘要</summary>
<div class="mono"><b>标题：</b>融合语义知识提升机器人操作臂深度强化学习性能</div>
<div class="mono" style="margin-top:8px">深度强化学习（DRL）是解决复杂序列决策问题的强大框架，尤其在机器人控制领域。然而，其实际部署常因学习所需的大量经验而受阻，导致高昂的计算与时间成本。本研究提出一种将DRL与知识图谱嵌入（KGEs）形式语义知识相结合的新方法，旨在通过为智能体提供上下文信息来提升学习效率。我们的架构将KGEs与视觉观测相融合，使智能体能在训练过程中利用环境知识。在包含固定与随机目标属性的环境中对机器人操作臂进行实验验证表明：该方法可实现高达60%的学习时间缩减，任务准确率提升约15个百分点，且未增加训练时间或计算复杂度。这些结果凸显了语义知识在降低样本复杂度、提升DRL在机器人应用中有效性的潜力。</div>
</details>
<details class="detail"><summary>Summary / 总结</summary>
<div class="mono">Deep Reinforcement Learning (DRL) for robotic control faces challenges due to high sample complexity, leading to substantial computational and time costs during training. To address this, the authors propose a novel method that integrates semantic knowledge, specifically Knowledge Graph Embeddings (KGEs), with visual observations to provide the agent with contextual environmental information, thereby enhancing learning efficiency. Experimental results with robotic manipulators in environments with fixed and randomized target attributes show that this approach reduces learning time by up to 60% and improves task accuracy by approximately 15 percentage points, without increasing training time or computational complexity.</div>
<div class="mono" style="margin-top:8px">深度强化学习（DRL）在机器人控制中因样本复杂度高、训练时间长而面临实际部署困难。为解决此问题，本研究提出将语义知识以知识图谱嵌入（KGEs）形式与DRL结合，通过将KGEs与视觉观测融合，为智能体提供环境上下文信息。在具有固定和随机目标属性的机器人操作器环境中进行实验验证，结果表明该方法可将学习时间减少高达60%，任务准确率提升约15个百分点，且未增加训练时间或计算复杂度。</div>
</details>
</div>
<div class="card">
<div class="title">Mixture-of-Models: Unifying Heterogeneous Agents via N-Way Self-Evaluating Deliberation</div>
<div class="meta-line">Authors: Tims Pecerskis, Aivars Smirnovs</div>
<div class="meta-line">First: 2026-01-23T16:11:54+00:00 · Latest: 2026-01-23T16:11:54+00:00</div>
<div class="links" style="margin-top:8px"><a href="https://arxiv.org/abs/2601.16863v1">Abs</a> · <a href="https://arxiv.org/pdf/2601.16863v1">PDF</a> · <a href="https://huggingface.co/huggingface">Code1</a> · <a href="https://huggingface.co/docs/hub/spaces">Code2</a></div>
<details class="detail"><summary>Abstract</summary>
<div class="mono">This paper introduces the N-Way Self-Evaluating Deliberation (NSED) protocol, a Runtime Mixture-of-Models (MoM) architecture that constructs emergent composite models from a plurality of distinct expert agents. Unlike traditional Mixture-of-Experts (MoE) which rely on static gating networks, NSED employs a Dynamic Expertise Broker - a runtime optimization engine that treats model selection as a variation of the Knapsack Problem, binding heterogeneous checkpoints to functional roles based on live telemetry and cost constraints. At the execution layer, we formalize deliberation as a Macro-Scale Recurrent Neural Network (RNN), where the consensus state loops back through a semantic forget gate to enable iterative refinement without proportional VRAM scaling. Key components include an orchestration fabric for trustless N-to-N peer review, a Quadratic Voting activation function for non-linear consensus, and a feedback-driven state update. Empirical validation on challenging benchmarks (AIME 2025, LiveCodeBench) demonstrates that this topology allows ensembles of small (less than 20B) consumer-grade models to match or exceed the performance of state-of-the-art 100B+ parameter models, establishing a new hardware arbitrage efficiency frontier. Furthermore, testing on the DarkBench safety suite reveals intrinsic alignment properties, with peer-mediated correction reducing sycophancy scores below that of any individual agent.</div></details>
<details class="detail"><summary>中文标题/摘要</summary>
<div class="mono"><b>标题：</b>模型混合：通过N路自评估协商统一异构智能体</div>
<div class="mono" style="margin-top:8px">本文提出N路自评估协商协议，这是一种运行时模型混合架构，能从多个独立专家智能体中构建涌现式复合模型。与传统依赖静态门控网络的混合专家模型不同，NSED采用动态专长代理——一种运行时优化引擎，将模型选择视为背包问题的变体，根据实时遥测数据与成本约束将异构检查点绑定至功能角色。在执行层，我们将协商形式化为宏观尺度循环神经网络，其共识状态通过语义遗忘门循环反馈，实现无需按比例扩展显存的迭代优化。关键组件包括：支持去信任N对N同行评审的编排框架、用于非线性共识的二次投票激活函数，以及反馈驱动的状态更新机制。在挑战性基准上的实证验证表明，该拓扑结构能使小型消费级模型组成的集成系统达到或超越百亿参数级前沿模型的性能，确立了新的硬件套利效率边界。此外，在DarkBench安全套件上的测试揭示了其内在对齐特性，同行介导的修正使谄媚倾向评分低于任何独立智能体。</div>
</details>
<details class="detail"><summary>Summary / 总结</summary>
<div class="mono">The research addresses the need to unify heterogeneous AI agents into a composite model that dynamically leverages their distinct expertise, moving beyond static Mixture-of-Experts approaches. The method introduces the N-Way Self-Evaluating Deliberation protocol, which features a Dynamic Expertise Broker that frames model selection as a Knapsack Problem for runtime optimization and formalizes deliberation as a Macro-Scale RNN with a semantic forget gate for iterative refinement without linear VRAM increase. Experimental results on benchmarks like AIME 2025 and LiveCodeBench show that ensembles of small (&lt;20B) models can match or surpass the performance of large (&gt;100B) state-of-the-art models, while tests on DarkBench indicate improved safety alignment through peer-mediated correction, reducing sycophancy below individual agent levels.</div>
<div class="mono" style="margin-top:8px">本研究旨在将异构AI智能体统一为复合模型，以动态利用多样化专业知识，解决静态混合专家方法的局限性。所提出的方法，即N路自评估审议协议，采用动态专家代理器，将模型选择视为背包问题的变体，根据实时遥测和成本约束将智能体绑定到功能角色，并将审议形式化为具有语义遗忘门的宏观循环神经网络，以实现无需按比例增加显存的迭代优化。在AIME 2025和LiveCodeBench等基准测试上的实验结果表明，小型模型（小于200亿参数）的集成能够匹配或超越最先进的1000亿以上参数模型的性能，而在DarkBench安全套件上的测试显示，同行介导的纠正将谄媚分数降低至低于任何单个智能体的水平。</div>
</details>
</div>
<div class="card">
<div class="title">Orbitopal Fixing in SAT</div>
<div class="meta-line">Authors: Markus Anders, Cayden Codel, Marijn J. H. Heule</div>
<div class="meta-line">First: 2026-01-23T16:01:48+00:00 · Latest: 2026-01-23T16:01:48+00:00</div>
<div class="meta-line">Comments: to appear at TACAS 2026</div>
<div class="links" style="margin-top:8px"><a href="https://arxiv.org/abs/2601.16855v1">Abs</a> · <a href="https://arxiv.org/pdf/2601.16855v1">PDF</a> · <a href="https://huggingface.co/huggingface">Code1</a> · <a href="https://huggingface.co/docs/hub/spaces">Code2</a></div>
<details class="detail"><summary>Abstract</summary>
<div class="mono">Despite their sophisticated heuristics, boolean satisfiability (SAT) solvers are still vulnerable to symmetry, causing them to visit search regions that are symmetric to ones already explored. While symmetry handling is routine in other solving paradigms, integrating it into state-of-the-art proof-producing SAT solvers is difficult: added reasoning must be fast, non-interfering with solver heuristics, and compatible with formal proof logging. To address these issues, we present a practical static symmetry breaking approach based on orbitopal fixing, a technique adapted from mixed-integer programming. Our approach adds only unit clauses, which minimizes downstream slowdowns, and it emits succinct proof certificates in the substitution redundancy proof system. Implemented in the satsuma tool, our methods deliver consistent speedups on symmetry-rich benchmarks with negligible regressions elsewhere.</div></details>
<details class="detail"><summary>中文标题/摘要</summary>
<div class="mono"><b>标题：</b>SAT中的轨道面固定技术</div>
<div class="mono" style="margin-top:8px">尽管布尔可满足性（SAT）求解器采用了复杂的启发式算法，但仍易受对称性影响，导致其重复探索已搜索区域的对称区域。虽然对称性处理在其他求解范式中已是常规操作，但将其集成到先进的证明生成式SAT求解器中仍面临挑战：新增的推理必须快速、不干扰求解器启发式策略，且与形式化证明日志兼容。为此，我们提出一种基于轨道面固定的实用静态对称性破除方法，该技术源自混合整数规划。我们的方法仅添加单元子句，从而最小化下游计算延迟，并在替换冗余证明系统中生成简洁的证明凭证。通过satsuma工具实现后，该方法在富含对称性的基准测试中实现了持续加速，且在其他场景下性能退化可忽略不计。</div>
</details>
<details class="detail"><summary>Summary / 总结</summary>
<div class="mono">The research is motivated by the vulnerability of SAT solvers to symmetry, which leads to redundant exploration of symmetric search spaces, despite existing symmetry handling being difficult to integrate into proof-producing SAT solvers due to requirements for speed, non-interference, and proof compatibility. The method introduces a static symmetry breaking approach based on orbitopal fixing, adapted from mixed-integer programming, which adds only unit clauses to minimize slowdown and emits succinct proof certificates in the substitution redundancy proof system. Experimental results from implementation in the satsuma tool show consistent speedups on symmetry-rich benchmarks with negligible performance regressions on other problems.</div>
<div class="mono" style="margin-top:8px">该研究的动机在于，尽管布尔可满足性（SAT）求解器存在对称性漏洞，导致重复探索对称搜索区域，但将对称性处理集成到可生成证明的SAT求解器中仍很困难，需要满足快速、不干扰求解器启发式策略且兼容形式化证明记录的要求。方法上，提出了一种基于轨道面固定的实用静态对称性破缺方法，该方法改编自混合整数规划，仅添加单元子句以最小化性能下降，并在替换冗余证明系统中生成简洁的证明证书。通过在satsuma工具中实现，实验结果表明，在富含对称性的基准测试上取得了稳定的加速效果，而在其他问题上性能回归可忽略不计。</div>
</details>
</div>
<div class="card">
<div class="title">Reasoning Promotes Robustness in Theory of Mind Tasks</div>
<div class="meta-line">Authors: Ian B. de Haan, Peter van der Putten, Max van Duijn</div>
<div class="meta-line">First: 2026-01-23T16:01:24+00:00 · Latest: 2026-01-23T16:01:24+00:00</div>
<div class="meta-line">Comments: 14 pages, 2 figures</div>
<div class="links" style="margin-top:8px"><a href="https://arxiv.org/abs/2601.16853v1">Abs</a> · <a href="https://arxiv.org/pdf/2601.16853v1">PDF</a> · <a href="https://huggingface.co/huggingface">Code1</a> · <a href="https://huggingface.co/docs/hub/spaces">Code2</a></div>
<details class="detail"><summary>Abstract</summary>
<div class="mono">Large language models (LLMs) have recently shown strong performance on Theory of Mind (ToM) tests, prompting debate about the nature and true performance of the underlying capabilities. At the same time, reasoning-oriented LLMs trained via reinforcement learning with verifiable rewards (RLVR) have achieved notable improvements across a range of benchmarks. This paper examines the behavior of such reasoning models in ToM tasks, using novel adaptations of machine psychological experiments and results from established benchmarks. We observe that reasoning models consistently exhibit increased robustness to prompt variations and task perturbations. Our analysis indicates that the observed gains are more plausibly attributed to increased robustness in finding the correct solution, rather than to fundamentally new forms of ToM reasoning. We discuss the implications of this interpretation for evaluating social-cognitive behavior in LLMs.</div></details>
<details class="detail"><summary>中文标题/摘要</summary>
<div class="mono"><b>标题：</b>推理能力提升心智理论任务的鲁棒性</div>
<div class="mono" style="margin-top:8px">大型语言模型（LLMs）近期在心智理论（ToM）测试中展现出优异性能，引发了关于其底层能力本质与真实表现的讨论。与此同时，通过可验证奖励的强化学习（RLVR）训练出的推理导向型LLMs，在一系列基准测试中取得了显著进步。本文通过改良的机器心理实验与经典基准测试结果，考察此类推理模型在ToM任务中的表现。研究发现推理模型对提示变化和任务干扰始终表现出更强的鲁棒性。分析表明，这种性能提升更可能源于寻找正确解决方案的鲁棒性增强，而非源于全新形式的ToM推理机制。本文进一步探讨了该结论对评估LLMs社会认知行为的重要意义。</div>
</details>
<details class="detail"><summary>Summary / 总结</summary>
<div class="mono">This study investigates whether reasoning-oriented large language models (LLMs) trained with reinforcement learning and verifiable rewards (RLVR) exhibit fundamentally new Theory of Mind (ToM) capabilities or simply greater robustness. The method involves evaluating these reasoning models using both novel adaptations of machine psychological experiments and established ToM benchmarks. Key experimental findings show that reasoning models demonstrate consistently increased robustness to variations in prompts and task perturbations, with analysis suggesting these gains stem from more reliable solution-finding rather than novel forms of ToM reasoning.</div>
<div class="mono" style="margin-top:8px">本研究旨在探究通过强化学习与可验证奖励训练、具备推理能力的大语言模型是否展现出更稳健的心理理论能力。研究方法包括使用新颖的机器心理实验改编版本和成熟的心理理论基准测试来评估这些模型，重点关注它们在多样化提示和任务扰动下的表现。主要实验结果表明，与标准模型相比，推理模型对这些变体表现出持续更强的稳健性；然而，分析指出，这种改进源于模型得出正确答案的可靠性增强，而非获得了全新形式的心理理论推理能力。</div>
</details>
</div>
<div class="card">
<div class="title">Improving Training Efficiency and Reducing Maintenance Costs via Language Specific Model Merging</div>
<div class="meta-line">Authors: Alphaeus Dmonte, Vidhi Gupta, Daniel J Perry, Mark Arehart</div>
<div class="meta-line">First: 2026-01-22T17:28:24+00:00 · Latest: 2026-01-23T15:50:05+00:00</div>
<div class="meta-line">Comments: Accepted to EACL 2026 Industry Track</div>
<div class="links" style="margin-top:8px"><a href="https://arxiv.org/abs/2601.16127v2">Abs</a> · <a href="https://arxiv.org/pdf/2601.16127v2">PDF</a> · <a href="https://huggingface.co/huggingface">Code1</a> · <a href="https://huggingface.co/docs/hub/spaces">Code2</a></div>
<details class="detail"><summary>Abstract</summary>
<div class="mono">Fine-tuning a task-specific multilingual large language model (LLM) involves training the model on a multilingual dataset with examples in all the required languages. Updating one or more supported languages with additional data or adding support for a new language involves retraining the model, which can be computationally inefficient and creates a severe maintenance bottleneck. Recent research on merging multilingual multitask models has shown promise in terms of improved quality, but its computational and maintenance efficiency remains unstudied. In this work, we provide the first focused analysis of this merging strategy from an efficiency perspective, evaluating it across three independent tasks. We demonstrate significant efficiency gains while maintaining parity in terms of quality: this merging approach reduces the initial training time by up to 50\%. We also demonstrate that updating an individual language and re-merging as part of model maintenance reduces training costs by more than 60\%, compared to re-training the full multilingual model. We show this on both public and proprietary industry datasets confirming that the approach works well for industrial use cases in addition to academic settings already studied in previous work.</div></details>
<details class="detail"><summary>中文标题/摘要</summary>
<div class="mono"><b>标题：</b>通过语言特定模型融合提升训练效率并降低维护成本</div>
<div class="mono" style="margin-top:8px">针对特定任务的多语言大语言模型（LLM）进行微调时，需使用包含所有目标语言示例的多语言数据集进行训练。若需用额外数据更新一个或多个支持语言，或新增语言支持，则必须重新训练模型，这会导致计算效率低下并形成严重的维护瓶颈。近期关于多语言多任务模型融合的研究在提升质量方面展现出潜力，但其计算与维护效率尚未得到充分研究。本研究首次从效率角度对该融合策略进行聚焦分析，并在三个独立任务中开展评估。结果表明，该方法在保持质量相当的同时实现了显著的效率提升：融合策略使初始训练时间最多减少50%。此外，在模型维护过程中，针对单一语言更新并重新融合，相比重新训练完整多语言模型，可降低超过60%的训练成本。我们在公开及行业专有数据集上验证了该方法的有效性，证实其不仅适用于先前研究已涉及的学术场景，同样能良好适配工业应用场景。</div>
</details>
<details class="detail"><summary>Summary / 总结</summary>
<div class="mono">The research addresses the computational inefficiency and maintenance bottlenecks of retraining multilingual large language models when updating or adding languages. The method involves merging language-specific models instead of full retraining, evaluated across three independent tasks. Experimental results show up to 50% reduction in initial training time and over 60% cost savings for language updates, while maintaining quality parity on both public and proprietary datasets.</div>
<div class="mono" style="margin-top:8px">本研究针对多语言大语言模型在更新语言或添加新语言时需要完整重新训练所导致的计算效率低下和维护瓶颈问题。方法上，研究探讨了语言特定模型合并策略，即先分别训练不同语言的独立模型再进行合并，以此替代联合多语言训练。在三个任务上的实验结果表明，该方法将初始训练时间减少了高达50%，并通过重新合并进行语言更新将训练成本降低了60%以上，同时保持了质量相当，其有效性在公开和专有行业数据集上都得到了验证。</div>
</details>
</div></div>
    <details style="margin-top:16px" class="detail"><summary>History</summary>
      <div class="history-list"><a href="archive/20260126_0626.html">20260126_0626</a>
<a href="archive/20260126_0526.html">20260126_0526</a>
<a href="archive/20260126_0327.html">20260126_0327</a>
<a href="archive/20260125_0624.html">20260125_0624</a>
<a href="archive/20260125_0524.html">20260125_0524</a>
<a href="archive/20260125_0440.html">20260125_0440</a>
<a href="archive/20260125_0325.html">20260125_0325</a>
<a href="archive/20260124_0627.html">20260124_0627</a>
<a href="archive/20260124_0526.html">20260124_0526</a>
<a href="archive/20260124_0444.html">20260124_0444</a>
<a href="archive/20260124_0334.html">20260124_0334</a>
<a href="archive/20260123_0627.html">20260123_0627</a>
<a href="archive/20260123_0529.html">20260123_0529</a>
<a href="archive/20260123_0446.html">20260123_0446</a>
<a href="archive/20260123_0334.html">20260123_0334</a>
<a href="archive/20260122_2019.html">20260122_2019</a>
<a href="archive/20260122_2013.html">20260122_2013</a>
<a href="archive/20260122_2008.html">20260122_2008</a>
<a href="archive/20260122_2001.html">20260122_2001</a>
<a href="archive/20260122_0629.html">20260122_0629</a>
<a href="archive/20260122_0535.html">20260122_0535</a>
<a href="archive/20260122_0449.html">20260122_0449</a>
<a href="archive/20260122_0336.html">20260122_0336</a>
<a href="archive/20260121_0625.html">20260121_0625</a>
<a href="archive/20260121_0529.html">20260121_0529</a>
<a href="archive/20260121_0450.html">20260121_0450</a>
<a href="archive/20260121_0423.html">20260121_0423</a>
<a href="archive/20260120_0626.html">20260120_0626</a>
<a href="archive/20260120_0528.html">20260120_0528</a>
<a href="archive/20260120_0443.html">20260120_0443</a>
<a href="archive/20260120_0330.html">20260120_0330</a>
<a href="archive/20260119_0624.html">20260119_0624</a>
<a href="archive/20260119_0525.html">20260119_0525</a>
<a href="archive/20260119_0440.html">20260119_0440</a>
<a href="archive/20260119_0325.html">20260119_0325</a>
<a href="archive/20260118_2225.html">20260118_2225</a>
<a href="archive/20260118_2159.html">20260118_2159</a>
<a href="archive/20260118_2135.html">20260118_2135</a>
<a href="archive/20260118_2040.html">20260118_2040</a>
<a href="archive/20260118_1953.html">20260118_1953</a>
<a href="archive/20260118_1907.html">20260118_1907</a>
<a href="archive/20260118_0327.html">20260118_0327</a>
<a href="archive/20260117_0332.html">20260117_0332</a>
<a href="archive/20260116_0339.html">20260116_0339</a>
<a href="archive/20260115_0334.html">20260115_0334</a>
<a href="archive/20260114_0333.html">20260114_0333</a>
<a href="archive/20260113_0334.html">20260113_0334</a>
<a href="archive/20260112_0331.html">20260112_0331</a>
<a href="archive/20260111_0329.html">20260111_0329</a>
<a href="archive/20260110_0333.html">20260110_0333</a>
<a href="archive/20260109_0334.html">20260109_0334</a>
<a href="archive/20260108_0335.html">20260108_0335</a>
<a href="archive/20260107_0330.html">20260107_0330</a>
<a href="archive/20260106_0336.html">20260106_0336</a>
<a href="archive/20260105_0328.html">20260105_0328</a>
<a href="archive/20260104_0328.html">20260104_0328</a>
<a href="archive/20260103_0325.html">20260103_0325</a>
<a href="archive/20260102_0339.html">20260102_0339</a>
<a href="archive/20260101_0329.html">20260101_0329</a>
<a href="archive/20251231_0333.html">20251231_0333</a>
<a href="archive/20251230_0332.html">20251230_0332</a>
<a href="archive/20251229_0329.html">20251229_0329</a>
<a href="archive/20251228_0332.html">20251228_0332</a>
<a href="archive/20251227_0329.html">20251227_0329</a>
<a href="archive/20251226_0330.html">20251226_0330</a>
<a href="archive/20251225_0329.html">20251225_0329</a>
<a href="archive/20251224_0331.html">20251224_0331</a>
<a href="archive/20251223_0332.html">20251223_0332</a>
<a href="archive/20251222_0328.html">20251222_0328</a>
<a href="archive/20251221_0329.html">20251221_0329</a>
<a href="archive/20251220_0330.html">20251220_0330</a>
<a href="archive/20251219_0330.html">20251219_0330</a>
<a href="archive/20251218_0345.html">20251218_0345</a>
<a href="archive/20251217_0332.html">20251217_0332</a>
<a href="archive/20251216_0333.html">20251216_0333</a>
<a href="archive/20251215_0333.html">20251215_0333</a>
<a href="archive/20251214_0327.html">20251214_0327</a>
<a href="archive/20251212_0333.html">20251212_0333</a>
<a href="archive/20251211_0331.html">20251211_0331</a>
<a href="archive/20251210_0332.html">20251210_0332</a>
<a href="archive/20251209_0331.html">20251209_0331</a>
<a href="archive/20251208_0328.html">20251208_0328</a>
<a href="archive/20251207_0327.html">20251207_0327</a>
<a href="archive/20251206_0330.html">20251206_0330</a>
<a href="archive/20251205_0331.html">20251205_0331</a>
<a href="archive/20251204_0331.html">20251204_0331</a>
<a href="archive/20251203_0333.html">20251203_0333</a>
<a href="archive/20251202_0335.html">20251202_0335</a>
<a href="archive/20251201_0328.html">20251201_0328</a>
<a href="archive/20251130_0327.html">20251130_0327</a>
<a href="archive/20251129_0328.html">20251129_0328</a>
<a href="archive/20251128_0327.html">20251128_0327</a>
<a href="archive/20251127_0327.html">20251127_0327</a>
<a href="archive/20251126_0329.html">20251126_0329</a>
<a href="archive/20251125_0327.html">20251125_0327</a>
<a href="archive/20251124_0327.html">20251124_0327</a>
<a href="archive/20251123_0326.html">20251123_0326</a>
<a href="archive/20251122_0328.html">20251122_0328</a>
<a href="archive/20251121_0328.html">20251121_0328</a>
<a href="archive/20251120_0329.html">20251120_0329</a></div>
    </details>
    <div class="footer">Generated by arxiv-tracker</div>
  </div>
</body></html>
