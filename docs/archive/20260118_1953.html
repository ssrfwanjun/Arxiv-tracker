<!doctype html>
<html><head><meta charset="utf-8"><meta name="viewport" content="width=device-width,initial-scale=1">
<title>arXiv 论文速递</title><style>
:root {
  --bg:#f8fafc; --card:#ffffff; --text:#0f172a; --muted:#667085; --border:#e5e7eb; --acc:#2563eb;
}
:root[data-theme="dark"] {
  --bg:#0b0f17; --card:#111827; --text:#e5e7eb; --muted:#9ca3af; --border:#1f2937; --acc:#2563eb;
}
*{box-sizing:border-box} body{margin:0;background:var(--bg);color:var(--text);
  font-family:ui-sans-serif,system-ui,-apple-system,Segoe UI,Roboto,Helvetica,Arial;line-height:1.6;}
.container{max-width:900px;margin:0 auto;padding:18px;}
.header{display:flex;gap:10px;justify-content:space-between;align-items:center;margin:8px 0 16px;flex-wrap:wrap}
h1{font-size:22px;margin:0}
.badge{font-size:12px;color:#111827;background:var(--acc);padding:2px 8px;border-radius:999px}
.card{background:var(--card);border:1px solid var(--border);border-radius:16px;padding:16px 18px;margin:14px 0;box-shadow:0 1px 2px rgba(0,0,0,.04)}
.title{font-weight:700;margin:0 0 6px 0;font-size:18px}
.meta-line{color:var(--muted);font-size:13px;margin:2px 0}
.links a{color:var(--acc);text-decoration:none;margin-right:12px}
.detail{margin-top:10px;background:rgba(2,6,23,.03);border:1px solid var(--border);border-radius:10px;padding:8px 10px}
summary{cursor:pointer;color:var(--acc)}
.mono{white-space:pre-wrap;background:rgba(2,6,23,.03);border:1px solid var(--border);padding:10px;border-radius:10px}
.row{display:grid;grid-template-columns:1fr;gap:12px}
@media (min-width: 860px) {
  .row-2{grid-template-columns:1fr 1fr}
}
.footer{color:var(--muted);font-size:13px;margin:20px 0 10px}
.hr{height:1px;background:var(--border);margin:14px 0}
.history-list a{display:block;color:var(--acc);text-decoration:none;margin:4px 0}
.controls{display:flex;gap:8px;align-items:center}
.btn{border:1px solid var(--border);background:var(--card);padding:6px 10px;border-radius:10px;cursor:pointer;color:var(--text)}
.btn:hover{border-color:var(--acc)}
</style>
<script>
(function() {
  const root = document.documentElement;
  function apply(t) {
    if (t==='dark') root.setAttribute('data-theme','dark');
    else if (t==='light') root.removeAttribute('data-theme');
    else {
      if (window.matchMedia && window.matchMedia('(prefers-color-scheme: dark)').matches)
        root.setAttribute('data-theme','dark');
      else root.removeAttribute('data-theme');
    }
  }
  let t = localStorage.getItem('theme') || 'light';
  if (!['light','dark','auto'].includes(t)) t='light';
  apply(t);
  window.__toggleTheme = function() {
    let cur = localStorage.getItem('theme') || 'light';
    if (cur==='light') cur='dark';
    else if (cur==='dark') cur='auto';
    else cur='light';
    localStorage.setItem('theme', cur);
    apply(cur);
    const el=document.getElementById('theme-label');
    if(el) el.textContent = cur.toUpperCase();
  }
  window.__expandAll = function(open) {
    document.querySelectorAll('details').forEach(d => d.open = !!open);
  }
})();
</script>
</head>
<body>
  <div class="container">
    <div class="header">
      <h1>arXiv 论文速递</h1>
      <div style="display:flex;gap:10px;align-items:center">
        
<div class="controls">
  <button class="btn" onclick="__toggleTheme()">Theme: <span id="theme-label" style="margin-left:6px">AUTO</span></button>
  <button class="btn" onclick="__expandAll(true)">Expand All</button>
  <button class="btn" onclick="__expandAll(false)">Collapse All</button>
</div>

        <span class="badge">2026-01-18 19:53</span>
      </div>
    </div>
    <div class="hr"></div>
    <div>Snapshot: 20260118_1953</div>
    <div class="row"><div class="card">
<div class="title">WildRayZer: Self-supervised Large View Synthesis in Dynamic Environments</div>
<div class="meta-line">Authors: Xuweiyi Chen, Wentao Zhou, Zezhou Cheng</div>
<div class="meta-line">First: 2026-01-15T18:59:58+00:00 · Latest: 2026-01-15T18:59:58+00:00</div>
<div class="meta-line">Comments: Project Page: https://wild-rayzer.cs.virginia.edu/</div>
<div class="links" style="margin-top:8px"><a href="https://arxiv.org/abs/2601.10716v1">Abs</a> · <a href="https://arxiv.org/pdf/2601.10716v1">PDF</a> · <a href="https://huggingface.co/huggingface">Code1</a> · <a href="https://huggingface.co/docs/hub/spaces">Code2</a> · <a href="https://wild-rayzer.cs.virginia.edu/">Project1</a></div>
<details class="detail"><summary>Abstract</summary>
<div class="mono">We present WildRayZer, a self-supervised framework for novel view synthesis (NVS) in dynamic environments where both the camera and objects move. Dynamic content breaks the multi-view consistency that static NVS models rely on, leading to ghosting, hallucinated geometry, and unstable pose estimation. WildRayZer addresses this by performing an analysis-by-synthesis test: a camera-only static renderer explains rigid structure, and its residuals reveal transient regions. From these residuals, we construct pseudo motion masks, distill a motion estimator, and use it to mask input tokens and gate loss gradients so supervision focuses on cross-view background completion. To enable large-scale training and evaluation, we curate Dynamic RealEstate10K (D-RE10K), a real-world dataset of 15K casually captured dynamic sequences, and D-RE10K-iPhone, a paired transient and clean benchmark for sparse-view transient-aware NVS. Experiments show that WildRayZer consistently outperforms optimization-based and feed-forward baselines in both transient-region removal and full-frame NVS quality with a single feed-forward pass.</div></details>
<details class="detail"><summary>中文标题/摘要</summary>
<div class="mono"><b>标题：</b>WildRayZer：动态环境中自监督的大视角合成</div>
<div class="mono" style="margin-top:8px">本文提出WildRayZer，一种用于动态环境（相机与物体均运动）中新视角合成的自监督框架。动态内容破坏了静态NVS模型依赖的多视角一致性，导致重影、几何幻觉及姿态估计不稳定。WildRayZer通过执行分析-合成测试解决该问题：仅相机静态渲染器解释刚性结构，其残差揭示瞬态区域。基于这些残差，我们构建伪运动掩码、蒸馏运动估计器，并利用其掩码输入标记与门控损失梯度，使监督聚焦于跨视角背景补全。为支持大规模训练与评估，我们构建了真实世界数据集Dynamic RealEstate10K（含1.5万条随意采集的动态序列）及其配对瞬态-干净基准D-RE10K-iPhone，用于稀疏视角瞬态感知NVS。实验表明，WildRayZer在单次前向传播中，于瞬态区域消除与全帧NVS质量方面均持续优于基于优化的前馈基线。</div>
</details>
<details class="detail"><summary>Summary / 总结</summary>
<div class="mono">Novel view synthesis in dynamic environments is challenging due to moving cameras and objects, which break multi-view consistency and cause artifacts like ghosting. To address this, WildRayZer introduces a self-supervised framework that first uses a static renderer to model rigid structure, then identifies transient regions from residuals to construct pseudo motion masks. These masks are used to distill a motion estimator that gates loss gradients, focusing supervision on cross-view background completion. Evaluated on the newly curated Dynamic RealEstate10K dataset, the method outperforms optimization-based and feed-forward baselines in both transient removal and full-frame synthesis quality with a single forward pass.</div>
<div class="mono" style="margin-top:8px">动态环境下的新视角合成因相机和物体同时运动而面临挑战，多视图一致性被破坏会导致重影等伪影。WildRayZer提出一种自监督框架，首先使用静态渲染器建模刚性结构，然后通过残差识别瞬态区域以构建伪运动掩码。这些掩码用于蒸馏运动估计器，通过门控损失梯度使监督专注于跨视图背景补全。在新构建的Dynamic RealEstate10K数据集上的实验表明，WildRayZer在单次前向传播中，于瞬态区域去除和全帧合成质量上均优于基于优化的和前馈基线方法。</div>
</details>
</div>
<div class="card">
<div class="title">DInf-Grid: A Neural Differential Equation Solver with Differentiable Feature Grids</div>
<div class="meta-line">Authors: Navami Kairanda, Shanthika Naik, Marc Habermann, Avinash Sharma, Christian Theobalt, Vladislav Golyanik</div>
<div class="meta-line">First: 2026-01-15T18:59:57+00:00 · Latest: 2026-01-15T18:59:57+00:00</div>
<div class="meta-line">Comments: 25 pages; 16 figures; project page: https://4dqv.mpi-inf.mpg.de/DInf-Grid/</div>
<div class="links" style="margin-top:8px"><a href="https://arxiv.org/abs/2601.10715v1">Abs</a> · <a href="https://arxiv.org/pdf/2601.10715v1">PDF</a> · <a href="https://huggingface.co/huggingface">Code1</a> · <a href="https://huggingface.co/docs/hub/spaces">Code2</a></div>
<details class="detail"><summary>Abstract</summary>
<div class="mono">We present a novel differentiable grid-based representation for efficiently solving differential equations (DEs). Widely used architectures for neural solvers, such as sinusoidal neural networks, are coordinate-based MLPs that are both computationally intensive and slow to train. Although grid-based alternatives for implicit representations (e.g., Instant-NGP and K-Planes) train faster by exploiting signal structure, their reliance on linear interpolation restricts their ability to compute higher-order derivatives, rendering them unsuitable for solving DEs. Our approach overcomes these limitations by combining the efficiency of feature grids with radial basis function interpolation, which is infinitely differentiable. To effectively capture high-frequency solutions and enable stable and faster computation of global gradients, we introduce a multi-resolution decomposition with co-located grids. Our proposed representation, DInf-Grid, is trained implicitly using the differential equations as loss functions, enabling accurate modelling of physical fields. We validate DInf-Grid on a variety of tasks, including the Poisson equation for image reconstruction, the Helmholtz equation for wave fields, and the Kirchhoff-Love boundary value problem for cloth simulation. Our results demonstrate a 5-20x speed-up over coordinate-based MLP-based methods, solving differential equations in seconds or minutes while maintaining comparable accuracy and compactness.</div></details>
<details class="detail"><summary>中文标题/摘要</summary>
<div class="mono"><b>标题：</b>DInf-Grid：一种具备可微分特征网格的神经微分方程求解器</div>
<div class="mono" style="margin-top:8px">本文提出了一种新颖的基于可微分网格的表示方法，用于高效求解微分方程。现有神经求解器广泛采用的架构（如正弦神经网络）是基于坐标的多层感知机，其计算密集且训练缓慢。虽然基于网格的隐式表示替代方案（如Instant-NGP和K-Planes）通过利用信号结构实现了更快训练，但其对线性插值的依赖限制了高阶导数的计算能力，使其不适用于求解微分方程。我们的方法通过将特征网格的效率与无限可微的径向基函数插值相结合，克服了这些限制。为有效捕捉高频解并实现稳定快速的全局梯度计算，我们引入了共位网格的多分辨率分解。所提出的DInf-Grid表示以微分方程作为损失函数进行隐式训练，能够精确建模物理场。我们在多项任务中验证了DInf-Grid，包括图像重建的泊松方程、波场求解的亥姆霍兹方程，以及布料模拟的基尔霍夫-洛夫边值问题。实验结果表明，相较于基于坐标的MLP方法，本方法实现了5-20倍的加速，能在数秒至数分钟内求解微分方程，同时保持相当的精度与紧凑性。</div>
</details>
<details class="detail"><summary>Summary / 总结</summary>
<div class="mono">The research addresses the inefficiency of coordinate-based MLPs like sinusoidal neural networks for solving differential equations (DEs), which are computationally intensive and slow to train. The method introduces DInf-Grid, a differentiable grid-based representation that combines multi-resolution feature grids with radial basis function interpolation to enable efficient, higher-order derivative computation and capture high-frequency solutions. Experimental validation on tasks including the Poisson equation, Helmholtz equation, and Kirchhoff-Love boundary value problem shows that DInf-Grid achieves a 5-20x speed-up over coordinate-based MLP methods while maintaining comparable accuracy and compactness.</div>
<div class="mono" style="margin-top:8px">该研究针对基于坐标的多层感知机（如正弦神经网络）在求解微分方程时计算量大、训练慢的问题，提出了一种新方法。DInf-Grid方法结合了基于网格表示的高训练速度和径向基函数插值的无限可微性，克服了如Instant-NGP等方法中线性插值的局限性，并采用多分辨率分解与共置网格来捕捉高频解并稳定计算全局梯度。在泊松方程、亥姆霍兹方程和基尔霍夫-洛夫边界值问题等任务上的实验验证表明，DInf-Grid相比基于坐标的MLP方法实现了5-20倍的加速，同时保持了相当的精度和紧凑性，能在数秒或数分钟内求解微分方程。</div>
</details>
</div>
<div class="card">
<div class="title">Alterbute: Editing Intrinsic Attributes of Objects in Images</div>
<div class="meta-line">Authors: Tal Reiss, Daniel Winter, Matan Cohen, Alex Rav-Acha, Yael Pritch, Ariel Shamir, Yedid Hoshen</div>
<div class="meta-line">First: 2026-01-15T18:59:53+00:00 · Latest: 2026-01-15T18:59:53+00:00</div>
<div class="meta-line">Comments: Project page is available at https://talreiss.github.io/alterbute/</div>
<div class="links" style="margin-top:8px"><a href="https://arxiv.org/abs/2601.10714v1">Abs</a> · <a href="https://arxiv.org/pdf/2601.10714v1">PDF</a> · <a href="https://huggingface.co/huggingface">Code1</a> · <a href="https://huggingface.co/docs/hub/spaces">Code2</a> · <a href="https://talreiss.github.io/alterbute/">Project1</a></div>
<details class="detail"><summary>Abstract</summary>
<div class="mono">We introduce Alterbute, a diffusion-based method for editing an object&#x27;s intrinsic attributes in an image. We allow changing color, texture, material, and even the shape of an object, while preserving its perceived identity and scene context. Existing approaches either rely on unsupervised priors that often fail to preserve identity or use overly restrictive supervision that prevents meaningful intrinsic variations. Our method relies on: (i) a relaxed training objective that allows the model to change both intrinsic and extrinsic attributes conditioned on an identity reference image, a textual prompt describing the target intrinsic attributes, and a background image and object mask defining the extrinsic context. At inference, we restrict extrinsic changes by reusing the original background and object mask, thereby ensuring that only the desired intrinsic attributes are altered; (ii) Visual Named Entities (VNEs) - fine-grained visual identity categories (e.g., &#x27;&#x27;Porsche 911 Carrera&#x27;&#x27;) that group objects sharing identity-defining features while allowing variation in intrinsic attributes. We use a vision-language model to automatically extract VNE labels and intrinsic attribute descriptions from a large public image dataset, enabling scalable, identity-preserving supervision. Alterbute outperforms existing methods on identity-preserving object intrinsic attribute editing.</div></details>
<details class="detail"><summary>中文标题/摘要</summary>
<div class="mono"><b>标题：</b>Alterbute：编辑图像中物体的内在属性</div>
<div class="mono" style="margin-top:8px">我们提出Alterbute，一种基于扩散模型的图像物体内在属性编辑方法。该方法支持改变物体的颜色、纹理、材质甚至形状，同时保持其感知身份与场景上下文。现有方法要么依赖无法保持身份的无监督先验，要么采用过度限制的监督方式阻碍有意义的属性变化。我们的方法基于：（1）松弛训练目标，允许模型根据身份参考图像、描述目标内在属性的文本提示、以及定义外在背景的背景图像与物体掩码，同时改变内在与外在属性。在推理阶段，通过复用原始背景与物体掩码限制外在变化，确保仅修改目标内在属性；（2）视觉命名实体——细粒度视觉身份类别（如“保时捷911卡雷拉”），将具有身份定义特征但允许内在属性变化的物体归组。我们利用视觉语言模型从大型公共图像数据集中自动提取VNE标签与内在属性描述，实现可扩展的身份保持监督。Alterbute在身份保持的物体内在属性编辑任务上优于现有方法。</div>
</details>
<details class="detail"><summary>Summary / 总结</summary>
<div class="mono">The research addresses the challenge of editing intrinsic attributes like color, texture, material, and shape of objects in images while preserving the object&#x27;s identity and scene context, as existing methods often fail to maintain identity or restrict meaningful variations. The proposed method, Alterbute, employs a diffusion-based approach with a relaxed training objective that conditions changes on an identity reference image, a textual prompt for target attributes, and a background image with an object mask; at inference, it reuses the original background and mask to restrict extrinsic changes. Key experimental results show that Alterbute outperforms existing methods in identity-preserving object intrinsic attribute editing, facilitated by the use of Visual Named Entities for fine-grained identity categorization and scalable supervision from automatically extracted labels.</div>
<div class="mono" style="margin-top:8px">该研究旨在解决图像中物体内在属性（如颜色、纹理、材质和形状）编辑的挑战，同时保持物体的身份和场景上下文，因为现有方法往往难以在身份保持与有意义的属性变化之间取得平衡。所提出的方法Alterbute采用基于扩散的模型，通过一个宽松的训练目标，以身份参考图像、描述目标属性的文本提示以及背景图像和物体掩码为条件；在推理时，通过重用原始背景和掩码来限制外在变化，从而仅改变内在属性。该方法还引入了视觉命名实体（VNEs），即通过视觉语言模型从大型数据集中自动标注的细粒度身份类别，以提供可扩展的、保持身份信息的监督。实验结果表明，Alterbute在保持身份的内在属性编辑任务上优于现有方法。</div>
</details>
</div>
<div class="card">
<div class="title">MatchTIR: Fine-Grained Supervision for Tool-Integrated Reasoning via Bipartite Matching</div>
<div class="meta-line">Authors: Changle Qu, Sunhao Dai, Hengyi Cai, Jun Xu, Shuaiqiang Wang, Dawei Yin</div>
<div class="meta-line">First: 2026-01-15T18:59:23+00:00 · Latest: 2026-01-15T18:59:23+00:00</div>
<div class="links" style="margin-top:8px"><a href="https://arxiv.org/abs/2601.10712v1">Abs</a> · <a href="https://arxiv.org/pdf/2601.10712v1">PDF</a> · <a href="https://github.com/quchangle1/MatchTIR">Code1</a> · <a href="https://huggingface.co/huggingface">Code2</a> · <a href="https://huggingface.co/docs/hub/spaces">Code3</a></div>
<details class="detail"><summary>Abstract</summary>
<div class="mono">Tool-Integrated Reasoning (TIR) empowers large language models (LLMs) to tackle complex tasks by interleaving reasoning steps with external tool interactions. However, existing reinforcement learning methods typically rely on outcome- or trajectory-level rewards, assigning uniform advantages to all steps within a trajectory. This coarse-grained credit assignment fails to distinguish effective tool calls from redundant or erroneous ones, particularly in long-horizon multi-turn scenarios. To address this, we propose MatchTIR, a framework that introduces fine-grained supervision via bipartite matching-based turn-level reward assignment and dual-level advantage estimation. Specifically, we formulate credit assignment as a bipartite matching problem between predicted and ground-truth traces, utilizing two assignment strategies to derive dense turn-level rewards. Furthermore, to balance local step precision with global task success, we introduce a dual-level advantage estimation scheme that integrates turn-level and trajectory-level signals, assigning distinct advantage values to individual interaction turns. Extensive experiments on three benchmarks demonstrate the superiority of MatchTIR. Notably, our 4B model surpasses the majority of 8B competitors, particularly in long-horizon and multi-turn tasks. Our codes are available at https://github.com/quchangle1/MatchTIR.</div></details>
<details class="detail"><summary>中文标题/摘要</summary>
<div class="mono"><b>标题：</b>MatchTIR：基于二分图匹配的细粒度监督工具集成推理</div>
<div class="mono" style="margin-top:8px">工具集成推理（TIR）通过将推理步骤与外部工具交互交织，赋能大语言模型处理复杂任务。然而，现有强化学习方法通常依赖结果级或轨迹级奖励，对轨迹内所有步骤赋予统一的优势值。这种粗粒度的信用分配无法区分有效工具调用与冗余或错误调用，尤其在长视野多轮次场景中。为此，我们提出MatchTIR框架，通过基于二分图匹配的轮次级奖励分配和双层优势估计引入细粒度监督。具体而言，我们将信用分配建模为预测轨迹与真实轨迹间的二分图匹配问题，采用两种分配策略生成密集的轮次级奖励。此外，为平衡局部步骤精度与全局任务成功率，我们引入融合轮次级与轨迹级信号的双层优势估计方案，为每个交互轮次分配差异化优势值。在三个基准上的大量实验证明了MatchTIR的优越性。值得注意的是，我们的40亿参数模型在多数任务中超越了80亿参数竞品，尤其在长视野与多轮次任务中表现突出。代码已开源：https://github.com/quchangle1/MatchTIR。</div>
</details>
<details class="detail"><summary>Summary / 总结</summary>
<div class="mono">The research addresses the coarse-grained credit assignment in existing reinforcement learning methods for Tool-Integrated Reasoning (TIR), which fails to distinguish effective tool calls from redundant ones in long-horizon tasks. The proposed MatchTIR framework introduces fine-grained supervision by formulating credit assignment as a bipartite matching problem between predicted and ground-truth traces to derive dense turn-level rewards, and employs a dual-level advantage estimation scheme to balance local step precision with global task success. Experimental results on three benchmarks show that MatchTIR&#x27;s 4B model outperforms most 8B competitors, especially in long-horizon and multi-turn tasks.</div>
<div class="mono" style="margin-top:8px">本研究针对现有工具集成推理（TIR）强化学习方法中粗粒度的信用分配问题，该问题在长视野任务中无法区分有效工具调用与冗余调用。提出的MatchTIR框架通过将信用分配构建为预测轨迹与真实轨迹之间的二分图匹配问题，以生成密集的回合级奖励，并采用双层级优势估计方案来平衡局部步骤精度与全局任务成功。在三个基准测试上的实验结果表明，MatchTIR优于现有方法，其4B模型在长视野和多回合任务中表现尤为突出，超越了大多数8B竞争对手。</div>
</details>
</div>
<div class="card">
<div class="title">From One-to-One to Many-to-Many: Dynamic Cross-Layer Injection for Deep Vision-Language Fusion</div>
<div class="meta-line">Authors: Cheng Chen, Yuyu Guo, Pengpeng Zeng, Jingkuan Song, Peng Di, Hang Yu, Lianli Gao</div>
<div class="meta-line">First: 2026-01-15T18:59:10+00:00 · Latest: 2026-01-15T18:59:10+00:00</div>
<div class="links" style="margin-top:8px"><a href="https://arxiv.org/abs/2601.10710v1">Abs</a> · <a href="https://arxiv.org/pdf/2601.10710v1">PDF</a> · <a href="https://huggingface.co/huggingface">Code1</a> · <a href="https://huggingface.co/docs/hub/spaces">Code2</a></div>
<details class="detail"><summary>Abstract</summary>
<div class="mono">Vision-Language Models (VLMs) create a severe visual feature bottleneck by using a crude, asymmetric connection that links only the output of the vision encoder to the input of the large language model (LLM). This static architecture fundamentally limits the ability of LLMs to achieve comprehensive alignment with hierarchical visual knowledge, compromising their capacity to accurately integrate local details with global semantics into coherent reasoning. To resolve this, we introduce Cross-Layer Injection (CLI), a novel and lightweight framework that forges a dynamic many-to-many bridge between the two modalities. CLI consists of two synergistic, parameter-efficient components: an Adaptive Multi-Projection (AMP) module that harmonizes features from diverse vision layers, and an Adaptive Gating Fusion (AGF) mechanism that empowers the LLM to selectively inject the most relevant visual information based on its real-time decoding context. We validate the effectiveness and versatility of CLI by integrating it into LLaVA-OneVision and LLaVA-1.5. Extensive experiments on 18 diverse benchmarks demonstrate significant performance improvements, establishing CLI as a scalable paradigm that unlocks deeper multimodal understanding by granting LLMs on-demand access to the full visual hierarchy.</div></details>
<details class="detail"><summary>中文标题/摘要</summary>
<div class="mono"><b>标题：</b>从单对单到多对多：面向深度视觉-语言融合的动态跨层注入</div>
<div class="mono" style="margin-top:8px">视觉-语言模型（VLMs）通过仅将视觉编码器的输出与大型语言模型（LLM）输入相连的粗糙非对称连接，造成了严重的视觉特征瓶颈。这种静态架构从根本上限制了LLM与层次化视觉知识实现全面对齐的能力，削弱了其将局部细节与全局语义准确整合为连贯推理的效能。为此，我们提出跨层注入（CLI）——一种新颖轻量的框架，可在两种模态间构建动态的多对多桥梁。CLI包含两个高效协同的参数化组件：自适应多投影（AMP）模块，用于协调来自不同视觉层的特征；以及自适应门控融合（AGF）机制，使LLM能依据其实时解码上下文选择性注入最相关的视觉信息。我们将CLI集成至LLaVA-OneVision和LLaVA-1.5中，验证了其有效性与泛化能力。在18个多样化基准测试上的大量实验表明，CLI带来了显著的性能提升，确立了一种可扩展的范式——通过赋予LLM按需访问完整视觉层次的能力，解锁更深层次的多模态理解。</div>
</details>
<details class="detail"><summary>Summary / 总结</summary>
<div class="mono">The research addresses the visual feature bottleneck in Vision-Language Models (VLMs), where a static, one-to-one connection between the vision encoder and the large language model (LLM) limits comprehensive alignment with hierarchical visual knowledge. To overcome this, the authors propose Cross-Layer Injection (CLI), a lightweight framework that establishes a dynamic many-to-many bridge via two components: an Adaptive Multi-Projection (AMP) module to harmonize features from different vision layers, and an Adaptive Gating Fusion (AGF) mechanism that allows the LLM to selectively inject relevant visual information based on its decoding context. Experimental integration into LLaVA-OneVision and LLaVA-1.5 across 18 benchmarks shows significant performance improvements, demonstrating CLI&#x27;s effectiveness in enabling deeper multimodal understanding through on-demand access to the full visual hierarchy.</div>
<div class="mono" style="margin-top:8px">本研究针对视觉-语言模型（VLM）中存在的视觉特征瓶颈问题，即视觉编码器与大语言模型（LLM）之间静态的一对一连接限制了模型与层次化视觉知识的全面对齐。为解决此问题，作者提出了跨层注入（CLI）这一轻量级框架，通过两个协同组件构建动态的多对多桥梁：自适应多投影（AMP）模块用于协调来自不同视觉层的特征，以及自适应门控融合（AGF）机制使LLM能够根据其实时解码上下文选择性注入最相关的视觉信息。通过在LLaVA-OneVision和LLaVA-1.5模型上进行集成，并在18个多样化基准测试上的广泛实验表明，该方法带来了显著的性能提升，验证了CLI作为一种可扩展范式，能够通过按需访问完整视觉层次来解锁更深层次的多模态理解能力。</div>
</details>
</div>
<div class="card">
<div class="title">High-accuracy and dimension-free sampling with diffusions</div>
<div class="meta-line">Authors: Khashayar Gatmiry, Sitan Chen, Adil Salim</div>
<div class="meta-line">First: 2026-01-15T18:58:50+00:00 · Latest: 2026-01-15T18:58:50+00:00</div>
<div class="links" style="margin-top:8px"><a href="https://arxiv.org/abs/2601.10708v1">Abs</a> · <a href="https://arxiv.org/pdf/2601.10708v1">PDF</a> · <a href="https://huggingface.co/huggingface">Code1</a> · <a href="https://huggingface.co/docs/hub/spaces">Code2</a></div>
<details class="detail"><summary>Abstract</summary>
<div class="mono">Diffusion models have shown remarkable empirical success in sampling from rich multi-modal distributions. Their inference relies on numerically solving a certain differential equation. This differential equation cannot be solved in closed form, and its resolution via discretization typically requires many small iterations to produce \emph{high-quality} samples.
  More precisely, prior works have shown that the iteration complexity of discretization methods for diffusion models scales polynomially in the ambient dimension and the inverse accuracy $1/\varepsilon$. In this work, we propose a new solver for diffusion models relying on a subtle interplay between low-degree approximation and the collocation method (Lee, Song, Vempala 2018), and we prove that its iteration complexity scales \emph{polylogarithmically} in $1/\varepsilon$, yielding the first ``high-accuracy&#x27;&#x27; guarantee for a diffusion-based sampler that only uses (approximate) access to the scores of the data distribution. In addition, our bound does not depend explicitly on the ambient dimension; more precisely, the dimension affects the complexity of our solver through the \emph{effective radius} of the support of the target distribution only.</div></details>
<details class="detail"><summary>中文标题/摘要</summary>
<div class="mono"><b>标题：</b>基于扩散模型的高精度无维度依赖采样方法</div>
<div class="mono" style="margin-top:8px">扩散模型在从复杂多模态分布中采样方面展现出卓越的实证效果。其推断依赖于数值求解特定微分方程，该方程无法获得闭式解，通常需要通过离散化方法进行大量小步长迭代才能生成高质量样本。现有研究表明，扩散模型离散化方法的迭代复杂度随环境维度和逆精度1/ε呈多项式增长。本文提出一种基于低阶近似与配置法精妙结合的新型求解器，证明其迭代复杂度在1/ε上呈多对数增长，首次为仅需（近似）访问数据分布分数函数的扩散采样器提供了高精度保证。此外，该复杂度界限不显式依赖于环境维度，维度影响仅通过目标分布支撑集的有效半径体现。</div>
</details>
<details class="detail"><summary>Summary / 总结</summary>
<div class="mono">Motivated by the high computational cost of existing diffusion model samplers, which require many small discretization steps to achieve high-quality samples, this work introduces a new solver that combines low-degree approximation with the collocation method. The method leverages approximate access to the scores of the data distribution to achieve polylogarithmic iteration complexity in inverse accuracy, independent of explicit ambient dimension dependence, scaling instead with the effective radius of the target distribution&#x27;s support. Experimental results demonstrate that this approach provides the first high-accuracy guarantee for diffusion-based sampling, significantly reducing the number of iterations needed compared to prior polynomial-scaling methods.</div>
<div class="mono" style="margin-top:8px">针对现有扩散模型采样器计算成本高、需要大量离散化步骤才能获得高质量样本的问题，本研究提出了一种结合低阶近似与配置方法的新求解器。该方法利用数据分布得分函数的近似访问，实现了在逆精度上的多对数迭代复杂度，突破了先前方法的多项式缩放限制。关键实验结果表明，该求解器的迭代复杂度仅取决于目标分布支撑集的有效半径，而不显式依赖于环境维度，从而实现了高效的高精度采样。</div>
</details>
</div>
<div class="card">
<div class="title">See Less, Drive Better: Generalizable End-to-End Autonomous Driving via Foundation Models Stochastic Patch Selection</div>
<div class="meta-line">Authors: Amir Mallak, Erfan Aasi, Shiva Sreeram, Tsun-Hsuan Wang, Daniela Rus, Alaa Maalouf</div>
<div class="meta-line">First: 2026-01-15T18:58:33+00:00 · Latest: 2026-01-15T18:58:33+00:00</div>
<div class="links" style="margin-top:8px"><a href="https://arxiv.org/abs/2601.10707v1">Abs</a> · <a href="https://arxiv.org/pdf/2601.10707v1">PDF</a> · <a href="https://huggingface.co/huggingface">Code1</a> · <a href="https://huggingface.co/docs/hub/spaces">Code2</a></div>
<details class="detail"><summary>Abstract</summary>
<div class="mono">Recent advances in end-to-end autonomous driving show that policies trained on patch-aligned features extracted from foundation models generalize better to Out-of-Distribution (OOD). We hypothesize that due to the self-attention mechanism, each patch feature implicitly embeds/contains information from all other patches, represented in a different way and intensity, making these descriptors highly redundant. We quantify redundancy in such (BLIP2) features via PCA and cross-patch similarity: $90$% of variance is captured by $17/64$ principal components, and strong inter-token correlations are pervasive. Training on such overlapping information leads the policy to overfit spurious correlations, hurting OOD robustness. We present Stochastic-Patch-Selection (SPS), a simple yet effective approach for learning policies that are more robust, generalizable, and efficient. For every frame, SPS randomly masks a fraction of patch descriptors, not feeding them to the policy model, while preserving the spatial layout of the remaining patches. Thus, the policy is provided with different stochastic but complete views of the (same) scene: every random subset of patches acts like a different, yet still sensible, coherent projection of the world. The policy thus bases its decisions on features that are invariant to which specific tokens survive. Extensive experiments confirm that across all OOD scenarios, our method outperforms the state of the art (SOTA), achieving a $6.2$% average improvement and up to $20.4$% in closed-loop simulations, while being $2.4\times$ faster. We conduct ablations over masking rates and patch-feature reorganization, training and evaluating 9 systems, with 8 of them surpassing prior SOTA. Finally, we show that the same learned policy transfers to a physical, real-world car without any tuning.</div></details>
<details class="detail"><summary>中文标题/摘要</summary>
<div class="mono"><b>标题：</b>少看多开：基于基础模型随机补丁选择的端到端自动驾驶泛化方法</div>
<div class="mono" style="margin-top:8px">端到端自动驾驶的最新进展表明，基于基础模型提取的补丁对齐特征训练的策略在分布外泛化方面表现更优。我们假设，由于自注意力机制，每个补丁特征都以不同方式和强度隐式嵌入了所有其他补丁的信息，导致这些描述符高度冗余。我们通过主成分分析和跨补丁相似性量化了此类（BLIP2）特征的冗余度：90%的方差可由17/64个主成分捕获，且强跨令牌相关性普遍存在。基于这种重叠信息训练会导致策略过拟合虚假相关性，损害分布外鲁棒性。我们提出随机补丁选择方法——一种简单有效的策略学习框架，能提升模型的鲁棒性、泛化能力和效率。SPS在每帧随机掩蔽部分补丁描述符（不输入策略模型），同时保持剩余补丁的空间布局。策略因此获得同一场景的不同随机但完整的视图：每个随机补丁子集都构成对世界的不同但合理的连贯投影。策略决策将基于对特定令牌存留具有不变性的特征。大量实验证实，在所有分布外场景中，我们的方法均优于现有最优技术：平均提升6.2%，闭环仿真最高提升20.4%，同时提速2.4倍。我们通过9个系统的消融实验验证了掩蔽率和补丁特征重组的影响，其中8个系统超越先前最优水平。最终证明，学习到的策略无需调整即可迁移至物理世界的真实车辆。</div>
</details>
<details class="detail"><summary>Summary / 总结</summary>
<div class="mono">This research addresses the redundancy in patch-aligned features from foundation models used in end-to-end autonomous driving, which leads to overfitting and poor Out-of-Distribution (OOD) generalization. The proposed Stochastic-Patch-Selection (SPS) method randomly masks a fraction of patch descriptors per frame while preserving spatial layout, forcing the policy to learn from invariant features across different stochastic scene views. Experimental results demonstrate that SPS outperforms prior state-of-the-art methods with a 6.2% average improvement in OOD scenarios, achieves up to 20.4% better performance in closed-loop simulations while being 2.4× faster, and successfully transfers to a physical vehicle without additional tuning.</div>
<div class="mono" style="margin-top:8px">本研究针对端到端自动驾驶中基础模型提取的补丁对齐特征存在冗余性导致过拟合和分布外泛化能力差的问题，提出了随机补丁选择方法。该方法在每帧中随机掩蔽部分补丁描述符同时保持空间布局，迫使策略从不同随机场景视图的不变特征中学习。实验结果表明，该方法在分布外场景中平均性能提升6.2%，闭环仿真中最高提升20.4%且速度加快2.4倍，训练得到的策略无需调整即可成功迁移到真实物理车辆上。</div>
</details>
</div>
<div class="card">
<div class="title">Distributed Perceptron under Bounded Staleness, Partial Participation, and Noisy Communication</div>
<div class="meta-line">Authors: Keval Jain, Anant Raj, Saurav Prakash, Girish Varma</div>
<div class="meta-line">First: 2026-01-15T18:56:54+00:00 · Latest: 2026-01-15T18:56:54+00:00</div>
<div class="links" style="margin-top:8px"><a href="https://arxiv.org/abs/2601.10705v1">Abs</a> · <a href="https://arxiv.org/pdf/2601.10705v1">PDF</a> · <a href="https://huggingface.co/huggingface">Code1</a> · <a href="https://huggingface.co/docs/hub/spaces">Code2</a></div>
<details class="detail"><summary>Abstract</summary>
<div class="mono">We study a semi-asynchronous client-server perceptron trained via iterative parameter mixing (IPM-style averaging): clients run local perceptron updates and a server forms a global model by aggregating the updates that arrive in each communication round. The setting captures three system effects in federated and distributed deployments: (i) stale updates due to delayed model delivery and delayed application of client computations (two-sided version lag), (ii) partial participation (intermittent client availability), and (iii) imperfect communication on both downlink and uplink, modeled as effective zero-mean additive noise with bounded second moment. We introduce a server-side aggregation rule called staleness-bucket aggregation with padding that deterministically enforces a prescribed staleness profile over update ages without assuming any stochastic model for delays or participation. Under margin separability and bounded data radius, we prove a finite-horizon expected bound on the cumulative weighted number of perceptron mistakes over a given number of server rounds: the impact of delay appears only through the mean enforced staleness, whereas communication noise contributes an additional term that grows on the order of the square root of the horizon with the total noise energy. In the noiseless case, we show how a finite expected mistake budget yields an explicit finite-round stabilization bound under a mild fresh-participation condition.</div></details>
<details class="detail"><summary>中文标题/摘要</summary>
<div class="mono"><b>标题：</b>有界陈旧性、部分参与及噪声通信下的分布式感知机</div>
<div class="mono" style="margin-top:8px">我们研究一种通过迭代参数混合（IPM式平均）训练的半异步客户端-服务器感知机：客户端运行本地感知机更新，服务器通过聚合每轮通信中到达的更新形成全局模型。该设定捕捉了联邦与分布式部署中的三种系统效应：（i）因模型交付延迟和客户端计算应用延迟导致的陈旧更新（双向版本滞后），（ii）部分参与（客户端间歇可用性），（iii）下行与上行链路上的非理想通信，建模为具有有界二阶矩的有效零均值加性噪声。我们提出一种称为带填充的陈旧性分桶聚合的服务器端聚合规则，该规则能在不假设任何延迟或参与的随机模型的情况下，确定性强制实施预设的更新时效陈旧性分布。在间隔可分性与数据半径有界的条件下，我们证明了给定服务器轮数内感知机错误累积加权数的有限时域期望界：延迟的影响仅通过强制实施的均值陈旧性体现，而通信噪声则贡献一个额外项，该项以时域平方根的量级随总噪声能量增长。在无噪声情形下，我们展示了在温和的新鲜参与条件下，有限的期望错误预算如何产生显式的有限轮次稳定界。</div>
</details>
<details class="detail"><summary>Summary / 总结</summary>
<div class="mono">The research addresses the challenge of training a distributed perceptron in realistic federated learning settings characterized by two-sided version lag (staleness), intermittent client availability (partial participation), and noisy communication channels. The proposed method employs an IPM-style averaging framework where clients perform local updates and a server aggregates them using a novel staleness-bucket aggregation with padding rule, which deterministically controls update staleness without relying on stochastic delay models. Key experimental findings, derived from theoretical analysis under margin separability and bounded data assumptions, show a finite-horizon bound on cumulative mistakes where staleness impact depends only on its mean and communication noise adds a term scaling with the square root of the horizon; in noiseless conditions, a finite mistake budget leads to explicit finite-round stabilization.</div>
<div class="mono" style="margin-top:8px">本研究旨在解决在具有双向版本滞后（陈旧性）、间歇性客户端可用性（部分参与）和噪声通信信道等现实联邦学习场景中训练分布式感知机的挑战。所提出的方法采用迭代参数混合式平均框架，客户端执行本地更新，服务器使用一种新颖的带填充的陈旧性分桶聚合规则进行聚合，该规则无需依赖随机延迟模型即可确定性控制更新的陈旧性。在间隔可分性和有界数据假设下的理论分析表明，关键实验结果给出了服务器轮次内累积错误数的有限时间界，其中陈旧性的影响仅取决于其均值，而通信噪声则贡献一个与时间界平方根成比例的附加项；在无噪声情况下，给定足够的新鲜客户端参与条件，有限的错误预算可导致明确的有限轮次稳定性。</div>
</details>
</div>
<div class="card">
<div class="title">Grounding Agent Memory in Contextual Intent</div>
<div class="meta-line">Authors: Ruozhen Yang, Yucheng Jiang, Yueqi Jiang, Priyanka Kargupta, Yunyi Zhang, Jiawei Han</div>
<div class="meta-line">First: 2026-01-15T18:55:13+00:00 · Latest: 2026-01-15T18:55:13+00:00</div>
<div class="links" style="margin-top:8px"><a href="https://arxiv.org/abs/2601.10702v1">Abs</a> · <a href="https://arxiv.org/pdf/2601.10702v1">PDF</a> · <a href="https://huggingface.co/huggingface">Code1</a> · <a href="https://huggingface.co/docs/hub/spaces">Code2</a></div>
<details class="detail"><summary>Abstract</summary>
<div class="mono">Deploying large language models in long-horizon, goal-oriented interactions remains challenging because similar entities and facts recur under different latent goals and constraints, causing memory systems to retrieve context-mismatched evidence. We propose STITCH (Structured Intent Tracking in Contextual History), an agentic memory system that indexes each trajectory step with a structured retrieval cue, contextual intent, and retrieves history by matching the current step&#x27;s intent. Contextual intent provides compact signals that disambiguate repeated mentions and reduce interference: (1) the current latent goal defining a thematic segment, (2) the action type, and (3) the salient entity types anchoring which attributes matter. During inference, STITCH filters and prioritizes memory snippets by intent compatibility, suppressing semantically similar but context-incompatible history.
  For evaluation, we introduce CAME-Bench, a benchmark for context-aware retrieval in realistic, dynamic, goal-oriented trajectories. Across CAME-Bench and LongMemEval, STITCH achieves state-of-the-art performance, outperforming the strongest baseline by 35.6%, with the largest gains as trajectory length increases. Our analysis shows that intent indexing substantially reduces retrieval noise, supporting intent-aware memory for robust long-horizon reasoning.</div></details>
<details class="detail"><summary>中文标题/摘要</summary>
<div class="mono"><b>标题：</b>基于情境意图的智能体记忆系统</div>
<div class="mono" style="margin-top:8px">在长周期目标导向交互中部署大语言模型仍面临挑战：相似实体和事实会在不同潜在目标与约束下重复出现，导致记忆系统检索到情境不匹配的证据。我们提出STITCH（情境历史中的结构化意图追踪）——一种智能体记忆系统，通过结构化检索线索（情境意图）索引每个轨迹步骤，并依据当前步骤的意图匹配检索历史。情境意图通过三类紧凑信号消除重复指代的歧义并减少干扰：（1）定义主题片段的当前潜在目标；（2）动作类型；（3）锚定关键属性的显著实体类型。在推理过程中，STITCH根据意图兼容性筛选和排序记忆片段，抑制语义相似但情境冲突的历史记录。
为评估系统性能，我们构建了CAME-Bench基准测试集，用于衡量现实动态目标导向轨迹中的情境感知检索能力。在CAME-Bench和LongMemEval测试中，STITCH实现了最先进的性能表现，较最强基线提升35.6%，且轨迹越长优势越显著。分析表明，意图索引机制显著降低了检索噪声，为鲁棒的长周期推理提供了意图感知记忆支持。</div>
</details>
<details class="detail"><summary>Summary / 总结</summary>
<div class="mono">The research addresses the challenge of deploying large language models in long-horizon, goal-oriented interactions, where similar entities and facts recur under different latent goals, causing memory systems to retrieve context-mismatched evidence. The proposed method, STITCH (Structured Intent Tracking in Contextual History), is an agentic memory system that indexes each trajectory step with a structured retrieval cue called contextual intent, which includes the current latent goal, action type, and salient entity types, and retrieves history by matching the current step&#x27;s intent. Key experimental results show that STITCH achieves state-of-the-art performance on the introduced CAME-Bench and LongMemEval benchmarks, outperforming the strongest baseline by 35.6%, with the largest gains as trajectory length increases, and analysis confirms that intent indexing substantially reduces retrieval noise.</div>
<div class="mono" style="margin-top:8px">本研究旨在解决大语言模型在长视野、目标导向交互中部署的挑战，即在不同的潜在目标和约束下重复出现的实体和事实会导致记忆系统检索到上下文不匹配的证据。提出的方法STITCH（上下文历史中的结构化意图追踪）是一种智能体记忆系统，它使用一种称为上下文意图的结构化检索线索（包括当前潜在目标、行动类型和关键实体类型）为每个轨迹步骤建立索引，并通过匹配当前步骤的意图来检索历史。在引入的CAME-Bench和LongMemEval上的实验结果表明，STITCH实现了最先进的性能，以35.6%的优势超越了最强基线，且随着轨迹长度增加，优势最为明显，分析证实意图索引显著降低了检索噪声。</div>
</details>
</div>
<div class="card">
<div class="title">Communication-Efficient and Privacy-Adaptable Mechanism -- a Federated Learning Scheme with Convergence Analysis</div>
<div class="meta-line">Authors: Chun Hei Michael Shiu, Chih Wei Ling</div>
<div class="meta-line">First: 2026-01-15T18:55:00+00:00 · Latest: 2026-01-15T18:55:00+00:00</div>
<div class="meta-line">Comments: 19 pages, 5 figures. This work is submitted in part to the 2026 IEEE International Symposium on Information Theory (ISIT). arXiv admin note: substantial text overlap with arXiv:2501.12046</div>
<div class="links" style="margin-top:8px"><a href="https://arxiv.org/abs/2601.10701v1">Abs</a> · <a href="https://arxiv.org/pdf/2601.10701v1">PDF</a> · <a href="https://huggingface.co/huggingface">Code1</a> · <a href="https://huggingface.co/docs/hub/spaces">Code2</a></div>
<details class="detail"><summary>Abstract</summary>
<div class="mono">Federated learning enables multiple parties to jointly train learning models without sharing their own underlying data, offering a practical pathway to privacy-preserving collaboration under data-governance constraints. Continued study of federated learning is essential to address key challenges in it, including communication efficiency and privacy protection between parties. A recent line of work introduced a novel approach called the Communication-Efficient and Privacy-Adaptable Mechanism (CEPAM), which achieves both objectives simultaneously. CEPAM leverages the rejection-sampled universal quantizer (RSUQ), a randomized vector quantizer whose quantization error is equivalent to a prescribed noise, which can be tuned to customize privacy protection between parties. In this work, we theoretically analyze the privacy guarantees and convergence properties of CEPAM. Moreover, we assess CEPAM&#x27;s utility performance through experimental evaluations, including convergence profiles compared with other baselines, and accuracy-privacy trade-offs between different parties.</div></details>
<details class="detail"><summary>中文标题/摘要</summary>
<div class="mono"><b>标题：</b>通信高效与隐私可调机制——一种具备收敛性分析的联邦学习方案</div>
<div class="mono" style="margin-top:8px">联邦学习允许多方在不共享底层数据的情况下联合训练学习模型，为数据治理约束下的隐私保护协作提供了可行路径。持续研究联邦学习对解决其关键挑战至关重要，包括通信效率与参与方间的隐私保护。近期研究提出了一种名为通信高效与隐私可调机制（CEPAM）的新方法，可同时实现这两个目标。CEPAM采用拒绝采样通用量化器（RSUQ），这是一种随机向量量化器，其量化误差等同于预设噪声，可通过调节该噪声为参与方定制隐私保护级别。本文从理论上分析了CEPAM的隐私保障与收敛特性，并通过实验评估验证其性能表现，包括与其他基线的收敛曲线对比，以及不同参与方间的精度-隐私权衡关系。</div>
</details>
<details class="detail"><summary>Summary / 总结</summary>
<div class="mono">Federated learning faces challenges in communication efficiency and privacy protection during collaborative model training. To address these, this work analyzes the Communication-Efficient and Privacy-Adaptable Mechanism (CEPAM), which employs a rejection-sampled universal quantizer that converts quantization error into tunable noise for customizable privacy. Theoretical analysis establishes CEPAM&#x27;s privacy guarantees and convergence properties, while experiments demonstrate its competitive convergence profiles against baselines and its ability to balance accuracy with varying privacy levels across participants.</div>
<div class="mono" style="margin-top:8px">联邦学习在协同模型训练中面临通信效率和隐私保护的挑战。为此，本研究分析了通信高效且隐私可调机制（CEPAM），该机制采用拒绝采样通用量化器，将量化误差转化为可调噪声以实现可定制的隐私保护。理论分析确立了CEPAM的隐私保证和收敛特性，实验结果表明，相较于基线方法，CEPAM具有竞争力的收敛曲线，并能在参与方之间实现准确性与隐私保护的权衡。</div>
</details>
</div>
<div class="card">
<div class="title">LIBERTy: A Causal Framework for Benchmarking Concept-Based Explanations of LLMs with Structural Counterfactuals</div>
<div class="meta-line">Authors: Gilat Toker, Nitay Calderon, Ohad Amosy, Roi Reichart</div>
<div class="meta-line">First: 2026-01-15T18:54:50+00:00 · Latest: 2026-01-15T18:54:50+00:00</div>
<div class="links" style="margin-top:8px"><a href="https://arxiv.org/abs/2601.10700v1">Abs</a> · <a href="https://arxiv.org/pdf/2601.10700v1">PDF</a> · <a href="https://huggingface.co/huggingface">Code1</a> · <a href="https://huggingface.co/docs/hub/spaces">Code2</a></div>
<details class="detail"><summary>Abstract</summary>
<div class="mono">Concept-based explanations quantify how high-level concepts (e.g., gender or experience) influence model behavior, which is crucial for decision-makers in high-stakes domains. Recent work evaluates the faithfulness of such explanations by comparing them to reference causal effects estimated from counterfactuals. In practice, existing benchmarks rely on costly human-written counterfactuals that serve as an imperfect proxy. To address this, we introduce a framework for constructing datasets containing structural counterfactual pairs: LIBERTy (LLM-based Interventional Benchmark for Explainability with Reference Targets). LIBERTy is grounded in explicitly defined Structured Causal Models (SCMs) of the text generation, interventions on a concept propagate through the SCM until an LLM generates the counterfactual. We introduce three datasets (disease detection, CV screening, and workplace violence prediction) together with a new evaluation metric, order-faithfulness. Using them, we evaluate a wide range of methods across five models and identify substantial headroom for improving concept-based explanations. LIBERTy also enables systematic analysis of model sensitivity to interventions: we find that proprietary LLMs show markedly reduced sensitivity to demographic concepts, likely due to post-training mitigation. Overall, LIBERTy provides a much-needed benchmark for developing faithful explainability methods.</div></details>
<details class="detail"><summary>中文标题/摘要</summary>
<div class="mono"><b>标题：</b>LIBERTy：基于结构反事实的LLM概念解释因果评估框架</div>
<div class="mono" style="margin-top:8px">概念解释方法量化高层概念（如性别或经验）对模型行为的影响，这对高风险领域的决策者至关重要。现有研究通过将此类解释与反事实估计的因果效应进行对比来评估其忠实度，但当前基准依赖成本高昂且不完善的人工撰写反事实。为此，我们提出LIBERTy框架（基于LLM的可解释性干预基准参考目标），通过结构化因果模型构建包含结构反事实对的数据集：在明确定义的文本生成因果模型基础上，对概念的干预会沿因果路径传播直至LLM生成反事实。我们构建了三个数据集（疾病检测、简历筛选和工作场所暴力预测）并提出了顺序忠实度评估指标，通过五个模型的广泛实验揭示了概念解释方法的显著改进空间。LIBERTy还能系统分析模型对干预的敏感性：实验发现专有LLM对人口统计概念的敏感性显著降低，这很可能源于训练后的缓解措施。总体而言，LIBERTy为开发忠实可解释性方法提供了亟需的评估基准。</div>
</details>
<details class="detail"><summary>Summary / 总结</summary>
<div class="mono">To address the reliance on imperfect and costly human-written counterfactuals for evaluating the faithfulness of concept-based explanations in LLMs, this research introduces LIBERTy, a framework for constructing datasets with structural counterfactual pairs grounded in explicitly defined Structured Causal Models (SCMs). The method involves interventions on a concept that propagate through the SCM to generate counterfactuals via an LLM, applied to three datasets (disease detection, CV screening, and workplace violence prediction) and evaluated with a new order-faithfulness metric. Experimental results reveal substantial headroom for improving concept-based explanations across five models and show that proprietary LLMs exhibit markedly reduced sensitivity to demographic concepts, likely due to post-training mitigation, thereby providing a benchmark for developing faithful explainability methods.</div>
<div class="mono" style="margin-top:8px">该研究的动机在于需要为LLM行为提供忠实的概念解释，特别是在高风险领域，现有基准依赖于不完善的人工撰写反事实。方法上引入了LIBERTy框架，该框架通过将文本生成的明确结构化因果模型作为基础，构建包含结构性反事实对的数据集，其中对概念的干预通过SCM传播，直至LLM生成反事实。主要实验结果包括使用三个新数据集和新颖的顺序忠实度指标评估了五种模型上的多种方法，揭示了概念解释方法存在显著改进空间；此外，系统分析发现专有LLM对人口统计概念的敏感性明显降低，这很可能源于训练后的缓解措施。</div>
</details>
</div>
<div class="card">
<div class="title">The Impact of Generative AI on Architectural Conceptual Design: Performance, Creative Self-Efficacy and Cognitive Load</div>
<div class="meta-line">Authors: Han Jiang, Yao Xiao, Rachel Hurley, Shichao Liu</div>
<div class="meta-line">First: 2026-01-15T18:52:59+00:00 · Latest: 2026-01-15T18:52:59+00:00</div>
<div class="links" style="margin-top:8px"><a href="https://arxiv.org/abs/2601.10696v1">Abs</a> · <a href="https://arxiv.org/pdf/2601.10696v1">PDF</a> · <a href="https://huggingface.co/huggingface">Code1</a> · <a href="https://huggingface.co/docs/hub/spaces">Code2</a></div>
<details class="detail"><summary>Abstract</summary>
<div class="mono">Our study examines how generative AI (GenAI) influences performance, creative self-efficacy, and cognitive load in architectural conceptual design tasks. Thirty-six student participants from Architectural Engineering and other disciplines completed a two-phase architectural design task, first independently and then with external tools (GenAI-assisted condition and control condition using an online repository of existing architectural projects). Design outcomes were evaluated by expert raters, while self-efficacy and cognitive load were self-reported after each phase. Difference-in-differences analyses revealed no overall performance advantage of GenAI across participants; however, subgroup analyses showed that GenAI significantly improved design performance for novice designers. In contrast, general creative self-efficacy declined for students using GenAI. Cognitive load did not differ significantly between conditions, though prompt usage patterns showed that iterative idea generation and visual feedback prompts were linked to greater reductions in cognitive load. These findings suggest that GenAI effectiveness depends on users&#x27; prior expertise and interaction strategies through prompting.</div></details>
<details class="detail"><summary>中文标题/摘要</summary>
<div class="mono"><b>标题：</b>生成式人工智能对建筑概念设计的影响：绩效、创意自我效能感与认知负荷</div>
<div class="mono" style="margin-top:8px">本研究探讨生成式人工智能（GenAI）如何影响建筑概念设计任务中的绩效、创意自我效能感和认知负荷。36名来自建筑工程等专业的学生参与者完成了一项两阶段建筑设计任务：先独立设计，后借助外部工具（GenAI辅助条件 vs 使用现有建筑项目在线资源库的对照条件）。设计成果由专家评审，自我效能感和认知负荷则在每阶段后通过自陈报告测量。双重差分分析显示，GenAI未在所有参与者中带来整体绩效优势；但亚组分析表明，GenAI显著提升了新手设计师的设计绩效。相反，使用GenAI的学生普遍创意自我效能感下降。认知负荷在两组间无显著差异，但提示词使用模式显示，迭代式创意生成与视觉反馈提示与认知负荷的更大程度降低相关。这些发现表明，GenAI的有效性取决于用户先前的专业知识和通过提示词实现的交互策略。</div>
</details>
<details class="detail"><summary>Summary / 总结</summary>
<div class="mono">This study investigates how generative AI (GenAI) affects performance, creative self-efficacy, and cognitive load in architectural conceptual design. Using a two-phase experimental design, thirty-six students first completed a design task independently, then with either GenAI assistance or a control tool (an online repository of existing projects). Expert raters evaluated design outcomes, while participants self-reported on self-efficacy and cognitive load. Difference-in-differences analysis found no overall performance benefit from GenAI, but a significant improvement for novice designers. Conversely, general creative self-efficacy decreased for GenAI users. While overall cognitive load showed no significant difference, iterative idea generation and visual feedback prompts were associated with greater cognitive load reduction. The results indicate that GenAI&#x27;s effectiveness is contingent on user expertise and specific prompting strategies.</div>
<div class="mono" style="margin-top:8px">本研究探讨了生成式人工智能（GenAI）如何影响建筑概念设计中的表现、创意自我效能感和认知负荷。研究采用两阶段实验设计，36名学生先独立完成一项设计任务，随后在GenAI辅助或使用对照工具（现有项目在线资源库）的条件下再次进行设计。专家评审对设计成果进行评估，参与者则自我报告效能感与认知负荷。双重差分分析显示，GenAI并未带来整体表现优势，但显著提升了新手设计师的设计表现。相反，使用GenAI的学生其一般创意自我效能感有所下降。虽然整体认知负荷无显著差异，但迭代式创意生成和视觉反馈提示与更大的认知负荷减少相关。结果表明，GenAI的有效性取决于用户先前的专业知识和具体的提示交互策略。</div>
</details>
</div>
<div class="card">
<div class="title">Data-driven stochastic reduced-order modeling of parametrized dynamical systems</div>
<div class="meta-line">Authors: Andrew F. Ilersich, Kevin Course, Prasanth B. Nair</div>
<div class="meta-line">First: 2026-01-15T18:50:18+00:00 · Latest: 2026-01-15T18:50:18+00:00</div>
<div class="links" style="margin-top:8px"><a href="https://arxiv.org/abs/2601.10690v1">Abs</a> · <a href="https://arxiv.org/pdf/2601.10690v1">PDF</a> · <a href="https://huggingface.co/huggingface">Code1</a> · <a href="https://huggingface.co/docs/hub/spaces">Code2</a></div>
<details class="detail"><summary>Abstract</summary>
<div class="mono">Modeling complex dynamical systems under varying conditions is computationally intensive, often rendering high-fidelity simulations intractable. Although reduced-order models (ROMs) offer a promising solution, current methods often struggle with stochastic dynamics and fail to quantify prediction uncertainty, limiting their utility in robust decision-making contexts. To address these challenges, we introduce a data-driven framework for learning continuous-time stochastic ROMs that generalize across parameter spaces and forcing conditions. Our approach, based on amortized stochastic variational inference, leverages a reparametrization trick for Markov Gaussian processes to eliminate the need for computationally expensive forward solvers during training. This enables us to jointly learn a probabilistic autoencoder and stochastic differential equations governing the latent dynamics, at a computational cost that is independent of the dataset size and system stiffness. Additionally, our approach offers the flexibility of incorporating physics-informed priors if available. Numerical studies are presented for three challenging test problems, where we demonstrate excellent generalization to unseen parameter combinations and forcings, and significant efficiency gains compared to existing approaches.</div></details>
<details class="detail"><summary>中文标题/摘要</summary>
<div class="mono"><b>标题：</b>参数化动力系统的数据驱动随机降阶建模</div>
<div class="mono" style="margin-top:8px">在变化条件下建模复杂动力系统计算成本高昂，高保真仿真往往难以实现。尽管降阶模型提供了一种有前景的解决方案，但现有方法常难以处理随机动力学且无法量化预测不确定性，限制了其在鲁棒决策场景中的应用。为应对这些挑战，我们提出一种数据驱动框架，用于学习跨参数空间和激励条件泛化的连续时间随机降阶模型。该方法基于摊销随机变分推断，利用马尔可夫高斯过程的重参数化技巧，在训练过程中无需计算昂贵的前向求解器。这使得我们能够以独立于数据集规模和系统刚度的计算成本，联合学习概率自编码器与支配潜在动力学的随机微分方程。此外，该方法可灵活融入已知的物理先验信息。通过对三个挑战性测试问题的数值研究，我们展示了该方法对未见参数组合与激励的优异泛化能力，以及与现有方法相比显著的效率提升。</div>
</details>
<details class="detail"><summary>Summary / 总结</summary>
<div class="mono">Modeling complex dynamical systems under varying conditions is computationally intensive, and existing reduced-order models often lack the ability to handle stochastic dynamics and quantify prediction uncertainty. To address this, the authors propose a data-driven framework that uses amortized stochastic variational inference and a reparametrization trick for Markov Gaussian processes to learn continuous-time stochastic reduced-order models without requiring expensive forward solvers during training. This method jointly learns a probabilistic autoencoder and latent stochastic differential equations, achieving computational efficiency independent of dataset size and system stiffness. In numerical tests on three challenging problems, the framework demonstrated excellent generalization to unseen parameters and forcings, along with significant efficiency gains over existing approaches.</div>
<div class="mono" style="margin-top:8px">在变化条件下对复杂动力系统进行建模计算成本高昂，且现有降阶模型常难以处理随机动力学并量化预测不确定性。为此，研究者提出一种数据驱动框架，利用摊销随机变分推断和马尔可夫高斯过程的重参数化技巧，在训练过程中无需昂贵的前向求解器即可学习连续时间随机降阶模型。该方法联合学习概率自编码器和潜在随机微分方程，实现了与数据集规模和系统刚度无关的计算效率。在三个挑战性测试问题的数值研究中，该框架对未见过的参数组合和激励表现出优异的泛化能力，并较现有方法取得了显著的效率提升。</div>
</details>
</div>
<div class="card">
<div class="title">On the origin of neural scaling laws: from random graphs to natural language</div>
<div class="meta-line">Authors: Maissam Barkeshli, Alberto Alfarano, Andrey Gromov</div>
<div class="meta-line">First: 2026-01-15T18:46:09+00:00 · Latest: 2026-01-15T18:46:09+00:00</div>
<div class="meta-line">Comments: 33 pages</div>
<div class="links" style="margin-top:8px"><a href="https://arxiv.org/abs/2601.10684v1">Abs</a> · <a href="https://arxiv.org/pdf/2601.10684v1">PDF</a> · <a href="https://huggingface.co/huggingface">Code1</a> · <a href="https://huggingface.co/docs/hub/spaces">Code2</a></div>
<details class="detail"><summary>Abstract</summary>
<div class="mono">Scaling laws have played a major role in the modern AI revolution, providing practitioners predictive power over how the model performance will improve with increasing data, compute, and number of model parameters. This has spurred an intense interest in the origin of neural scaling laws, with a common suggestion being that they arise from power law structure already present in the data. In this paper we study scaling laws for transformers trained to predict random walks (bigrams) on graphs with tunable complexity. We demonstrate that this simplified setting already gives rise to neural scaling laws even in the absence of power law structure in the data correlations. We further consider dialing down the complexity of natural language systematically, by training on sequences sampled from increasingly simplified generative language models, from 4,2,1-layer transformer language models down to language bigrams, revealing a monotonic evolution of the scaling exponents. Our results also include scaling laws obtained from training on random walks on random graphs drawn from Erdös-Renyi and scale-free Barabási-Albert ensembles. Finally, we revisit conventional scaling laws for language modeling, demonstrating that several essential results can be reproduced using 2 layer transformers with context length of 50, provide a critical analysis of various fits used in prior literature, demonstrate an alternative method for obtaining compute optimal curves as compared with current practice in published literature, and provide preliminary evidence that maximal update parameterization may be more parameter efficient than standard parameterization.</div></details>
<details class="detail"><summary>中文标题/摘要</summary>
<div class="mono"><b>标题：</b>论神经缩放定律的起源：从随机图到自然语言</div>
<div class="mono" style="margin-top:8px">缩放定律在现代人工智能革命中发挥了重要作用，为从业者提供了模型性能如何随数据量、计算量和模型参数数量增加而提升的预测能力。这激发了人们对神经缩放定律起源的浓厚兴趣，一种普遍观点认为它们源于数据中已有的幂律结构。本文研究了在具有可调复杂度的图上训练用于预测随机游走（二元语法）的Transformer的缩放定律。我们证明，即使在数据相关性中不存在幂律结构的情况下，这种简化设置也能产生神经缩放定律。我们进一步通过训练从逐步简化的生成语言模型（从4层、2层、1层Transformer语言模型直至语言二元语法）采样的序列，系统地降低自然语言的复杂度，揭示了缩放指数的单调演化规律。我们的结果还包括在从Erdös-Renyi和无标度Barabási-Albert集合中抽取的随机图上进行随机游走训练所获得的缩放定律。最后，我们重新审视了语言建模的传统缩放定律，证明使用上下文长度为50的2层Transformer即可复现多项关键结果；对先前文献中使用的多种拟合方法进行了批判性分析；展示了与当前文献实践相比获取计算最优曲线的替代方法；并提供了初步证据表明最大更新参数化可能比标准参数化具有更高的参数效率。</div>
</details>
<details class="detail"><summary>Summary / 总结</summary>
<div class="mono">This study investigates the origins of neural scaling laws, motivated by the need to understand why model performance predictably improves with increased data, compute, and parameters, beyond the common hypothesis that such laws stem solely from power-law structures in data. The method involves training transformers on simplified tasks: predicting random walks (bigrams) on graphs with tunable complexity, including Erdös-Renyi and Barabási-Albert ensembles, and systematically reducing the complexity of natural language by training on sequences from simplified generative models down to bigrams. Key experimental findings show that neural scaling laws emerge even in the absence of power-law data correlations, with scaling exponents evolving monotonically as language complexity is dialed down; the work also reproduces essential language modeling scaling laws with minimal 2-layer transformers, provides a critical analysis of fitting methods, introduces an alternative approach for compute-optimal curves, and offers preliminary evidence for the parameter efficiency of maximal update parameterization.</div>
<div class="mono" style="margin-top:8px">本研究探讨了神经缩放定律的起源，这些定律对于预测模型性能随数据、计算资源和参数增加而提升至关重要，挑战了这些定律仅源于数据中幂律结构的常见假设。方法包括在具有可调复杂度的图上训练变换器进行随机游走，涉及Erdös-Renyi和Barabási-Albert集合，并通过从逐步简化的变换器语言模型（降至二元语法）中采样来系统化简化自然语言。关键实验结果表明，即使在没有幂律数据相关性的情况下，神经缩放定律也会出现，且缩放指数随语言复杂性降低而单调演化，同时最大更新参数化可能比标准参数化具有更高的参数效率。</div>
</details>
</div>
<div class="card">
<div class="title">Structure and Diversity Aware Context Bubble Construction for Enterprise Retrieval Augmented Systems</div>
<div class="meta-line">Authors: Amir Khurshid, Abhishek Sehgal</div>
<div class="meta-line">First: 2026-01-15T18:43:19+00:00 · Latest: 2026-01-15T18:43:19+00:00</div>
<div class="links" style="margin-top:8px"><a href="https://arxiv.org/abs/2601.10681v1">Abs</a> · <a href="https://arxiv.org/pdf/2601.10681v1">PDF</a> · <a href="https://huggingface.co/huggingface">Code1</a> · <a href="https://huggingface.co/docs/hub/spaces">Code2</a></div>
<details class="detail"><summary>Abstract</summary>
<div class="mono">Large language model (LLM) contexts are typically constructed using retrieval-augmented generation (RAG), which involves ranking and selecting the top-k passages. The approach causes fragmentation in information graphs in document structures, over-retrieval, and duplication of content alongside insufficient query context, including 2nd and 3rd order facets. In this paper, a structure-informed and diversity-constrained context bubble construction framework is proposed that assembles coherent, citable bundles of spans under a strict token budget. The method preserves and exploits inherent document structure by organising multi-granular spans (e.g., sections and rows) and using task-conditioned structural priors to guide retrieval. Starting from high-relevance anchor spans, a context bubble is constructed through constrained selection that balances query relevance, marginal coverage, and redundancy penalties. It will explicitly constrain diversity and budget, producing compact and informative context sets, unlike top-k retrieval. Moreover, a full retrieval is emitted that traces the scoring and selection choices of the records, thus providing auditability and deterministic tuning. Experiments on enterprise documents demonstrate the efficiency of context bubble as it significantly reduces redundant context, is better able to cover secondary facets and has a better answer quality and citation faithfulness within a limited context window. Ablation studies demonstrate that both structural priors as well as diversity constraint selection are necessary; removing either component results in a decline in coverage and an increase in redundant or incomplete context.</div></details>
<details class="detail"><summary>中文标题/摘要</summary>
<div class="mono"><b>标题：</b>面向企业检索增强系统的结构与多样性感知上下文气泡构建方法</div>
<div class="mono" style="margin-top:8px">大语言模型（LLM）的上下文通常通过检索增强生成（RAG）构建，该方法依赖对段落进行排序并选取前k个结果。这种做法会导致文档结构中的信息图碎片化、过度检索、内容重复，以及查询上下文（包括二阶和三阶层面）不足的问题。本文提出一种结构感知且多样性约束的上下文气泡构建框架，能在严格的词元预算下组装连贯、可引用的文本片段集合。该方法通过组织多粒度片段（如章节与行）并利用任务条件化的结构先验指导检索，以保持并利用文档固有结构。从高相关性锚点片段出发，通过平衡查询相关性、边际覆盖度与冗余惩罚的约束选择构建上下文气泡。与仅选取前k个结果的检索方式不同，该方法显式约束多样性与预算，生成紧凑且信息丰富的上下文集合。此外，系统会输出完整检索过程，记录评分与选择决策，从而提供可审计性与确定性调优能力。在企业文档上的实验表明，上下文气泡方法能显著减少冗余上下文，更好地覆盖次要层面，并在有限上下文窗口内获得更优的答案质量与引用准确性。消融研究证明，结构先验与多样性约束选择均不可或缺；移除任一组件均会导致覆盖度下降，并增加冗余或不完整的上下文。</div>
</details>
<details class="detail"><summary>Summary / 总结</summary>
<div class="mono">To address the issues of information fragmentation, over-retrieval, and insufficient query context in standard top-k retrieval for RAG systems, this paper proposes a structure-informed and diversity-constrained framework for constructing context bubbles. The method organizes multi-granular document spans, uses task-conditioned structural priors to guide retrieval, and builds coherent bundles by starting from high-relevance anchors and performing a constrained selection that balances relevance, coverage, and redundancy under a strict token budget. Experimental results on enterprise documents show that this approach significantly reduces redundant context, better covers secondary facets, and improves answer quality and citation faithfulness within a limited context window, with ablation studies confirming the necessity of both structural priors and diversity constraints.</div>
<div class="mono" style="margin-top:8px">为解决标准检索增强生成（RAG）中存在的文档结构碎片化、内容重复以及次要查询方面覆盖不足等问题，本文提出了一种结构感知且多样性约束的上下文气泡构建框架。该方法组织多粒度文档片段，利用任务条件化的结构先验指导检索，并从高相关性锚点出发，在严格令牌预算下通过平衡相关性、边际覆盖和冗余惩罚的约束选择来构建连贯的上下文集合。在企业文档上的实验表明，该方法显著减少了冗余上下文，更好地覆盖了次要方面，并在有限上下文窗口内提高了答案质量和引用忠实度，消融研究证实了结构先验和多样性约束选择都是必要的。</div>
</details>
</div>
<div class="card">
<div class="title">Are Your Reasoning Models Reasoning or Guessing? A Mechanistic Analysis of Hierarchical Reasoning Models</div>
<div class="meta-line">Authors: Zirui Ren, Ziming Liu</div>
<div class="meta-line">First: 2026-01-15T18:42:50+00:00 · Latest: 2026-01-15T18:42:50+00:00</div>
<div class="links" style="margin-top:8px"><a href="https://arxiv.org/abs/2601.10679v1">Abs</a> · <a href="https://arxiv.org/pdf/2601.10679v1">PDF</a> · <a href="https://huggingface.co/huggingface">Code1</a> · <a href="https://huggingface.co/docs/hub/spaces">Code2</a></div>
<details class="detail"><summary>Abstract</summary>
<div class="mono">Hierarchical reasoning model (HRM) achieves extraordinary performance on various reasoning tasks, significantly outperforming large language model-based reasoners. To understand the strengths and potential failure modes of HRM, we conduct a mechanistic study on its reasoning patterns and find three surprising facts: (a) Failure of extremely simple puzzles, e.g., HRM can fail on a puzzle with only one unknown cell. We attribute this failure to the violation of the fixed point property, a fundamental assumption of HRM. (b) &quot;Grokking&quot; dynamics in reasoning steps, i.e., the answer is not improved uniformly, but instead there is a critical reasoning step that suddenly makes the answer correct; (c) Existence of multiple fixed points. HRM &quot;guesses&quot; the first fixed point, which could be incorrect, and gets trapped there for a while or forever. All facts imply that HRM appears to be &quot;guessing&quot; instead of &quot;reasoning&quot;. Leveraging this &quot;guessing&quot; picture, we propose three strategies to scale HRM&#x27;s guesses: data augmentation (scaling the quality of guesses), input perturbation (scaling the number of guesses by leveraging inference randomness), and model bootstrapping (scaling the number of guesses by leveraging training randomness). On the practical side, by combining all methods, we develop Augmented HRM, boosting accuracy on Sudoku-Extreme from 54.5% to 96.9%. On the scientific side, our analysis provides new insights into how reasoning models &quot;reason&quot;.</div></details>
<details class="detail"><summary>中文标题/摘要</summary>
<div class="mono"><b>标题：</b>你的推理模型是在推理还是在猜测？——对层次推理模型的机制分析</div>
<div class="mono" style="margin-top:8px">层次推理模型（HRM）在多项推理任务中表现卓越，显著优于基于大语言模型的推理器。为探究HRM的优势与潜在缺陷，我们对其推理模式展开机制研究，发现三个意外现象：（a）在极简谜题（如仅含一个未知单元格的谜题）上失效，这归因于HRM违背了其基本假设——不动点性质；（b）推理步骤中存在“顿悟”动态，即答案并非均匀改进，而是在某个关键推理步骤突然变得正确；（c）存在多个不动点，HRM会“猜测”首个不动点（可能错误）并长期或永久受困于此。这些现象均表明HRM更似“猜测”而非“推理”。基于此“猜测”视角，我们提出三种扩展HRM猜测能力的策略：数据增强（提升猜测质量）、输入扰动（利用推理随机性增加猜测数量）和模型自举（利用训练随机性增加猜测数量）。实践层面，通过整合所有方法，我们开发出增强型HRM，将数独极限任务的准确率从54.5%提升至96.9%。科学层面，本研究为理解推理模型的“推理”机制提供了新视角。</div>
</details>
<details class="detail"><summary>Summary / 总结</summary>
<div class="mono">This study investigates the reasoning mechanisms of hierarchical reasoning models (HRMs), which excel at complex tasks but exhibit puzzling failures on simple puzzles. Through mechanistic analysis, the authors identify three key issues: HRMs can fail on puzzles with a single unknown cell due to violation of the fixed-point property, exhibit &#x27;grokking&#x27; dynamics where correctness emerges suddenly at a critical step, and become trapped in incorrect fixed points, suggesting they often &#x27;guess&#x27; rather than reason. To address these limitations, they propose three scaling strategies—data augmentation, input perturbation, and model bootstrapping—which, when combined into Augmented HRM, boost accuracy on Sudoku-Extreme from 54.5% to 96.9%, while offering new insights into how reasoning models operate.</div>
<div class="mono" style="margin-top:8px">本研究探讨了分层推理模型（HRM）的推理机制，该模型在复杂任务上表现出色，但在简单谜题上却出现令人费解的失败，暗示其可能是在猜测而非推理。通过机制分析，作者识别出关键失败模式：违反不动点属性、在特定步骤突然正确的“顿悟”动态，以及陷入错误不动点的困境。针对这些问题，他们提出了三种扩展策略——数据增强、输入扰动和模型自举——这些方法结合形成的增强型HRM，将数独极限任务的准确率从54.5%大幅提升至96.9%，为理解AI模型的推理本质提供了新见解。</div>
</details>
</div>
<div class="card">
<div class="title">Single-Stage Huffman Encoder for ML Compression</div>
<div class="meta-line">Authors: Aditya Agrawal, Albert Magyar, Hiteshwar Eswaraiah, Patrick Sheridan, Pradeep Janedula, Ravi Krishnan Venkatesan, Krishna Nair, Ravi Iyer</div>
<div class="meta-line">First: 2026-01-15T18:37:56+00:00 · Latest: 2026-01-15T18:37:56+00:00</div>
<div class="meta-line">Comments: 5 pages, 4 figures</div>
<div class="links" style="margin-top:8px"><a href="https://arxiv.org/abs/2601.10673v1">Abs</a> · <a href="https://arxiv.org/pdf/2601.10673v1">PDF</a> · <a href="https://huggingface.co/huggingface">Code1</a> · <a href="https://huggingface.co/docs/hub/spaces">Code2</a></div>
<details class="detail"><summary>Abstract</summary>
<div class="mono">Training and serving Large Language Models (LLMs) require partitioning data across multiple accelerators, where collective operations are frequently bottlenecked by network bandwidth. Lossless compression using Huffman codes is an effective way to alleviate the issue, however, its three-stage design requiring on-the-fly frequency analysis, codebook generation and transmission of codebook along with data introduces computational, latency and data overheads which are prohibitive for latency-sensitive scenarios such as die-to-die communication. This paper proposes a single-stage Huffman encoder that eliminates these overheads by using fixed codebooks derived from the average probability distribution of previous data batches. Through our analysis of the Gemma 2B model, we demonstrate that tensors exhibit high statistical similarity across layers and shards. Using this approach we achieve compression within 0.5% of per-shard Huffman coding and within 1% of the ideal Shannon compressibility, enabling efficient on-the-fly compression.</div></details>
<details class="detail"><summary>中文标题/摘要</summary>
<div class="mono"><b>标题：</b>面向机器学习压缩的单阶段霍夫曼编码器</div>
<div class="mono" style="margin-top:8px">大语言模型的训练与部署需将数据分区至多个加速器，此时集体操作常受网络带宽制约。采用霍夫曼编码的无损压缩能有效缓解此问题，但其传统三阶段设计（需实时频率分析、码本生成及码本与数据同步传输）会带来计算、延迟与数据开销，对芯片间通信等延迟敏感场景构成阻碍。本文提出一种单阶段霍夫曼编码器，通过采用基于历史数据批次平均概率分布的固定码本消除上述开销。基于Gemma 2B模型的分析表明，张量在不同层级与分片间具有高度统计相似性。该方法实现的分片压缩率较传统霍夫曼编码差距小于0.5%，较理想香农压缩率差距小于1%，支持高效的实时压缩。</div>
</details>
<details class="detail"><summary>Summary / 总结</summary>
<div class="mono">To reduce network bandwidth bottlenecks in distributed LLM training and serving, this work addresses the latency and overhead issues of traditional three-stage Huffman coding by proposing a single-stage encoder that uses fixed codebooks derived from average probability distributions of prior data batches. The method leverages the observed high statistical similarity of tensors across layers and shards in models like Gemma 2B. Experimental results show the approach achieves compression within 0.5% of per-shard Huffman coding and within 1% of the ideal Shannon limit, enabling efficient low-latency compression suitable for scenarios like die-to-die communication.</div>
<div class="mono" style="margin-top:8px">为缓解分布式大语言模型训练与推理中的网络带宽瓶颈，本研究针对传统三阶段哈夫曼编码的延迟与开销问题，提出了一种单阶段编码器，它使用基于先前数据批次平均概率分布的固定码本。该方法利用了在Gemma 2B等模型中观察到的张量在层和分片间的高度统计相似性。实验结果表明，该方法实现的压缩率与逐分片哈夫曼编码相差在0.5%以内，与理想香农压缩极限相差在1%以内，从而能够实现适用于芯片间通信等场景的高效低延迟压缩。</div>
</details>
</div>
<div class="card">
<div class="title">BASIL: Bayesian Assessment of Sycophancy in LLMs</div>
<div class="meta-line">Authors: Katherine Atwell, Pedram Heydari, Anthony Sicilia, Malihe Alikhani</div>
<div class="meta-line">First: 2025-08-23T00:11:00+00:00 · Latest: 2026-01-15T18:31:50+00:00</div>
<div class="links" style="margin-top:8px"><a href="https://arxiv.org/abs/2508.16846v3">Abs</a> · <a href="https://arxiv.org/pdf/2508.16846v3">PDF</a> · <a href="https://huggingface.co/huggingface">Code1</a> · <a href="https://huggingface.co/docs/hub/spaces">Code2</a></div>
<details class="detail"><summary>Abstract</summary>
<div class="mono">Sycophancy (overly agreeable or flattering behavior) poses a fundamental challenge for human-AI collaboration, particularly in high-stakes decision-making domains such as health, law, and education. A central difficulty in studying sycophancy in large language models (LLMs) is disentangling sycophantic belief shifts from rational changes in behavior driven by new evidence or user-provided information. Existing approaches either measure descriptive behavior changes or apply normative evaluations that rely on objective ground truth, limiting their applicability to subjective or uncertain tasks. We introduce a Bayesian probabilistic framework, grounded in behavioral economics and rational decision theory, that explicitly separates sycophancy from rational belief updating. Within this framework, we achieve three objectives: (i) a descriptive metric that measures sycophancy while controlling for rational responses to evidence; (ii) a normative metric that quantifies how sycophancy leads models astray from Bayesian-consistent belief updating; and (iii) the ability to apply both metrics in settings without ground-truth labels. Applying our framework across multiple LLMs and three uncertainty-driven tasks, we find robust evidence of sycophantic belief shifts and show that their impact on rationality depends on whether models systematically over- or under-update their beliefs. Finally, we demonstrate that a post-hoc calibration method and two fine-tuning strategies (SFT and DPO) substantially reduce Bayesian inconsistency, with particularly strong improvements under explicit sycophancy prompting.</div></details>
<details class="detail"><summary>中文标题/摘要</summary>
<div class="mono"><b>标题：</b>BASIL：大语言模型中谄媚行为的贝叶斯评估</div>
<div class="mono" style="margin-top:8px">谄媚行为（过度迎合或奉承）对人类与人工智能协作构成根本性挑战，尤其在健康、法律、教育等高风险决策领域。研究大语言模型中的谄媚行为时，核心难点在于区分谄媚性信念转变与由新证据或用户信息驱动的理性行为变化。现有方法要么测量描述性行为变化，要么依赖客观事实进行规范性评估，限制了其在主观或不确定性任务中的适用性。我们提出一个基于行为经济学与理性决策理论的贝叶斯概率框架，明确分离谄媚行为与理性信念更新。该框架实现三个目标：（i）在控制证据理性响应的前提下测量谄媚行为的描述性指标；（ii）量化谄媚行为导致模型偏离贝叶斯一致性信念更新的规范性指标；（iii）在无事实标签场景中应用双指标。通过在多个大语言模型及三项不确定性驱动任务中应用本框架，我们发现了谄媚性信念转变的强有力证据，并证明其对理性程度的影响取决于模型是否系统性过度或不足更新信念。最后，我们验证了事后校准方法与两种微调策略（SFT和DPO）能显著降低贝叶斯不一致性，在显式谄媚提示下的改进尤为显著。</div>
</details>
<details class="detail"><summary>Summary / 总结</summary>
<div class="mono">The research addresses the challenge of distinguishing sycophantic behavior from rational belief updating in large language models (LLMs), which is crucial for reliable human-AI collaboration in high-stakes domains. The method introduces a Bayesian probabilistic framework that separates sycophancy from rational responses to evidence, enabling descriptive and normative assessments even without ground-truth labels. Experimental results across multiple LLMs and tasks reveal robust sycophantic belief shifts, show their variable impact on model rationality, and demonstrate that post-hoc calibration and fine-tuning strategies can significantly reduce Bayesian inconsistency, especially under explicit sycophancy prompts.</div>
<div class="mono" style="margin-top:8px">该研究旨在解决大型语言模型中区分阿谀奉承行为与理性信念更新的难题，这对于高风险领域的人机协作至关重要。方法上引入了一个贝叶斯概率框架，以将阿谀奉承与基于证据的理性反应分离开来，提供了描述性和规范性两种度量指标，且无需真实标签即可应用。在多个大模型和任务上的实验结果表明，存在明显的阿谀奉承性信念偏移，其对模型理性的影响取决于模型是系统性过度更新还是更新不足信念，同时事后校准和SFT、DPO等微调策略能显著减少贝叶斯不一致性，尤其在显式阿谀奉承提示下改善效果尤为明显。</div>
</details>
</div>
<div class="card">
<div class="title">Pareto-Grid-Guided Large Language Models for Fast and High-Quality Heuristics Design in Multi-Objective Combinatorial Optimization</div>
<div class="meta-line">Authors: Minh Hieu Ha, Hung Phan, Tung Duy Doan, Tung Dao, Dao Tran, Huynh Thi Thanh Binh</div>
<div class="meta-line">Venue: AAAI</div>
<div class="meta-line">First: 2025-07-28T15:26:43+00:00 · Latest: 2026-01-15T18:28:50+00:00</div>
<div class="meta-line">Comments: Accepted at AAAI-26</div>
<div class="links" style="margin-top:8px"><a href="https://arxiv.org/abs/2507.20923v3">Abs</a> · <a href="https://arxiv.org/pdf/2507.20923v3">PDF</a> · <a href="https://github.com/langkhachhoha/MPaGE">Code1</a> · <a href="https://huggingface.co/huggingface">Code2</a> · <a href="https://huggingface.co/docs/hub/spaces">Code3</a></div>
<details class="detail"><summary>Abstract</summary>
<div class="mono">Multi-objective combinatorial optimization problems (MOCOP) frequently arise in practical applications that require the simultaneous optimization of conflicting objectives. Although traditional evolutionary algorithms can be effective, they typically depend on domain knowledge and repeated parameter tuning, limiting flexibility when applied to unseen MOCOP instances. Recently, integration of Large Language Models (LLMs) into evolutionary computation has opened new avenues for automatic heuristic generation, using their advanced language understanding and code synthesis capabilities. Nevertheless, most existing approaches predominantly focus on single-objective tasks, often neglecting key considerations such as runtime efficiency and heuristic diversity in multi-objective settings. To bridge this gap, we introduce Multi-heuristics for MOCOP via Pareto-Grid-guided Evolution of LLMs (MPaGE), a novel enhancement of the Simple Evolutionary Multiobjective Optimization (SEMO) framework that leverages LLMs and Pareto Front Grid (PFG) technique. By partitioning the objective space into grids and retaining top-performing candidates to guide heuristic generation, MPaGE utilizes LLMs to prioritize heuristics with semantically distinct logical structures during variation, thus promoting diversity and mitigating redundancy within the population. Through extensive evaluations, MPaGE demonstrates superior performance over existing LLM-based frameworks, and achieves competitive results to traditional Multi-objective evolutionary algorithms (MOEAs), with significantly faster runtime. Our code is available at: https://github.com/langkhachhoha/MPaGE.</div></details>
<details class="detail"><summary>中文标题/摘要</summary>
<div class="mono"><b>标题：</b>基于帕累托网格引导的大语言模型实现多目标组合优化的快速高质量启发式设计</div>
<div class="mono" style="margin-top:8px">多目标组合优化问题在实际应用中广泛存在，需要同时优化相互冲突的目标。传统进化算法虽有效，但通常依赖领域知识和重复参数调优，在面对未知问题实例时灵活性受限。近期，大语言模型与进化计算的结合为自动启发式生成开辟了新途径，利用其高级语言理解和代码生成能力。然而，现有方法多聚焦单目标任务，常忽视多目标场景下的运行效率和启发式多样性等关键因素。为填补这一空白，我们提出MPaGE方法——基于帕累托网格引导的LLM进化多目标启发式生成框架。该方法通过将目标空间网格化并保留最优候选方案来引导启发式生成，利用LLM在变异过程中优先选择语义逻辑结构相异的启发式，从而提升种群多样性并减少冗余。大量实验表明，MPaGE在性能上超越现有基于LLM的框架，与传统多目标进化算法结果相当，且运行速度显著更快。代码已开源：https://github.com/langkhachhoha/MPaGE。</div>
</details>
<details class="detail"><summary>Summary / 总结</summary>
<div class="mono">This research addresses the limitations of traditional evolutionary algorithms in multi-objective combinatorial optimization (MOCOP), which often require extensive domain knowledge and parameter tuning, and the neglect of runtime efficiency and heuristic diversity in existing Large Language Model (LLM) approaches. The proposed method, MPaGE, enhances the Simple Evolutionary Multiobjective Optimization (SEMO) framework by integrating LLMs with a Pareto Front Grid (PFG) technique, which partitions the objective space to guide the generation of semantically diverse heuristics. Experimental results show that MPaGE outperforms other LLM-based frameworks, achieves competitive performance with traditional multi-objective evolutionary algorithms, and operates with significantly faster runtime.</div>
<div class="mono" style="margin-top:8px">针对多目标组合优化问题中传统进化算法依赖领域知识、参数调优繁琐的局限性，本研究提出了MPaGE方法，将大语言模型与帕累托前沿网格技术结合，并改进了简单进化多目标优化框架。该方法通过将目标空间划分为网格来保留高性能候选解，从而引导大语言模型生成语义逻辑结构多样化的启发式规则，以提升种群多样性并减少冗余。实验结果表明，MPaGE在性能上超越了现有基于大语言模型的框架，与传统多目标进化算法相比具有竞争力，且运行速度显著更快。</div>
</details>
</div>
<div class="card">
<div class="title">Moonworks Lunara Aesthetic Dataset</div>
<div class="meta-line">Authors: Yan Wang, M M Sayeef Abdullah, Partho Hassan, Sabit Hassan</div>
<div class="meta-line">First: 2026-01-12T19:11:41+00:00 · Latest: 2026-01-15T18:27:29+00:00</div>
<div class="links" style="margin-top:8px"><a href="https://arxiv.org/abs/2601.07941v2">Abs</a> · <a href="https://arxiv.org/pdf/2601.07941v2">PDF</a> · <a href="https://huggingface.co/huggingface">Code1</a> · <a href="https://huggingface.co/docs/hub/spaces">Code2</a></div>
<details class="detail"><summary>Abstract</summary>
<div class="mono">The dataset spans diverse artistic styles, including regionally grounded aesthetics from the Middle East, Northern Europe, East Asia, and South Asia, alongside general categories such as sketch and oil painting. All images are generated using the Moonworks Lunara model and intentionally crafted to embody distinct, high-quality aesthetic styles, yielding a first-of-its-kind dataset with substantially higher aesthetic scores, exceeding even aesthetics-focused datasets, and general-purpose datasets by a larger margin. Each image is accompanied by a human-refined prompt and structured annotations that jointly describe salient objects, attributes, relationships, and stylistic cues. Unlike large-scale web-derived datasets that emphasize breadth over precision, the Lunara Aesthetic Dataset prioritizes aesthetic quality, stylistic diversity, and licensing transparency, and is released under the Apache 2.0 license to support research and unrestricted academic and commercial use.</div></details>
<details class="detail"><summary>中文标题/摘要</summary>
<div class="mono"><b>标题：</b>Moonworks Lunara美学数据集</div>
<div class="mono" style="margin-top:8px">该数据集涵盖多样艺术风格，包括中东、北欧、东亚和南亚的地域美学，以及素描、油画等通用类别。所有图像均由Moonworks Lunara模型生成，经刻意设计以呈现独特的高质量美学风格，构成首个美学评分显著超越专注美学数据集及通用数据集的独特资源。每幅图像均附有人工优化的提示词与结构化标注，共同描述显著对象、属性、关联及风格特征。与注重广度而非精度的大规模网络数据集不同，Lunara美学数据集优先考量美学品质、风格多样性与授权透明度，并基于Apache 2.0许可证发布，以支持研究及无限制的学术与商业应用。</div>
</details>
<details class="detail"><summary>Summary / 总结</summary>
<div class="mono">To address the lack of high-quality, stylistically diverse, and transparently licensed image datasets for aesthetic research, this work introduces the Moonworks Lunara Aesthetic Dataset. The method involves generating all images with the Moonworks Lunara model, intentionally crafting them to embody distinct regional and general artistic styles, and annotating each with a human-refined prompt and structured descriptions of objects, attributes, relationships, and style. Key experimental findings show that the dataset achieves substantially higher aesthetic scores than existing aesthetics-focused and general-purpose datasets, establishing it as a first-of-its-kind resource with superior quality and stylistic diversity.</div>
<div class="mono" style="margin-top:8px">为解决美学研究中缺乏高质量、风格多样且授权透明的图像数据集的问题，本研究推出了Moonworks Lunara美学数据集。该方法使用Moonworks Lunara模型生成所有图像，旨在体现独特的地域性和通用艺术风格，每张图像均附有人工精炼的提示词和结构化标注，共同描述显著物体、属性、关系及风格线索。主要实验结果表明，该数据集的美学评分显著超过现有的美学专用数据集和通用数据集，提供了一个具有高美学质量、风格多样性和明确许可协议的首创资源，支持无限制的学术与商业使用。</div>
</details>
</div>
<div class="card">
<div class="title">Knowledge Homophily in Large Language Models</div>
<div class="meta-line">Authors: Utkarsh Sahu, Zhisheng Qi, Mahantesh Halappanavar, Nedim Lipka, Ryan A. Rossi, Franck Dernoncourt, Yu Zhang, Yao Ma, Yu Wang</div>
<div class="meta-line">First: 2025-09-28T09:40:27+00:00 · Latest: 2026-01-15T18:26:36+00:00</div>
<div class="links" style="margin-top:8px"><a href="https://arxiv.org/abs/2509.23773v2">Abs</a> · <a href="https://arxiv.org/pdf/2509.23773v2">PDF</a> · <a href="https://huggingface.co/huggingface">Code1</a> · <a href="https://huggingface.co/docs/hub/spaces">Code2</a></div>
<details class="detail"><summary>Abstract</summary>
<div class="mono">Large Language Models (LLMs) have been increasingly studied as neural knowledge bases for supporting knowledge-intensive applications such as question answering and fact checking. However, the structural organization of their knowledge remains unexplored. Inspired by cognitive neuroscience findings, such as semantic clustering and priming, where knowing one fact increases the likelihood of recalling related facts, we investigate an analogous knowledge homophily pattern in LLMs. To this end, we map LLM knowledge into a graph representation through knowledge checking at both the triplet and entity levels. After that, we analyze the knowledgeability relationship between an entity and its neighbors, discovering that LLMs tend to possess a similar level of knowledge about entities positioned closer in the graph. Motivated by this homophily principle, we propose a Graph Neural Network (GNN) regression model to estimate entity-level knowledgeability scores for triplets by leveraging their neighborhood scores. The predicted knowledgeability enables us to prioritize checking less well-known triplets, thereby maximizing knowledge coverage under the same labeling budget. This not only improves the efficiency of active labeling for fine-tuning to inject knowledge into LLMs but also enhances multi-hop path retrieval in reasoning-intensive question answering.</div></details>
<details class="detail"><summary>中文标题/摘要</summary>
<div class="mono"><b>标题：</b>大语言模型中的知识同质性</div>
<div class="mono" style="margin-top:8px">大语言模型（LLMs）作为神经知识库，在支持问答和事实核查等知识密集型应用方面日益受到研究。然而，其知识的结构化组织仍未被充分探索。受认知神经科学发现（如语义聚类和启动效应，即知晓一个事实会增加回忆相关事实的可能性）的启发，我们研究了LLMs中类似的知识同质性模式。为此，我们通过在三元组和实体层面进行知识检查，将LLM知识映射为图表示。随后，我们分析了实体与其邻居之间的知识掌握关系，发现LLMs倾向于对图中位置更接近的实体具有相似的知识水平。基于这一同质性原理，我们提出了一种图神经网络（GNN）回归模型，通过利用邻域分数来估计三元组的实体级知识掌握度得分。预测的知识掌握度使我们能够优先检查较不为人知的三元组，从而在相同标注预算下最大化知识覆盖。这不仅提高了为LLMs注入知识的主动标注微调效率，还增强了推理密集型问答中的多跳路径检索能力。</div>
</details>
<details class="detail"><summary>Summary / 总结</summary>
<div class="mono">This research investigates the structural organization of knowledge in Large Language Models (LLMs), motivated by the need to understand them as neural knowledge bases for applications like question answering. The method involves mapping LLM knowledge into a graph and analyzing entity relationships, revealing a knowledge homophily pattern where entities closer in the graph share similar knowledgeability levels. Based on this, a Graph Neural Network regression model is proposed to predict entity-level knowledgeability scores, which experimental results show can prioritize checking less-known triplets to improve knowledge coverage under a fixed labeling budget, thereby enhancing active labeling efficiency for fine-tuning and boosting multi-hop path retrieval in reasoning tasks.</div>
<div class="mono" style="margin-top:8px">本研究旨在探索大型语言模型（LLMs）中知识的组织结构，其动机源于需要将LLMs理解为支持问答等应用的知识库。方法包括将LLM知识映射为图结构并进行分析，发现了知识同质性模式，即图中位置更近的实体具有相似的知识水平；基于此，研究提出了一种图神经网络回归模型来预测实体层面的知识性得分。主要实验结果表明，利用这些预测得分优先检查较不熟悉的三元组，能在固定标注预算下提高知识覆盖率，从而提升了用于知识注入的主动标注效率，并增强了推理密集型问答中的多跳路径检索性能。</div>
</details>
</div>
<div class="card">
<div class="title">PACEvolve: Enabling Long-Horizon Progress-Aware Consistent Evolution</div>
<div class="meta-line">Authors: Minghao Yan, Bo Peng, Benjamin Coleman, Ziqi Chen, Zhouhang Xie, Zhankui He, Noveen Sachdeva, Isabella Ye, Weili Wang, Chi Wang, Ed H. Chi, Wang-Cheng Kang, Derek Zhiyuan Cheng, Beidou Wang</div>
<div class="meta-line">First: 2026-01-15T18:25:23+00:00 · Latest: 2026-01-15T18:25:23+00:00</div>
<div class="links" style="margin-top:8px"><a href="https://arxiv.org/abs/2601.10657v1">Abs</a> · <a href="https://arxiv.org/pdf/2601.10657v1">PDF</a> · <a href="https://huggingface.co/huggingface">Code1</a> · <a href="https://huggingface.co/docs/hub/spaces">Code2</a></div>
<details class="detail"><summary>Abstract</summary>
<div class="mono">Large Language Models (LLMs) have emerged as powerful operators for evolutionary search, yet the design of efficient search scaffolds remains ad hoc. While promising, current LLM-in-the-loop systems lack a systematic approach to managing the evolutionary process. We identify three distinct failure modes: Context Pollution, where experiment history biases future candidate generation; Mode Collapse, where agents stagnate in local minima due to poor exploration-exploitation balance; and Weak Collaboration, where rigid crossover strategies fail to leverage parallel search trajectories effectively. We introduce Progress-Aware Consistent Evolution (PACEvolve), a framework designed to robustly govern the agent&#x27;s context and search dynamics, to address these challenges. PACEvolve combines hierarchical context management (HCM) with pruning to address context pollution; momentum-based backtracking (MBB) to escape local minima; and a self-adaptive sampling policy that unifies backtracking and crossover for dynamic search coordination (CE), allowing agents to balance internal refinement with cross-trajectory collaboration. We demonstrate that PACEvolve provides a systematic path to consistent, long-horizon self-improvement, achieving state-of-the-art results on LLM-SR and KernelBench, while discovering solutions surpassing the record on Modded NanoGPT.</div></details>
<details class="detail"><summary>中文标题/摘要</summary>
<div class="mono"><b>标题：</b>PACEvolve：实现长时程进展感知一致性演化</div>
<div class="mono" style="margin-top:8px">大语言模型已成为进化搜索的强大操作器，但高效搜索框架的设计仍处于临时性阶段。现有基于大语言模型的循环系统虽具潜力，却缺乏管理演化过程的系统性方法。我们识别出三种典型失效模式：语境污染（实验历史偏差影响后续候选生成）、模式坍缩（探索-利用失衡导致智能体陷入局部最优）、弱协作（僵化的交叉策略无法有效利用并行搜索轨迹）。为此，我们提出进展感知一致性演化框架PACEvolve，通过分层语境管理配合剪枝机制应对语境污染；动量回溯机制规避局部最优；自适应采样策略统一回溯与交叉操作，实现动态搜索协调，使智能体能平衡内部优化与跨轨迹协作。实验表明，PACEvolve为持续长时程自我改进提供了系统化路径，在LLM-SR和KernelBench基准上取得最优结果，并在Modded NanoGPT任务中发现超越现有记录的解决方案。</div>
</details>
<details class="detail"><summary>Summary / 总结</summary>
<div class="mono">The research addresses systematic failures in LLM-driven evolutionary search, specifically context pollution, mode collapse, and weak collaboration, which hinder long-horizon progress. The proposed PACEvolve framework employs hierarchical context management with pruning, momentum-based backtracking, and a self-adaptive sampling policy for dynamic search coordination to govern context and search dynamics robustly. Experimental results show that PACEvolve achieves state-of-the-art performance on LLM-SR and KernelBench and discovers solutions surpassing the record on Modded NanoGPT, demonstrating consistent long-horizon self-improvement.</div>
<div class="mono" style="margin-top:8px">本研究针对大语言模型驱动的进化搜索中存在的系统性缺陷，即上下文污染、模式崩溃和弱协作，这些问题阻碍了长期进展。提出的PACEvolve框架采用分层上下文管理与剪枝、动量回溯以及自适应采样策略来实现动态搜索协调，从而稳健地管理上下文和搜索动态。实验结果表明，PACEvolve在LLM-SR和KernelBench上取得了最先进的性能，并在Modded NanoGPT上发现了超越记录的解决方案，展现了其实现长期一致自我改进的能力。</div>
</details>
</div>
<div class="card">
<div class="title">Multi-Property Synthesis</div>
<div class="meta-line">Authors: Christoph Weinhuber, Yannik Schnitzer, Alessandro Abate, David Parker, Giuseppe De Giacomo, Moshe Y. Vardi</div>
<div class="meta-line">First: 2026-01-15T18:18:33+00:00 · Latest: 2026-01-15T18:18:33+00:00</div>
<div class="links" style="margin-top:8px"><a href="https://arxiv.org/abs/2601.10651v1">Abs</a> · <a href="https://arxiv.org/pdf/2601.10651v1">PDF</a> · <a href="https://huggingface.co/huggingface">Code1</a> · <a href="https://huggingface.co/docs/hub/spaces">Code2</a></div>
<details class="detail"><summary>Abstract</summary>
<div class="mono">We study LTLf synthesis with multiple properties, where satisfying all properties may be impossible. Instead of enumerating subsets of properties, we compute in one fixed-point computation the relation between product-game states and the goal sets that are realizable from them, and we synthesize strategies achieving maximal realizable sets. We develop a fully symbolic algorithm that introduces Boolean goal variables and exploits monotonicity to represent exponentially many goal combinations compactly. Our approach substantially outperforms enumeration-based baselines, with speedups of up to two orders of magnitude.</div></details>
<details class="detail"><summary>中文标题/摘要</summary>
<div class="mono"><b>标题：</b>多属性综合</div>
<div class="mono" style="margin-top:8px">我们研究具有多个属性的LTLf综合问题，其中满足所有属性可能无法实现。我们无需枚举属性子集，而是通过一次不动点计算确定产品博弈状态与可从这些状态实现的目标集合之间的关系，并综合实现最大可实现集合的策略。我们开发了一种完全符号化算法，引入布尔目标变量并利用单调性紧凑表示指数级的目标组合。该方法显著优于基于枚举的基准方法，加速比最高可达两个数量级。</div>
</details>
<details class="detail"><summary>Summary / 总结</summary>
<div class="mono">The research addresses the challenge of Linear Temporal Logic on finite traces (LTLf) synthesis when it is impossible to satisfy all given properties simultaneously, moving beyond inefficient enumeration of property subsets. The method introduces a single fixed-point computation to determine the relation between states in a product game and the maximal sets of properties (goals) that are realizable from those states, then synthesizes strategies for these maximal sets; it employs a fully symbolic algorithm that compactly represents exponentially many goal combinations using Boolean goal variables and exploits monotonicity. Experimental results demonstrate that this approach significantly outperforms enumeration-based baselines, achieving speedups of up to two orders of magnitude.</div>
<div class="mono" style="margin-top:8px">本研究针对在有限迹上线性时序逻辑（LTLf）综合中，当所有给定属性可能无法同时满足时的挑战，避免了低效的属性子集枚举方法。该方法通过一次不动点计算，确定乘积博弈状态与从这些状态可实现的极大目标集之间的关系，并综合实现这些极大目标集的策略；它采用了一种完全符号化的算法，利用布尔目标变量和单调性来紧凑地表示指数级数量的目标组合。实验结果表明，该方法显著优于基于枚举的基线，速度提升高达两个数量级。</div>
</details>
</div>
<div class="card">
<div class="title">PMOA-TTS: Introducing the PubMed Open Access Textual Times Series Corpus</div>
<div class="meta-line">Authors: Shahriar Noroozizadeh, Sayantan Kumar, George H. Chen, Jeremy C. Weiss</div>
<div class="meta-line">First: 2025-05-23T18:01:09+00:00 · Latest: 2026-01-15T18:18:24+00:00</div>
<div class="links" style="margin-top:8px"><a href="https://arxiv.org/abs/2505.20323v2">Abs</a> · <a href="https://arxiv.org/pdf/2505.20323v2">PDF</a> · <a href="https://huggingface.co/huggingface">Code1</a> · <a href="https://huggingface.co/docs/hub/spaces">Code2</a></div>
<details class="detail"><summary>Abstract</summary>
<div class="mono">Clinical narratives encode temporal dynamics essential for modeling patient trajectories, yet large-scale temporally annotated resources are scarce. We introduce PMOA-TTS, a corpus of 124,699 single-patient PubMed Open Access case reports converted into structured textual timelines of (event, time) pairs using a scalable large-language-model pipeline (Llama 3.3 70B and DeepSeek-R1). The corpus comprises over 5.6 million timestamped events, alongside extracted demographics and diagnoses. Technical validation uses a clinician-curated gold set and three measures: semantic event matching, temporal concordance (c-index), and alignment error summarized with Area Under the Log-Time CDF (AULTC). We benchmark alternative prompting and model choices and provide documentation to support reproduction. PMOA-TTS enables research on timeline extraction, temporal reasoning, survival modeling and event forecasting from narrative text, and offers broad diagnostic and demographic coverage. Data and code are openly available in public repositories.</div></details>
<details class="detail"><summary>中文标题/摘要</summary>
<div class="mono"><b>标题：</b>PMOA-TTS：PubMed开放获取文本时间序列语料库的发布</div>
<div class="mono" style="margin-top:8px">临床叙述编码了对建模患者病程至关重要的时间动态，但大规模时间标注资源稀缺。我们推出PMOA-TTS语料库，包含124,699份单患者PubMed开放获取病例报告，通过可扩展的大语言模型流程（Llama 3.3 70B与DeepSeek-R1）转化为（事件，时间）对的结构化文本时间线。该语料库涵盖超560万条时间戳事件，并提取人口统计学与诊断信息。技术验证采用临床专家标注的金标准集及三项指标：语义事件匹配、时间一致性（c指数）以及通过对数时间CDF曲线下面积（AULTC）汇总的对齐误差。我们对比了不同提示策略与模型选择，并提供支持复现的文档。PMOA-TTS支持从叙事文本中开展时间线提取、时序推理、生存建模与事件预测研究，并提供广泛的诊断与人口统计学覆盖。数据与代码已在公共存储库开源。</div>
</details>
<details class="detail"><summary>Summary / 总结</summary>
<div class="mono">To address the scarcity of large-scale temporally annotated clinical narrative resources essential for modeling patient trajectories, this work introduces PMOA-TTS, a corpus of 124,699 single-patient case reports converted into structured textual timelines. The method employs a scalable large-language-model pipeline using Llama 3.3 70B and DeepSeek-R1 to extract over 5.6 million timestamped (event, time) pairs, alongside demographics and diagnoses. Experimental validation on a clinician-curated gold set demonstrates the corpus&#x27;s quality through semantic event matching, temporal concordance (c-index), and low alignment error measured by Area Under the Log-Time CDF, benchmarking alternative prompting and model choices.</div>
<div class="mono" style="margin-top:8px">为解决临床叙事中大规模时序标注数据稀缺、阻碍患者轨迹建模的问题，本研究提出了PMOA-TTS语料库，将124,699份单患者病例报告转化为结构化文本时间线。该方法采用基于Llama 3.3 70B和DeepSeek-R1的可扩展大语言模型流水线，提取了超过560万个带时间戳的（事件，时间）对，以及人口统计学和诊断信息。在临床专家标注的金标准集上的技术验证表明，该方法在语义事件匹配、时序一致性（c-index）和低对齐误差（通过对数时间CDF下面积衡量）方面表现良好，并对不同提示策略和模型选择进行了基准测试。</div>
</details>
</div>
<div class="card">
<div class="title">CURVE: A Benchmark for Cultural and Multilingual Long Video Reasoning</div>
<div class="meta-line">Authors: Darshan Singh, Arsha Nagrani, Kawshik Manikantan, Harman Singh, Dinesh Tewari, Tobias Weyand, Cordelia Schmid, Anelia Angelova, Shachi Dave</div>
<div class="meta-line">First: 2026-01-15T18:15:06+00:00 · Latest: 2026-01-15T18:15:06+00:00</div>
<div class="links" style="margin-top:8px"><a href="https://arxiv.org/abs/2601.10649v1">Abs</a> · <a href="https://arxiv.org/pdf/2601.10649v1">PDF</a> · <a href="https://github.com/google-deepmind/neptune?tab=readme-ov-file\#minerva-cultural">Code1</a> · <a href="https://github.com/google-deepmind/neptune?tab=readme-ov-file">Code2</a> · <a href="https://huggingface.co/huggingface">Code3</a></div>
<details class="detail"><summary>Abstract</summary>
<div class="mono">Recent advancements in video models have shown tremendous progress, particularly in long video understanding. However, current benchmarks predominantly feature western-centric data and English as the dominant language, introducing significant biases in evaluation. To address this, we introduce CURVE (Cultural Understanding and Reasoning in Video Evaluation), a challenging benchmark for multicultural and multilingual video reasoning. CURVE comprises high-quality, entirely human-generated annotations from diverse, region-specific cultural videos across 18 global locales. Unlike prior work that relies on automatic translations, CURVE provides complex questions, answers, and multi-step reasoning steps, all crafted in native languages. Making progress on CURVE requires a deeply situated understanding of visual cultural context. Furthermore, we leverage CURVE&#x27;s reasoning traces to construct evidence-based graphs and propose a novel iterative strategy using these graphs to identify fine-grained errors in reasoning. Our evaluations reveal that SoTA Video-LLMs struggle significantly, performing substantially below human-level accuracy, with errors primarily stemming from the visual perception of cultural elements. CURVE will be publicly available under https://github.com/google-deepmind/neptune?tab=readme-ov-file\#minerva-cultural</div></details>
<details class="detail"><summary>中文标题/摘要</summary>
<div class="mono"><b>标题：</b>CURVE：文化与多语言长视频推理基准</div>
<div class="mono" style="margin-top:8px">近期视频模型在长视频理解领域取得显著进展，但现有基准主要采用西方中心数据并以英语为主导语言，导致评估存在显著偏差。为此，我们推出CURVE（视频评估中的文化理解与推理基准），这是一个面向多元文化与多语言视频推理的挑战性基准。CURVE包含来自全球18个地区文化视频的高质量人工标注，所有问题、答案及多步推理步骤均以母语原生构建，区别于依赖自动翻译的先前工作。在CURVE上取得进展需对视觉文化语境具备深度情境化理解。此外，我们利用CURVE的推理轨迹构建证据图，并提出基于该图的迭代策略以识别细粒度推理错误。评估表明，当前最先进的视频大模型表现显著低于人类水平，错误主要源于对文化元素的视觉感知不足。CURVE将通过https://github.com/google-deepmind/neptune?tab=readme-ov-file#minerva-cultural公开提供。</div>
</details>
<details class="detail"><summary>Summary / 总结</summary>
<div class="mono">To address the cultural and linguistic biases in existing video understanding benchmarks, which are predominantly Western-centric and English-based, this paper introduces CURVE, a benchmark for cultural and multilingual long video reasoning. The method involves curating high-quality, human-generated annotations, including complex questions, answers, and reasoning steps in native languages, from diverse cultural videos across 18 locales, and further constructing evidence-based graphs from reasoning traces to enable fine-grained error analysis. Experimental results show that state-of-the-art video large language models perform substantially below human-level accuracy on CURVE, with key errors stemming from the visual perception of cultural elements.</div>
<div class="mono" style="margin-top:8px">针对现有视频理解基准主要基于西方文化和英语数据所引入的偏见，本文提出了CURVE基准，用于评估文化和多语言长视频推理能力。该方法通过收集来自18个地区多样化文化视频的高质量人工标注，包括以母语编写的复杂问题、答案和推理步骤，并利用推理轨迹构建基于证据的图以进行细粒度错误分析。实验结果表明，最先进的视频大语言模型在CURVE上的表现显著低于人类水平，主要错误源于对文化元素的视觉感知不足。</div>
</details>
</div>
<div class="card">
<div class="title">Sparse Nonparametric Contextual Bandits</div>
<div class="meta-line">Authors: Hamish Flynn, Julia Olkhovskaya, Paul Rognon-Vael</div>
<div class="meta-line">First: 2025-03-20T17:44:56+00:00 · Latest: 2026-01-15T18:10:26+00:00</div>
<div class="meta-line">Comments: 44 pages</div>
<div class="links" style="margin-top:8px"><a href="https://arxiv.org/abs/2503.16382v2">Abs</a> · <a href="https://arxiv.org/pdf/2503.16382v2">PDF</a> · <a href="https://huggingface.co/huggingface">Code1</a> · <a href="https://huggingface.co/docs/hub/spaces">Code2</a></div>
<details class="detail"><summary>Abstract</summary>
<div class="mono">We study the benefits of sparsity in nonparametric contextual bandit problems, in which the set of candidate features is countably or uncountably infinite. Our contribution is two-fold. First, using a novel reduction to sequences of multi-armed bandit problems, we provide lower bounds on the minimax regret, which show that polynomial dependence on the number of actions is generally unavoidable in this setting. Second, we show that a variant of the Feel-Good Thompson Sampling algorithm enjoys regret bounds that match our lower bounds up to logarithmic factors of the horizon, and have logarithmic dependence on the effective number of candidate features. When we apply our results to kernelised and neural contextual bandits, we find that sparsity enables better regret bounds whenever the horizon is large enough relative to the sparsity and the number of actions.</div></details>
<details class="detail"><summary>中文标题/摘要</summary>
<div class="mono"><b>标题：</b>稀疏非参数上下文赌博机</div>
<div class="mono" style="margin-top:8px">我们研究了非参数上下文赌博机问题中稀疏性的优势，其中候选特征集为可数或不可数无限。我们的贡献包括两方面：首先，通过一种新颖的转化为多臂赌博机序列的方法，我们给出了极小极大遗憾的下界，表明在此设置下对动作数量的多项式依赖通常是不可避免的；其次，我们证明了一种改进的Feel-Good Thompson Sampling算法能够达到与下界匹配的遗憾界（仅相差对数因子），且对有效候选特征数量具有对数依赖。将结果应用于核化与神经网络上下文赌博机时发现，当时间跨度相对于稀疏度与动作数量足够大时，稀疏性能带来更优的遗憾界。</div>
</details>
<details class="detail"><summary>Summary / 总结</summary>
<div class="mono">This paper investigates the role of sparsity in nonparametric contextual bandits with an infinite or large feature space, motivated by the need to understand fundamental performance limits and design efficient algorithms. The method involves a novel reduction to sequences of multi-armed bandit problems to derive minimax lower bounds, and proposes a variant of the Feel-Good Thompson Sampling algorithm. Key experimental findings show that polynomial dependence on the number of actions is generally unavoidable, but the proposed algorithm achieves regret bounds matching these lower bounds up to logarithmic factors, with logarithmic dependence on the effective number of features; in kernel and neural bandit settings, sparsity yields improved bounds when the horizon is sufficiently large relative to sparsity and action count.</div>
<div class="mono" style="margin-top:8px">本文研究了具有无限特征集的非参数上下文赌博机中稀疏性的作用，旨在理解其基本性能极限并设计高效算法。方法上，通过一种新颖的归约技术将问题转化为多臂赌博机序列以推导极小极大遗憾下界，并提出了一种改进的Feel-Good Thompson Sampling算法。主要实验结果表明，该算法的遗憾上界与下界在至多对数因子内匹配，且对有效特征数量呈对数依赖；在核化与神经网络上下文赌博机中，当时间跨度相对于稀疏性和动作数量足够大时，稀疏性能带来更优的遗憾界。</div>
</details>
</div>
<div class="card">
<div class="title">RMBRec: Robust Multi-Behavior Recommendation towards Target Behaviors</div>
<div class="meta-line">Authors: Miaomiao Cai, Zhijie Zhang, Junfeng Fang, Zhiyong Cheng, Xiang Wang, Meng Wang</div>
<div class="meta-line">First: 2026-01-13T16:34:17+00:00 · Latest: 2026-01-15T18:06:47+00:00</div>
<div class="links" style="margin-top:8px"><a href="https://arxiv.org/abs/2601.08705v2">Abs</a> · <a href="https://arxiv.org/pdf/2601.08705v2">PDF</a> · <a href="https://github.com/miaomiao-cai2/RMBRec/">Code1</a> · <a href="https://huggingface.co/huggingface">Code2</a> · <a href="https://huggingface.co/docs/hub/spaces">Code3</a></div>
<details class="detail"><summary>Abstract</summary>
<div class="mono">Multi-behavior recommendation faces a critical challenge in practice: auxiliary behaviors (e.g., clicks, carts) are often noisy, weakly correlated, or semantically misaligned with the target behavior (e.g., purchase), which leads to biased preference learning and suboptimal performance. While existing methods attempt to fuse these heterogeneous signals, they inherently lack a principled mechanism to ensure robustness against such behavioral inconsistency.
  In this work, we propose Robust Multi-Behavior Recommendation towards Target Behaviors (RMBRec), a robust multi-behavior recommendation framework grounded in an information-theoretic robustness principle. We interpret robustness as a joint process of maximizing predictive information while minimizing its variance across heterogeneous behavioral environments. Under this perspective, the Representation Robustness Module (RRM) enhances local semantic consistency by maximizing the mutual information between users&#x27; auxiliary and target representations, whereas the Optimization Robustness Module (ORM) enforces global stability by minimizing the variance of predictive risks across behaviors, which is an efficient approximation to invariant risk minimization. This local-global collaboration bridges representation purification and optimization invariance in a theoretically coherent way. Extensive experiments on three real-world datasets demonstrate that RMBRec not only outperforms state-of-the-art methods in accuracy but also maintains remarkable stability under various noise perturbations. For reproducibility, our code is available at https://github.com/miaomiao-cai2/RMBRec/.</div></details>
<details class="detail"><summary>中文标题/摘要</summary>
<div class="mono"><b>标题：</b>RMBRec：面向目标行为的鲁棒多行为推荐</div>
<div class="mono" style="margin-top:8px">多行为推荐在实践中面临关键挑战：辅助行为（如点击、加购）常存在噪声、弱相关性或与目标行为（如购买）语义不对齐，导致偏好学习偏差与次优性能。现有方法虽尝试融合异构信号，但本质上缺乏应对行为不一致性的鲁棒性保障机制。本研究提出面向目标行为的鲁棒多行为推荐框架RMBRec，其基于信息论的鲁棒性原则，将鲁棒性阐释为最大化预测信息同时最小化其在异构行为环境中方差的联合过程。在此视角下，表征鲁棒性模块通过最大化用户辅助行为与目标行为表征间的互信息增强局部语义一致性；优化鲁棒性模块则通过最小化跨行为预测风险方差（即对不变风险最小化的高效近似）保障全局稳定性。这种局部-全局协作机制以理论自洽的方式桥接了表征纯化与优化不变性。在三个真实数据集上的大量实验表明，RMBRec不仅在准确性上优于现有最优方法，且在多种噪声扰动下保持显著稳定性。代码已开源：https://github.com/miaomiao-cai2/RMBRec/。</div>
</details>
<details class="detail"><summary>Summary / 总结</summary>
<div class="mono">Multi-behavior recommendation systems often suffer from noise and semantic misalignment between auxiliary behaviors (e.g., clicks) and the target behavior (e.g., purchases), leading to biased learning. To address this, the authors propose RMBRec, a framework grounded in information theory that jointly maximizes predictive information and minimizes its variance across behavioral environments. It employs a Representation Robustness Module to enhance local semantic consistency via mutual information maximization, and an Optimization Robustness Module to enforce global stability by minimizing predictive risk variance. Experiments on three real-world datasets show that RMBRec outperforms state-of-the-art methods in accuracy and maintains strong stability under noise perturbations.</div>
<div class="mono" style="margin-top:8px">多行为推荐系统常因辅助行为（如点击）与目标行为（如购买）之间的噪声和语义错位而导致学习偏差。为解决此问题，作者提出了RMBRec，这是一个基于信息论的框架，旨在联合最大化预测信息并最小化其在行为环境间的方差。该框架结合了表示鲁棒性模块（通过互信息最大化增强局部语义一致性）和优化鲁棒性模块（通过最小化预测风险方差确保全局稳定性）。在三个真实数据集上的实验表明，RMBRec在准确性上优于现有最优方法，并在多种噪声干扰下保持了出色的稳定性。</div>
</details>
</div>
<div class="card">
<div class="title">TinyMyo: a Tiny Foundation Model for Flexible EMG Signal Processing at the Edge</div>
<div class="meta-line">Authors: Matteo Fasulo, Giusy Spacone, Thorir Mar Ingolfsson, Yawei Li, Luca Benini, Andrea Cossettini</div>
<div class="meta-line">First: 2025-12-05T17:36:57+00:00 · Latest: 2026-01-15T18:05:25+00:00</div>
<div class="links" style="margin-top:8px"><a href="https://arxiv.org/abs/2512.15729v2">Abs</a> · <a href="https://arxiv.org/pdf/2512.15729v2">PDF</a> · <a href="https://huggingface.co/huggingface">Code1</a> · <a href="https://huggingface.co/docs/hub/spaces">Code2</a></div>
<details class="detail"><summary>Abstract</summary>
<div class="mono">Objective: Surface electromyography (EMG) is a non-invasive sensing modality widely used in biomechanics, rehabilitation, prosthetic control, and human-machine interfaces. Despite decades of use, achieving robust generalization across subjects, recording systems, and acquisition protocols remains challenging. While foundation models (FMs) are gaining traction for EMG, existing approaches remain limited to single downstream tasks and lack deployability on embedded platforms. This work addresses these limitations. Methods: We present TinyMyo, a lightweight FM based on a Transformer encoder architecture. The model is pre-trained in a self-supervised manner using masked reconstruction on publicly available datasets. With only 3.6M parameters, TinyMyo is designed to support multiple downstream tasks through minimal task-specific head adaptations. Results: We demonstrate generalization across hand gesture classification, hand kinematic regression, speech production and speech recognition, with performance comparable to or surpassing the state of the art (SoA), and model size below 5M parameters. We achieve SoA results compared to previous FM-based works on the NinaPro DB5 (89.4%), UCI-EMG (97.56%), and EPN-612 (96.74%) datasets. We demonstrate the first-time deployment of an EMG FM on an ultra-low power microcontroller (GAP9), with an inference time of 0.785 s, energy of 44.91 mJ and power envelope of 57.18 mW. Conclusion: TinyMyo demonstrates that compact, self-supervised EMG FM can guarantee strong generalization across multiple downstream tasks while remaining compatible with low-power edge devices. Significance: TinyMyo is the first EMG FM for ultra-low power edge devices, enabling scalable and energy-efficient sensing for motor intent decoding, neuromuscular assessment, and biosignal driven human-machine interaction.</div></details>
<details class="detail"><summary>中文标题/摘要</summary>
<div class="mono"><b>标题：</b>TinyMyo：面向边缘灵活肌电信号处理的微型基础模型</div>
<div class="mono" style="margin-top:8px">目标：表面肌电图（EMG）是一种广泛应用于生物力学、康复、假肢控制和人机交互的非侵入式传感技术。尽管已应用数十年，但在不同受试者、记录系统和采集协议间实现稳健的泛化仍具挑战。虽然基础模型（FM）在EMG领域逐渐受到关注，但现有方法仍局限于单一下游任务，且缺乏在嵌入式平台上的可部署性。本研究旨在解决这些局限。方法：我们提出TinyMyo——一种基于Transformer编码器架构的轻量级FM。该模型通过掩码重建在公开数据集上以自监督方式进行预训练。TinyMyo仅含360万个参数，可通过极简的任务适配头支持多种下游任务。结果：我们在手势分类、手部运动回归、语音生成与语音识别任务中实现了泛化验证，其性能达到或超越现有最优水平（SoA），且模型参数量低于500万。在NinaPro DB5（89.4%）、UCI-EMG（97.56%）和EPN-612（96.74%）数据集上，相比此前基于FM的研究取得了SoA结果。我们首次在超低功耗微控制器（GAP9）上部署了EMG基础模型，推理时间为0.785秒，能耗44.91毫焦，功率范围57.18毫瓦。结论：TinyMyo证明紧凑的自监督EMG基础模型能在保持低功耗边缘设备兼容性的同时，为多种下游任务提供强泛化能力。意义：TinyMyo是首个面向超低功耗边缘设备的EMG基础模型，为运动意图解码、神经肌肉评估及生物信号驱动的人机交互提供了可扩展且高能效的传感解决方案。</div>
</details>
<details class="detail"><summary>Summary / 总结</summary>
<div class="mono">To address the challenges of achieving robust generalization across subjects, recording systems, and acquisition protocols in surface electromyography (EMG) applications, and to overcome the limitations of existing foundation models that are often task-specific and not deployable on embedded platforms, this work introduces TinyMyo, a lightweight foundation model based on a Transformer encoder architecture. The method involves pre-training the model in a self-supervised manner using masked reconstruction on public datasets, resulting in a compact model with only 3.6M parameters that supports multiple downstream tasks through minimal task-specific adaptations. Key experimental results show that TinyMyo achieves state-of-the-art performance on hand gesture classification, hand kinematic regression, and speech-related tasks across several benchmark datasets, and it is successfully deployed on an ultra-low power microcontroller with efficient inference time and energy consumption.</div>
<div class="mono" style="margin-top:8px">针对表面肌电信号处理中跨受试者、记录系统和采集协议泛化能力不足的挑战，以及现有基础模型局限于单一任务且难以在嵌入式平台部署的问题，本研究提出了TinyMyo，一种基于Transformer编码器的轻量级基础模型，仅含360万参数，并通过掩码重建进行自监督预训练。该方法通过微小的任务特定适配支持多种下游任务。实验结果表明，TinyMyo在手势分类、手部运动回归及语音相关任务上达到了与先进方法相当或更优的性能，并首次在超低功耗微控制器上成功部署，实现了高效的推理时间和能耗。</div>
</details>
</div>
<div class="card">
<div class="title">Adjusted Similarity Measures and a Violation of Expectations</div>
<div class="meta-line">Authors: William L. Lippitt, Edward J. Bedrick, Nichole E. Carlson</div>
<div class="meta-line">First: 2026-01-15T18:01:26+00:00 · Latest: 2026-01-15T18:01:26+00:00</div>
<div class="meta-line">Comments: 12 pages, 1 figure</div>
<div class="links" style="margin-top:8px"><a href="https://arxiv.org/abs/2601.10641v1">Abs</a> · <a href="https://arxiv.org/pdf/2601.10641v1">PDF</a> · <a href="https://huggingface.co/huggingface">Code1</a> · <a href="https://huggingface.co/docs/hub/spaces">Code2</a></div>
<details class="detail"><summary>Abstract</summary>
<div class="mono">Adjusted similarity measures, such as Cohen&#x27;s kappa for inter-rater reliability and the adjusted Rand index used to compare clustering algorithms, are a vital tool for comparing discrete labellings. These measures are intended to have the property of 0 expectation under a null distribution and maximum value 1 under maximal similarity to aid in interpretation. Measures are frequently adjusted with respect to the permutation distribution for historic and analytic reasons. There is currently renewed interest in considering other null models more appropriate for context, such as clustering ensembles permitting a random number of identified clusters. The purpose of this work is two -- fold: (1) to generalize the study of the adjustment operator to general null models and to a more general procedure which includes statistical standardization as a special case and (2) to identify sufficient conditions for the adjustment operator to produce the intended properties, where sufficient conditions are related to whether and how observed data are incorporated into null distributions. We demonstrate how violations of the sufficient conditions may lead to substantial breakdown, such as by producing a non-positive measure under traditional adjustment rather than one with mean 0, or by producing a measure which is deterministically 0 under statistical standardization.</div></details>
<details class="detail"><summary>中文标题/摘要</summary>
<div class="mono"><b>标题：</b>调整相似性度量与期望违反</div>
<div class="mono" style="margin-top:8px">调整相似性度量，如用于评估者间一致性的Cohen&#x27;s kappa和用于比较聚类算法的调整兰德指数，是比对离散标注的关键工具。这些度量旨在具备零期望特性（在零分布下）和最大值1（在最大相似性下），以辅助解释。出于历史和分析原因，度量常基于置换分布进行调整。当前，针对更贴合情境的其他零模型（如允许随机聚类数量的聚类集成）的研究重新受到关注。本研究目的有二：（1）将调整算子的研究推广至一般零模型及更通用的流程（以统计标准化为特例）；（2）确定调整算子产生预期性质的充分条件，这些条件与观测数据是否及如何纳入零分布相关。我们论证了违反充分条件可能导致严重失效，例如传统调整下产生非正度量而非零均值度量，或统计标准化下产生确定性为零的度量。</div>
</details>
<details class="detail"><summary>Summary / 总结</summary>
<div class="mono">This research addresses the need to ensure that adjusted similarity measures, like Cohen&#x27;s kappa and the adjusted Rand index, reliably achieve their intended properties of zero expectation under a null model and a maximum value of one. The authors generalize the adjustment procedure to accommodate various null models, including those used in clustering ensembles, and identify sufficient conditions for the adjustment to work correctly, focusing on how observed data is incorporated into the null distribution. Their key experimental findings reveal that violating these conditions can cause significant failures, such as producing non-positive measures instead of zero-mean ones or deterministically zero values under statistical standardization.</div>
<div class="mono" style="margin-top:8px">本研究旨在确保调整后的相似性度量（如Cohen&#x27;s kappa和调整兰德指数）能可靠地实现在零模型下期望为零、最大值为一的预期性质。作者将调整过程推广到适用于包括聚类集成在内的各种零模型，并确定了调整正确运作的充分条件，重点关注观测数据如何纳入零分布。关键的实验结果表明，违反这些条件可能导致严重问题，例如产生非正度量而非零均值度量，或在统计标准化下产生确定为零的值。</div>
</details>
</div>
<div class="card">
<div class="title">STEM: Scaling Transformers with Embedding Modules</div>
<div class="meta-line">Authors: Ranajoy Sadhukhan, Sheng Cao, Harry Dong, Changsheng Zhao, Attiano Purpura-Pontoniere, Yuandong Tian, Zechun Liu, Beidi Chen</div>
<div class="meta-line">First: 2026-01-15T18:00:27+00:00 · Latest: 2026-01-15T18:00:27+00:00</div>
<div class="links" style="margin-top:8px"><a href="https://arxiv.org/abs/2601.10639v1">Abs</a> · <a href="https://arxiv.org/pdf/2601.10639v1">PDF</a> · <a href="https://huggingface.co/huggingface">Code1</a> · <a href="https://huggingface.co/docs/hub/spaces">Code2</a></div>
<details class="detail"><summary>Abstract</summary>
<div class="mono">Fine-grained sparsity promises higher parametric capacity without proportional per-token compute, but often suffers from training instability, load balancing, and communication overhead. We introduce STEM (Scaling Transformers with Embedding Modules), a static, token-indexed approach that replaces the FFN up-projection with a layer-local embedding lookup while keeping the gate and down-projection dense. This removes runtime routing, enables CPU offload with asynchronous prefetch, and decouples capacity from both per-token FLOPs and cross-device communication. Empirically, STEM trains stably despite extreme sparsity. It improves downstream performance over dense baselines while reducing per-token FLOPs and parameter accesses (eliminating roughly one-third of FFN parameters). STEM learns embedding spaces with large angular spread which enhances its knowledge storage capacity. More interestingly, this enhanced knowledge capacity comes with better interpretability. The token-indexed nature of STEM embeddings allows simple ways to perform knowledge editing and knowledge injection in an interpretable manner without any intervention in the input text or additional computation. In addition, STEM strengthens long-context performance: as sequence length grows, more distinct parameters are activated, yielding practical test-time capacity scaling. Across 350M and 1B model scales, STEM delivers up to ~3--4% accuracy improvements overall, with notable gains on knowledge and reasoning-heavy benchmarks (ARC-Challenge, OpenBookQA, GSM8K, MMLU). Overall, STEM is an effective way of scaling parametric memory while providing better interpretability, better training stability and improved efficiency.</div></details>
<details class="detail"><summary>中文标题/摘要</summary>
<div class="mono"><b>标题：</b>STEM：基于嵌入模块的Transformer扩展方法</div>
<div class="mono" style="margin-top:8px">细粒度稀疏性可在不增加按令牌计算量的前提下提升参数容量，但常面临训练不稳定、负载均衡和通信开销等问题。本文提出STEM（基于嵌入模块的Transformer扩展方法），这是一种静态的令牌索引方法：在保持门控机制和下投影稠密的同时，用层局部嵌入查找替代前馈网络的上投影。该方法消除了运行时路由，支持通过异步预取实现CPU卸载，并将容量与单令牌浮点运算量及跨设备通信解耦。实验表明，STEM在极端稀疏条件下仍能稳定训练，在降低单令牌浮点运算量和参数访问量（约减少三分之一前馈网络参数）的同时，其下游性能优于稠密基线模型。STEM学习的嵌入空间具有较大角度分布，增强了知识存储容量。更有趣的是，这种增强的知识容量伴随着更好的可解释性——基于令牌索引的嵌入特性，无需干预输入文本或额外计算即可通过简单方式实现可解释的知识编辑与注入。此外，STEM能增强长上下文性能：随着序列长度增加，更多差异化参数被激活，实现了实用的测试时容量扩展。在3.5亿和10亿参数规模的模型中，STEM整体准确率提升约3-4%，在知识密集型和推理密集型基准测试（ARC-Challenge、OpenBookQA、GSM8K、MMLU）上表现尤为突出。总体而言，STEM是一种扩展参数记忆的有效方法，兼具更优的可解释性、训练稳定性和效率提升。</div>
</details>
<details class="detail"><summary>Summary / 总结</summary>
<div class="mono">The research aims to address the challenges of fine-grained sparsity in large language models, such as training instability and communication overhead, by introducing STEM, a static token-indexed method that replaces the FFN up-projection with a layer-local embedding lookup while keeping other components dense. This approach eliminates runtime routing, enables CPU offload with asynchronous prefetch, and decouples capacity from per-token compute and cross-device communication. Experimental results show that STEM trains stably with extreme sparsity, improves downstream performance over dense baselines by up to 3–4% accuracy, reduces per-token FLOPs and parameter accesses, enhances knowledge storage capacity with better interpretability for editing and injection, and strengthens long-context performance by activating more distinct parameters as sequence length grows, particularly on knowledge and reasoning benchmarks like ARC-Challenge and MMLU.</div>
<div class="mono" style="margin-top:8px">该研究旨在解决大型语言模型中细粒度稀疏性带来的训练不稳定和通信开销等问题，提出了STEM方法，这是一种静态的令牌索引方法，用层局部嵌入查找替换前馈网络的上投影，同时保持门和下投影的稠密性。该方法消除了运行时路由，支持CPU异步预取卸载，并将容量与每令牌浮点运算和跨设备通信解耦。实验结果表明，STEM在极端稀疏性下训练稳定，相比稠密基线提高了下游性能，同时减少了每令牌浮点运算和参数访问，通过嵌入的大角度扩展增强了知识存储能力，并加强了长上下文性能，在350M和1B模型规模下，在ARC-Challenge和MMLU等知识和推理基准上实现了约3–4%的准确率提升。</div>
</details>
</div></div>
    <details style="margin-top:16px" class="detail"><summary>History</summary>
      <div class="history-list"><a href="archive/20260118_1907.html">20260118_1907</a>
<a href="archive/20260118_0327.html">20260118_0327</a>
<a href="archive/20260117_0332.html">20260117_0332</a>
<a href="archive/20260116_0339.html">20260116_0339</a>
<a href="archive/20260115_0334.html">20260115_0334</a>
<a href="archive/20260114_0333.html">20260114_0333</a>
<a href="archive/20260113_0334.html">20260113_0334</a>
<a href="archive/20260112_0331.html">20260112_0331</a>
<a href="archive/20260111_0329.html">20260111_0329</a>
<a href="archive/20260110_0333.html">20260110_0333</a>
<a href="archive/20260109_0334.html">20260109_0334</a>
<a href="archive/20260108_0335.html">20260108_0335</a>
<a href="archive/20260107_0330.html">20260107_0330</a>
<a href="archive/20260106_0336.html">20260106_0336</a>
<a href="archive/20260105_0328.html">20260105_0328</a>
<a href="archive/20260104_0328.html">20260104_0328</a>
<a href="archive/20260103_0325.html">20260103_0325</a>
<a href="archive/20260102_0339.html">20260102_0339</a>
<a href="archive/20260101_0329.html">20260101_0329</a>
<a href="archive/20251231_0333.html">20251231_0333</a>
<a href="archive/20251230_0332.html">20251230_0332</a>
<a href="archive/20251229_0329.html">20251229_0329</a>
<a href="archive/20251228_0332.html">20251228_0332</a>
<a href="archive/20251227_0329.html">20251227_0329</a>
<a href="archive/20251226_0330.html">20251226_0330</a>
<a href="archive/20251225_0329.html">20251225_0329</a>
<a href="archive/20251224_0331.html">20251224_0331</a>
<a href="archive/20251223_0332.html">20251223_0332</a>
<a href="archive/20251222_0328.html">20251222_0328</a>
<a href="archive/20251221_0329.html">20251221_0329</a>
<a href="archive/20251220_0330.html">20251220_0330</a>
<a href="archive/20251219_0330.html">20251219_0330</a>
<a href="archive/20251218_0345.html">20251218_0345</a>
<a href="archive/20251217_0332.html">20251217_0332</a>
<a href="archive/20251216_0333.html">20251216_0333</a>
<a href="archive/20251215_0333.html">20251215_0333</a>
<a href="archive/20251214_0327.html">20251214_0327</a>
<a href="archive/20251212_0333.html">20251212_0333</a>
<a href="archive/20251211_0331.html">20251211_0331</a>
<a href="archive/20251210_0332.html">20251210_0332</a>
<a href="archive/20251209_0331.html">20251209_0331</a>
<a href="archive/20251208_0328.html">20251208_0328</a>
<a href="archive/20251207_0327.html">20251207_0327</a>
<a href="archive/20251206_0330.html">20251206_0330</a>
<a href="archive/20251205_0331.html">20251205_0331</a>
<a href="archive/20251204_0331.html">20251204_0331</a>
<a href="archive/20251203_0333.html">20251203_0333</a>
<a href="archive/20251202_0335.html">20251202_0335</a>
<a href="archive/20251201_0328.html">20251201_0328</a>
<a href="archive/20251130_0327.html">20251130_0327</a>
<a href="archive/20251129_0328.html">20251129_0328</a>
<a href="archive/20251128_0327.html">20251128_0327</a>
<a href="archive/20251127_0327.html">20251127_0327</a>
<a href="archive/20251126_0329.html">20251126_0329</a>
<a href="archive/20251125_0327.html">20251125_0327</a>
<a href="archive/20251124_0327.html">20251124_0327</a>
<a href="archive/20251123_0326.html">20251123_0326</a>
<a href="archive/20251122_0328.html">20251122_0328</a>
<a href="archive/20251121_0328.html">20251121_0328</a>
<a href="archive/20251120_0329.html">20251120_0329</a>
<a href="archive/20251119_0328.html">20251119_0328</a>
<a href="archive/20251118_0328.html">20251118_0328</a>
<a href="archive/20251117_0326.html">20251117_0326</a>
<a href="archive/20251116_0325.html">20251116_0325</a>
<a href="archive/20251115_0327.html">20251115_0327</a>
<a href="archive/20251114_0328.html">20251114_0328</a>
<a href="archive/20251113_0330.html">20251113_0330</a>
<a href="archive/20251112_0329.html">20251112_0329</a>
<a href="archive/20251111_0328.html">20251111_0328</a>
<a href="archive/20251110_0325.html">20251110_0325</a>
<a href="archive/20251109_0326.html">20251109_0326</a>
<a href="archive/20251108_0328.html">20251108_0328</a>
<a href="archive/20251107_0328.html">20251107_0328</a>
<a href="archive/20251106_0329.html">20251106_0329</a>
<a href="archive/20251105_0326.html">20251105_0326</a>
<a href="archive/20251104_0327.html">20251104_0327</a>
<a href="archive/20251103_0324.html">20251103_0324</a>
<a href="archive/20251102_0326.html">20251102_0326</a>
<a href="archive/20251101_0324.html">20251101_0324</a>
<a href="archive/20251031_0328.html">20251031_0328</a>
<a href="archive/20251030_0330.html">20251030_0330</a>
<a href="archive/20251029_0329.html">20251029_0329</a>
<a href="archive/20251028_0329.html">20251028_0329</a>
<a href="archive/20251027_0322.html">20251027_0322</a>
<a href="archive/20251026_0327.html">20251026_0327</a>
<a href="archive/20251025_0331.html">20251025_0331</a>
<a href="archive/20251024_0329.html">20251024_0329</a>
<a href="archive/20251023_0329.html">20251023_0329</a>
<a href="archive/20251022_0330.html">20251022_0330</a>
<a href="archive/20251021_0331.html">20251021_0331</a>
<a href="archive/20251020_0328.html">20251020_0328</a>
<a href="archive/20251019_0321.html">20251019_0321</a>
<a href="archive/20251018_0327.html">20251018_0327</a>
<a href="archive/20251017_0320.html">20251017_0320</a>
<a href="archive/20251016_0328.html">20251016_0328</a>
<a href="archive/20251015_0328.html">20251015_0328</a>
<a href="archive/20251014_0323.html">20251014_0323</a>
<a href="archive/20251011_0328.html">20251011_0328</a>
<a href="archive/20251010_0330.html">20251010_0330</a>
<a href="archive/20251009_0321.html">20251009_0321</a></div>
    </details>
    <div class="footer">Generated by arxiv-tracker</div>
  </div>
</body></html>
