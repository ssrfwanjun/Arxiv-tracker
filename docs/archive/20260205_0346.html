<!doctype html>
<html><head><meta charset="utf-8"><meta name="viewport" content="width=device-width,initial-scale=1">
<title>arXiv 论文速递</title><style>
:root {
  --bg:#f8fafc; --card:#ffffff; --text:#0f172a; --muted:#667085; --border:#e5e7eb; --acc:#2563eb;
}
:root[data-theme="dark"] {
  --bg:#0b0f17; --card:#111827; --text:#e5e7eb; --muted:#9ca3af; --border:#1f2937; --acc:#2563eb;
}
*{box-sizing:border-box} body{margin:0;background:var(--bg);color:var(--text);
  font-family:ui-sans-serif,system-ui,-apple-system,Segoe UI,Roboto,Helvetica,Arial;line-height:1.6;}
.container{max-width:900px;margin:0 auto;padding:18px;}
.header{display:flex;gap:10px;justify-content:space-between;align-items:center;margin:8px 0 16px;flex-wrap:wrap}
h1{font-size:22px;margin:0}
.badge{font-size:12px;color:#111827;background:var(--acc);padding:2px 8px;border-radius:999px}
.card{background:var(--card);border:1px solid var(--border);border-radius:16px;padding:16px 18px;margin:14px 0;box-shadow:0 1px 2px rgba(0,0,0,.04)}
.title{font-weight:700;margin:0 0 6px 0;font-size:18px}
.meta-line{color:var(--muted);font-size:13px;margin:2px 0}
.links a{color:var(--acc);text-decoration:none;margin-right:12px}
.detail{margin-top:10px;background:rgba(2,6,23,.03);border:1px solid var(--border);border-radius:10px;padding:8px 10px}
summary{cursor:pointer;color:var(--acc)}
.mono{white-space:pre-wrap;background:rgba(2,6,23,.03);border:1px solid var(--border);padding:10px;border-radius:10px}
.row{display:grid;grid-template-columns:1fr;gap:12px}
@media (min-width: 860px) {
  .row-2{grid-template-columns:1fr 1fr}
}
.footer{color:var(--muted);font-size:13px;margin:20px 0 10px}
.hr{height:1px;background:var(--border);margin:14px 0}
.history-list a{display:block;color:var(--acc);text-decoration:none;margin:4px 0}
.controls{display:flex;gap:8px;align-items:center}
.btn{border:1px solid var(--border);background:var(--card);padding:6px 10px;border-radius:10px;cursor:pointer;color:var(--text)}
.btn:hover{border-color:var(--acc)}
</style>
<script>
(function() {
  const root = document.documentElement;
  function apply(t) {
    if (t==='dark') root.setAttribute('data-theme','dark');
    else if (t==='light') root.removeAttribute('data-theme');
    else {
      if (window.matchMedia && window.matchMedia('(prefers-color-scheme: dark)').matches)
        root.setAttribute('data-theme','dark');
      else root.removeAttribute('data-theme');
    }
  }
  let t = localStorage.getItem('theme') || 'light';
  if (!['light','dark','auto'].includes(t)) t='light';
  apply(t);
  window.__toggleTheme = function() {
    let cur = localStorage.getItem('theme') || 'light';
    if (cur==='light') cur='dark';
    else if (cur==='dark') cur='auto';
    else cur='light';
    localStorage.setItem('theme', cur);
    apply(cur);
    const el=document.getElementById('theme-label');
    if(el) el.textContent = cur.toUpperCase();
  }
  window.__expandAll = function(open) {
    document.querySelectorAll('details').forEach(d => d.open = !!open);
  }
})();
</script>
</head>
<body>
  <div class="container">
    <div class="header">
      <h1>arXiv 论文速递</h1>
      <div style="display:flex;gap:10px;align-items:center">
        
<div class="controls">
  <button class="btn" onclick="__toggleTheme()">Theme: <span id="theme-label" style="margin-left:6px">AUTO</span></button>
  <button class="btn" onclick="__expandAll(true)">Expand All</button>
  <button class="btn" onclick="__expandAll(false)">Collapse All</button>
</div>

        <span class="badge">2026-02-05 03:46</span>
      </div>
    </div>
    <div class="hr"></div>
    <div>Snapshot: 20260205_0346</div>
    <div class="row"><div class="card">
<div class="title">PLATE: Plasticity-Tunable Efficient Adapters for Geometry-Aware Continual Learning</div>
<div class="meta-line">Authors: Romain Cosentino</div>
<div class="meta-line">First: 2026-02-03T18:59:42+00:00 · Latest: 2026-02-03T18:59:42+00:00</div>
<div class="links" style="margin-top:8px"><a href="https://arxiv.org/abs/2602.03846v1">Abs</a> · <a href="https://arxiv.org/pdf/2602.03846v1">PDF</a> · <a href="https://github.com/SalesforceAIResearch/PLATE">Code1</a> · <a href="https://huggingface.co/huggingface">Code2</a> · <a href="https://huggingface.co/docs/hub/spaces">Code3</a></div>
<details class="detail"><summary>Abstract</summary>
<div class="mono">We develop a continual learning method for pretrained models that \emph{requires no access to old-task data}, addressing a practical barrier in foundation model adaptation where pretraining distributions are often unavailable. Our key observation is that pretrained networks exhibit substantial \emph{geometric redundancy}, and that this redundancy can be exploited in two complementary ways. First, redundant neurons provide a proxy for dominant pretraining-era feature directions, enabling the construction of approximately protected update subspaces directly from pretrained weights. Second, redundancy offers a natural bias for \emph{where} to place plasticity: by restricting updates to a subset of redundant neurons and constraining the remaining degrees of freedom, we obtain update families with reduced functional drift on the old-data distribution and improved worst-case retention guarantees. These insights lead to \textsc{PLATE} (\textbf{Pla}sticity-\textbf{T}unable \textbf{E}fficient Adapters), a continual learning method requiring no past-task data that provides explicit control over the plasticity-retention trade-off. PLATE parameterizes each layer with a structured low-rank update $ΔW = B A Q^\top$, where $B$ and $Q$ are computed once from pretrained weights and kept frozen, and only $A$ is trained on the new task. The code is available at https://github.com/SalesforceAIResearch/PLATE.</div></details>
<details class="detail"><summary>中文标题/摘要</summary>
<div class="mono"><b>标题：</b>PLATE：面向几何感知持续学习的可塑性可调高效适配器</div>
<div class="mono" style="margin-top:8px">我们为预训练模型开发了一种持续学习方法，该方法无需访问旧任务数据，解决了基础模型适应中预训练分布常不可用的实际障碍。我们的核心发现是：预训练网络存在显著的几何冗余，这种冗余可通过两种互补方式利用。首先，冗余神经元为预训练阶段主导特征方向提供了代理，使得能够直接从预训练权重构建近似受保护的更新子空间。其次，冗余为可塑性配置位置提供了自然偏置：通过将更新限制在冗余神经元子集并约束其余自由度，我们获得了在旧数据分布上功能漂移更小、最坏情况保留保证更强的更新族。这些洞见催生了PLATE（可塑性可调高效适配器）——一种无需历史任务数据、能显式控制可塑性-保留权衡的持续学习方法。PLATE通过结构化低秩更新$ΔW = B A Q^\top$参数化各层，其中$B$和$Q$从预训练权重一次性计算并保持冻结，仅$A$在新任务上训练。代码发布于https://github.com/SalesforceAIResearch/PLATE。</div>
</details>
<details class="detail"><summary>Summary / 总结</summary>
<div class="mono">This work addresses the practical challenge of adapting pretrained foundation models to new tasks without access to original pretraining data, a common constraint in real-world deployment. The method, named PLATE, leverages the observation that pretrained networks contain geometric redundancy, which is exploited to construct protected update subspaces directly from the frozen weights and to strategically allocate plasticity to a subset of redundant neurons. This is implemented via a structured low-rank adapter per layer, ΔW = B A Q^⊤, where only the small matrix A is trained on new tasks while B and Q are fixed projections derived from the pretrained model. Experiments demonstrate that PLATE provides explicit control over the plasticity-retention trade-off, effectively reduces functional drift on old tasks, and offers improved worst-case retention guarantees compared to prior data-free continual learning approaches.</div>
<div class="mono" style="margin-top:8px">该研究旨在解决持续学习中预训练模型适应新任务时无法访问旧任务数据的实际挑战，这在现实场景中常见。PLATE方法利用预训练网络中的几何冗余，通过从预训练权重构建受保护的更新子空间，并将可塑性限制在冗余神经元子集上，参数化为结构化低秩更新，仅训练一个小矩阵。实验结果表明，PLATE有效平衡了可塑性和保留性，减少了旧任务上的功能漂移，并在无需过去数据的情况下提供了改进的最坏情况保留保证。</div>
</details>
</div>
<div class="card">
<div class="title">Reuse your FLOPs: Scaling RL on Hard Problems by Conditioning on Very Off-Policy Prefixes</div>
<div class="meta-line">Authors: Amrith Setlur, Zijian Wang, Andrew Cohen, Paria Rashidinejad, Sang Michael Xie</div>
<div class="meta-line">First: 2026-01-26T18:57:00+00:00 · Latest: 2026-02-03T18:58:52+00:00</div>
<div class="links" style="margin-top:8px"><a href="https://arxiv.org/abs/2601.18795v2">Abs</a> · <a href="https://arxiv.org/pdf/2601.18795v2">PDF</a> · <a href="https://huggingface.co/huggingface">Code1</a> · <a href="https://huggingface.co/docs/hub/spaces">Code2</a></div>
<details class="detail"><summary>Abstract</summary>
<div class="mono">Typical reinforcement learning (RL) methods for LLM reasoning waste compute on hard problems, where correct on-policy traces are rare, policy gradients vanish, and learning stalls. To bootstrap more efficient RL, we consider reusing old sampling FLOPs (from prior inference or RL training) in the form of off-policy traces. Standard off-policy methods supervise against off-policy data, causing instabilities during RL optimization. We introduce PrefixRL, where we condition on the prefix of successful off-policy traces and run on-policy RL to complete them, side-stepping off-policy instabilities. PrefixRL boosts the learning signal on hard problems by modulating the difficulty of the problem through the off-policy prefix length. We prove that the PrefixRL objective is not only consistent with the standard RL objective but also more sample efficient. Empirically, we discover back-generalization: training only on prefixed problems generalizes to out-of-distribution unprefixed performance, with learned strategies often differing from those in the prefix. In our experiments, we source the off-policy traces by rejection sampling with the base model, creating a self-improvement loop. On hard reasoning problems, PrefixRL reaches the same training reward 2x faster than the strongest baseline (SFT on off-policy data then RL), even after accounting for the compute spent on the initial rejection sampling, and increases the final reward by 3x. The gains transfer to held-out benchmarks, and PrefixRL is still effective when off-policy traces are derived from a different model family, validating its flexibility in practical settings.</div></details>
<details class="detail"><summary>中文标题/摘要</summary>
<div class="mono"><b>标题：</b>复用计算资源：通过基于极离策略前缀的条件化实现困难问题的强化学习扩展</div>
<div class="mono" style="margin-top:8px">传统大语言模型推理的强化学习方法在困难问题上存在计算浪费：正确同策略轨迹稀少、策略梯度消失、学习停滞。为提升强化学习效率，我们提出复用历史采样计算资源（来自先前推理或强化学习训练）形成的离策略轨迹。标准离策略方法直接监督离策略数据会导致强化学习优化不稳定。我们提出前缀强化学习方法：基于成功离策略轨迹的前缀执行条件化，运行同策略强化学习完成后续轨迹，从而规避离策略不稳定性。该方法通过调节离策略前缀长度控制问题难度，增强困难问题的学习信号。我们证明该方法目标不仅与标准强化学习目标一致，且具有更高样本效率。实验发现反向泛化现象：仅基于前缀问题的训练可泛化至非前缀分布外性能，习得策略常与原始前缀策略不同。实验中通过基础模型的拒绝采样获取离策略轨迹，形成自我改进循环。在困难推理问题上，即使计入初始拒绝采样计算成本，该方法仍以2倍速度达到与最强基线（离策略数据监督微调后强化学习）相同的训练奖励，最终奖励提升3倍。该优势可迁移至保留基准测试，且当离策略轨迹源自不同模型家族时依然有效，验证了其在实际场景中的灵活性。</div>
</details>
<details class="detail"><summary>Summary / 总结</summary>
<div class="mono">The research addresses the inefficiency of standard reinforcement learning (RL) methods for large language models on hard reasoning problems, where on-policy traces are scarce and policy gradients vanish, leading to stalled learning. To overcome this, the authors propose PrefixRL, a method that conditions on the prefixes of successful off-policy traces—sourced via rejection sampling from a base model—and then performs on-policy RL to complete them, thereby avoiding the instabilities of direct off-policy supervision while modulating problem difficulty via prefix length. Experimental results demonstrate that PrefixRL achieves the same training reward twice as fast as strong baselines like supervised fine-tuning followed by RL, even after accounting for initial sampling compute, and triples the final reward on hard problems, with gains transferring to held-out benchmarks and showing effectiveness even with off-policy traces from different model families.</div>
<div class="mono" style="margin-top:8px">该研究针对大型语言模型在困难推理问题上标准强化学习方法效率低下的问题，其中在线策略学习信号稀疏且梯度消失。提出的方法PrefixRL利用通过拒绝采样获取的成功离线策略轨迹的前缀进行条件化，并应用在线策略强化学习来完成它们，从而避免了直接离线策略监督的不稳定性，同时通过前缀长度调节问题难度。实验表明，PrefixRL在困难问题上达到相同训练奖励的速度比最强基线快两倍，并将最终奖励提高三倍，其增益可迁移到保留基准测试中，即使使用来自不同模型家族的离线策略数据也有效，同时还发现了反向泛化现象，即在前缀问题上训练能提升无前缀性能。</div>
</details>
</div>
<div class="card">
<div class="title">Polynomial Neural Sheaf Diffusion: A Spectral Filtering Approach on Cellular Sheaves</div>
<div class="meta-line">Authors: Alessio Borgi, Fabrizio Silvestri, Pietro Liò</div>
<div class="meta-line">Venue: ICML 2026</div>
<div class="meta-line">First: 2025-11-28T23:10:54+00:00 · Latest: 2026-02-03T18:57:37+00:00</div>
<div class="meta-line">Comments: Under Review at ICML 2026</div>
<div class="links" style="margin-top:8px"><a href="https://arxiv.org/abs/2512.00242v2">Abs</a> · <a href="https://arxiv.org/pdf/2512.00242v2">PDF</a> · <a href="https://huggingface.co/huggingface">Code1</a> · <a href="https://huggingface.co/docs/hub/spaces">Code2</a></div>
<details class="detail"><summary>Abstract</summary>
<div class="mono">Sheaf Neural Networks equip graph structures with a cellular sheaf: a geometric structure which assigns local vector spaces (stalks) and a linear learnable restriction/transport maps to nodes and edges, yielding an edge-aware inductive bias that handles heterophily and limits oversmoothing. However, common Neural Sheaf Diffusion implementations rely on SVD-based sheaf normalization and dense per-edge restriction maps, which scale with stalk dimension, require frequent Laplacian rebuilds, and yield brittle gradients. To address these limitations, we introduce Polynomial Neural Sheaf Diffusion (PolyNSD), a new sheaf diffusion approach whose propagation operator is a degree-K polynomial in a normalised sheaf Laplacian, evaluated via a stable three-term recurrence on a spectrally rescaled operator. This provides an explicit K-hop receptive field in a single layer (independently of the stalk dimension), with a trainable spectral response obtained as a convex mixture of K+1 orthogonal polynomial basis responses. PolyNSD enforces stability via convex mixtures, spectral rescaling, and residual/gated paths, reaching new state-of-the-art results on both homophilic and heterophilic benchmarks, inverting the Neural Sheaf Diffusion trend by obtaining these results with just diagonal restriction maps, decoupling performance from large stalk dimension, while reducing runtime and memory requirements.</div></details>
<details class="detail"><summary>中文标题/摘要</summary>
<div class="mono"><b>标题：</b>多项式神经层扩散：胞腔层上的谱滤波方法</div>
<div class="mono" style="margin-top:8px">层神经网络为图结构配备胞腔层：一种几何结构，为节点和边分配局部向量空间（茎）及可学习的线性限制/传输映射，从而产生能处理异配性并限制过度平滑的边缘感知归纳偏置。然而，常见的神经层扩散实现依赖基于SVD的层归一化和稠密的逐边限制映射，其计算量随茎维度增长，需要频繁重建拉普拉斯矩阵，且产生脆弱的梯度。为克服这些局限，我们提出多项式神经层扩散（PolyNSD）——一种新的层扩散方法，其传播算子为归一化层拉普拉斯算子的K次多项式，通过谱重缩放算子的稳定三项递推进行计算。该方法在单层内提供显式的K跳感受野（独立于茎维度），并通过K+1个正交多项式基响应的凸组合获得可训练的谱响应。PolyNSD通过凸组合、谱重缩放及残差/门控路径确保稳定性，在同配性与异配性基准测试中均达到最新最优结果，仅使用对角限制映射即实现性能突破，使性能与高茎维度解耦，同时降低运行时间和内存需求。</div>
</details>
<details class="detail"><summary>Summary / 总结</summary>
<div class="mono">To overcome the computational and stability limitations of existing Neural Sheaf Diffusion methods, which rely on SVD-based normalization and dense per-edge restriction maps, this paper introduces Polynomial Neural Sheaf Diffusion (PolyNSD). The method defines a propagation operator as a degree-K polynomial in a normalized sheaf Laplacian, evaluated via a stable recurrence on a spectrally rescaled operator, providing an explicit K-hop receptive field and a trainable spectral response as a convex mixture of orthogonal polynomial bases. Experiments show that PolyNSD achieves state-of-the-art results on both homophilic and heterophilic graph benchmarks using only diagonal restriction maps, thereby decoupling performance from large stalk dimensions while improving runtime and memory efficiency.</div>
<div class="mono" style="margin-top:8px">本研究针对神经层扩散模型的可扩展性和稳定性限制，该模型使用胞腔层处理图异配性，但存在计算效率低下的问题，主要源于稠密的每边限制映射和频繁的拉普拉斯重建。提出的多项式神经层扩散方法将传播算子构建为归一化层拉普拉斯算子的K次多项式，通过谱重缩放算子的稳定三项递推实现，从而获得明确的K跳感受野，并以正交多项式基的凸组合作为可训练的谱响应。实验结果表明，该方法在同配和异配图基准测试中均达到最先进性能，仅使用对角限制映射即可实现，降低了运行时间和内存需求，同时使性能与大茎维解耦。</div>
</details>
</div>
<div class="card">
<div class="title">PrevizWhiz: Combining Rough 3D Scenes and 2D Video to Guide Generative Video Previsualization</div>
<div class="meta-line">Authors: Erzhen Hu, Frederik Brudy, David Ledo, George Fitzmaurice, Fraser Anderson</div>
<div class="meta-line">First: 2026-02-03T18:56:40+00:00 · Latest: 2026-02-03T18:56:40+00:00</div>
<div class="meta-line">Comments: 21 pages, 13 figures; accepted and to appear at CHI 2026</div>
<div class="links" style="margin-top:8px"><a href="https://arxiv.org/abs/2602.03838v1">Abs</a> · <a href="https://arxiv.org/pdf/2602.03838v1">PDF</a> · <a href="https://huggingface.co/huggingface">Code1</a> · <a href="https://huggingface.co/docs/hub/spaces">Code2</a></div>
<details class="detail"><summary>Abstract</summary>
<div class="mono">In pre-production, filmmakers and 3D animation experts must rapidly prototype ideas to explore a film&#x27;s possibilities before fullscale production, yet conventional approaches involve trade-offs in efficiency and expressiveness. Hand-drawn storyboards often lack spatial precision needed for complex cinematography, while 3D previsualization demands expertise and high-quality rigged assets. To address this gap, we present PrevizWhiz, a system that leverages rough 3D scenes in combination with generative image and video models to create stylized video previews. The workflow integrates frame-level image restyling with adjustable resemblance, time-based editing through motion paths or external video inputs, and refinement into high-fidelity video clips. A study with filmmakers demonstrates that our system lowers technical barriers for film-makers, accelerates creative iteration, and effectively bridges the communication gap, while also surfacing challenges of continuity, authorship, and ethical consideration in AI-assisted filmmaking.</div></details>
<details class="detail"><summary>中文标题/摘要</summary>
<div class="mono"><b>标题：</b>PrevizWhiz：结合粗略3D场景与2D视频引导生成式视频预可视化</div>
<div class="mono" style="margin-top:8px">在影视预制作阶段，电影制作人与3D动画专家需快速原型化创意以探索影片可能性，但传统方法常在效率与表现力间取舍。手绘故事板常缺乏复杂镜头运动所需的空间精度，而3D预可视化则需专业能力与高质量绑定资产。为弥合此鸿沟，我们提出PrevizWhiz系统，利用粗略3D场景结合生成式图像与视频模型创建风格化视频预览。该工作流集成可调节相似度的帧级图像风格重绘、通过运动路径或外部视频输入的时间轴编辑，以及高保真视频片段精修。针对电影制作人的研究表明，本系统降低了技术门槛、加速创意迭代、有效弥合沟通间隙，同时揭示了AI辅助制片中连续性、作者权与伦理考量等挑战。</div>
</details>
<details class="detail"><summary>Summary / 总结</summary>
<div class="mono">To address the trade-offs between spatial precision and efficiency in film pre-production, this research introduces PrevizWhiz, a system that combines rough 3D scenes with generative image and video models to create stylized video previews. The method integrates frame-level image restyling with adjustable resemblance controls, time-based editing via motion paths or external video inputs, and refinement into high-fidelity video clips. A study with filmmakers found that the system lowers technical barriers, accelerates creative iteration, and improves communication, while also revealing challenges related to continuity, authorship, and ethical considerations in AI-assisted filmmaking.</div>
<div class="mono" style="margin-top:8px">为解决电影预制作中手绘故事板缺乏空间精度、三维预可视化要求高专业性的效率与表现力权衡问题，本研究提出了PrevizWhiz系统。该系统将粗略三维场景与生成式图像和视频模型相结合，集成了帧级重风格化、通过运动路径或外部视频的时间编辑以及高保真视频片段精炼。对电影制作人的研究表明，该系统降低了技术门槛，加速了创意迭代，并有效改善了沟通，同时也揭示了AI辅助电影制作中连续性、作者权和伦理方面的挑战。</div>
</details>
</div>
<div class="card">
<div class="title">MixGRPO: Unlocking Flow-based GRPO Efficiency with Mixed ODE-SDE</div>
<div class="meta-line">Authors: Junzhe Li, Yutao Cui, Tao Huang, Yinping Ma, Chun Fan, Miles Yang, Zhao Zhong</div>
<div class="meta-line">First: 2025-07-29T13:40:09+00:00 · Latest: 2026-02-03T18:56:25+00:00</div>
<div class="links" style="margin-top:8px"><a href="https://arxiv.org/abs/2507.21802v4">Abs</a> · <a href="https://arxiv.org/pdf/2507.21802v4">PDF</a> · <a href="https://huggingface.co/huggingface">Code1</a> · <a href="https://huggingface.co/docs/hub/spaces">Code2</a></div>
<details class="detail"><summary>Abstract</summary>
<div class="mono">Although GRPO substantially enhances flow matching models in human preference alignment of image generation, methods such as FlowGRPO and DanceGRPO still exhibit inefficiency due to the necessity of sampling and optimizing over all denoising steps specified by the Markov Decision Process (MDP). In this paper, we propose $\textbf{MixGRPO}$, a novel framework that leverages the flexibility of mixed sampling strategies through the integration of stochastic differential equations (SDE) and ordinary differential equations (ODE). This streamlines the optimization process within the MDP to improve efficiency and boost performance. Specifically, MixGRPO introduces a sliding window mechanism, using SDE sampling and GRPO-guided optimization only within the window, while applying ODE sampling outside. This design confines sampling randomness to the time-steps within the window, thereby reducing the optimization overhead, and allowing for more focused gradient updates to accelerate convergence. Additionally, as time-steps beyond the sliding window are not involved in optimization, higher-order solvers are supported for faster sampling. So we present a faster variant, termed $\textbf{MixGRPO-Flash}$, which further improves training efficiency while achieving comparable performance. MixGRPO exhibits substantial gains across multiple dimensions of human preference alignment, outperforming DanceGRPO in both effectiveness and efficiency, with nearly 50% lower training time. Notably, MixGRPO-Flash further reduces training time by 71%.</div></details>
<details class="detail"><summary>中文标题/摘要</summary>
<div class="mono"><b>标题：</b>MixGRPO：通过混合ODE-SDE解锁基于流的GRPO效率</div>
<div class="mono" style="margin-top:8px">尽管GRPO在图像生成的人类偏好对齐中显著提升了流匹配模型的性能，但FlowGRPO和DanceGRPO等方法因需对马尔可夫决策过程（MDP）指定的所有去噪步骤进行采样和优化，仍存在效率瓶颈。本文提出$\textbf{MixGRPO}$，一种通过整合随机微分方程（SDE）和常微分方程（ODE）来利用混合采样策略灵活性的新框架。该框架优化了MDP内的优化流程，从而提升效率与性能。具体而言，MixGRPO引入滑动窗口机制：仅在窗口内使用SDE采样和GRPO引导的优化，而在窗口外采用ODE采样。这一设计将采样随机性限制在窗口内的时间步，降低了优化开销，并通过更聚焦的梯度更新加速收敛。此外，由于滑动窗口外的时间步不参与优化，可支持高阶求解器以实现更快采样。为此我们提出加速变体$\textbf{MixGRPO-Flash}$，在保持相当性能的同时进一步提升训练效率。MixGRPO在人类偏好对齐的多个维度上取得显著提升，在效果和效率上均优于DanceGRPO，训练时间降低近50%。值得注意的是，MixGRPO-Flash进一步将训练时间缩减了71%。</div>
</details>
<details class="detail"><summary>Summary / 总结</summary>
<div class="mono">To address the inefficiency of existing GRPO methods like FlowGRPO and DanceGRPO, which require sampling and optimizing over all denoising steps in the Markov Decision Process, this paper introduces MixGRPO. The method integrates stochastic and ordinary differential equations (SDE and ODE) through a sliding window mechanism, applying SDE sampling and GRPO-guided optimization only within the window while using ODE sampling outside to confine randomness and reduce optimization overhead. Experimental results show that MixGRPO outperforms DanceGRPO in human preference alignment with nearly 50% lower training time, and its faster variant, MixGRPO-Flash, further reduces training time by 71% while maintaining comparable performance.</div>
<div class="mono" style="margin-top:8px">针对现有GRPO方法（如FlowGRPO和DanceGRPO）因需对马尔可夫决策过程中所有去噪步骤进行采样和优化而导致的效率低下问题，本文提出了MixGRPO。该方法通过结合随机微分方程和常微分方程，并引入滑动窗口机制：仅在窗口内使用SDE采样和GRPO引导的优化，在窗口外则使用ODE采样，从而限制随机性并降低优化开销。实验结果表明，MixGRPO在人类偏好对齐的多个维度上均取得显著提升，其效果和效率均优于DanceGRPO，训练时间减少近50%；其更快变体MixGRPO-Flash进一步将训练时间减少了71%，同时保持了可比性能。</div>
</details>
</div>
<div class="card">
<div class="title">Accelerating Scientific Research with Gemini: Case Studies and Common Techniques</div>
<div class="meta-line">Authors: David P. Woodruff, Vincent Cohen-Addad, Lalit Jain, Jieming Mao, Song Zuo, MohammadHossein Bateni, Simina Branzei, Michael P. Brenner, Lin Chen, Ying Feng, Lance Fortnow, Gang Fu, Ziyi Guan, Zahra Hadizadeh, Mohammad T. Hajiaghayi, Mahdi JafariRaviz, Adel Javanmard, Karthik C. S., Ken-ichi Kawarabayashi, Ravi Kumar, Silvio Lattanzi, Euiwoong Lee, Yi Li, Ioannis Panageas, Dimitris Paparas, Benjamin Przybocki, Bernardo Subercaseaux, Ola Svensson, Shayan Taherijam, Xuan Wu, Eylon Yogev, Morteza Zadimoghaddam, Samson Zhou, Vahab Mirrokni</div>
<div class="meta-line">First: 2026-02-03T18:56:17+00:00 · Latest: 2026-02-03T18:56:17+00:00</div>
<div class="links" style="margin-top:8px"><a href="https://arxiv.org/abs/2602.03837v1">Abs</a> · <a href="https://arxiv.org/pdf/2602.03837v1">PDF</a> · <a href="https://huggingface.co/huggingface">Code1</a> · <a href="https://huggingface.co/docs/hub/spaces">Code2</a></div>
<details class="detail"><summary>Abstract</summary>
<div class="mono">Recent advances in large language models (LLMs) have opened new avenues for accelerating scientific research. While models are increasingly capable of assisting with routine tasks, their ability to contribute to novel, expert-level mathematical discovery is less understood. We present a collection of case studies demonstrating how researchers have successfully collaborated with advanced AI models, specifically Google&#x27;s Gemini-based models (in particular Gemini Deep Think and its advanced variants), to solve open problems, refute conjectures, and generate new proofs across diverse areas in theoretical computer science, as well as other areas such as economics, optimization, and physics. Based on these experiences, we extract common techniques for effective human-AI collaboration in theoretical research, such as iterative refinement, problem decomposition, and cross-disciplinary knowledge transfer. While the majority of our results stem from this interactive, conversational methodology, we also highlight specific instances that push beyond standard chat interfaces. These include deploying the model as a rigorous adversarial reviewer to detect subtle flaws in existing proofs, and embedding it within a &quot;neuro-symbolic&quot; loop that autonomously writes and executes code to verify complex derivations. Together, these examples highlight the potential of AI not just as a tool for automation, but as a versatile, genuine partner in the creative process of scientific discovery.</div></details>
<details class="detail"><summary>中文标题/摘要</summary>
<div class="mono"><b>标题：</b>利用Gemini加速科学研究：案例研究与常用技术</div>
<div class="mono" style="margin-top:8px">近期大语言模型（LLMs）的进展为加速科学研究开辟了新途径。尽管模型在辅助常规任务方面日益成熟，但其对新颖、专家级数学发现的贡献能力尚不明确。本文通过一系列案例研究，展示了研究人员如何与先进AI模型（特别是基于Google Gemini的模型，如Gemini Deep Think及其高级变体）成功协作，解决开放性问题、反驳猜想，并在理论计算机科学以及经济学、优化和物理学等多个领域生成新证明。基于这些经验，我们提炼出理论研究中有效人机协作的常用技术，例如迭代优化、问题分解和跨学科知识迁移。虽然大部分成果源于这种交互式对话方法，但我们也强调了超越标准聊天界面的特定实例，包括将模型部署为严格的对抗性评审员以检测现有证明中的细微缺陷，以及将其嵌入“神经符号”循环中，自主编写和执行代码以验证复杂推导。这些案例共同凸显了AI不仅作为自动化工具，更作为科学发现创造性过程中多才多艺、真正合作伙伴的潜力。</div>
</details>
<details class="detail"><summary>Summary / 总结</summary>
<div class="mono">This study investigates how advanced large language models can accelerate scientific discovery beyond routine tasks, focusing on their potential for novel mathematical and theoretical contributions. Researchers employed Google&#x27;s Gemini models, particularly Gemini Deep Think variants, through interactive collaboration techniques including iterative refinement, problem decomposition, and cross-disciplinary knowledge transfer to solve open problems, refute conjectures, and generate new proofs across theoretical computer science, economics, optimization, and physics. Experimental results demonstrate successful human-AI partnerships yielding concrete discoveries, with specific instances extending beyond standard chat interfaces to deploy models as rigorous adversarial reviewers for proof verification and within neuro-symbolic loops for autonomous code execution and derivation verification.</div>
<div class="mono" style="margin-top:8px">本研究探讨了先进大语言模型如何超越常规任务，加速科学发现，重点关注其在数学和理论创新方面的潜力。研究人员通过迭代精炼和问题分解等交互协作技术，利用谷歌Gemini模型（特别是Gemini Deep Think变体）解决理论计算机科学、经济学、优化和物理学领域的开放性问题。主要实验成果包括解决开放问题、反驳猜想和生成新证明，其中关键方法超越了标准聊天界面，例如将模型用作对抗性证明审查员，以及将其嵌入神经符号循环中以自主编写和执行代码进行验证。</div>
</details>
</div>
<div class="card">
<div class="title">AutoFigure: Generating and Refining Publication-Ready Scientific Illustrations</div>
<div class="meta-line">Authors: Minjun Zhu, Zhen Lin, Yixuan Weng, Panzhong Lu, Qiujie Xie, Yifan Wei, Sifan Liu, Qiyao Sun, Yue Zhang</div>
<div class="meta-line">Venue: ICLR 2026</div>
<div class="meta-line">First: 2026-02-03T18:41:43+00:00 · Latest: 2026-02-03T18:41:43+00:00</div>
<div class="meta-line">Comments: Accepted at the ICLR 2026</div>
<div class="links" style="margin-top:8px"><a href="https://arxiv.org/abs/2602.03828v1">Abs</a> · <a href="https://arxiv.org/pdf/2602.03828v1">PDF</a> · <a href="https://github.com/ResearAI/AutoFigure">Code1</a> · <a href="https://huggingface.co/huggingface">Code2</a> · <a href="https://huggingface.co/docs/hub/spaces">Code3</a></div>
<details class="detail"><summary>Abstract</summary>
<div class="mono">High-quality scientific illustrations are crucial for effectively communicating complex scientific and technical concepts, yet their manual creation remains a well-recognized bottleneck in both academia and industry. We present FigureBench, the first large-scale benchmark for generating scientific illustrations from long-form scientific texts. It contains 3,300 high-quality scientific text-figure pairs, covering diverse text-to-illustration tasks from scientific papers, surveys, blogs, and textbooks. Moreover, we propose AutoFigure, the first agentic framework that automatically generates high-quality scientific illustrations based on long-form scientific text. Specifically, before rendering the final result, AutoFigure engages in extensive thinking, recombination, and validation to produce a layout that is both structurally sound and aesthetically refined, outputting a scientific illustration that achieves both structural completeness and aesthetic appeal. Leveraging the high-quality data from FigureBench, we conduct extensive experiments to test the performance of AutoFigure against various baseline methods. The results demonstrate that AutoFigure consistently surpasses all baseline methods, producing publication-ready scientific illustrations. The code, dataset and huggingface space are released in https://github.com/ResearAI/AutoFigure.</div></details>
<details class="detail"><summary>中文标题/摘要</summary>
<div class="mono"><b>标题：</b>AutoFigure：生成与优化可发表级科学插图</div>
<div class="mono" style="margin-top:8px">高质量科学插图对于有效传达复杂科技概念至关重要，但其手动制作在学术界与工业界仍是公认的瓶颈。本文提出FigureBench——首个基于长篇科学文本生成插图的大规模基准，包含3,300组高质量科学文本-插图对，涵盖科研论文、综述、博客及教材中的多样化文本转插图任务。进一步，我们提出AutoFigure——首个基于长篇科学文本自动生成高质量科学插图的智能体框架。该框架在最终渲染前，通过深度思考、重组与验证生成结构严谨且美学精炼的布局，输出兼具结构完整性与视觉吸引力的科学插图。依托FigureBench的高质量数据，我们开展大量实验对比AutoFigure与多种基线方法。结果表明，AutoFigure始终优于所有基线方法，能生成可直接用于出版的科学插图。代码、数据集及HuggingFace空间已发布于https://github.com/ResearAI/AutoFigure。</div>
</details>
<details class="detail"><summary>Summary / 总结</summary>
<div class="mono">The research addresses the bottleneck of manually creating high-quality scientific illustrations for communicating complex concepts. The authors introduce FigureBench, a large-scale benchmark with 3,300 text-figure pairs from diverse sources, and propose AutoFigure, an agentic framework that generates illustrations through extensive thinking, recombination, and validation processes to ensure structural soundness and aesthetic refinement. Experimental results on FigureBench demonstrate that AutoFigure consistently outperforms baseline methods in producing publication-ready scientific illustrations.</div>
<div class="mono" style="margin-top:8px">该研究的动机在于，手动创建用于传达复杂概念的高质量科学插图是一个公认的瓶颈。方法上提出了AutoFigure，这是一个基于长篇幅科学文本自动生成出版级插图的智能体框架，通过深入的思考、重组和验证过程来确保结构的完整性和美观性。在包含3300个文本-插图对的新基准FigureBench上的实验结果表明，AutoFigure在生成高质量插图方面持续优于各种基线方法。</div>
</details>
</div>
<div class="card">
<div class="title">Multi-Agent Pathfinding Under Team-Connected Communication Constraint via Adaptive Path Expansion and Dynamic Leading</div>
<div class="meta-line">Authors: Hoang-Dung Bui, Erion Plaku, Gregoy J. Stein</div>
<div class="meta-line">First: 2025-01-06T05:21:18+00:00 · Latest: 2026-02-03T18:36:02+00:00</div>
<div class="links" style="margin-top:8px"><a href="https://arxiv.org/abs/2501.02770v5">Abs</a> · <a href="https://arxiv.org/pdf/2501.02770v5">PDF</a> · <a href="https://huggingface.co/huggingface">Code1</a> · <a href="https://huggingface.co/docs/hub/spaces">Code2</a></div>
<details class="detail"><summary>Abstract</summary>
<div class="mono">This paper proposes a novel planning framework to handle a multi-agent pathfinding problem under team-connected communication constraint, where all agents must have a connected communication channel to the rest of the team during their entire movements. Standard multi-agent path finding approaches (e.g., priority-based search) have potential in this domain but fail when neighboring configurations at start and goal differ. Their single-expansion approach -- computing each agent&#x27;s path from the start to the goal in just a single expansion -- cannot reliably handle planning under communication constraints for agents as their neighbors change during navigating. Similarly, leader-follower approaches (e.g., platooning) are effective at maintaining team communication, but fixing the leader at the outset of planning can cause planning to become stuck in dense-clutter environments, limiting their practical utility. To overcome this limitation, we propose a novel two-level multi-agent pathfinding framework that integrates two techniques: adaptive path expansion to expand agent paths to their goals in multiple stages; and dynamic leading technique that enables the reselection of the leading agent during each agent path expansion whenever progress cannot be made. Simulation experiments show the efficiency of our planners, which can handle up to 25 agents across five environment types under a limited communication range constraint and up to 11-12 agents on three environment types under line-of-sight communication constraint, exceeding 90% success-rate where baselines routinely fail.</div></details>
<details class="detail"><summary>中文标题/摘要</summary>
<div class="mono"><b>标题：</b>基于自适应路径扩展与动态引导的团队连通通信约束下多智能体路径规划</div>
<div class="mono" style="margin-top:8px">本文提出一种新颖的规划框架，用于解决团队连通通信约束下的多智能体路径规划问题，要求所有智能体在整个移动过程中保持与团队其他成员的通信链路连通。传统多智能体路径规划方法（如基于优先级的搜索）在该领域有一定潜力，但在起点与目标点邻域配置差异较大时失效。其单次扩展方法——仅通过单次扩展为每个智能体计算从起点到目标的路径——无法在通信约束下可靠处理智能体因移动中邻居变化而产生的规划需求。类似地，领导者-跟随者方法（如队列行进）能有效维持团队通信，但若在规划初期固定领导者，易在密集杂乱环境中陷入规划僵局，限制其实用性。为克服此局限，我们提出一种新颖的双层多智能体路径规划框架，整合两项技术：自适应路径扩展，分多阶段扩展智能体至目标的路径；动态引导技术，在每次路径扩展无法推进时重新选择引导智能体。仿真实验表明，本规划器在有限通信距离约束下可处理五类环境中最多25个智能体，在视线通信约束下可处理三类环境中最多11-12个智能体，成功率超过90%，而基准方法在此类场景中普遍失效。</div>
</details>
<details class="detail"><summary>Summary / 总结</summary>
<div class="mono">This research addresses the multi-agent pathfinding problem under a team-connected communication constraint, where agents must maintain a connected communication channel throughout their movements. The proposed method introduces a two-level planning framework that combines adaptive path expansion, which expands agent paths to goals in multiple stages, and dynamic leading, which allows reselection of the leading agent during expansion when progress stalls. Experimental results demonstrate that the framework efficiently handles up to 25 agents under limited communication range and up to 11-12 agents under line-of-sight constraints across various environments, achieving over 90% success rates where baseline methods often fail.</div>
<div class="mono" style="margin-top:8px">本研究针对团队连通通信约束下的多智能体路径规划问题，要求智能体在整个移动过程中保持通信连接。所提出的方法采用了一个双层规划框架，结合了自适应路径扩展（分阶段计算路径）和动态引导技术（在扩展过程中重新选择引导智能体以避免停滞）。实验结果表明，该方法在有限通信范围下能高效处理多达25个智能体，在视线通信约束下能处理11-12个智能体，在基线方法常失败的环境中成功率超过90%。</div>
</details>
</div>
<div class="card">
<div class="title">Adaptive Evidence Weighting for Audio-Spatiotemporal Fusion</div>
<div class="meta-line">Authors: Oscar Ovanger, Levi Harris, Timothy H. Keitt</div>
<div class="meta-line">First: 2026-02-03T18:21:13+00:00 · Latest: 2026-02-03T18:21:13+00:00</div>
<div class="links" style="margin-top:8px"><a href="https://arxiv.org/abs/2602.03817v1">Abs</a> · <a href="https://arxiv.org/pdf/2602.03817v1">PDF</a> · <a href="https://huggingface.co/huggingface">Code1</a> · <a href="https://huggingface.co/docs/hub/spaces">Code2</a></div>
<details class="detail"><summary>Abstract</summary>
<div class="mono">Many machine learning systems have access to multiple sources of evidence for the same prediction target, yet these sources often differ in reliability and informativeness across inputs. In bioacoustic classification, species identity may be inferred both from the acoustic signal and from spatiotemporal context such as location and season; while Bayesian inference motivates multiplicative evidence combination, in practice we typically only have access to discriminative predictors rather than calibrated generative models. We introduce \textbf{F}usion under \textbf{IN}dependent \textbf{C}onditional \textbf{H}ypotheses (\textbf{FINCH}), an adaptive log-linear evidence fusion framework that integrates a pre-trained audio classifier with a structured spatiotemporal predictor. FINCH learns a per-sample gating function that estimates the reliability of contextual information from uncertainty and informativeness statistics. The resulting fusion family \emph{contains} the audio-only classifier as a special case and explicitly bounds the influence of contextual evidence, yielding a risk-contained hypothesis class with an interpretable audio-only fallback. Across benchmarks, FINCH consistently outperforms fixed-weight fusion and audio-only baselines, improving robustness and error trade-offs even when contextual information is weak in isolation. We achieve state-of-the-art performance on CBI and competitive or improved performance on several subsets of BirdSet using a lightweight, interpretable, evidence-based approach. Code is available: \texttt{\href{https://anonymous.4open.science/r/birdnoise-85CD/README.md}{anonymous-repository}}</div></details>
<details class="detail"><summary>中文标题/摘要</summary>
<div class="mono"><b>标题：</b>面向音频-时空融合的自适应证据加权方法</div>
<div class="mono" style="margin-top:8px">许多机器学习系统可获取同一预测目标的多个证据源，但这些证据源在不同输入中的可靠性和信息量常存在差异。在生物声学分类中，物种身份既可从声学信号推断，也可通过时空上下文（如地理位置和季节）推断；虽然贝叶斯推断支持乘法证据融合，但实践中通常只能使用判别式预测器而非校准的生成模型。本文提出\textbf{FINCH}（独立条件假设下的融合）框架——一种自适应对数线性证据融合框架，将预训练的音频分类器与结构化时空预测器相结合。FINCH通过学习样本级门控函数，基于不确定性和信息量统计量估计上下文信息的可靠性。该融合族\emph{包含}纯音频分类器作为特例，并显式约束上下文证据的影响，形成具有可解释纯音频回退机制的风险可控假设类。在多个基准测试中，FINCH始终优于固定权重融合和纯音频基线，即使上下文信息本身较弱时仍能提升鲁棒性并优化误差权衡。我们通过轻量化、可解释、基于证据的方法，在CBI数据集上取得最先进性能，并在BirdSet的多个子集上实现竞争性或改进性能。代码已开源：\texttt{\href{https://anonymous.4open.science/r/birdnoise-85CD/README.md}{匿名仓库}}</div>
</details>
<details class="detail"><summary>Summary / 总结</summary>
<div class="mono">The research addresses the challenge of effectively combining multiple evidence sources, such as audio signals and spatiotemporal context, for bioacoustic classification, where the reliability of each source varies per input. The method introduces FINCH, an adaptive log-linear fusion framework that integrates a pre-trained audio classifier with a spatiotemporal predictor by learning a per-sample gating function to estimate contextual reliability based on uncertainty and informativeness. Experimental results show that FINCH consistently outperforms fixed-weight fusion and audio-only baselines across benchmarks, achieving state-of-the-art performance on CBI and competitive or improved results on BirdSet subsets, while providing robustness and an interpretable audio-only fallback.</div>
<div class="mono" style="margin-top:8px">本研究旨在解决生物声学分类中有效融合音频信号和时空上下文等多源证据的挑战，其中每个证据源的可靠性随输入而变化。提出的方法FINCH是一种自适应对数线性融合框架，它整合了预训练的音频分类器和时空预测器，通过基于不确定性和信息量的逐样本门控函数来估计上下文可靠性。实验结果表明，在多个基准测试中，FINCH持续优于固定权重融合和仅音频基线，在CBI上取得了最先进的性能，在BirdSet子集上获得了竞争性或改进的结果，同时提供了鲁棒性和可解释的仅音频回退机制。</div>
</details>
</div>
<div class="card">
<div class="title">Conformal Thinking: Risk Control for Reasoning on a Compute Budget</div>
<div class="meta-line">Authors: Xi Wang, Anushri Suresh, Alvin Zhang, Rishi More, William Jurayj, Benjamin Van Durme, Mehrdad Farajtabar, Daniel Khashabi, Eric Nalisnick</div>
<div class="meta-line">First: 2026-02-03T18:17:22+00:00 · Latest: 2026-02-03T18:17:22+00:00</div>
<div class="links" style="margin-top:8px"><a href="https://arxiv.org/abs/2602.03814v1">Abs</a> · <a href="https://arxiv.org/pdf/2602.03814v1">PDF</a> · <a href="https://huggingface.co/huggingface">Code1</a> · <a href="https://huggingface.co/docs/hub/spaces">Code2</a></div>
<details class="detail"><summary>Abstract</summary>
<div class="mono">Reasoning Large Language Models (LLMs) enable test-time scaling, with dataset-level accuracy improving as the token budget increases, motivating adaptive reasoning -- spending tokens when they improve reliability and stopping early when additional computation is unlikely to help. However, setting the token budget, as well as the threshold for adaptive reasoning, is a practical challenge that entails a fundamental risk-accuracy trade-off. We re-frame the budget setting problem as risk control, limiting the error rate while minimizing compute. Our framework introduces an upper threshold that stops reasoning when the model is confident (risking incorrect output) and a novel parametric lower threshold that preemptively stops unsolvable instances (risking premature stoppage). Given a target risk and a validation set, we use distribution-free risk control to optimally specify these stopping mechanisms. For scenarios with multiple budget controlling criteria, we incorporate an efficiency loss to select the most computationally efficient exiting mechanism. Empirical results across diverse reasoning tasks and models demonstrate the effectiveness of our risk control approach, demonstrating computational efficiency gains from the lower threshold and ensemble stopping mechanisms while adhering to the user-specified risk target.</div></details>
<details class="detail"><summary>中文标题/摘要</summary>
<div class="mono"><b>标题：</b>保形思维：计算预算约束下的推理风险控制</div>
<div class="mono" style="margin-top:8px">推理型大语言模型（LLMs）支持测试时扩展，其数据集级准确率随计算令牌预算增加而提升，这催生了自适应推理机制——在能提升可靠性时消耗令牌，而在额外计算可能无效时提前终止。然而，设定令牌预算及自适应推理阈值存在实际挑战，涉及风险与准确率间的根本权衡。我们将预算设定问题重构为风险控制问题，在最小化计算量的同时限制错误率。该框架引入双重阈值：上阈值在模型置信时停止推理（承担输出错误风险），创新的参数化下阈值则主动终止不可解实例（承担过早停止风险）。给定目标风险与验证集，我们采用无分布风险控制方法优化设定这些停止机制。针对多预算控制标准的场景，通过引入效率损失函数选择计算效率最优的退出机制。跨多种推理任务与模型的实证结果表明，该风险控制方法在遵循用户指定风险目标的同时，通过下阈值与集成停止机制显著提升了计算效率。</div>
</details>
<details class="detail"><summary>Summary / 总结</summary>
<div class="mono">The research addresses the practical challenge of setting token budgets and thresholds for adaptive reasoning in Large Language Models (LLMs), where accuracy improves with increased computation but entails a risk-accuracy trade-off. The method reframes budget setting as a risk control problem, introducing an upper threshold to stop when confident and a novel parametric lower threshold to preemptively stop unsolvable instances, using distribution-free risk control to optimally specify these mechanisms given a target risk and validation set; it also incorporates an efficiency loss for scenarios with multiple criteria to select the most computationally efficient exiting mechanism. Experimental results across diverse reasoning tasks and models show the approach effectively gains computational efficiency from the lower threshold and ensemble stopping mechanisms while adhering to user-specified risk targets.</div>
<div class="mono" style="margin-top:8px">该研究针对大型语言模型中自适应推理的令牌预算和阈值设置这一实际问题，其中增加计算量可提高准确性，但涉及风险与准确性的权衡。方法将预算设置重新定义为风险控制问题，引入一个上限阈值在模型置信时停止推理，以及一个新的参数化下限阈值来预先阻止不可解实例，利用无分布风险控制根据目标风险和验证集优化指定这些机制，并在多标准场景中纳入效率损失以选择计算效率最高的退出机制。在不同推理任务和模型上的实验结果表明，该方法能有效将错误率控制在用户指定目标内，同时通过下限阈值和集成停止机制实现了计算效率的提升。</div>
</details>
</div>
<div class="card">
<div class="title">Antidistillation Fingerprinting</div>
<div class="meta-line">Authors: Yixuan Even Xu, John Kirchenbauer, Yash Savani, Asher Trockman, Alexander Robey, Tom Goldstein, Fei Fang, J. Zico Kolter</div>
<div class="meta-line">First: 2026-02-03T18:15:50+00:00 · Latest: 2026-02-03T18:15:50+00:00</div>
<div class="meta-line">Comments: 26 pages, 11 figures</div>
<div class="links" style="margin-top:8px"><a href="https://arxiv.org/abs/2602.03812v1">Abs</a> · <a href="https://arxiv.org/pdf/2602.03812v1">PDF</a> · <a href="https://huggingface.co/huggingface">Code1</a> · <a href="https://huggingface.co/docs/hub/spaces">Code2</a></div>
<details class="detail"><summary>Abstract</summary>
<div class="mono">Model distillation enables efficient emulation of frontier large language models (LLMs), creating a need for robust mechanisms to detect when a third-party student model has trained on a teacher model&#x27;s outputs. However, existing fingerprinting techniques that could be used to detect such distillation rely on heuristic perturbations that impose a steep trade-off between generation quality and fingerprinting strength, often requiring significant degradation of utility to ensure the fingerprint is effectively internalized by the student. We introduce antidistillation fingerprinting (ADFP), a principled approach that aligns the fingerprinting objective with the student&#x27;s learning dynamics. Building upon the gradient-based framework of antidistillation sampling, ADFP utilizes a proxy model to identify and sample tokens that directly maximize the expected detectability of the fingerprint in the student after fine-tuning, rather than relying on the incidental absorption of the un-targeted biases of a more naive watermark. Experiments on GSM8K and OASST1 benchmarks demonstrate that ADFP achieves a significant Pareto improvement over state-of-the-art baselines, yielding stronger detection confidence with minimal impact on utility, even when the student model&#x27;s architecture is unknown.</div></details>
<details class="detail"><summary>中文标题/摘要</summary>
<div class="mono"><b>标题：</b>抗蒸馏指纹识别</div>
<div class="mono" style="margin-top:8px">模型蒸馏技术能够高效模拟前沿大语言模型（LLMs），这催生了对检测第三方学生模型是否基于教师模型输出进行训练的鲁棒机制的需求。然而，现有可用于检测此类蒸馏的指纹识别技术依赖于启发式扰动，导致生成质量与指纹强度之间存在显著权衡，通常需要大幅降低模型效用以确保指纹被学生模型有效内化。本文提出抗蒸馏指纹识别（ADFP），这是一种将指纹识别目标与学生模型学习动态对齐的原理性方法。基于抗蒸馏采样的梯度框架，ADFP利用代理模型识别并采样能直接最大化微调后学生模型中指纹预期可检测性的词元，而非依赖对简单水印非目标偏见的偶然吸收。在GSM8K和OASST1基准测试上的实验表明，ADFP相比现有先进基线实现了显著的帕累托改进，即使学生模型架构未知，也能以最小效用代价获得更强的检测置信度。</div>
</details>
<details class="detail"><summary>Summary / 总结</summary>
<div class="mono">The need to detect when a third-party student model has been trained on a teacher model&#x27;s outputs via distillation motivates this work, as existing fingerprinting techniques impose a steep trade-off between generation quality and detection strength. The proposed method, antidistillation fingerprinting (ADFP), aligns the fingerprinting objective with the student&#x27;s learning dynamics by using a proxy model to identify and sample tokens that directly maximize the expected detectability of the fingerprint after fine-tuning, rather than relying on incidental biases. Experimental results on GSM8K and OASST1 benchmarks show that ADFP achieves a significant Pareto improvement over state-of-the-art baselines, yielding stronger detection confidence with minimal impact on utility, even when the student model&#x27;s architecture is unknown.</div>
<div class="mono" style="margin-top:8px">模型蒸馏使得高效模仿前沿大语言模型成为可能，因此需要可靠的机制来检测第三方学生模型是否基于教师模型的输出进行了训练。现有指纹技术依赖于启发式扰动，导致生成质量与指纹强度之间存在严重权衡。本研究提出的抗蒸馏指纹方法（ADFP）将指纹目标与学生的学习动态对齐，通过使用代理模型识别并采样能直接最大化微调后指纹可检测性的标记，而非依赖朴素水印的非针对性偏差的偶然吸收。在GSM8K和OASST1基准上的实验表明，ADFP相比现有先进基线实现了显著的帕累托改进，即使在学生模型架构未知的情况下，也能以最小的效用损失获得更强的检测置信度。</div>
</details>
</div>
<div class="card">
<div class="title">Enhancing Imbalanced Node Classification via Curriculum-Guided Feature Learning and Three-Stage Attention Network</div>
<div class="meta-line">Authors: Abdul Joseph Fofanah, Lian Wen, David Chen, Shaoyang Zhang</div>
<div class="meta-line">First: 2026-02-03T18:10:40+00:00 · Latest: 2026-02-03T18:10:40+00:00</div>
<div class="links" style="margin-top:8px"><a href="https://arxiv.org/abs/2602.03808v1">Abs</a> · <a href="https://arxiv.org/pdf/2602.03808v1">PDF</a> · <a href="https://huggingface.co/huggingface">Code1</a> · <a href="https://huggingface.co/docs/hub/spaces">Code2</a></div>
<details class="detail"><summary>Abstract</summary>
<div class="mono">Imbalanced node classification in graph neural networks (GNNs) happens when some labels are much more common than others, which causes the model to learn unfairly and perform badly on the less common classes. To solve this problem, we propose a Curriculum-Guided Feature Learning and Three-Stage Attention Network (CL3AN-GNN), a learning network that uses a three-step attention system (Engage, Enact, Embed) similar to how humans learn. The model begins by engaging with structurally simpler features, defined as (1) local neighbourhood patterns (1-hop), (2) low-degree node attributes, and (3) class-separable node pairs identified via initial graph convolutional networks and graph attention networks (GCN and GAT) embeddings. This foundation enables stable early learning despite label skew. The Enact stage then addresses complicated aspects: (1) connections that require multiple steps, (2) edges that connect different types of nodes, and (3) nodes at the edges of minority classes by using adjustable attention weights. Finally, Embed consolidates these features via iterative message passing and curriculum-aligned loss weighting. We evaluate CL3AN-GNN on eight Open Graph Benchmark datasets spanning social, biological, and citation networks. Experiments show consistent improvements across all datasets in accuracy, F1-score, and AUC over recent state-of-the-art methods. The model&#x27;s step-by-step method works well with different types of graph datasets, showing quicker results than training everything at once, better performance on new, imbalanced graphs, and clear explanations of each step using gradient stability and attention correlation learning curves. This work provides both a theoretically grounded framework for curriculum learning in GNNs and practical evidence of its effectiveness against imbalances, validated through metrics, convergence speeds, and generalisation tests.</div></details>
<details class="detail"><summary>中文标题/摘要</summary>
<div class="mono"><b>标题：</b>通过课程引导特征学习与三阶段注意力网络增强不平衡节点分类</div>
<div class="mono" style="margin-top:8px">图神经网络（GNN）中的不平衡节点分类问题指某些标签远比其他标签更常见，导致模型学习不公且在少数类上表现不佳。为解决此问题，我们提出课程引导特征学习与三阶段注意力网络（CL3AN-GNN），该网络采用类似人类学习的三步注意力机制（Engage、Enact、Embed）。模型首先从结构简单的特征入手，包括：（1）局部邻域模式（1跳），（2）低度节点属性，（3）通过初始图卷积网络和图注意力网络（GCN与GAT）嵌入识别的类可分节点对。这一基础确保了在标签偏斜下的稳定早期学习。Enact阶段随后处理复杂特征：（1）需多步连接的路径，（2）异质节点间的边，（3）通过可调注意力权重处理的少数类边界节点。最后，Embed阶段通过迭代消息传递和课程对齐损失加权整合特征。我们在涵盖社交、生物和引文网络的八个Open Graph Benchmark数据集上评估CL3AN-GNN。实验表明，该模型在准确率、F1分数和AUC上均优于当前先进方法，且逐步学习方法适用于多种图数据集，相比整体训练收敛更快，在新不平衡图上泛化能力更强，并通过梯度稳定性与注意力相关性学习曲线提供可解释性。本研究为GNN课程学习提供了理论框架，并通过指标、收敛速度和泛化测试验证了其应对不平衡问题的有效性。</div>
</details>
<details class="detail"><summary>Summary / 总结</summary>
<div class="mono">The research addresses the problem of imbalanced node classification in graph neural networks, where models exhibit poor performance on minority classes due to label distribution skew. The proposed method, CL3AN-GNN, introduces a curriculum-guided feature learning approach with a three-stage attention mechanism (Engage, Enact, Embed) that progressively learns from structurally simpler to more complex graph features, utilizing adaptive attention weights and curriculum-aligned loss weighting. Experimental evaluation on eight Open Graph Benchmark datasets demonstrates consistent improvements in accuracy, F1-score, and AUC over state-of-the-art methods, along with faster convergence, better generalization to unseen imbalanced graphs, and interpretable learning dynamics.</div>
<div class="mono" style="margin-top:8px">本研究针对图神经网络中节点分类的类别不平衡问题，即标签分布不均导致模型对少数类性能下降。提出的CL3AN-GNN方法采用课程引导的特征学习框架，通过三阶段注意力机制（Engage、Enact、Embed）从结构简单的特征逐步学习到复杂特征，并利用自适应注意力权重和迭代消息传递。在八个Open Graph Benchmark数据集上的实验表明，该方法在准确率、F1分数和AUC指标上均优于现有先进方法，同时实现了更快的收敛速度、对未见不平衡图更好的泛化能力，并提供了可解释的学习过程分析。</div>
</details>
</div>
<div class="card">
<div class="title">Bridging Online and Offline RL: Contextual Bandit Learning for Multi-Turn Code Generation</div>
<div class="meta-line">Authors: Ziru Chen, Dongdong Chen, Ruinan Jin, Yingbin Liang, Yujia Xie, Huan Sun</div>
<div class="meta-line">First: 2026-02-03T18:08:41+00:00 · Latest: 2026-02-03T18:08:41+00:00</div>
<div class="links" style="margin-top:8px"><a href="https://arxiv.org/abs/2602.03806v1">Abs</a> · <a href="https://arxiv.org/pdf/2602.03806v1">PDF</a> · <a href="https://github.com/OSU-NLP-Group/cobalt">Code1</a> · <a href="https://huggingface.co/huggingface">Code2</a> · <a href="https://huggingface.co/docs/hub/spaces">Code3</a></div>
<details class="detail"><summary>Abstract</summary>
<div class="mono">Recently, there have been significant research interests in training large language models (LLMs) with reinforcement learning (RL) on real-world tasks, such as multi-turn code generation. While online RL tends to perform better than offline RL, its higher training cost and instability hinders wide adoption. In this paper, we build on the observation that multi-turn code generation can be formulated as a one-step recoverable Markov decision process and propose contextual bandit learning with offline trajectories (Cobalt), a new method that combines the benefits of online and offline RL. Cobalt first collects code generation trajectories using a reference LLM and divides them into partial trajectories as contextual prompts. Then, during online bandit learning, the LLM is trained to complete each partial trajectory prompt through single-step code generation. Cobalt outperforms two multi-turn online RL baselines based on GRPO and VeRPO, and substantially improves R1-Distill 8B and Qwen3 8B by up to 9.0 and 6.2 absolute Pass@1 scores on LiveCodeBench. Also, we analyze LLMs&#x27; in-context reward hacking behaviors and augment Cobalt training with perturbed trajectories to mitigate this issue. Overall, our results demonstrate Cobalt as a promising solution for iterative decision-making tasks like multi-turn code generation. Our code and data are available at https://github.com/OSU-NLP-Group/cobalt.</div></details>
<details class="detail"><summary>中文标题/摘要</summary>
<div class="mono"><b>标题：</b>连接在线与离线强化学习：面向多轮代码生成的上下文赌博机学习</div>
<div class="mono" style="margin-top:8px">近年来，利用强化学习在真实世界任务（如多轮代码生成）上训练大语言模型引起了广泛研究关注。尽管在线强化学习通常表现优于离线强化学习，但其较高的训练成本和不稳定性限制了广泛应用。本文基于多轮代码生成可建模为单步可恢复马尔可夫决策过程的观察，提出了基于离线轨迹的上下文赌博机学习方法（Cobalt），该方法融合了在线与离线强化学习的优势。Cobalt首先使用参考大语言模型收集代码生成轨迹，并将其分割为部分轨迹作为上下文提示；随后在在线赌博机学习阶段，通过单步代码生成训练大语言模型完成每个部分轨迹提示。Cobalt在LiveCodeBench基准上显著优于基于GRPO和VeRPO的两种多轮在线强化学习基线，并将R1-Distill 8B和Qwen3 8B模型的绝对Pass@1分数分别提升最高达9.0和6.2分。此外，本文分析了大语言模型的上下文奖励攻击行为，并通过扰动轨迹增强Cobalt训练以缓解该问题。总体而言，我们的结果表明Cobalt为多轮代码生成等迭代决策任务提供了有前景的解决方案。代码与数据已开源：https://github.com/OSU-NLP-Group/cobalt。</div>
</details>
<details class="detail"><summary>Summary / 总结</summary>
<div class="mono">To address the high cost and instability of online reinforcement learning (RL) for training large language models on real-world multi-turn code generation tasks, this work formulates the problem as a one-step recoverable Markov decision process and introduces Contextual Bandit Learning with Offline Trajectories (Cobalt). The method first collects code generation trajectories using a reference model, segments them into partial trajectories as contextual prompts, and then trains the LLM online through single-step completions of these prompts. Experimental results show that Cobalt outperforms online RL baselines like GRPO and VeRPO, substantially improving the Pass@1 scores of models such as R1-Distill 8B and Qwen3 8B by up to 9.0 and 6.2 points on LiveCodeBench, while also mitigating in-context reward hacking through data augmentation with perturbed trajectories.</div>
<div class="mono" style="margin-top:8px">为解决在线强化学习训练大语言模型进行多轮代码生成时成本高、不稳定的问题，本研究将任务建模为一步可恢复马尔可夫决策过程，提出了基于离线轨迹的上下文赌博机学习方法。该方法首先使用参考模型收集代码生成轨迹，将其分割为部分轨迹作为上下文提示，然后通过在线单步完成这些提示来训练模型。实验结果表明，该方法优于GRPO和VeRPO等在线强化学习基线，在LiveCodeBench上将R1-Distill 8B和Qwen3 8B模型的Pass@1分数分别提升了最高9.0和6.2分，同时通过扰动轨迹的数据增强缓解了上下文奖励黑客行为。</div>
</details>
</div>
<div class="card">
<div class="title">Measuring Agents in Production</div>
<div class="meta-line">Authors: Melissa Z. Pan, Negar Arabzadeh, Riccardo Cogo, Yuxuan Zhu, Alexander Xiong, Lakshya A Agrawal, Huanzhi Mao, Emma Shen, Sid Pallerla, Liana Patel, Shu Liu, Tianneng Shi, Xiaoyuan Liu, Jared Quincy Davis, Emmanuele Lacavalla, Alessandro Basile, Shuyi Yang, Paul Castro, Daniel Kang, Joseph E. Gonzalez, Koushik Sen, Dawn Song, Ion Stoica, Matei Zaharia, Marquita Ellis</div>
<div class="meta-line">First: 2025-12-02T16:45:10+00:00 · Latest: 2026-02-03T18:06:26+00:00</div>
<div class="links" style="margin-top:8px"><a href="https://arxiv.org/abs/2512.04123v3">Abs</a> · <a href="https://arxiv.org/pdf/2512.04123v3">PDF</a> · <a href="https://huggingface.co/huggingface">Code1</a> · <a href="https://huggingface.co/docs/hub/spaces">Code2</a></div>
<details class="detail"><summary>Abstract</summary>
<div class="mono">LLM-based agents already operate in production across many industries, yet we lack an understanding of what technical methods make deployments successful. We present the first systematic study of Measuring Agents in Production, MAP, using first-hand data from agent developers. We conducted 20 case studies via in-depth interviews and surveyed 306 practitioners across 26 domains. We investigate why organizations build agents, how they build them, how they evaluate them, and their top development challenges. Our study finds that production agents are built using simple, controllable approaches: 68% execute at most 10 steps before human intervention, 70% rely on prompting off-the-shelf models instead of weight tuning, and 74% depend primarily on human evaluation. Reliability (consistent correct behavior over time) remains the top development challenge, which practitioners currently address through systems-level design. MAP documents the current state of production agents, providing the research community with visibility into deployment realities and under-explored research avenues.</div></details>
<details class="detail"><summary>中文标题/摘要</summary>
<div class="mono"><b>标题：</b>生产环境中智能体的度量研究</div>
<div class="mono" style="margin-top:8px">基于大语言模型的智能体已在多行业生产环境中运行，但对其成功部署的技术方法仍缺乏系统认知。本研究通过开发者一手数据，首次对生产环境智能体度量（MAP）开展系统性研究：通过深度访谈完成20个案例研究，并调研了涵盖26个领域的306名从业者。我们探究了机构构建智能体的动因、构建方法、评估体系及核心开发挑战。研究发现，生产环境智能体普遍采用简洁可控的实现方案：68%的智能体在人工干预前最多执行10个步骤，70%依赖现成模型的提示工程而非权重调优，74%主要依靠人工评估。可靠性（长期保持行为一致性与正确性）仍是首要开发挑战，从业者目前通过系统级设计应对。MAP研究记录了生产环境智能体的现状，为学界揭示实际部署情况并指明尚未充分探索的研究路径。</div>
</details>
<details class="detail"><summary>Summary / 总结</summary>
<div class="mono">To address the lack of systematic understanding of what makes LLM-based agent deployments successful in real-world settings, this study conducted the first large-scale investigation, Measuring Agents in Production (MAP), using first-hand data. The method involved 20 in-depth case study interviews and a survey of 306 practitioners across 26 domains to analyze why and how agents are built, evaluated, and their key challenges. Key findings reveal that production agents predominantly employ simple, controllable designs: 68% execute at most 10 steps before requiring human intervention, 70% rely on prompting off-the-shelf models rather than fine-tuning, and 74% depend primarily on human evaluation for assessment. The foremost development challenge identified is ensuring reliability, which practitioners currently tackle through systems-level design rather than model-centric approaches.</div>
<div class="mono" style="margin-top:8px">本研究动机在于，尽管基于大语言模型的智能体已在各行业的生产环境中广泛部署，但对其成功部署的技术方法仍缺乏系统性理解。研究方法采用了首次系统性研究MAP，通过20个深度案例访谈和对26个领域的306名从业者的调查，收集第一手数据，以探究组织构建智能体的原因、方法、评估方式及其主要挑战。主要实验结果表明，生产环境中的智能体主要采用简单可控的方法：68%的智能体在执行最多10步后即需要人工干预，70%依赖提示现成模型而非权重调优，74%主要依靠人工评估，而可靠性是首要的开发挑战，目前通过系统级设计加以解决。</div>
</details>
</div>
<div class="card">
<div class="title">Do We Need Asynchronous SGD? On the Near-Optimality of Synchronous Methods</div>
<div class="meta-line">Authors: Grigory Begunov, Alexander Tyurin</div>
<div class="meta-line">First: 2026-02-03T18:02:14+00:00 · Latest: 2026-02-03T18:02:14+00:00</div>
<div class="links" style="margin-top:8px"><a href="https://arxiv.org/abs/2602.03802v1">Abs</a> · <a href="https://arxiv.org/pdf/2602.03802v1">PDF</a> · <a href="https://huggingface.co/huggingface">Code1</a> · <a href="https://huggingface.co/docs/hub/spaces">Code2</a></div>
<details class="detail"><summary>Abstract</summary>
<div class="mono">Modern distributed optimization methods mostly rely on traditional synchronous approaches, despite substantial recent progress in asynchronous optimization. We revisit Synchronous SGD and its robust variant, called $m$-Synchronous SGD, and theoretically show that they are nearly optimal in many heterogeneous computation scenarios, which is somewhat unexpected. We analyze the synchronous methods under random computation times and adversarial partial participation of workers, and prove that their time complexities are optimal in many practical regimes, up to logarithmic factors. While synchronous methods are not universal solutions and there exist tasks where asynchronous methods may be necessary, we show that they are sufficient for many modern heterogeneous computation scenarios.</div></details>
<details class="detail"><summary>中文标题/摘要</summary>
<div class="mono"><b>标题：</b>我们是否需要异步SGD？论同步方法的近优性</div>
<div class="mono" style="margin-top:8px">尽管异步优化近期取得显著进展，现代分布式优化方法仍主要依赖传统同步方法。我们重新审视同步SGD及其鲁棒变体$m$-同步SGD，从理论上证明它们在许多异构计算场景中具有接近最优的性能，这一结论出人意料。我们在随机计算时间和对抗性部分工作节点参与的设定下分析同步方法，证明其时间复杂度在许多实际场景中达到对数因子内的最优性。虽然同步方法并非通用解决方案，且存在需要异步方法的特定任务，但我们证明它们足以应对许多现代异构计算场景。</div>
</details>
<details class="detail"><summary>Summary / 总结</summary>
<div class="mono">This paper revisits synchronous SGD methods to determine their efficacy in modern heterogeneous computing environments, motivated by the ongoing debate between synchronous and asynchronous distributed optimization. The authors theoretically analyze Synchronous SGD and its robust variant, m-Synchronous SGD, under conditions of random worker computation times and adversarial partial participation. The key finding is that these synchronous methods achieve near-optimal time complexity, up to logarithmic factors, in many practical heterogeneous regimes, suggesting they are often sufficient despite the progress in asynchronous optimization.</div>
<div class="mono" style="margin-top:8px">本文重新审视同步SGD方法，旨在探讨其在异构分布式环境中的最优性，动机源于同步与异步优化方法之间的持续争论。作者在随机计算时间和对抗性部分工作节点参与的条件下，从理论上分析了同步SGD及其鲁棒变体m-同步SGD。主要实验结果表明，在许多实际的异构计算场景中，这些同步方法的时间复杂度达到了接近最优的水平（仅差对数因子），这表明尽管异步技术有所进展，同步方法对于许多现代场景而言已经足够。</div>
</details>
</div>
<div class="card">
<div class="title">Conformal Reachability for Safe Control in Unknown Environments</div>
<div class="meta-line">Authors: Xinhang Ma, Junlin Wu, Yiannis Kantaros, Yevgeniy Vorobeychik</div>
<div class="meta-line">First: 2026-02-03T18:01:38+00:00 · Latest: 2026-02-03T18:01:38+00:00</div>
<div class="links" style="margin-top:8px"><a href="https://arxiv.org/abs/2602.03799v1">Abs</a> · <a href="https://arxiv.org/pdf/2602.03799v1">PDF</a> · <a href="https://huggingface.co/huggingface">Code1</a> · <a href="https://huggingface.co/docs/hub/spaces">Code2</a></div>
<details class="detail"><summary>Abstract</summary>
<div class="mono">Designing provably safe control is a core problem in trustworthy autonomy. However, most prior work in this regard assumes either that the system dynamics are known or deterministic, or that the state and action space are finite, significantly limiting application scope. We address this limitation by developing a probabilistic verification framework for unknown dynamical systems which combines conformal prediction with reachability analysis. In particular, we use conformal prediction to obtain valid uncertainty intervals for the unknown dynamics at each time step, with reachability then verifying whether safety is maintained within the conformal uncertainty bounds. Next, we develop an algorithmic approach for training control policies that optimize nominal reward while also maximizing the planning horizon with sound probabilistic safety guarantees. We evaluate the proposed approach in seven safe control settings spanning four domains -- cartpole, lane following, drone control, and safe navigation -- for both affine and nonlinear safety specifications. Our experiments show that the policies we learn achieve the strongest provable safety guarantees while still maintaining high average reward.</div></details>
<details class="detail"><summary>中文标题/摘要</summary>
<div class="mono"><b>标题：</b>未知环境下安全控制的保形可达性分析</div>
<div class="mono" style="margin-top:8px">设计可证明的安全控制是可信自主系统的核心问题。然而，现有研究大多假设系统动力学已知或确定，或状态与动作空间有限，这严重限制了应用范围。我们通过开发结合保形预测与可达性分析的未知动态系统概率验证框架来解决这一局限。具体而言，我们利用保形预测获取每个时间步未知动态的有效不确定区间，再通过可达性分析验证在保形不确定边界内是否保持安全性。进一步，我们提出一种算法框架来训练控制策略，在优化名义奖励的同时，通过可靠的概率安全保证最大化规划时域。我们在涵盖倒立摆、车道跟随、无人机控制和安全导航四个领域的七种安全控制场景中评估所提方法，覆盖线性和非线性安全约束。实验表明，所学策略在保持高平均奖励的同时，实现了最强的可证明安全保证。</div>
</details>
<details class="detail"><summary>Summary / 总结</summary>
<div class="mono">To enable provably safe control for unknown dynamical systems without restrictive assumptions on dynamics or state-action spaces, this work introduces a probabilistic verification framework that integrates conformal prediction with reachability analysis. The method uses conformal prediction to derive statistically valid uncertainty intervals for the unknown dynamics at each time step and then performs reachability analysis to verify safety within these bounds; it further trains control policies to optimize nominal reward while maximizing the planning horizon with probabilistic safety guarantees. Experimental evaluation across seven safe control settings in four domains (cartpole, lane following, drone control, and safe navigation) for both affine and nonlinear safety specifications demonstrates that the learned policies achieve the strongest provable safety guarantees while maintaining high average reward.</div>
<div class="mono" style="margin-top:8px">为使未知动态系统能够实现可证明的安全控制，避免对系统动力学或状态-动作空间的限制性假设，本研究提出了一种将共形预测与可达性分析相结合的概率验证框架。该方法利用共形预测为每个时间步的未知动力学推导统计有效的置信区间，然后通过可达性分析验证在这些区间内的安全性；进一步训练控制策略以优化名义奖励，同时在概率安全保证下最大化规划范围。在倒立摆、车道跟随、无人机控制和安全导航四个领域的七个实验场景中的评估表明，所学习的策略在保持高平均奖励的同时，实现了最强的可证明安全保证。</div>
</details>
</div>
<div class="card">
<div class="title">Understanding Agent Scaling in LLM-Based Multi-Agent Systems via Diversity</div>
<div class="meta-line">Authors: Yingxuan Yang, Chengrui Qu, Muning Wen, Laixi Shi, Ying Wen, Weinan Zhang, Adam Wierman, Shangding Gu</div>
<div class="meta-line">First: 2026-02-03T17:58:10+00:00 · Latest: 2026-02-03T17:58:10+00:00</div>
<div class="links" style="margin-top:8px"><a href="https://arxiv.org/abs/2602.03794v1">Abs</a> · <a href="https://arxiv.org/pdf/2602.03794v1">PDF</a> · <a href="https://github.com/SafeRL-Lab/Agent-Scaling">Code1</a> · <a href="https://huggingface.co/huggingface">Code2</a> · <a href="https://huggingface.co/docs/hub/spaces">Code3</a></div>
<details class="detail"><summary>Abstract</summary>
<div class="mono">LLM-based multi-agent systems (MAS) have emerged as a promising approach to tackle complex tasks that are difficult for individual LLMs. A natural strategy is to scale performance by increasing the number of agents; however, we find that such scaling exhibits strong diminishing returns in homogeneous settings, while introducing heterogeneity (e.g., different models, prompts, or tools) continues to yield substantial gains. This raises a fundamental question: what limits scaling, and why does diversity help? We present an information-theoretic framework showing that MAS performance is bounded by the intrinsic task uncertainty, not by agent count. We derive architecture-agnostic bounds demonstrating that improvements depend on how many effective channels the system accesses. Homogeneous agents saturate early because their outputs are strongly correlated, whereas heterogeneous agents contribute complementary evidence. We further introduce $K^*$, an effective channel count that quantifies the number of effective channels without ground-truth labels. Empirically, we show that heterogeneous configurations consistently outperform homogeneous scaling: 2 diverse agents can match or exceed the performance of 16 homogeneous agents. Our results provide principled guidelines for building efficient and robust MAS through diversity-aware design. Code and Dataset are available at the link: https://github.com/SafeRL-Lab/Agent-Scaling.</div></details>
<details class="detail"><summary>中文标题/摘要</summary>
<div class="mono"><b>标题：</b>通过多样性理解基于LLM的多智能体系统中的智能体扩展</div>
<div class="mono" style="margin-top:8px">基于大语言模型（LLM）的多智能体系统（MAS）已成为解决单个LLM难以处理的复杂任务的一种有前景的方法。一种自然的策略是通过增加智能体数量来扩展性能；然而，我们发现这种扩展在同类设置中表现出强烈的收益递减效应，而引入异质性（例如不同模型、提示或工具）则能持续带来显著增益。这引发了一个根本性问题：什么限制了扩展，以及多样性为何有助于提升？我们提出了一个信息论框架，表明MAS性能受限于任务的内在不确定性，而非智能体数量。我们推导出与架构无关的边界，证明改进取决于系统访问的有效通道数量。同类智能体因其输出高度相关而早期饱和，而异类智能体则提供互补证据。我们进一步引入$K^*$，这是一种无需真实标签即可量化有效通道数量的指标。实证研究表明，异类配置始终优于同类扩展：2个异类智能体的性能可匹配或超越16个同类智能体。我们的结果为通过多样性感知设计构建高效且稳健的MAS提供了原则性指导。代码和数据集可在以下链接获取：https://github.com/SafeRL-Lab/Agent-Scaling。</div>
</details>
<details class="detail"><summary>Summary / 总结</summary>
<div class="mono">This research investigates why scaling the number of agents in LLM-based multi-agent systems (MAS) shows diminishing returns in homogeneous settings, while heterogeneous configurations yield continued performance gains. The authors propose an information-theoretic framework to show that MAS performance is fundamentally bounded by the intrinsic task uncertainty, not by agent count, and introduce $K^*$, a metric to quantify the number of effective information channels a system accesses. Experimental results demonstrate that heterogeneous systems, using agents with different models, prompts, or tools, significantly outperform homogeneous scaling, with just two diverse agents matching or exceeding the performance of sixteen homogeneous agents.</div>
<div class="mono" style="margin-top:8px">本研究探讨了在基于大语言模型的多智能体系统中，单纯增加智能体数量为何常导致收益递减，旨在理解其根本限制因素以及多样性的作用。方法上采用了一个信息论框架，表明系统性能受限于任务固有的不确定性，并引入了无需真实标签即可量化有效信息通道数量的指标$K^*$。关键实验结果表明，异构智能体配置（使用不同模型、提示或工具）显著优于同构扩展，仅两个多样化的智能体就能达到或超过十六个同构智能体的性能，这证明多样性提供了互补证据并缓解了输出相关性。</div>
</details>
</div>
<div class="card">
<div class="title">WebSentinel: Detecting and Localizing Prompt Injection Attacks for Web Agents</div>
<div class="meta-line">Authors: Xilong Wang, Yinuo Liu, Zhun Wang, Dawn Song, Neil Gong</div>
<div class="meta-line">First: 2026-02-03T17:55:04+00:00 · Latest: 2026-02-03T17:55:04+00:00</div>
<div class="links" style="margin-top:8px"><a href="https://arxiv.org/abs/2602.03792v1">Abs</a> · <a href="https://arxiv.org/pdf/2602.03792v1">PDF</a> · <a href="https://github.com/wxl-lxw/WebSentinel">Code1</a> · <a href="https://huggingface.co/huggingface">Code2</a> · <a href="https://huggingface.co/docs/hub/spaces">Code3</a></div>
<details class="detail"><summary>Abstract</summary>
<div class="mono">Prompt injection attacks manipulate webpage content to cause web agents to execute attacker-specified tasks instead of the user&#x27;s intended ones. Existing methods for detecting and localizing such attacks achieve limited effectiveness, as their underlying assumptions often do not hold in the web-agent setting. In this work, we propose WebSentinel, a two-step approach for detecting and localizing prompt injection attacks in webpages. Given a webpage, Step I extracts \emph{segments of interest} that may be contaminated, and Step II evaluates each segment by checking its consistency with the webpage content as context. We show that WebSentinel is highly effective, substantially outperforming baseline methods across multiple datasets of both contaminated and clean webpages that we collected. Our code is available at: https://github.com/wxl-lxw/WebSentinel.</div></details>
<details class="detail"><summary>中文标题/摘要</summary>
<div class="mono"><b>标题：</b>WebSentinel：面向网页代理的提示注入攻击检测与定位</div>
<div class="mono" style="margin-top:8px">提示注入攻击通过操纵网页内容，诱使网页代理执行攻击者指定的任务而非用户预期操作。现有检测与定位方法因基本假设在网页代理场景中常不成立，效果有限。本文提出WebSentinel，采用两步法检测并定位网页中的提示注入攻击：第一步提取可能受污染的“关注片段”，第二步以网页内容为上下文检验各片段的一致性。实验表明，WebSentinel在自建的多数据集（含污染与干净网页）上效果显著，大幅优于基线方法。代码已开源：https://github.com/wxl-lxw/WebSentinel。</div>
</details>
<details class="detail"><summary>Summary / 总结</summary>
<div class="mono">Prompt injection attacks manipulate webpage content to hijack web agents&#x27; behavior, but existing detection methods are limited due to unrealistic assumptions in web-agent settings. To address this, WebSentinel introduces a two-step approach: first extracting potentially contaminated segments of interest from webpages, then evaluating each segment&#x27;s consistency with the surrounding webpage content as context. Experimental evaluation on collected datasets of both contaminated and clean webpages demonstrates that WebSentinel substantially outperforms baseline methods in both detection and localization effectiveness.</div>
<div class="mono" style="margin-top:8px">提示注入攻击通过操纵网页内容使网络代理执行攻击者指定的任务而非用户意图，但现有检测方法因在网络代理场景中假设不切实际而效果有限。为此，WebSentinel提出一种两步方法：首先从网页中提取可能被污染的兴趣片段，然后通过检查每个片段与网页上下文内容的一致性进行评估。在收集的污染和干净网页数据集上的实验结果表明，WebSentinel在检测和定位此类攻击方面显著优于基线方法。</div>
</details>
</div>
<div class="card">
<div class="title">Fast Sampling for Flows and Diffusions with Lazy and Point Mass Stochastic Interpolants</div>
<div class="meta-line">Authors: Gabriel Damsholt, Jes Frellsen, Susanne Ditlevsen</div>
<div class="meta-line">First: 2026-02-03T17:48:34+00:00 · Latest: 2026-02-03T17:48:34+00:00</div>
<div class="links" style="margin-top:8px"><a href="https://arxiv.org/abs/2602.03789v1">Abs</a> · <a href="https://arxiv.org/pdf/2602.03789v1">PDF</a> · <a href="https://huggingface.co/huggingface">Code1</a> · <a href="https://huggingface.co/docs/hub/spaces">Code2</a></div>
<details class="detail"><summary>Abstract</summary>
<div class="mono">Stochastic interpolants unify flows and diffusions, popular generative modeling frameworks. A primary hyperparameter in these methods is the interpolation schedule that determines how to bridge a standard Gaussian base measure to an arbitrary target measure. We prove how to convert a sample path of a stochastic differential equation (SDE) with arbitrary diffusion coefficient under any schedule into the unique sample path under another arbitrary schedule and diffusion coefficient. We then extend the stochastic interpolant framework to admit a larger class of point mass schedules in which the Gaussian base measure collapses to a point mass measure. Under the assumption of Gaussian data, we identify lazy schedule families that make the drift identically zero and show that with deterministic sampling one gets a variance-preserving schedule commonly used in diffusion models, whereas with statistically optimal SDE sampling one gets our point mass schedule. Finally, to demonstrate the usefulness of our theoretical results on realistic highly non-Gaussian data, we apply our lazy schedule conversion to a state-of-the-art pretrained flow model and show that this allows for generating images in fewer steps without retraining the model.</div></details>
<details class="detail"><summary>中文标题/摘要</summary>
<div class="mono"><b>标题：</b>基于惰性与点质量随机插值的流与扩散快速采样方法</div>
<div class="mono" style="margin-top:8px">随机插值统一了流与扩散这两种主流生成建模框架。这些方法的核心超参数是插值调度，它决定了如何将标准高斯基测度与任意目标测度相连接。我们证明了如何将任意扩散系数下、任意调度对应的随机微分方程样本路径，转换为另一任意调度与扩散系数下的唯一样本路径。随后，我们将随机插值框架扩展至允许更广泛的点质量调度类别，其中高斯基测度坍缩为点质量测度。在高斯数据假设下，我们识别出使漂移项恒为零的惰性调度族，并证明：采用确定性采样会得到扩散模型中常用的方差保持调度，而采用统计最优的随机微分方程采样则会得到我们的点质量调度。最后，为验证理论结果在现实高度非高斯数据上的实用性，我们将惰性调度转换应用于先进的预训练流模型，结果表明无需重新训练模型即可用更少步骤生成图像。</div>
</details>
<details class="detail"><summary>Summary / 总结</summary>
<div class="mono">This research addresses the need for flexible sampling schedules in generative models based on stochastic interpolants, which unify flow and diffusion methods. The authors develop a theoretical framework to convert sample paths between arbitrary stochastic differential equation schedules and diffusion coefficients, and extend the framework to include point mass schedules where the Gaussian base collapses. Key experimental findings show that under Gaussian data assumptions, lazy schedules produce zero drift, with deterministic sampling yielding variance-preserving schedules and optimal SDE sampling producing point mass schedules. When applied to a pretrained flow model on non-Gaussian image data, the lazy schedule conversion enables faster image generation without model retraining.</div>
<div class="mono" style="margin-top:8px">本研究旨在通过优化连接高斯基分布与目标分布的插值调度，提高基于随机插值（统一了流和扩散）的生成模型的效率。方法提出了一个理论框架，可在任意调度和扩散系数之间转换样本路径，扩展了框架以包含基分布坍缩为点质量的点质量调度，并在高斯数据假设下识别出使漂移项为零的惰性调度族。关键实验结果表明，将惰性调度转换应用于预训练的流模型，可在不重新训练的情况下以更少步骤生成图像，证明了其在非高斯数据上的实际效用。</div>
</details>
</div>
<div class="card">
<div class="title">AOrchestra: Automating Sub-Agent Creation for Agentic Orchestration</div>
<div class="meta-line">Authors: Jianhao Ruan, Zhihao Xu, Yiran Peng, Fashen Ren, Zhaoyang Yu, Xinbing Liang, Jinyu Xiang, Bang Liu, Chenglin Wu, Yuyu Luo, Jiayi Zhang</div>
<div class="meta-line">First: 2026-02-03T17:46:16+00:00 · Latest: 2026-02-03T17:46:16+00:00</div>
<div class="links" style="margin-top:8px"><a href="https://arxiv.org/abs/2602.03786v1">Abs</a> · <a href="https://arxiv.org/pdf/2602.03786v1">PDF</a> · <a href="https://github.com/FoundationAgents/AOrchestra">Code1</a> · <a href="https://huggingface.co/huggingface">Code2</a> · <a href="https://huggingface.co/docs/hub/spaces">Code3</a></div>
<details class="detail"><summary>Abstract</summary>
<div class="mono">Language agents have shown strong promise for task automation. Realizing this promise for increasingly complex, long-horizon tasks has driven the rise of a sub-agent-as-tools paradigm for multi-turn task solving. However, existing designs still lack a dynamic abstraction view of sub-agents, thereby hurting adaptability. We address this challenge with a unified, framework-agnostic agent abstraction that models any agent as a tuple Instruction, Context, Tools, Model. This tuple acts as a compositional recipe for capabilities, enabling the system to spawn specialized executors for each task on demand. Building on this abstraction, we introduce an agentic system AOrchestra, where the central orchestrator concretizes the tuple at each step: it curates task-relevant context, selects tools and models, and delegates execution via on-the-fly automatic agent creation. Such designs enable reducing human engineering efforts, and remain framework-agnostic with plug-and-play support for diverse agents as task executors. It also enables a controllable performance-cost trade-off, allowing the system to approach Pareto-efficient. Across three challenging benchmarks (GAIA, SWE-Bench, Terminal-Bench), AOrchestra achieves 16.28% relative improvement against the strongest baseline when paired with Gemini-3-Flash. The code is available at: https://github.com/FoundationAgents/AOrchestra</div></details>
<details class="detail"><summary>中文标题/摘要</summary>
<div class="mono"><b>标题：</b>AOrchestra：面向智能体编排的子智能体自动创建框架</div>
<div class="mono" style="margin-top:8px">语言智能体在任务自动化方面展现出巨大潜力。为实现对日益复杂的长周期任务的自动化处理，基于子智能体即工具范式的多轮任务求解模式逐渐兴起。然而现有设计仍缺乏对子智能体的动态抽象视角，限制了系统适应性。本研究提出一种统一且框架无关的智能体抽象模型，将任意智能体表征为四元组（指令、上下文、工具、模型）。该四元组作为能力组合的配方，使系统能够按需为每个任务生成专用执行器。基于此抽象模型，我们构建了智能体系统AOrchestra，其核心编排器在每一步动态实例化四元组：整合任务相关上下文、选择工具与模型，并通过实时自动创建智能体进行任务委派。该设计显著降低人工工程成本，保持框架无关性并支持即插即用的多样化智能体作为任务执行器，同时实现可控的性能-成本权衡，使系统趋近帕累托最优。在三大挑战性基准测试（GAIA、SWE-Bench、Terminal-Bench）中，AOrchestra配合Gemini-3-Flash模型相比最强基线获得16.28%的相对性能提升。代码已开源：https://github.com/FoundationAgents/AOrchestra</div>
</details>
<details class="detail"><summary>Summary / 总结</summary>
<div class="mono">To address the lack of adaptability in existing sub-agent designs for complex, long-horizon task automation, this research proposes a unified, framework-agnostic agent abstraction that models any agent as a tuple of Instruction, Context, Tools, and Model. This abstraction enables the AOrchestra system, where a central orchestrator dynamically concretizes this tuple at each step by curating context, selecting tools and models, and delegating execution via on-the-fly automatic agent creation. Experimental results on three benchmarks (GAIA, SWE-Bench, Terminal-Bench) show that AOrchestra, when paired with Gemini-3-Flash, achieves a 16.28% relative improvement over the strongest baseline, demonstrating enhanced performance while enabling a controllable performance-cost trade-off.</div>
<div class="mono" style="margin-top:8px">为解决多轮任务求解中智能体子代理缺乏动态抽象、导致适应性不足的问题，本研究提出了一种统一的智能体抽象模型：将任何智能体表示为指令、上下文、工具和模型的元组。基于此，AOrchestra系统使中央编排器能够为每个任务步骤动态实例化该元组，策划上下文、选择工具和模型，并按需自动创建专用执行器。在GAIA、SWE-Bench和Terminal-Bench三个基准测试上的实验结果表明，AOrchestra与Gemini-3-Flash配合使用时，相比最强基线实现了16.28%的相对性能提升，展现了减少工程负担、框架无关的即插即用支持以及可控的性能-成本权衡能力。</div>
</details>
</div>
<div class="card">
<div class="title">Efficient Estimation of Kernel Surrogate Models for Task Attribution</div>
<div class="meta-line">Authors: Zhenshuo Zhang, Minxuan Duan, Hongyang R. Zhang</div>
<div class="meta-line">Venue: ICLR 2026</div>
<div class="meta-line">First: 2026-02-03T17:43:48+00:00 · Latest: 2026-02-03T17:43:48+00:00</div>
<div class="meta-line">Comments: 27 pages. To appear in ICLR 2026</div>
<div class="links" style="margin-top:8px"><a href="https://arxiv.org/abs/2602.03783v1">Abs</a> · <a href="https://arxiv.org/pdf/2602.03783v1">PDF</a> · <a href="https://huggingface.co/huggingface">Code1</a> · <a href="https://huggingface.co/docs/hub/spaces">Code2</a></div>
<details class="detail"><summary>Abstract</summary>
<div class="mono">Modern AI agents such as large language models are trained on diverse tasks -- translation, code generation, mathematical reasoning, and text prediction -- simultaneously. A key question is to quantify how each individual training task influences performance on a target task, a problem we refer to as task attribution. The direct approach, leave-one-out retraining, measures the effect of removing each task, but is computationally infeasible at scale. An alternative approach that builds surrogate models to predict a target task&#x27;s performance for any subset of training tasks has emerged in recent literature. Prior work focuses on linear surrogate models, which capture first-order relationships, but miss nonlinear interactions such as synergy, antagonism, or XOR-type effects. In this paper, we first consider a unified task weighting framework for analyzing task attribution methods, and show a new connection between linear surrogate models and influence functions through a second-order analysis. Then, we introduce kernel surrogate models, which more effectively represent second-order task interactions. To efficiently learn the kernel surrogate, we develop a gradient-based estimation procedure that leverages a first-order approximation of pretrained models; empirically, this yields accurate estimates with less than $2\%$ relative error without repeated retraining. Experiments across multiple domains -- including math reasoning in transformers, in-context learning, and multi-objective reinforcement learning -- demonstrate the effectiveness of kernel surrogate models. They achieve a $25\%$ higher correlation with the leave-one-out ground truth than linear surrogates and influence-function baselines. When used for downstream task selection, kernel surrogate models yield a $40\%$ improvement in demonstration selection for in-context learning and multi-objective reinforcement learning benchmarks.</div></details>
<details class="detail"><summary>中文标题/摘要</summary>
<div class="mono"><b>标题：</b>面向任务归因的核代理模型高效估计方法</div>
<div class="mono" style="margin-top:8px">现代人工智能代理（如大语言模型）通常在翻译、代码生成、数学推理和文本预测等多样化任务上同时训练。核心问题在于量化每个独立训练任务对目标任务性能的影响，即任务归因问题。直接方法（留一重训练法）通过移除各任务来测量影响，但计算成本过高。近期研究提出构建代理模型来预测任意训练任务子集对目标任务的性能表现。现有工作主要聚焦线性代理模型，这类模型虽能捕捉一阶关系，却无法表征非线性交互作用（如协同效应、拮抗效应或异或型效应）。本文首先提出统一的任务加权框架来分析任务归因方法，并通过二阶分析揭示线性代理模型与影响函数的新关联。进而引入能更有效表征二阶任务交互的核代理模型。为高效学习核代理模型，我们开发了基于梯度的估计方法，该方法利用预训练模型的一阶近似；实证表明，该方法无需重复训练即可实现低于2%相对误差的精确估计。在数学推理Transformer、上下文学习及多目标强化学习等跨领域实验中，核代理模型展现出显著优势：其与留一法基准真相的相关系数较线性代理模型和影响函数基线提升25%；应用于下游任务选择时，在上下文学习的示例选择和多目标强化学习基准测试中实现40%的性能提升。</div>
</details>
<details class="detail"><summary>Summary / 总结</summary>
<div class="mono">To address the computational infeasibility of leave-one-out retraining for task attribution in modern AI agents, this paper introduces kernel surrogate models that capture nonlinear task interactions like synergy and antagonism. The method employs a gradient-based estimation procedure leveraging a first-order approximation of pretrained models, enabling efficient learning with less than 2% relative error without repeated retraining. Experiments across math reasoning, in-context learning, and multi-objective reinforcement learning show that kernel surrogates achieve 25% higher correlation with ground truth than linear baselines and yield a 40% improvement in downstream task selection.</div>
<div class="mono" style="margin-top:8px">为解决现代AI智能体（如大语言模型）中通过留一法重训练量化各训练任务对目标任务性能影响时计算不可行的问题，本文提出了能捕捉非线性任务交互的核代理模型。该方法利用预训练模型的一阶近似，开发了一种基于梯度的估计程序来高效学习核代理，无需重复训练即可实现低于2%的相对误差。在数学推理、上下文学习和多目标强化学习等多个领域的实验中，核代理模型相比线性代理和影响函数基线，与真实值的相关性提高了25%，并在下游任务选择中实现了40%的性能提升。</div>
</details>
</div>
<div class="card">
<div class="title">Reward Redistribution for CVaR MDPs using a Bellman Operator on L-infinity</div>
<div class="meta-line">Authors: Aneri Muni, Vincent Taboga, Esther Derman, Pierre-Luc Bacon, Erick Delage</div>
<div class="meta-line">First: 2026-02-03T17:39:45+00:00 · Latest: 2026-02-03T17:39:45+00:00</div>
<div class="links" style="margin-top:8px"><a href="https://arxiv.org/abs/2602.03778v1">Abs</a> · <a href="https://arxiv.org/pdf/2602.03778v1">PDF</a> · <a href="https://huggingface.co/huggingface">Code1</a> · <a href="https://huggingface.co/docs/hub/spaces">Code2</a></div>
<details class="detail"><summary>Abstract</summary>
<div class="mono">Tail-end risk measures such as static conditional value-at-risk (CVaR) are used in safety-critical applications to prevent rare, yet catastrophic events. Unlike risk-neutral objectives, the static CVaR of the return depends on entire trajectories without admitting a recursive Bellman decomposition in the underlying Markov decision process. A classical resolution relies on state augmentation with a continuous variable. However, unless restricted to a specialized class of admissible value functions, this formulation induces sparse rewards and degenerate fixed points. In this work, we propose a novel formulation of the static CVaR objective based on augmentation. Our alternative approach leads to a Bellman operator with: (1) dense per-step rewards; (2) contracting properties on the full space of bounded value functions. Building on this theoretical foundation, we develop risk-averse value iteration and model-free Q-learning algorithms that rely on discretized augmented states. We further provide convergence guarantees and approximation error bounds due to discretization. Empirical results demonstrate that our algorithms successfully learn CVaR-sensitive policies and achieve effective performance-safety trade-offs.</div></details>
<details class="detail"><summary>中文标题/摘要</summary>
<div class="mono"><b>标题：</b>基于L-无穷范数贝尔曼算子的CVaR MDP奖励重分配</div>
<div class="mono" style="margin-top:8px">在安全关键应用中，常采用静态条件风险价值（CVaR）等尾部风险度量来预防罕见但灾难性的事件。与风险中性目标不同，回报的静态CVaR依赖于完整轨迹，无法在底层马尔可夫决策过程中进行递归贝尔曼分解。经典解决方案通过引入连续变量进行状态增广，但除非限制在特定可容许值函数类，否则该形式会导致稀疏奖励和退化不动点。本文提出一种基于增广的静态CVaR目标新形式，其替代方法产生的贝尔曼算子具有：（1）密集的逐步奖励；（2）在有界值函数全空间上的压缩特性。基于此理论框架，我们开发了依赖离散化增广状态的风险规避值迭代与无模型Q学习算法，并提供了收敛性保证及离散化导致的近似误差界。实验结果表明，所提算法能有效学习CVaR敏感策略，实现性能与安全性的均衡权衡。</div>
</details>
<details class="detail"><summary>Summary / 总结</summary>
<div class="mono">This research addresses the challenge of optimizing conditional value-at-risk (CVaR) in Markov decision processes, which is crucial for safety-critical applications to mitigate rare but severe outcomes. The authors introduce a novel state-augmentation formulation that yields a Bellman operator with dense per-step rewards and contraction properties on bounded value functions, enabling the development of risk-averse value iteration and Q-learning algorithms with discretized augmented states. Experimental results confirm that the proposed methods learn CVaR-sensitive policies and achieve effective trade-offs between performance and safety, supported by convergence guarantees and discretization error bounds.</div>
<div class="mono" style="margin-top:8px">针对马尔可夫决策过程中静态条件风险价值（CVaR）优化缺乏递归贝尔曼分解、且现有增广方法可能导致稀疏奖励和退化不动点的问题，本研究提出了一种基于状态增广的新颖表述。该方法定义了一个贝尔曼算子，能提供密集的每步奖励，并在有界值函数空间上具有压缩性，从而支持开发基于离散化增广状态的风险规避值迭代和Q学习算法。实验结果表明，这些算法能成功学习对CVaR敏感的策略，并在性能与安全性之间实现有效权衡，同时提供了收敛保证和离散化误差界。</div>
</details>
</div>
<div class="card">
<div class="title">PAINT: Parallel-in-time Neural Twins for Dynamical System Reconstruction</div>
<div class="meta-line">Authors: Andreas Radler, Vincent Seyfried, Johannes Brandstetter, Thomas Lichtenegger</div>
<div class="meta-line">First: 2025-10-14T14:22:45+00:00 · Latest: 2026-02-03T17:39:05+00:00</div>
<div class="meta-line">Comments: 28 pages, 23 figures</div>
<div class="links" style="margin-top:8px"><a href="https://arxiv.org/abs/2510.16004v2">Abs</a> · <a href="https://arxiv.org/pdf/2510.16004v2">PDF</a> · <a href="https://huggingface.co/huggingface">Code1</a> · <a href="https://huggingface.co/docs/hub/spaces">Code2</a></div>
<details class="detail"><summary>Abstract</summary>
<div class="mono">Neural surrogates have shown great potential in simulating dynamical systems, while offering real-time capabilities. We envision Neural Twins as a progression of neural surrogates, aiming to create digital replicas of real systems. A neural twin consumes measurements at test time to update its state, thereby enabling context-specific decision-making. We argue, that a critical property of neural twins is their ability to remain on-trajectory, i.e., to stay close to the true system state over time. We introduce Parallel-in-time Neural Twins (PAINT), an architecture-agnostic family of methods for modeling dynamical systems from measurements. PAINT trains a generative neural network to model the distribution of states in parallel over time. At test time, states are predicted from measurements in a sliding window fashion. Our theoretical analysis shows that PAINT is on-trajectory, whereas autoregressive models generally are not. Empirically, we evaluate our method on a challenging two-dimensional turbulent fluid dynamics problem. The results demonstrate that PAINT stays on-trajectory and predicts system states from sparse measurements with high fidelity. These findings underscore PAINT&#x27;s potential for developing neural twins that stay on-trajectory, enabling more accurate state estimation and decision-making.</div></details>
<details class="detail"><summary>中文标题/摘要</summary>
<div class="mono"><b>标题：</b>PAINT：用于动态系统重构的并行时间神经孪生</div>
<div class="mono" style="margin-top:8px">神经代理模型在模拟动态系统方面展现出巨大潜力，同时具备实时能力。我们提出神经孪生作为神经代理模型的进阶，旨在创建真实系统的数字副本。神经孪生在测试时通过测量数据更新状态，从而实现情境化决策。我们认为神经孪生的关键特性在于其保持轨迹追踪的能力，即随时间推移始终接近真实系统状态。本文提出并行时间神经孪生（PAINT）——一种与架构无关的动态系统建模方法族。PAINT训练生成式神经网络并行建模状态的时间分布，测试时通过滑动窗口方式从测量数据预测状态。理论分析表明PAINT具有轨迹追踪特性，而自回归模型通常不具备该特性。我们在二维湍流流体动力学难题上实证评估该方法，结果表明PAINT能保持轨迹追踪，并通过稀疏测量高保真地预测系统状态。这些发现凸显了PAINT在开发具有轨迹追踪能力的神经孪生方面的潜力，有助于实现更精确的状态估计与决策。</div>
</details>
<details class="detail"><summary>Summary / 总结</summary>
<div class="mono">This research aims to advance neural surrogates into Neural Twins, digital replicas of real systems that can update their state from measurements for context-specific decision-making, with a critical requirement being the ability to remain &#x27;on-trajectory&#x27; close to the true system state over time. The proposed method, Parallel-in-time Neural Twins (PAINT), is an architecture-agnostic framework that trains a generative neural network to model the distribution of system states in parallel over time; at test time, it predicts states from sparse measurements using a sliding window approach. Theoretical analysis proves PAINT&#x27;s on-trajectory property, unlike autoregressive models, and empirical evaluation on a 2D turbulent fluid dynamics problem demonstrates its high-fidelity state prediction from sparse measurements and its ability to stay on-trajectory, highlighting its potential for accurate state estimation.</div>
<div class="mono" style="margin-top:8px">本研究旨在将神经代理模型发展为神经孪生体——真实动力系统的数字副本，能够根据测量数据更新状态以进行情境决策。作者指出此类模型保持“在轨”（即长期接近真实系统状态）的关键需求，并提出了PAINT方法，这是一种与架构无关的方法，训练生成式神经网络并行建模系统状态随时间分布，在测试时通过滑动窗口从测量数据预测状态。理论分析证明PAINT具有在轨特性，而自回归模型通常不具备；在二维湍流流体动力学问题上的实证评估表明，该方法能保持在轨并从稀疏测量中高保真地预测系统状态，从而实现准确的状态估计。</div>
</details>
</div>
<div class="card">
<div class="title">DiffLOB: Diffusion Models for Counterfactual Generation in Limit Order Books</div>
<div class="meta-line">Authors: Zhuohan Wang, Carmine Ventre</div>
<div class="meta-line">First: 2026-02-03T17:34:56+00:00 · Latest: 2026-02-03T17:34:56+00:00</div>
<div class="meta-line">Comments: 12 pages, 8 figures</div>
<div class="links" style="margin-top:8px"><a href="https://arxiv.org/abs/2602.03776v1">Abs</a> · <a href="https://arxiv.org/pdf/2602.03776v1">PDF</a> · <a href="https://huggingface.co/huggingface">Code1</a> · <a href="https://huggingface.co/docs/hub/spaces">Code2</a></div>
<details class="detail"><summary>Abstract</summary>
<div class="mono">Modern generative models for limit order books (LOBs) can reproduce realistic market dynamics, but remain fundamentally passive: they either model what typically happens without accounting for hypothetical future market conditions, or they require interaction with another agent to explore alternative outcomes. This limits their usefulness for stress testing, scenario analysis, and decision-making. We propose \textbf{DiffLOB}, a regime-conditioned \textbf{Diff}usion model for controllable and counterfactual generation of \textbf{LOB} trajectories. DiffLOB explicitly conditions the generative process on future market regimes--including trend, volatility, liquidity, and order-flow imbalance, which enables the model to answer counterfactual queries of the form: ``If the future market regime were X instead of Y, how would the limit order book evolve?&#x27;&#x27; Our systematic evaluation framework for counterfactual LOB generation consists of three criteria: (1) \textit{Controllable Realism}, measuring how well generated trajectories can reproduce marginal distributions, temporal dependence structure and regime variables; (2) \textit{Counterfactual validity}, testing whether interventions on future regimes induce consistent changes in the generated LOB dynamics; (3) \textit{Counterfactual usefulness}, assessing whether synthetic counterfactual trajectories improve downstream prediction of future market regimes.</div></details>
<details class="detail"><summary>中文标题/摘要</summary>
<div class="mono"><b>标题：</b>DiffLOB：限价订单簿反事实生成的扩散模型</div>
<div class="mono" style="margin-top:8px">现有的限价订单簿（LOB）生成模型虽能复现真实市场动态，但本质上是被动的：它们要么仅模拟典型市场行为而未考虑假设性未来市场条件，要么需依赖其他智能体交互来探索替代结果。这限制了其在压力测试、情景分析和决策制定中的应用。本文提出\textbf{DiffLOB}——一种基于市场状态的\textbf{扩散}模型，用于\textbf{限价订单簿}轨迹的可控及反事实生成。DiffLOB将生成过程显式地条件于未来市场状态（包括趋势、波动性、流动性和订单流失衡），使模型能够回答以下形式的反事实问题：“若未来市场状态为X而非Y，限价订单簿将如何演化？”我们构建的系统性反事实LOB生成评估框架包含三个标准：（1）\textit{可控真实性}：衡量生成轨迹复现边缘分布、时间依赖结构和状态变量的能力；（2）\textit{反事实有效性}：检验对未来状态的干预是否在生成的LOB动态中引发一致变化；（3）\textit{反事实实用性}：评估合成反事实轨迹是否能提升下游对未来市场状态的预测性能。</div>
</details>
<details class="detail"><summary>Summary / 总结</summary>
<div class="mono">Existing generative models for limit order books (LOBs) are passive, lacking the ability to explore hypothetical market conditions for stress testing and scenario analysis. To address this, the authors propose DiffLOB, a diffusion model that explicitly conditions the generation of LOB trajectories on future market regimes such as trend and volatility, enabling counterfactual queries about how the LOB would evolve under different regime scenarios. Experimental evaluation demonstrates that DiffLOB achieves controllable realism by accurately reproducing statistical properties, ensures counterfactual validity by showing consistent changes from interventions, and proves useful by improving downstream predictions of market regimes.</div>
<div class="mono" style="margin-top:8px">现有的限价订单簿（LOB）生成模型是被动的，仅模拟典型市场动态而无法考虑假设的未来条件，这限制了其在压力测试和情景分析中的实用性。为此，作者提出了DiffLOB，一种基于市场状态的扩散模型，该模型将生成过程显式地条件于未来市场状态（如趋势、波动性、流动性和订单流不平衡），从而能够回答关于在不同市场状态下LOB将如何演变的假设性问题。实验评估表明，DiffLOB实现了可控的真实性，能准确复现边际分布和时间依赖结构；具备反事实有效性，对市场状态的干预能引起LOB动态的一致变化；并提供了反事实实用性，通过生成的合成数据改进了对未来市场状态的预测。</div>
</details>
</div>
<div class="card">
<div class="title">An Empirical Study of Collective Behaviors and Social Dynamics in Large Language Model Agents</div>
<div class="meta-line">Authors: Farnoosh Hashemi, Michael W. Macy</div>
<div class="meta-line">First: 2026-02-03T17:34:32+00:00 · Latest: 2026-02-03T17:34:32+00:00</div>
<div class="links" style="margin-top:8px"><a href="https://arxiv.org/abs/2602.03775v1">Abs</a> · <a href="https://arxiv.org/pdf/2602.03775v1">PDF</a> · <a href="https://huggingface.co/huggingface">Code1</a> · <a href="https://huggingface.co/docs/hub/spaces">Code2</a></div>
<details class="detail"><summary>Abstract</summary>
<div class="mono">Large Language Models (LLMs) increasingly mediate our social, cultural, and political interactions. While they can simulate some aspects of human behavior and decision-making, it is still underexplored whether repeated interactions with other agents amplify their biases or lead to exclusionary behaviors. To this end, we study Chirper.ai-an LLM-driven social media platform-analyzing 7M posts and interactions among 32K LLM agents over a year. We start with homophily and social influence among LLMs, learning that similar to humans&#x27;, their social networks exhibit these fundamental phenomena. Next, we study the toxic language of LLMs, its linguistic features, and their interaction patterns, finding that LLMs show different structural patterns in toxic posting than humans. After studying the ideological leaning in LLMs posts, and the polarization in their community, we focus on how to prevent their potential harmful activities. We present a simple yet effective method, called Chain of Social Thought (CoST), that reminds LLM agents to avoid harmful posting.</div></details>
<details class="detail"><summary>中文标题/摘要</summary>
<div class="mono"><b>标题：</b>大型语言模型代理集体行为与社会动态的实证研究</div>
<div class="mono" style="margin-top:8px">大型语言模型（LLMs）日益介入我们的社会、文化和政治互动。尽管它们能模拟人类行为与决策的某些方面，但与其他代理的重复互动是否会放大其偏见或导致排他性行为，仍待深入探究。为此，我们研究了LLM驱动的社交媒体平台Chirper.ai，分析了32,000个LLM代理在一年内的700万条帖子和互动。我们从LLMs间的同质性与社会影响入手，发现其社交网络与人类类似，展现出这些基本现象。接着，我们研究了LLMs的毒性语言、其语言特征及互动模式，发现LLMs在毒性发帖中表现出与人类不同的结构模式。在探究LLMs帖子的意识形态倾向及其社群极化后，我们聚焦于如何预防其潜在有害活动。我们提出了一种简单而有效的方法，称为“社会思维链”（CoST），以提醒LLM代理避免有害发帖。</div>
</details>
<details class="detail"><summary>Summary / 总结</summary>
<div class="mono">This study investigates whether repeated interactions among Large Language Model (LLM) agents amplify biases or lead to exclusionary behaviors, given their growing role in mediating social interactions. The method involves a year-long empirical analysis of 7 million posts and interactions among 32,000 LLM agents on the Chirper.ai platform, examining homophily, social influence, toxic language patterns, ideological leaning, and polarization. Key findings reveal that LLM agents exhibit human-like homophily and social influence in their social networks but display distinct structural patterns in toxic posting compared to humans; the study also proposes and validates the Chain of Social Thought (CoST) method as an effective intervention to reduce harmful content generation by LLM agents.</div>
<div class="mono" style="margin-top:8px">本研究探讨大型语言模型（LLM）智能体在模拟平台上反复互动时如何形成集体行为与社会动态，其动机源于担忧此类互动可能放大偏见或导致排斥性结果。研究方法是对Chirper.ai平台上32,000个LLM智能体一年内的700万条帖子与互动进行大规模实证分析，考察了同质性、社会影响、毒性语言模式及意识形态极化。主要实验发现表明，LLM智能体在其社交网络中表现出类似人类的同质性与社会影响现象，但在毒性内容发布的结构模式上与人类存在差异；研究还提出并验证了一种名为“社会思维链”的简单干预方法，通过提醒智能体遵守社会规范，能有效减少其生成有害内容。</div>
</details>
</div>
<div class="card">
<div class="title">PluriHarms: Benchmarking the Full Spectrum of Human Judgments on AI Harm</div>
<div class="meta-line">Authors: Jing-Jing Li, Joel Mire, Eve Fleisig, Valentina Pyatkin, Anne Collins, Maarten Sap, Sydney Levine</div>
<div class="meta-line">First: 2026-01-13T19:41:11+00:00 · Latest: 2026-02-03T17:34:31+00:00</div>
<div class="links" style="margin-top:8px"><a href="https://arxiv.org/abs/2601.08951v2">Abs</a> · <a href="https://arxiv.org/pdf/2601.08951v2">PDF</a> · <a href="https://huggingface.co/huggingface">Code1</a> · <a href="https://huggingface.co/docs/hub/spaces">Code2</a></div>
<details class="detail"><summary>Abstract</summary>
<div class="mono">Current AI safety frameworks, which often treat harmfulness as binary, lack the flexibility to handle borderline cases where humans meaningfully disagree. To build more pluralistic systems, it is essential to move beyond consensus and instead understand where and why disagreements arise. We introduce PluriHarms, a benchmark designed to systematically study human harm judgments across two key dimensions -- the harm axis (benign to harmful) and the agreement axis (agreement to disagreement). Our scalable framework generates prompts that capture diverse AI harms and human values while targeting cases with high disagreement rates, validated by human data. The benchmark includes 150 prompts with 15,000 ratings from 100 human annotators, enriched with demographic and psychological traits and prompt-level features of harmful actions, effects, and values. Our analyses show that prompts that relate to imminent risks and tangible harms amplify perceived harmfulness, while annotator traits (e.g., toxicity experience, education) and their interactions with prompt content explain systematic disagreement. We benchmark AI safety models and alignment methods on PluriHarms, finding that while personalization significantly improves prediction of human harm judgments, considerable room remains for future progress. By explicitly targeting value diversity and disagreement, our work provides a principled benchmark for moving beyond &quot;one-size-fits-all&quot; safety toward pluralistically safe AI.</div></details>
<details class="detail"><summary>中文标题/摘要</summary>
<div class="mono"><b>标题：</b>PluriHarms：全面评估人工智能危害的人类判断基准</div>
<div class="mono" style="margin-top:8px">当前将危害性简单二值化的AI安全框架缺乏处理人类存在实质性分歧的边缘案例的灵活性。为构建更具多元包容性的系统，必须超越共识机制，深入探究分歧产生的具体领域与成因。我们推出PluriHarms基准，通过两大核心维度系统研究人类对AI危害的判断——危害轴（从良性到有害）与共识轴（从一致到分歧）。该可扩展框架生成涵盖多元AI危害与人类价值观的提示语，并针对高分歧率案例进行设计，经人类数据验证。基准包含150条提示语及来自100位标注者的15,000条评分，同时收录人口统计学特征、心理特质以及提示语层面的危害行为、影响与价值观特征。分析表明：涉及紧迫风险与实体危害的提示语会放大感知危害性，而标注者特质（如受毒性经历、教育背景）及其与提示内容的交互作用可系统解释分歧成因。我们在PluriHarms上测试了AI安全模型与对齐方法，发现个性化技术虽能显著提升对人类危害判断的预测能力，但未来仍有巨大改进空间。通过明确关注价值多元性与分歧现象，本研究为超越“一刀切”安全模式、迈向多元安全的人工智能提供了原则性基准。</div>
</details>
<details class="detail"><summary>Summary / 总结</summary>
<div class="mono">Current AI safety frameworks often treat harmfulness as binary, which fails to accommodate borderline cases where human judgments meaningfully diverge. To address this, the authors introduce PluriHarms, a benchmark designed to systematically study human harm judgments across two dimensions: the harm axis (from benign to harmful) and the agreement axis (from agreement to disagreement). The scalable framework generates prompts capturing diverse AI harms and human values, specifically targeting high-disagreement cases, and includes 150 prompts with 15,000 ratings from 100 annotators, enriched with demographic, psychological, and prompt-level features. Experimental analyses reveal that prompts involving imminent risks and tangible harms amplify perceived harmfulness, while annotator traits (e.g., personal toxicity experience, education) and their interactions with prompt content explain systematic disagreement. Benchmarking AI safety models and alignment methods shows that personalization significantly improves prediction of human harm judgments, though substantial room for progress remains.</div>
<div class="mono" style="margin-top:8px">当前AI安全框架常将有害性视为二元判断，缺乏处理存在有意义人类分歧的边界案例的灵活性。为构建更包容多元的系统，本研究提出了PluriHarms基准，旨在从两个维度系统研究人类对AI危害的判断：危害轴（从良性到有害）和共识轴（从一致到分歧）。该可扩展框架生成捕捉多样化AI危害和人类价值观的提示，特别针对高分歧案例，并包含150个提示、来自100名标注者的15,000条评分，同时丰富了人口统计、心理特征及提示层面的危害行为、影响和价值观特征。分析表明，涉及紧迫风险和具体危害的提示会放大感知有害性，而标注者特质（如毒性经历、教育水平）及其与提示内容的交互解释了系统性分歧。对AI安全模型的基准测试显示，个性化方法显著提升了对人类危害判断的预测能力，但仍存在较大改进空间。</div>
</details>
</div>
<div class="card">
<div class="title">UniGeM: Unifying Data Mixing and Selection via Geometric Exploration and Mining</div>
<div class="meta-line">Authors: Changhao Wang, Yunfei Yu, Xinhao Yao, Jiaolong Yang, Riccardo Cantoro, Chaobo Li, Qing Cui, Jun Zhou</div>
<div class="meta-line">First: 2026-02-03T17:32:56+00:00 · Latest: 2026-02-03T17:32:56+00:00</div>
<div class="links" style="margin-top:8px"><a href="https://arxiv.org/abs/2602.03772v1">Abs</a> · <a href="https://arxiv.org/pdf/2602.03772v1">PDF</a> · <a href="https://huggingface.co/huggingface">Code1</a> · <a href="https://huggingface.co/docs/hub/spaces">Code2</a></div>
<details class="detail"><summary>Abstract</summary>
<div class="mono">The scaling of Large Language Models (LLMs) is increasingly limited by data quality. Most methods handle data mixing and sample selection separately, which can break the structure in code corpora. We introduce \textbf{UniGeM}, a framework that unifies mixing and selection by treating data curation as a \textit{manifold approximation} problem without training proxy models or relying on external reference datasets. UniGeM operates hierarchically: \textbf{Macro-Exploration} learns mixing weights with stability-based clustering; \textbf{Micro-Mining} filters high-quality instances by their geometric distribution to ensure logical consistency. Validated by training 8B and 16B MoE models on 100B tokens, UniGeM achieves \textbf{2.0$\times$ data efficiency} over a random baseline and further improves overall performance compared to SOTA methods in reasoning-heavy evaluations and multilingual generalization.</div></details>
<details class="detail"><summary>中文标题/摘要</summary>
<div class="mono"><b>标题：</b>UniGeM：通过几何探索与挖掘统一数据混合与选择</div>
<div class="mono" style="margin-top:8px">大语言模型（LLMs）的扩展日益受到数据质量的限制。现有方法大多将数据混合与样本选择分开处理，这可能破坏代码语料库的结构。我们提出\textbf{UniGeM}框架，通过将数据整理视为\textit{流形逼近}问题来统一混合与选择过程，无需训练代理模型或依赖外部参考数据集。UniGeM采用分层架构：\textbf{宏观探索}通过基于稳定性的聚类学习混合权重；\textbf{微观挖掘}依据几何分布筛选高质量实例以确保逻辑一致性。通过在1000亿token上训练80亿和160亿参数的混合专家模型验证，UniGeM相比随机基线实现\textbf{2.0倍数据效率提升}，在强推理评估与多语言泛化任务中进一步超越现有最优方法的整体性能。</div>
</details>
<details class="detail"><summary>Summary / 总结</summary>
<div class="mono">To address the data quality bottleneck in scaling large language models, where existing methods treat data mixing and sample selection separately and risk disrupting structural patterns in code corpora, this paper proposes UniGeM, a unified framework that formulates data curation as a manifold approximation problem without requiring proxy models or external datasets. The method hierarchically combines macro-exploration, which learns mixing weights via stability-based clustering, with micro-mining, which filters instances based on geometric distribution to maintain logical consistency. Experiments training 8B and 16B mixture-of-experts models on 100B tokens show UniGeM achieves 2.0× data efficiency over a random baseline and outperforms state-of-the-art methods in reasoning-heavy and multilingual generalization tasks.</div>
<div class="mono" style="margin-top:8px">针对大规模语言模型扩展中数据质量受限的问题，现有方法通常将数据混合与样本选择分开处理，可能破坏代码语料库的结构模式，本研究提出了UniGeM框架，将数据管理统一为流形逼近问题，无需训练代理模型或依赖外部数据集。该方法采用分层设计：宏观探索通过基于稳定性的聚类学习混合权重，微观挖掘则依据几何分布筛选高质量实例以确保逻辑一致性。在100B token上训练8B和16B混合专家模型的实验表明，UniGeM相比随机基线实现了2.0倍的数据效率提升，并在推理密集型评估和多语言泛化任务中超越了现有最优方法。</div>
</details>
</div>
<div class="card">
<div class="title">The Epistemic Planning Domain Definition Language: Official Guideline</div>
<div class="meta-line">Authors: Alessandro Burigana, Francesco Fabiano</div>
<div class="meta-line">First: 2026-01-28T19:10:52+00:00 · Latest: 2026-02-03T17:32:48+00:00</div>
<div class="links" style="margin-top:8px"><a href="https://arxiv.org/abs/2601.20969v2">Abs</a> · <a href="https://arxiv.org/pdf/2601.20969v2">PDF</a> · <a href="https://huggingface.co/huggingface">Code1</a> · <a href="https://huggingface.co/docs/hub/spaces">Code2</a></div>
<details class="detail"><summary>Abstract</summary>
<div class="mono">Epistemic planning extends (multi-agent) automated planning by making agents&#x27; knowledge and beliefs first-class aspects of the planning formalism. One of the most well-known frameworks for epistemic planning is Dynamic Epistemic Logic (DEL), which offers an rich and natural semantics for modelling problems in this setting. The high expressive power provided by DEL make DEL-based epistemic planning a challenging problem to tackle both theoretically, and in practical implementations. As a result, existing epistemic planners often target different DEL fragments, and typically rely on ad hoc languages to represent benchmarks, and sometimes no language at all. This fragmentation hampers comparison, reuse, and systematic benchmark development. We address these issues by introducing the Epistemic Planning Domain Definition Language (EPDDL). EPDDL provides a unique PDDL-like representation that captures the entire DEL semantics, enabling uniform specification of epistemic planning tasks. Our main contributions are: 1. A formal development of abstract event models, a novel representation for epistemic actions used to define the semantics of our language; 2. A formal specification of EPDDL&#x27;s syntax and semantics grounded in DEL with abstract event models. Through examples of representative benchmarks, we illustrate how EPDDL facilitates interoperability, reproducible evaluation, and future advances in epistemic planning.</div></details>
<details class="detail"><summary>中文标题/摘要</summary>
<div class="mono"><b>标题：</b>认知规划领域定义语言：官方指南</div>
<div class="mono" style="margin-top:8px">认知规划通过将智能体的知识与信念作为规划形式体系的一等要素，扩展了（多智能体）自动规划领域。动态认知逻辑是认知规划中最著名的框架之一，为这类问题建模提供了丰富自然的语义。DEL的高表达能力使得基于DEL的认知规划在理论研究和实际实现中都面临挑战。因此，现有认知规划器常针对不同的DEL片段，通常依赖特定领域语言表示基准测试案例，有时甚至完全不使用规范语言。这种碎片化阻碍了比较、复用和系统性基准开发。我们通过引入认知规划领域定义语言来解决这些问题。EPDDL提供了一种独特的类PDDL表示法，能够完整捕获DEL语义，实现认知规划任务的统一规范。主要贡献包括：1. 提出抽象事件模型的形式化框架，这是一种用于定义语言语义的新型认知行动表示方法；2. 基于抽象事件模型的DEL语义，建立EPDDL语法与语义的形式化规范。通过典型基准案例展示EPDDL如何促进互操作性、可复现评估及认知规划领域的未来发展。</div>
</details>
<details class="detail"><summary>Summary / 总结</summary>
<div class="mono">The motivation for this work is to address the fragmentation in epistemic planning research, where existing planners target different fragments of Dynamic Epistemic Logic (DEL) and often rely on ad hoc or non-existent benchmark languages, hindering comparison and systematic development. The method introduces the Epistemic Planning Domain Definition Language (EPDDL), a PDDL-like language that formally captures the full semantics of DEL through a novel representation called abstract event models for epistemic actions. The key result is a complete formal specification of EPDDL&#x27;s syntax and semantics, demonstrated through representative benchmarks to show how it enables uniform task specification, interoperability, and reproducible evaluation for the field.</div>
<div class="mono" style="margin-top:8px">本研究针对认知规划领域存在的碎片化问题，即现有规划器使用互不兼容的临时语言或根本没有形式化语言，阻碍了基准测试的比较与复用。作者引入了认知规划领域定义语言（EPDDL），这是一种基于动态认知逻辑（DEL）语义、使用一种称为抽象事件模型的新表示方法来定义认知动作的PDDL式语言。所提出的EPDDL提供了能够捕获完整DEL语义的统一规范，从而为该领域实现了互操作性、可复现的评估以及系统化的基准测试开发。</div>
</details>
</div>
<div class="card">
<div class="title">Decision-oriented benchmarking to transform AI weather forecast access: Application to the Indian monsoon</div>
<div class="meta-line">Authors: Rajat Masiwal, Colin Aitken, Adam Marchakitus, Mayank Gupta, Katherine Kowal, Hamid A. Pahlavan, Tyler Yang, Y. Qiang Sun, Michael Kremer, Amir Jina, William R. Boos, Pedram Hassanzadeh</div>
<div class="meta-line">First: 2026-02-03T17:27:22+00:00 · Latest: 2026-02-03T17:27:22+00:00</div>
<div class="links" style="margin-top:8px"><a href="https://arxiv.org/abs/2602.03767v1">Abs</a> · <a href="https://arxiv.org/pdf/2602.03767v1">PDF</a> · <a href="https://huggingface.co/huggingface">Code1</a> · <a href="https://huggingface.co/docs/hub/spaces">Code2</a></div>
<details class="detail"><summary>Abstract</summary>
<div class="mono">Artificial intelligence weather prediction (AIWP) models now often outperform traditional physics-based models on common metrics while requiring orders-of-magnitude less computing resources and time. Open-access AIWP models thus hold promise as transformational tools for helping low- and middle-income populations make decisions in the face of high-impact weather shocks. Yet, current approaches to evaluating AIWP models focus mainly on aggregated meteorological metrics without considering local stakeholders&#x27; needs in decision-oriented, operational frameworks. Here, we introduce such a framework that connects meteorology, AI, and social sciences. As an example, we apply it to the 150-year-old problem of Indian monsoon forecasting, focusing on benefits to rain-fed agriculture, which is highly susceptible to climate change. AIWP models skillfully predict an agriculturally relevant onset index at regional scales weeks in advance when evaluated out-of-sample using deterministic and probabilistic metrics. This framework informed a government-led effort in 2025 to send 38 million Indian farmers AI-based monsoon onset forecasts, which captured an unusual weeks-long pause in monsoon progression. This decision-oriented benchmarking framework provides a key component of a blueprint for harnessing the power of AIWP models to help large vulnerable populations adapt to weather shocks in the face of climate variability and change.</div></details>
<details class="detail"><summary>中文标题/摘要</summary>
<div class="mono"><b>标题：</b>面向决策的基准测试变革AI天气预报获取：以印度季风为例的应用</div>
<div class="mono" style="margin-top:8px">人工智能天气预测模型目前在常用指标上已常超越传统物理模型，且所需计算资源和时间呈数量级减少。开放获取的AI天气预测模型有望成为变革性工具，帮助中低收入人群应对高影响天气冲击的决策。然而，现有评估方法主要关注聚合气象指标，未在面向决策的业务框架中考虑本地利益相关者的需求。本文提出融合气象学、人工智能与社会科学的评估框架，并以印度季风预报这一延续150年的难题为例，聚焦易受气候变化影响的雨养农业领域。通过确定性及概率性指标的样本外评估，AI天气预测模型能提前数周在区域尺度精准预测农业相关的季风爆发指数。该框架支撑了2025年印度政府主导的向3800万农户发送AI季风爆发预报的项目，成功捕捉到季风进程中罕见的数周停滞现象。这一面向决策的基准测试框架为利用AI天气预测模型助力脆弱人群适应气候变率与变化的蓝图提供了关键组成部分。</div>
</details>
<details class="detail"><summary>Summary / 总结</summary>
<div class="mono">The research is motivated by the need to move beyond aggregated meteorological metrics in evaluating AI weather prediction (AIWP) models and instead assess their value for specific, high-impact decisions faced by vulnerable populations, such as farmers in low- and middle-income countries. The method introduces a decision-oriented benchmarking framework that integrates meteorology, AI, and social sciences, applying it to the case of Indian monsoon forecasting with a focus on agriculturally relevant onset indices. Key experimental results show that AIWP models skillfully predict this onset index at regional scales weeks in advance in out-of-sample evaluations, and the framework directly informed a 2025 government initiative that provided AI-based onset forecasts to 38 million farmers, successfully capturing an unusual pause in the monsoon.</div>
<div class="mono" style="margin-top:8px">本研究的动机是，需要超越传统的聚合气象指标来评估人工智能天气预测模型，转而评估其对特定现实世界决策的价值，特别是针对中低收入国家的脆弱人群。方法上，研究引入了一个融合气象学、人工智能和社会科学的决策导向基准测试框架，并将其应用于印度季风预测，重点关注对雨养农业的支持。关键的实验结果表明，在样本外评估中，AIWP模型能够提前数周熟练预测区域尺度的、与农业相关的季风爆发指数，该框架直接促成了2025年一项政府主导的行动，向3800万农民提供了基于人工智能的季风爆发预报，并成功捕捉到一次异常的季风暂停过程。</div>
</details>
</div>
<div class="card">
<div class="title">Self-Foveate: Enhancing Diversity and Difficulty of Synthesized Instructions from Unsupervised Text via Multi-Level Foveation</div>
<div class="meta-line">Authors: Mingzhe Li, Xin Lu, Yanyan Zhao</div>
<div class="meta-line">Venue: ACL 2025</div>
<div class="meta-line">First: 2025-07-31T11:18:42+00:00 · Latest: 2026-02-03T17:26:10+00:00</div>
<div class="meta-line">Comments: Accepted to ACL 2025 (Findings). 23 pages, 4 figures</div>
<div class="links" style="margin-top:8px"><a href="https://arxiv.org/abs/2507.23440v2">Abs</a> · <a href="https://arxiv.org/pdf/2507.23440v2">PDF</a> · <a href="https://github.com/Mubuky/Self-Foveate">Code1</a> · <a href="https://huggingface.co/huggingface">Code2</a> · <a href="https://huggingface.co/docs/hub/spaces">Code3</a></div>
<details class="detail"><summary>Abstract</summary>
<div class="mono">Synthesizing high-quality instruction data from unsupervised text is a promising paradigm for training large language models (LLMs), yet automated methods for this task still exhibit significant limitations in the diversity and difficulty of synthesized instructions. To address these challenges, we propose Self-Foveate, an LLM-driven method for instruction synthesis. Inspired by hierarchical human visual perception, Self-Foveate introduces a &quot;Micro-Scatter-Macro&quot; multi-level foveation methodology that guides the extraction of textual information at three complementary granularities, from fine-grained details through cross-region connections to holistic patterns, thereby enhancing both the diversity and difficulty of synthesized instructions. Furthermore, a re-synthesis module is incorporated to improve the fidelity of instructions to source text and their overall quality. Comprehensive experiments across multiple unsupervised corpora and diverse model architectures demonstrate that Self-Foveate consistently outperforms existing methods. We publicly release our code at https://github.com/Mubuky/Self-Foveate</div></details>
<details class="detail"><summary>中文标题/摘要</summary>
<div class="mono"><b>标题：</b>Self-Foveate：通过多级注视增强无监督文本合成指令的多样性与难度</div>
<div class="mono" style="margin-top:8px">从无监督文本合成高质量指令数据是训练大语言模型（LLM）的有效范式，但现有自动化方法在合成指令的多样性与难度方面仍存在明显局限。为应对这些挑战，我们提出Self-Foveate——一种基于LLM驱动的指令合成方法。该方法受人类层次化视觉感知机制启发，引入“微观-散射-宏观”多级注视技术，通过细粒度细节、跨区域关联到整体模式三个互补粒度引导文本信息提取，从而同步提升合成指令的多样性与难度。此外，我们整合了再合成模块以增强指令对源文本的忠实度及整体质量。在多个无监督语料库和不同模型架构上的综合实验表明，Self-Foveate持续优于现有方法。代码已开源：https://github.com/Mubuky/Self-Foveate</div>
</details>
<details class="detail"><summary>Summary / 总结</summary>
<div class="mono">The research addresses the limitations in diversity and difficulty of instruction data synthesized from unsupervised text for training large language models. The proposed Self-Foveate method employs a multi-level foveation approach, inspired by human visual perception, to extract textual information at micro, scatter, and macro granularities, and incorporates a re-synthesis module to enhance instruction fidelity. Experimental results on multiple corpora and model architectures show that Self-Foveate consistently outperforms existing instruction synthesis methods.</div>
<div class="mono" style="margin-top:8px">本研究旨在解决从无监督文本合成用于训练大语言模型的指令数据时，其多样性和难度存在的局限性。提出的Self-Foveate方法受人类视觉感知启发，采用一种多级注视方法，在微观、分散和宏观粒度上提取文本信息，并包含一个再合成模块以提高指令的保真度。在多个语料库和模型架构上的实验结果表明，Self-Foveate在指令合成任务上持续优于现有方法。</div>
</details>
</div></div>
    <details style="margin-top:16px" class="detail"><summary>History</summary>
      <div class="history-list"><a href="archive/20260204_0633.html">20260204_0633</a>
<a href="archive/20260204_0541.html">20260204_0541</a>
<a href="archive/20260204_0456.html">20260204_0456</a>
<a href="archive/20260204_0354.html">20260204_0354</a>
<a href="archive/20260202_0623.html">20260202_0623</a>
<a href="archive/20260202_0525.html">20260202_0525</a>
<a href="archive/20260202_0441.html">20260202_0441</a>
<a href="archive/20260202_0331.html">20260202_0331</a>
<a href="archive/20260201_0625.html">20260201_0625</a>
<a href="archive/20260201_0527.html">20260201_0527</a>
<a href="archive/20260201_0443.html">20260201_0443</a>
<a href="archive/20260201_0331.html">20260201_0331</a>
<a href="archive/20260131_0628.html">20260131_0628</a>
<a href="archive/20260131_0535.html">20260131_0535</a>
<a href="archive/20260131_0449.html">20260131_0449</a>
<a href="archive/20260131_0342.html">20260131_0342</a>
<a href="archive/20260130_0631.html">20260130_0631</a>
<a href="archive/20260130_0533.html">20260130_0533</a>
<a href="archive/20260130_0449.html">20260130_0449</a>
<a href="archive/20260130_0341.html">20260130_0341</a>
<a href="archive/20260129_0630.html">20260129_0630</a>
<a href="archive/20260129_0536.html">20260129_0536</a>
<a href="archive/20260129_0450.html">20260129_0450</a>
<a href="archive/20260129_0336.html">20260129_0336</a>
<a href="archive/20260128_0625.html">20260128_0625</a>
<a href="archive/20260128_0439.html">20260128_0439</a>
<a href="archive/20260128_0334.html">20260128_0334</a>
<a href="archive/20260127_0627.html">20260127_0627</a>
<a href="archive/20260127_0529.html">20260127_0529</a>
<a href="archive/20260127_0439.html">20260127_0439</a>
<a href="archive/20260127_0333.html">20260127_0333</a>
<a href="archive/20260126_0626.html">20260126_0626</a>
<a href="archive/20260126_0526.html">20260126_0526</a>
<a href="archive/20260126_0327.html">20260126_0327</a>
<a href="archive/20260125_0624.html">20260125_0624</a>
<a href="archive/20260125_0524.html">20260125_0524</a>
<a href="archive/20260125_0440.html">20260125_0440</a>
<a href="archive/20260125_0325.html">20260125_0325</a>
<a href="archive/20260124_0627.html">20260124_0627</a>
<a href="archive/20260124_0526.html">20260124_0526</a>
<a href="archive/20260124_0444.html">20260124_0444</a>
<a href="archive/20260124_0334.html">20260124_0334</a>
<a href="archive/20260123_0627.html">20260123_0627</a>
<a href="archive/20260123_0529.html">20260123_0529</a>
<a href="archive/20260123_0446.html">20260123_0446</a>
<a href="archive/20260123_0334.html">20260123_0334</a>
<a href="archive/20260122_2019.html">20260122_2019</a>
<a href="archive/20260122_2013.html">20260122_2013</a>
<a href="archive/20260122_2008.html">20260122_2008</a>
<a href="archive/20260122_2001.html">20260122_2001</a>
<a href="archive/20260122_0629.html">20260122_0629</a>
<a href="archive/20260122_0535.html">20260122_0535</a>
<a href="archive/20260122_0449.html">20260122_0449</a>
<a href="archive/20260122_0336.html">20260122_0336</a>
<a href="archive/20260121_0625.html">20260121_0625</a>
<a href="archive/20260121_0529.html">20260121_0529</a>
<a href="archive/20260121_0450.html">20260121_0450</a>
<a href="archive/20260121_0423.html">20260121_0423</a>
<a href="archive/20260120_0626.html">20260120_0626</a>
<a href="archive/20260120_0528.html">20260120_0528</a>
<a href="archive/20260120_0443.html">20260120_0443</a>
<a href="archive/20260120_0330.html">20260120_0330</a>
<a href="archive/20260119_0624.html">20260119_0624</a>
<a href="archive/20260119_0525.html">20260119_0525</a>
<a href="archive/20260119_0440.html">20260119_0440</a>
<a href="archive/20260119_0325.html">20260119_0325</a>
<a href="archive/20260118_2225.html">20260118_2225</a>
<a href="archive/20260118_2159.html">20260118_2159</a>
<a href="archive/20260118_2135.html">20260118_2135</a>
<a href="archive/20260118_2040.html">20260118_2040</a>
<a href="archive/20260118_1953.html">20260118_1953</a>
<a href="archive/20260118_1907.html">20260118_1907</a>
<a href="archive/20260118_0327.html">20260118_0327</a>
<a href="archive/20260117_0332.html">20260117_0332</a>
<a href="archive/20260116_0339.html">20260116_0339</a>
<a href="archive/20260115_0334.html">20260115_0334</a>
<a href="archive/20260114_0333.html">20260114_0333</a>
<a href="archive/20260113_0334.html">20260113_0334</a>
<a href="archive/20260112_0331.html">20260112_0331</a>
<a href="archive/20260111_0329.html">20260111_0329</a>
<a href="archive/20260110_0333.html">20260110_0333</a>
<a href="archive/20260109_0334.html">20260109_0334</a>
<a href="archive/20260108_0335.html">20260108_0335</a>
<a href="archive/20260107_0330.html">20260107_0330</a>
<a href="archive/20260106_0336.html">20260106_0336</a>
<a href="archive/20260105_0328.html">20260105_0328</a>
<a href="archive/20260104_0328.html">20260104_0328</a>
<a href="archive/20260103_0325.html">20260103_0325</a>
<a href="archive/20260102_0339.html">20260102_0339</a>
<a href="archive/20260101_0329.html">20260101_0329</a>
<a href="archive/20251231_0333.html">20251231_0333</a>
<a href="archive/20251230_0332.html">20251230_0332</a>
<a href="archive/20251229_0329.html">20251229_0329</a>
<a href="archive/20251228_0332.html">20251228_0332</a>
<a href="archive/20251227_0329.html">20251227_0329</a>
<a href="archive/20251226_0330.html">20251226_0330</a>
<a href="archive/20251225_0329.html">20251225_0329</a>
<a href="archive/20251224_0331.html">20251224_0331</a>
<a href="archive/20251223_0332.html">20251223_0332</a>
<a href="archive/20251222_0328.html">20251222_0328</a></div>
    </details>
    <div class="footer">Generated by arxiv-tracker</div>
  </div>
</body></html>
