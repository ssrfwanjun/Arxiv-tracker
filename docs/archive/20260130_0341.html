<!doctype html>
<html><head><meta charset="utf-8"><meta name="viewport" content="width=device-width,initial-scale=1">
<title>arXiv 论文速递</title><style>
:root {
  --bg:#f8fafc; --card:#ffffff; --text:#0f172a; --muted:#667085; --border:#e5e7eb; --acc:#2563eb;
}
:root[data-theme="dark"] {
  --bg:#0b0f17; --card:#111827; --text:#e5e7eb; --muted:#9ca3af; --border:#1f2937; --acc:#2563eb;
}
*{box-sizing:border-box} body{margin:0;background:var(--bg);color:var(--text);
  font-family:ui-sans-serif,system-ui,-apple-system,Segoe UI,Roboto,Helvetica,Arial;line-height:1.6;}
.container{max-width:900px;margin:0 auto;padding:18px;}
.header{display:flex;gap:10px;justify-content:space-between;align-items:center;margin:8px 0 16px;flex-wrap:wrap}
h1{font-size:22px;margin:0}
.badge{font-size:12px;color:#111827;background:var(--acc);padding:2px 8px;border-radius:999px}
.card{background:var(--card);border:1px solid var(--border);border-radius:16px;padding:16px 18px;margin:14px 0;box-shadow:0 1px 2px rgba(0,0,0,.04)}
.title{font-weight:700;margin:0 0 6px 0;font-size:18px}
.meta-line{color:var(--muted);font-size:13px;margin:2px 0}
.links a{color:var(--acc);text-decoration:none;margin-right:12px}
.detail{margin-top:10px;background:rgba(2,6,23,.03);border:1px solid var(--border);border-radius:10px;padding:8px 10px}
summary{cursor:pointer;color:var(--acc)}
.mono{white-space:pre-wrap;background:rgba(2,6,23,.03);border:1px solid var(--border);padding:10px;border-radius:10px}
.row{display:grid;grid-template-columns:1fr;gap:12px}
@media (min-width: 860px) {
  .row-2{grid-template-columns:1fr 1fr}
}
.footer{color:var(--muted);font-size:13px;margin:20px 0 10px}
.hr{height:1px;background:var(--border);margin:14px 0}
.history-list a{display:block;color:var(--acc);text-decoration:none;margin:4px 0}
.controls{display:flex;gap:8px;align-items:center}
.btn{border:1px solid var(--border);background:var(--card);padding:6px 10px;border-radius:10px;cursor:pointer;color:var(--text)}
.btn:hover{border-color:var(--acc)}
</style>
<script>
(function() {
  const root = document.documentElement;
  function apply(t) {
    if (t==='dark') root.setAttribute('data-theme','dark');
    else if (t==='light') root.removeAttribute('data-theme');
    else {
      if (window.matchMedia && window.matchMedia('(prefers-color-scheme: dark)').matches)
        root.setAttribute('data-theme','dark');
      else root.removeAttribute('data-theme');
    }
  }
  let t = localStorage.getItem('theme') || 'light';
  if (!['light','dark','auto'].includes(t)) t='light';
  apply(t);
  window.__toggleTheme = function() {
    let cur = localStorage.getItem('theme') || 'light';
    if (cur==='light') cur='dark';
    else if (cur==='dark') cur='auto';
    else cur='light';
    localStorage.setItem('theme', cur);
    apply(cur);
    const el=document.getElementById('theme-label');
    if(el) el.textContent = cur.toUpperCase();
  }
  window.__expandAll = function(open) {
    document.querySelectorAll('details').forEach(d => d.open = !!open);
  }
})();
</script>
</head>
<body>
  <div class="container">
    <div class="header">
      <h1>arXiv 论文速递</h1>
      <div style="display:flex;gap:10px;align-items:center">
        
<div class="controls">
  <button class="btn" onclick="__toggleTheme()">Theme: <span id="theme-label" style="margin-left:6px">AUTO</span></button>
  <button class="btn" onclick="__expandAll(true)">Expand All</button>
  <button class="btn" onclick="__expandAll(false)">Collapse All</button>
</div>

        <span class="badge">2026-01-30 03:41</span>
      </div>
    </div>
    <div class="hr"></div>
    <div>Snapshot: 20260130_0341</div>
    <div class="row"><div class="card">
<div class="title">Recursive Language Models</div>
<div class="meta-line">Authors: Alex L. Zhang, Tim Kraska, Omar Khattab</div>
<div class="meta-line">First: 2025-12-31T03:43:41+00:00 · Latest: 2026-01-28T18:59:39+00:00</div>
<div class="meta-line">Comments: 9 pages, 33 with Appendix</div>
<div class="links" style="margin-top:8px"><a href="https://arxiv.org/abs/2512.24601v2">Abs</a> · <a href="https://arxiv.org/pdf/2512.24601v2">PDF</a> · <a href="https://github.com/alexzhang13/rlm">Code1</a> · <a href="https://huggingface.co/huggingface">Code2</a> · <a href="https://huggingface.co/docs/hub/spaces">Code3</a></div>
<details class="detail"><summary>Abstract</summary>
<div class="mono">We study allowing large language models (LLMs) to process arbitrarily long prompts through the lens of inference-time scaling. We propose Recursive Language Models (RLMs), a general inference paradigm that treats long prompts as part of an external environment and allows the LLM to programmatically examine, decompose, and recursively call itself over snippets of the prompt. We find that RLMs can successfully process inputs up to two orders of magnitude beyond model context windows and, even for shorter prompts, dramatically outperform the quality of vanilla frontier LLMs and common long-context scaffolds across four diverse long-context tasks while having comparable cost. At a small scale, we post-train the first natively recursive language model. Our model, RLM-Qwen3-8B, outperforms the underlying Qwen3-8B model by $28.3\%$ on average and even approaches the quality of vanilla GPT-5 on three long-context tasks. Code is available at https://github.com/alexzhang13/rlm.</div></details>
<details class="detail"><summary>中文标题/摘要</summary>
<div class="mono"><b>标题：</b>递归语言模型</div>
<div class="mono" style="margin-top:8px">本研究从推理时扩展的视角探索让大语言模型（LLM）处理任意长度提示的方法。我们提出递归语言模型（RLM），这是一种通用推理范式，将长提示视为外部环境的一部分，允许LLM以编程方式检查、分解提示片段并递归调用自身。研究发现，RLM能成功处理超出模型上下文窗口两个数量级的输入，即使在较短提示场景下，在四项多样化长上下文任务中，其质量也显著超越原始前沿LLM及常见长上下文框架，同时保持相近成本。我们通过小规模后训练实现了首个原生递归语言模型RLM-Qwen3-8B，其在三项长上下文任务中平均性能超越基础模型28.3%，甚至接近原始GPT-5水平。代码发布于https://github.com/alexzhang13/rlm。</div>
</details>
<details class="detail"><summary>Summary / 总结</summary>
<div class="mono">To enable large language models (LLMs) to handle arbitrarily long prompts beyond their fixed context windows, this work introduces Recursive Language Models (RLMs), an inference-time scaling paradigm. The method treats long prompts as an external environment, allowing the LLM to programmatically examine, decompose, and recursively call itself on prompt snippets. Experimental results show RLMs can process inputs up to two orders of magnitude longer than standard context windows, significantly outperform baseline LLMs and long-context scaffolds across four diverse tasks at comparable cost, and a post-trained model, RLM-Qwen3-8B, outperforms its base model by 28.3% on average and approaches the quality of a much larger model on three long-context tasks.</div>
<div class="mono" style="margin-top:8px">本研究旨在解决大型语言模型因固定上下文窗口而无法处理任意长提示的局限性。提出的方法——递归语言模型（RLMs）——是一种推理范式，它使LLM能够以编程方式检查、分解长提示，并对其片段进行递归调用，将提示视为外部环境。实验结果表明，RLMs能处理比标准上下文窗口长两个数量级的输入，在四个不同的长上下文任务上显著优于基线LLM和常见的长上下文框架，且成本相当；一个经过后训练的模型RLM-Qwen3-8B，平均比其基础模型性能提升28.3%，并在三个长上下文任务上接近更大模型的性能。</div>
</details>
</div>
<div class="card">
<div class="title">Evolutionary Strategies lead to Catastrophic Forgetting in LLMs</div>
<div class="meta-line">Authors: Immanuel Abdi, Akshat Gupta, Micah Mok, Alexander Lu, Nicholas Lee, Gopala Anumanchipalli</div>
<div class="meta-line">First: 2026-01-28T18:59:34+00:00 · Latest: 2026-01-28T18:59:34+00:00</div>
<div class="links" style="margin-top:8px"><a href="https://arxiv.org/abs/2601.20861v1">Abs</a> · <a href="https://arxiv.org/pdf/2601.20861v1">PDF</a> · <a href="https://huggingface.co/huggingface">Code1</a> · <a href="https://huggingface.co/docs/hub/spaces">Code2</a></div>
<details class="detail"><summary>Abstract</summary>
<div class="mono">One of the biggest missing capabilities in current AI systems is the ability to learn continuously after deployment. Implementing such continually learning systems have several challenges, one of which is the large memory requirement of gradient-based algorithms that are used to train state-of-the-art LLMs. Evolutionary Strategies (ES) have recently re-emerged as a gradient-free alternative to traditional learning algorithms and have shown encouraging performance on specific tasks in LLMs. In this paper, we perform a comprehensive analysis of ES and specifically evaluate its forgetting curves when training for an increasing number of update steps. We first find that ES is able to reach performance numbers close to GRPO for math and reasoning tasks with a comparable compute budget. However, and most importantly for continual learning, the performance gains in ES is accompanied by significant forgetting of prior abilities, limiting its applicability for training models online. We also explore the reason behind this behavior and show that the updates made using ES are much less sparse and have orders of magnitude larger $\ell_2$ norm compared to corresponding GRPO updates, explaining the contrasting forgetting curves between the two algorithms. With this study, we aim to highlight the issue of forgetting in gradient-free algorithms like ES and hope to inspire future work to mitigate these issues.</div></details>
<details class="detail"><summary>中文标题/摘要</summary>
<div class="mono"><b>标题：</b>进化策略导致大语言模型灾难性遗忘</div>
<div class="mono" style="margin-top:8px">当前AI系统最显著的能力缺失之一是部署后无法持续学习。实现此类持续学习系统面临诸多挑战，其中一大难点是训练尖端大语言模型所用的基于梯度的算法对内存需求极高。进化策略作为无需梯度的传统学习算法替代方案近期重新兴起，并在大语言模型的特定任务中展现出令人鼓舞的性能。本文对进化策略进行了全面分析，重点评估了在增加更新步数训练时的遗忘曲线。我们首先发现，在计算预算相近的情况下，进化策略在数学和推理任务上能达到接近GRPO的性能水平。然而，对于持续学习而言最关键的是，进化策略的性能提升伴随着对先前能力的显著遗忘，这限制了其在在线训练模型中的应用。我们还探究了该现象背后的原因，结果表明与相应的GRPO更新相比，进化策略的更新稀疏度低得多，且其ℓ₂范数量级更大，这解释了两算法间截然不同的遗忘曲线。通过本研究，我们旨在揭示进化策略等无梯度算法的遗忘问题，以期启发未来研究缓解这些缺陷。</div>
</details>
<details class="detail"><summary>Summary / 总结</summary>
<div class="mono">The research is motivated by the need for AI systems capable of continuous learning after deployment, a challenge partly due to the high memory demands of gradient-based methods. The study comprehensively analyzes Evolutionary Strategies (ES) as a gradient-free alternative, evaluating its forgetting behavior over multiple update steps on math and reasoning tasks. Key experimental findings show that while ES can achieve performance close to GRPO with comparable compute, it suffers from significant catastrophic forgetting of prior abilities, which is linked to its updates being less sparse and having a much larger ℓ₂ norm than GRPO updates, thereby limiting its suitability for online continual learning.</div>
<div class="mono" style="margin-top:8px">本研究旨在解决已部署AI系统中持续学习的需求，其中基于梯度的方法面临高内存要求，因此探索了进化策略（ES）等无梯度替代方案。方法包括对ES进行全面分析，特别评估其在数学和推理任务上延长训练时的遗忘曲线，并与GRPO在性能和更新特性上进行比较。关键实验结果表明，ES在相似计算预算下能达到接近GRPO的性能，但会伴随显著的灾难性遗忘，这归因于其更新稀疏度较低且ℓ₂范数更大，从而限制了其在在线持续学习中的应用。</div>
</details>
</div>
<div class="card">
<div class="title">ArchesClimate: Probabilistic Decadal Ensemble Generation With Flow Matching</div>
<div class="meta-line">Authors: Graham Clyne, Guillaume Couairon, Guillaume Gastineau, Claire Monteleoni, Anastase Charantonis</div>
<div class="meta-line">First: 2025-09-19T12:53:24+00:00 · Latest: 2026-01-28T18:58:50+00:00</div>
<div class="links" style="margin-top:8px"><a href="https://arxiv.org/abs/2509.15942v2">Abs</a> · <a href="https://arxiv.org/pdf/2509.15942v2">PDF</a> · <a href="https://huggingface.co/huggingface">Code1</a> · <a href="https://huggingface.co/docs/hub/spaces">Code2</a></div>
<details class="detail"><summary>Abstract</summary>
<div class="mono">Climate projections have uncertainties related to components of the climate system and their interactions. A typical approach to quantifying these uncertainties is to use climate models to create ensembles of repeated simulations under different initial conditions. Due to the complexity of these simulations, generating such ensembles of projections is computationally expensive. In this work, we present ArchesClimate, a deep learning-based climate model emulator that aims to reduce this cost. ArchesClimate is trained on decadal hindcasts of the IPSL-CM6A-LR climate model at a spatial resolution of approximately 2.5x1.25 degrees. We train a flow matching model following ArchesWeatherGen, which we adapt to predict near-term climate. Once trained, the model generates states at a one-month lead time and can be used to auto-regressively emulate climate model simulations of any length. We show that for up to 10 years, these generations are stable and physically consistent. We also show that for several important climate variables, ArchesClimate generates simulations that are interchangeable with the IPSL model. This work suggests that climate model emulators could significantly reduce the cost of climate model simulations.</div></details>
<details class="detail"><summary>中文标题/摘要</summary>
<div class="mono"><b>标题：</b>ArchesClimate：基于流匹配的概率性年代际集合生成</div>
<div class="mono" style="margin-top:8px">气候预测存在与气候系统各组分及其相互作用相关的不确定性。量化这些不确定性的典型方法是利用气候模型在不同初始条件下生成重复模拟的集合。由于这些模拟的复杂性，生成此类预测集合的计算成本极高。本研究提出ArchesClimate——一种基于深度学习的气候模型仿真器，旨在降低这一成本。该模型在IPSL-CM6A-LR气候模型约2.5×1.25度空间分辨率的年代际后报数据上训练，采用基于ArchesWeatherGen的流匹配模型架构，并适配于近未来气候预测。训练完成后，模型能以一个月为提前期生成气候状态，并可通过自回归方式仿真任意时长的气候模型模拟。实验表明，该模型在长达10年的时间尺度上能保持生成结果的稳定性和物理一致性，且对多个重要气候变量生成的模拟结果与IPSL模型具有可互换性。这项工作表明气候模型仿真器可显著降低气候模拟的计算成本。</div>
</details>
<details class="detail"><summary>Summary / 总结</summary>
<div class="mono">Generating ensembles of climate projections to quantify uncertainties is computationally expensive due to the complexity of traditional climate models. To reduce this cost, this work introduces ArchesClimate, a deep learning-based emulator trained on decadal hindcasts from the IPSL-CM6A-LR model at approximately 2.5x1.25-degree resolution using a flow matching method adapted from ArchesWeatherGen for near-term climate prediction. The model auto-regressively generates stable and physically consistent monthly states for up to 10 years, producing simulations for key climate variables that are statistically interchangeable with those from the original IPSL model, demonstrating the potential of emulators to significantly lower computational expenses.</div>
<div class="mono" style="margin-top:8px">由于传统气候模型的复杂性，生成用于量化不确定性的气候预测集合计算成本高昂。为降低这一成本，本研究提出了ArchesClimate，这是一个基于深度学习的模拟器，它使用从ArchesWeatherGen适配的流匹配方法，在约2.5x1.25度空间分辨率的IPSL-CM6A-LR模型年代际后报数据上训练，用于近未来气候预测。该模型能以自回归方式生成长达10年的稳定且物理一致的月度状态，针对多个重要气候变量产生的模拟结果与原始IPSL模型具有统计可互换性，表明气候模拟器有望显著降低计算开销。</div>
</details>
</div>
<div class="card">
<div class="title">DCP-Bench-Open: Evaluating LLMs for Constraint Modelling of Discrete Combinatorial Problems</div>
<div class="meta-line">Authors: Kostis Michailidis, Dimos Tsouros, Tias Guns</div>
<div class="meta-line">First: 2025-06-06T12:56:02+00:00 · Latest: 2026-01-28T18:58:23+00:00</div>
<div class="meta-line">Comments: This version is currently submitted and it is under review. For CP-Bench (the paper accepted at ECAI25), please refer to the previous version of this entry (v2)</div>
<div class="links" style="margin-top:8px"><a href="https://arxiv.org/abs/2506.06052v3">Abs</a> · <a href="https://arxiv.org/pdf/2506.06052v3">PDF</a> · <a href="https://huggingface.co/huggingface">Code1</a> · <a href="https://huggingface.co/docs/hub/spaces">Code2</a></div>
<details class="detail"><summary>Abstract</summary>
<div class="mono">Discrete Combinatorial Problems (DCPs) are prevalent in industrial decision-making and optimisation. However, while constraint solving technologies for DCPs have advanced significantly, the core process of formalising them, namely constraint modelling, requires significant expertise and remains a bottleneck for wider adoption. Aiming to alleviate this bottleneck, recent studies have explored using Large Language Models (LLMs) to transform combinatorial problem descriptions into executable constraint models. However, the existing evaluation datasets for discrete constraint modelling are often limited to small, homogeneous, or domain-specific problems, which do not capture the diversity of real-world scenarios. This work addresses this gap by introducing DCP-Bench-Open, a novel benchmark that includes a diverse set of well-known discrete combinatorial problems sourced from the Constraint Programming (CP) and Operations Research (OR) communities, structured explicitly for evaluating LLM-driven constraint modelling. With this dataset, and given the variety of modelling frameworks, we compare and evaluate the modelling capabilities of LLMs for three distinct constraint modelling systems, which vary in abstraction level and underlying syntax. Notably, the results show higher performance when modelling with a high-level Python-based framework. Additionally, we systematically evaluate the use of prompt-based and inference-time compute methods across different LLMs, which further increase accuracy, reaching up to 91% on this highly challenging benchmark. DCP-Bench-Open is publicly available.</div></details>
<details class="detail"><summary>中文标题/摘要</summary>
<div class="mono"><b>标题：</b>DCP-Bench-Open：评估大语言模型在离散组合问题约束建模中的能力</div>
<div class="mono" style="margin-top:8px">离散组合问题在工业决策与优化中普遍存在。尽管针对此类问题的约束求解技术已取得显著进展，但其形式化的核心过程——即约束建模——仍需大量专业知识，并成为广泛应用的瓶颈。为缓解此瓶颈，近期研究探索利用大语言模型将组合问题描述转化为可执行的约束模型。然而，现有离散约束建模评估数据集通常局限于小型、同质或特定领域问题，未能涵盖现实场景的多样性。本研究通过引入DCP-Bench-Open填补这一空白，该新颖基准包含源自约束编程与运筹学领域的多样化经典离散组合问题，并明确构建用于评估LLM驱动的约束建模。基于此数据集及多样化的建模框架，我们比较评估了LLM在三种不同抽象层次与底层语法的约束建模系统中的建模能力。值得注意的是，结果显示使用基于Python的高级框架建模时性能更优。此外，我们系统评估了不同LLM中基于提示与推理时计算方法的运用，进一步将准确率提升至91%（基于此高难度基准）。DCP-Bench-Open已公开提供。</div>
</details>
<details class="detail"><summary>Summary / 总结</summary>
<div class="mono">This research addresses the bottleneck in constraint modelling for Discrete Combinatorial Problems (DCPs), which requires significant expertise despite advances in solving technologies. The authors introduce DCP-Bench-Open, a novel and diverse benchmark sourced from CP and OR communities, to systematically evaluate how Large Language Models (LLMs) can transform problem descriptions into executable constraint models across three distinct modelling systems. Experimental results demonstrate that LLMs achieve higher performance when using a high-level Python-based framework, and that prompt-based and inference-time compute methods can further increase accuracy up to 91% on this challenging benchmark.</div>
<div class="mono" style="margin-top:8px">本研究针对离散组合问题形式化这一制约约束求解技术广泛应用的瓶颈，旨在评估大型语言模型在自动化约束建模中的潜力。作者引入了DCP-Bench-Open这一新颖基准，它包含来自约束规划和运筹学社区的多样化经典问题，专为评估LLM的建模能力而设计。通过系统比较LLM在三种不同抽象层次和语法的建模系统中的表现，实验发现基于Python的高级框架性能最高，且基于提示和推理时计算的方法能进一步提升准确率，在这一高难度基准上最高可达91%。</div>
</details>
</div>
<div class="card">
<div class="title">SokoBench: Evaluating Long-Horizon Planning and Reasoning in Large Language Models</div>
<div class="meta-line">Authors: Sebastiano Monti, Carlo Nicolini, Gianni Pellegrini, Jacopo Staiano, Bruno Lepri</div>
<div class="meta-line">First: 2026-01-28T18:56:00+00:00 · Latest: 2026-01-28T18:56:00+00:00</div>
<div class="links" style="margin-top:8px"><a href="https://arxiv.org/abs/2601.20856v1">Abs</a> · <a href="https://arxiv.org/pdf/2601.20856v1">PDF</a> · <a href="https://huggingface.co/huggingface">Code1</a> · <a href="https://huggingface.co/docs/hub/spaces">Code2</a></div>
<details class="detail"><summary>Abstract</summary>
<div class="mono">Although the capabilities of large language models have been increasingly tested on complex reasoning tasks, their long-horizon planning abilities have not yet been extensively investigated. In this work, we provide a systematic assessment of the planning and long-horizon reasoning capabilities of state-of-the-art Large Reasoning Models (LRMs). We propose a novel benchmark based on Sokoban puzzles, intentionally simplified to isolate long-horizon planning from state persistence. Our findings reveal a consistent degradation in planning performance when more than 25 moves are required to reach the solution, suggesting a fundamental constraint on forward planning capacity. We show that equipping LRMs with Planning Domain Definition Language (PDDL) parsing, validation, and solving tools allows for modest improvements, suggesting inherent architectural limitations which might not be overcome by test-time scaling approaches alone.</div></details>
<details class="detail"><summary>中文标题/摘要</summary>
<div class="mono"><b>标题：</b>SokoBench：评估大语言模型的长程规划与推理能力</div>
<div class="mono" style="margin-top:8px">尽管大语言模型在复杂推理任务上的能力日益受到检验，但其长程规划能力尚未得到广泛研究。本研究对前沿大语言推理模型的规划与长程推理能力进行了系统评估。我们提出基于推箱子游戏的新型基准测试，通过刻意简化设计以隔离状态持续性对长程规划的影响。研究发现当求解需要超过25步操作时，规划性能呈现系统性下降，这揭示了前向规划能力的根本性约束。实验表明，为模型配备规划领域定义语言的解析、验证与求解工具可带来有限改进，暗示了仅靠测试时扩展方法可能无法克服的内在架构局限。</div>
</details>
<details class="detail"><summary>Summary / 总结</summary>
<div class="mono">This study addresses the need to systematically evaluate long-horizon planning in large language models, which remains underexplored despite advances in complex reasoning. The authors introduce SokoBench, a benchmark based on simplified Sokoban puzzles designed to isolate long-horizon planning from state persistence challenges. Key experimental results show a consistent performance decline in models when solutions require over 25 moves, indicating a fundamental constraint on forward planning capacity; integrating PDDL tools yields only modest improvements, suggesting inherent architectural limitations not easily overcome by scaling alone.</div>
<div class="mono" style="margin-top:8px">本研究旨在系统评估大语言模型的长时程规划能力，该能力在复杂推理任务进展中仍未得到充分探索。方法上提出了基于推箱子游戏的新基准SokoBench，有意简化设计以隔离长时程规划与状态持久性问题。主要实验结果表明，当解决方案需要超过25步时，规划性能持续下降，揭示了模型前向规划能力的根本性约束；尽管集成PDDL工具带来有限改进，但这暗示了固有的架构限制，仅靠测试时扩展方法难以克服。</div>
</details>
</div>
<div class="card">
<div class="title">From Specialist to Generalist: Unlocking SAM&#x27;s Learning Potential on Unlabeled Medical Images</div>
<div class="meta-line">Authors: Vi Vu, Thanh-Huy Nguyen, Tien-Thinh Nguyen, Ba-Thinh Lam, Hoang-Thien Nguyen, Tianyang Wang, Xingjian Li, Min Xu</div>
<div class="meta-line">Venue: ISBI 2026</div>
<div class="meta-line">First: 2026-01-25T18:13:48+00:00 · Latest: 2026-01-28T18:55:46+00:00</div>
<div class="meta-line">Comments: Accepted to ISBI 2026</div>
<div class="links" style="margin-top:8px"><a href="https://arxiv.org/abs/2601.17934v2">Abs</a> · <a href="https://arxiv.org/pdf/2601.17934v2">PDF</a> · <a href="https://github.com/vnlvi2k3/SC-SAM">Code1</a> · <a href="https://huggingface.co/huggingface">Code2</a> · <a href="https://huggingface.co/docs/hub/spaces">Code3</a></div>
<details class="detail"><summary>Abstract</summary>
<div class="mono">Foundation models like the Segment Anything Model (SAM) show strong generalization, yet adapting them to medical images remains difficult due to domain shift, scarce labels, and the inability of Parameter-Efficient Fine-Tuning (PEFT) to exploit unlabeled data. While conventional models like U-Net excel in semi-supervised medical learning, their potential to assist a PEFT SAM has been largely overlooked. We introduce SC-SAM, a specialist-generalist framework where U-Net provides point-based prompts and pseudo-labels to guide SAM&#x27;s adaptation, while SAM serves as a powerful generalist supervisor to regularize U-Net. This reciprocal guidance forms a bidirectional co-training loop that allows both models to effectively exploit the unlabeled data. Across prostate MRI and polyp segmentation benchmarks, our method achieves state-of-the-art results, outperforming other existing semi-supervised SAM variants and even medical foundation models like MedSAM, highlighting the value of specialist-generalist cooperation for label-efficient medical image segmentation. Our code is available at https://github.com/vnlvi2k3/SC-SAM.</div></details>
<details class="detail"><summary>中文标题/摘要</summary>
<div class="mono"><b>标题：</b>从专家到通才：释放SAM在无标注医学图像上的学习潜力</div>
<div class="mono" style="margin-top:8px">以Segment Anything Model（SAM）为代表的基础模型展现出强大的泛化能力，但由于领域偏移、标注稀缺以及参数高效微调（PEFT）无法利用无标注数据，其在医学图像上的适配仍面临挑战。尽管U-Net等传统模型在半监督医学学习中表现优异，其辅助PEFT SAM的潜力长期被忽视。我们提出SC-SAM——一种专家-通才协作框架：U-Net通过点提示与伪标注引导SAM适配，同时SAM作为强大的通才监督器对U-Net进行正则化。这种双向指导形成协同训练循环，使两种模型能有效利用无标注数据。在前列腺MRI与息肉分割基准测试中，本方法取得最先进成果，优于现有半监督SAM变体及MedSAM等医学基础模型，彰显了专家-通才协作在标签高效医学图像分割中的价值。代码已开源：https://github.com/vnlvi2k3/SC-SAM。</div>
</details>
<details class="detail"><summary>Summary / 总结</summary>
<div class="mono">The research addresses the challenge of adapting the Segment Anything Model (SAM) to medical image segmentation, where domain shift and scarce labeled data hinder performance, and Parameter-Efficient Fine-Tuning (PEFT) cannot leverage unlabeled data. The proposed method, SC-SAM, establishes a specialist-generalist co-training framework: a U-Net specialist generates point-based prompts and pseudo-labels from unlabeled images to guide SAM&#x27;s adaptation, while SAM acts as a generalist supervisor to regularize the U-Net. Experimental results on prostate MRI and polyp segmentation benchmarks demonstrate state-of-the-art performance, surpassing other semi-supervised SAM variants and medical foundation models like MedSAM, validating the efficacy of reciprocal guidance for label-efficient learning.</div>
<div class="mono" style="margin-top:8px">本研究旨在解决将Segment Anything Model (SAM)适配到医学图像分割的挑战，其中领域偏移和标注数据稀缺限制了性能，且参数高效微调(PEFT)无法利用未标注数据。所提出的SC-SAM方法构建了一个专家-通才框架：U-Net专家从未标注图像生成基于点的提示和伪标签以指导SAM的适配，同时SAM作为通才监督器来正则化U-Net，形成一个双向协同训练循环。在前列腺MRI和息肉分割基准测试上的实验表明，SC-SAM取得了最先进的结果，优于其他半监督SAM变体及MedSAM等医学基础模型，证明了专家-通才协作在标签高效分割中的有效性。</div>
</details>
</div>
<div class="card">
<div class="title">Exploring Transformer Placement in Variational Autoencoders for Tabular Data Generation</div>
<div class="meta-line">Authors: Aníbal Silva, Moisés Santos, André Restivo, Carlos Soares</div>
<div class="meta-line">First: 2026-01-28T18:54:27+00:00 · Latest: 2026-01-28T18:54:27+00:00</div>
<div class="links" style="margin-top:8px"><a href="https://arxiv.org/abs/2601.20854v1">Abs</a> · <a href="https://arxiv.org/pdf/2601.20854v1">PDF</a> · <a href="https://huggingface.co/huggingface">Code1</a> · <a href="https://huggingface.co/docs/hub/spaces">Code2</a></div>
<details class="detail"><summary>Abstract</summary>
<div class="mono">Tabular data remains a challenging domain for generative models. In particular, the standard Variational Autoencoder (VAE) architecture, typically composed of multilayer perceptrons, struggles to model relationships between features, especially when handling mixed data types. In contrast, Transformers, through their attention mechanism, are better suited for capturing complex feature interactions. In this paper, we empirically investigate the impact of integrating Transformers into different components of a VAE. We conduct experiments on 57 datasets from the OpenML CC18 suite and draw two main conclusions. First, results indicate that positioning Transformers to leverage latent and decoder representations leads to a trade-off between fidelity and diversity. Second, we observe a high similarity between consecutive blocks of a Transformer in all components. In particular, in the decoder, the relationship between the input and output of a Transformer is approximately linear.</div></details>
<details class="detail"><summary>中文标题/摘要</summary>
<div class="mono"><b>标题：</b>探索Transformer在变分自编码器中用于表格数据生成的位置配置</div>
<div class="mono" style="margin-top:8px">表格数据对生成模型而言仍是一个具有挑战性的领域。特别是标准的变分自编码器（VAE）架构，通常由多层感知机构成，难以建模特征间的关系，尤其是在处理混合数据类型时。相比之下，Transformer通过其注意力机制更适合捕捉复杂的特征交互。本文通过实证研究探讨了将Transformer集成到VAE不同组件中的影响。我们在OpenML CC18套件的57个数据集上进行了实验，并得出两个主要结论：首先，结果表明将Transformer置于利用潜在表示和解码器表示的位置会导致保真度与多样性之间的权衡；其次，我们观察到Transformer在所有组件中连续块之间具有高度相似性，特别是在解码器中，Transformer输入与输出之间的关系近似线性。</div>
</details>
<details class="detail"><summary>Summary / 总结</summary>
<div class="mono">This study addresses the challenge of generating high-quality tabular data, where standard Variational Autoencoders (VAEs) with multilayer perceptrons often fail to model complex feature interactions. The authors empirically explore integrating Transformers into different VAE components to leverage their attention mechanism for capturing feature relationships. Experiments on 57 OpenML CC18 datasets reveal that placing Transformers to use latent and decoder representations creates a fidelity-diversity trade-off, and they observe high similarity between consecutive Transformer blocks, with an approximately linear relationship between input and output in the decoder.</div>
<div class="mono" style="margin-top:8px">本研究针对表格数据生成的挑战，即标准变分自编码器（VAE）通常使用的多层感知机难以建模特征间复杂关系，尤其是在处理混合数据类型时。方法通过实验探索将具有注意力机制的Transformer模块集成到VAE的不同组件中，以更好地捕捉特征交互。在OpenML CC18套件的57个数据集上的实验结果表明，将Transformer置于利用潜在表示和解码器表示的位置时，需要在保真度和多样性之间进行权衡，并且观察到Transformer连续块之间高度相似，特别是在解码器中，其输入与输出之间近似呈线性关系。</div>
</details>
</div>
<div class="card">
<div class="title">HeuriGym: An Agentic Benchmark for LLM-Crafted Heuristics in Combinatorial Optimization</div>
<div class="meta-line">Authors: Hongzheng Chen, Yingheng Wang, Yaohui Cai, Hins Hu, Jiajie Li, Shirley Huang, Chenhui Deng, Rongjian Liang, Shufeng Kong, Haoxing Ren, Samitha Samaranayake, Carla P. Gomes, Zhiru Zhang</div>
<div class="meta-line">Venue: ICLR</div>
<div class="meta-line">First: 2025-06-09T17:46:47+00:00 · Latest: 2026-01-28T18:52:54+00:00</div>
<div class="meta-line">Comments: Accepted to ICLR&#x27;26</div>
<div class="links" style="margin-top:8px"><a href="https://arxiv.org/abs/2506.07972v2">Abs</a> · <a href="https://arxiv.org/pdf/2506.07972v2">PDF</a> · <a href="https://huggingface.co/huggingface">Code1</a> · <a href="https://huggingface.co/docs/hub/spaces">Code2</a></div>
<details class="detail"><summary>Abstract</summary>
<div class="mono">While Large Language Models (LLMs) have demonstrated significant advancements in reasoning and agent-based problem-solving, current evaluation methodologies fail to adequately assess their capabilities: existing benchmarks either rely on closed-ended questions prone to saturation and memorization, or subjective comparisons that lack consistency and rigor. In this work, we introduce HeuriGym, an agentic framework designed for evaluating heuristic algorithms generated by LLMs for combinatorial optimization problems, characterized by clearly defined objectives and expansive solution spaces. HeuriGym empowers LLMs to propose heuristics, receive evaluative feedback via code execution, and iteratively refine their solutions. We evaluate nine state-of-the-art models on nine problems across domains such as computer systems, logistics, and biology, exposing persistent limitations in tool use, planning, and adaptive reasoning. To quantify performance, we propose the Quality-Yield Index (QYI), a metric that captures both solution pass rate and quality. Even top models like GPT-o4-mini-high and Gemini-2.5-Pro attain QYI scores of only 0.6, well below the expert baseline of 1. Our open-source benchmark aims to guide the development of LLMs toward more effective and realistic problem-solving in scientific and engineering domains.</div></details>
<details class="detail"><summary>中文标题/摘要</summary>
<div class="mono"><b>标题：</b>HeuriGym：面向组合优化中LLM启发式算法生成的智能体基准</div>
<div class="mono" style="margin-top:8px">尽管大语言模型在推理和基于智能体的问题解决方面取得显著进展，现有评估方法仍难以充分衡量其能力：当前基准测试要么依赖易饱和和记忆的封闭式问题，要么采用缺乏一致性和严谨性的主观比较。本研究提出HeuriGym——一个用于评估大语言模型生成组合优化启发式算法的智能体框架，其特点在于目标定义明确且解空间广阔。该框架支持大语言模型提出启发式策略、通过代码执行获取评估反馈，并迭代优化解决方案。我们在计算机系统、物流、生物学等领域的九个问题上测试了九个前沿模型，揭示了其在工具使用、规划与自适应推理方面的持续局限。为量化性能，我们提出质量-产出指数——一种同时衡量解决方案通过率与质量的指标。即使如GPT-4o-mini-high和Gemini-2.5-Pro等顶级模型，其QYI得分也仅为0.6，远低于专家基线水平1.0。本开源基准旨在引导大语言模型向更有效、更贴近实际的科学与工程问题解决方向发展。</div>
</details>
<details class="detail"><summary>Summary / 总结</summary>
<div class="mono">The research addresses the limitations of current evaluation methods for large language models (LLMs), which often rely on closed-ended questions prone to saturation or subjective comparisons lacking rigor, by introducing HeuriGym, an agentic framework for assessing LLM-generated heuristic algorithms in combinatorial optimization problems. The method enables LLMs to propose heuristics, receive feedback through code execution, and iteratively refine solutions, evaluated across nine state-of-the-art models on nine problems from domains like computer systems and logistics. Key experimental findings reveal persistent limitations in tool use and planning, with even top models such as GPT-4o-mini-high and Gemini-2.5-Pro achieving a Quality-Yield Index (QYI) score of only 0.6, significantly below the expert baseline of 1, highlighting the need for improved problem-solving capabilities in scientific and engineering contexts.</div>
<div class="mono" style="margin-top:8px">本研究针对当前大型语言模型评估方法依赖封闭式问题或主观比较的局限性，提出了HeuriGym这一智能体框架，用于评估组合优化问题中LLM生成的启发式算法。该方法允许LLM提出启发式策略，通过代码执行获得反馈并迭代优化解决方案，在计算机系统、物流和生物学等领域的九个问题上进行评估，并提出了综合衡量通过率和解决方案质量的指标——质量-产出指数。对九个先进模型的实验结果表明，它们在工具使用和自适应推理方面存在持续不足，顶级模型的QYI得分仅为0.6左右，远低于专家基准1，这凸显了LLM在科学和工程领域问题解决能力上仍需提升。</div>
</details>
</div>
<div class="card">
<div class="title">Post-Training Fairness Control: A Single-Train Framework for Dynamic Fairness in Recommendation</div>
<div class="meta-line">Authors: Weixin Chen, Li Chen, Yuhan Zhao</div>
<div class="meta-line">Venue: WWW 2026 Oral Presentation</div>
<div class="meta-line">First: 2026-01-28T18:48:43+00:00 · Latest: 2026-01-28T18:48:43+00:00</div>
<div class="meta-line">Comments: Accepted to WWW 2026 Workshop on HCRS (Oral Presentation)</div>
<div class="links" style="margin-top:8px"><a href="https://arxiv.org/abs/2601.20848v1">Abs</a> · <a href="https://arxiv.org/pdf/2601.20848v1">PDF</a> · <a href="https://github.com/weixinchen98/Cofair">Code1</a> · <a href="https://huggingface.co/huggingface">Code2</a> · <a href="https://huggingface.co/docs/hub/spaces">Code3</a></div>
<details class="detail"><summary>Abstract</summary>
<div class="mono">Despite growing efforts to mitigate unfairness in recommender systems, existing fairness-aware methods typically fix the fairness requirement at training time and provide limited post-training flexibility. However, in real-world scenarios, diverse stakeholders may demand differing fairness requirements over time, so retraining for different fairness requirements becomes prohibitive. To address this limitation, we propose Cofair, a single-train framework that enables post-training fairness control in recommendation. Specifically, Cofair introduces a shared representation layer with fairness-conditioned adapter modules to produce user embeddings specialized for varied fairness levels, along with a user-level regularization term that guarantees user-wise monotonic fairness improvements across these levels. We theoretically establish that the adversarial objective of Cofair upper bounds demographic parity and the regularization term enforces progressive fairness at user level. Comprehensive experiments on multiple datasets and backbone models demonstrate that our framework provides dynamic fairness at different levels, delivering comparable or better fairness-accuracy curves than state-of-the-art baselines, without the need to retrain for each new fairness requirement. Our code is publicly available at https://github.com/weixinchen98/Cofair.</div></details>
<details class="detail"><summary>中文标题/摘要</summary>
<div class="mono"><b>标题：</b>训练后公平性控制：推荐系统中动态公平性的单次训练框架</div>
<div class="mono" style="margin-top:8px">尽管缓解推荐系统不公平性的研究日益增多，现有公平性方法通常在训练时固定公平性要求，缺乏训练后的灵活调整能力。然而在实际场景中，不同利益相关方可能随时间提出差异化的公平性需求，为每种需求重新训练模型成本过高。为此，我们提出Cofair——一种支持训练后公平性控制的单次训练框架。该框架通过共享表征层与公平性条件适配器模块，生成适应不同公平性水平的用户嵌入向量，并引入用户级正则化项确保跨公平性水平的单调改进。理论证明表明，Cofair的对抗目标为人口统计平等性提供上界约束，正则化项则在用户层面实现渐进式公平性提升。在多数据集与骨干模型上的实验表明，本框架能在不同公平性水平实现动态调控，其公平性-准确性曲线优于或媲美现有基线方法，且无需针对新公平性需求重新训练。代码已开源：https://github.com/weixinchen98/Cofair。</div>
</details>
<details class="detail"><summary>Summary / 总结</summary>
<div class="mono">Existing fairness-aware recommendation methods often fix fairness requirements at training time, lacking flexibility for diverse stakeholder demands that may change over time. To address this, the authors propose Cofair, a single-train framework that introduces a shared representation layer with fairness-conditioned adapter modules to generate user embeddings for different fairness levels, coupled with a user-level regularization term to ensure monotonic fairness improvements. Experiments on multiple datasets and backbone models show that Cofair enables dynamic fairness control, achieving comparable or superior fairness-accuracy trade-offs without retraining for each new requirement.</div>
<div class="mono" style="margin-top:8px">为解决现有公平性推荐系统因固定训练时公平性要求而缺乏灵活性、需要为不同要求重新训练的问题，本文提出了Cofair，一个支持训练后公平性控制的单次训练框架。该方法通过引入带有公平性条件适配器模块的共享表示层来生成适应不同公平性水平的用户嵌入，并结合用户级正则化项确保公平性随水平单调提升。在多个数据集和骨干模型上的综合实验表明，Cofair能够在不同水平上提供动态公平性控制，在不重新训练的情况下，取得了与先进基线相当或更优的公平性-准确性权衡曲线。</div>
</details>
</div>
<div class="card">
<div class="title">Fail Fast, Win Big: Rethinking the Drafting Strategy in Speculative Decoding via Diffusion LLMs</div>
<div class="meta-line">Authors: Rui Pan, Zhuofu Chen, Hongyi Liu, Arvind Krishnamurthy, Ravi Netravali</div>
<div class="meta-line">First: 2025-12-23T18:16:58+00:00 · Latest: 2026-01-28T18:48:35+00:00</div>
<div class="links" style="margin-top:8px"><a href="https://arxiv.org/abs/2512.20573v3">Abs</a> · <a href="https://arxiv.org/pdf/2512.20573v3">PDF</a> · <a href="https://github.com/ruipeterpan/failfast">Code1</a> · <a href="https://huggingface.co/huggingface">Code2</a> · <a href="https://huggingface.co/docs/hub/spaces">Code3</a></div>
<details class="detail"><summary>Abstract</summary>
<div class="mono">Diffusion Large Language Models (dLLMs) offer fast, parallel token generation, but their standalone use is plagued by an inherent efficiency-quality tradeoff. We show that, if carefully applied, the attributes of dLLMs can actually be a strength for drafters in speculative decoding with autoregressive (AR) verifiers. Our core insight is that dLLM&#x27;s speed from parallel decoding drastically lowers the risk of costly rejections, providing a practical mechanism to effectively realize the (elusive) lengthy drafts that lead to large speedups with speculative decoding. We present FailFast, a dLLM-based speculative decoding framework that realizes this approach by dynamically adapting its speculation length. It &quot;fails fast&quot; by spending minimal compute in hard-to-speculate regions to shrink speculation latency and &quot;wins big&quot; by aggressively extending draft lengths in easier regions to reduce verification latency (in many cases, speculating and accepting 70 tokens at a time!). Without any fine-tuning, FailFast delivers lossless acceleration of AR LLMs and achieves up to 4.9$\times$ speedup over vanilla decoding, 1.7$\times$ over the best naive dLLM drafter, and 1.7$\times$ over EAGLE-3 across diverse models and workloads. We open-source FailFast at https://github.com/ruipeterpan/failfast.</div></details>
<details class="detail"><summary>中文标题/摘要</summary>
<div class="mono"><b>标题：</b>快速失败，大获全胜：通过扩散大语言模型重新思考推测解码中的草稿策略</div>
<div class="mono" style="margin-top:8px">扩散大语言模型（dLLMs）提供快速、并行的令牌生成，但其独立使用受制于固有的效率与质量权衡。我们证明，若精心应用，dLLMs的特性实际上可成为推测解码中自回归验证器草稿生成的优势。核心洞见在于：dLLMs通过并行解码实现的速度，大幅降低了高代价拒绝的风险，为有效实现推测解码中（难以捉摸的）长草稿提供了实用机制，从而带来显著加速。我们提出FailFast，一个基于dLLM的推测解码框架，通过动态调整推测长度实现此方法：在难以推测的区域“快速失败”，以最小计算缩短推测延迟；在易推测区域“大获全胜”，通过大幅延长草稿长度减少验证延迟（常可一次推测并接受70个令牌！）。无需任何微调，FailFast实现了对自回归大语言模型的无损加速，相比原始解码最高达4.9倍加速，优于最佳朴素dLLM草稿器1.7倍，且在不同模型与工作负载中均超越EAGLE-3达1.7倍。项目已开源：https://github.com/ruipeterpan/failfast。</div>
</details>
<details class="detail"><summary>Summary / 总结</summary>
<div class="mono">This research addresses the efficiency-quality tradeoff in diffusion large language models (dLLMs) by reimagining their role as drafters in speculative decoding with autoregressive verifiers. The proposed FailFast framework leverages dLLMs&#x27; fast parallel token generation to produce lengthy draft sequences with minimal rejection risk, dynamically adapting speculation length to fail quickly in difficult regions and win big with long accepted drafts in easier ones. Experimental results show that FailFast achieves lossless acceleration, delivering up to 4.9× speedup over vanilla decoding, 1.7× over naive dLLM drafting, and 1.7× over EAGLE-3 across diverse models and workloads, often accepting 70-token drafts at once.</div>
<div class="mono" style="margin-top:8px">本研究针对扩散大语言模型（dLLM）存在的效率与质量权衡问题，提出将其重新用作自回归验证器推测解码中的草稿模型。所提出的FailFast框架利用dLLM的并行生成能力，以低拒绝风险生成长草稿序列，并动态调整推测长度，从而在困难上下文中最小化计算开销，在简单上下文中最大化利用。实验结果表明，FailFast实现了无损加速，相比原始解码最高达到4.9倍加速，且优于其他草稿模型，在部分情况下能一次性成功推测并接受约70个令牌。</div>
</details>
</div>
<div class="card">
<div class="title">A New Dataset and Framework for Robust Road Surface Classification via Camera-IMU Fusion</div>
<div class="meta-line">Authors: Willams de Lima Costa, Thifany Ketuli Silva de Souza, Jonas Ferreira Silva, Carlos Gabriel Bezerra Pereira, Bruno Reis Vila Nova, Leonardo Silvino Brito, Rafael Raider Leoni, Juliano Silva, Valter Ferreira, Sibele Miguel Soares Neto, Samantha Uehara, Daniel Giacomo, João Marcelo Teixeira, Veronica Teichrieb, Cristiano Coelho de Araújo</div>
<div class="meta-line">First: 2026-01-28T18:46:29+00:00 · Latest: 2026-01-28T18:46:29+00:00</div>
<div class="links" style="margin-top:8px"><a href="https://arxiv.org/abs/2601.20847v1">Abs</a> · <a href="https://arxiv.org/pdf/2601.20847v1">PDF</a> · <a href="https://huggingface.co/huggingface">Code1</a> · <a href="https://huggingface.co/docs/hub/spaces">Code2</a></div>
<details class="detail"><summary>Abstract</summary>
<div class="mono">Road surface classification (RSC) is a key enabler for environment-aware predictive maintenance systems. However, existing RSC techniques often fail to generalize beyond narrow operational conditions due to limited sensing modalities and datasets that lack environmental diversity. This work addresses these limitations by introducing a multimodal framework that fuses images and inertial measurements using a lightweight bidirectional cross-attention module followed by an adaptive gating layer that adjusts modality contributions under domain shifts. Given the limitations of current benchmarks, especially regarding lack of variability, we introduce ROAD, a new dataset composed of three complementary subsets: (i) real-world multimodal recordings with RGB-IMU streams synchronized using a gold-standard industry datalogger, captured across diverse lighting, weather, and surface conditions; (ii) a large vision-only subset designed to assess robustness under adverse illumination and heterogeneous capture setups; and (iii) a synthetic subset generated to study out-of-distribution generalization in scenarios difficult to obtain in practice. Experiments show that our method achieves a +1.4 pp improvement over the previous state-of-the-art on the PVS benchmark and an +11.6 pp improvement on our multimodal ROAD subset, with consistently higher F1-scores on minority classes. The framework also demonstrates stable performance across challenging visual conditions, including nighttime, heavy rain, and mixed-surface transitions. These findings indicate that combining affordable camera and IMU sensors with multimodal attention mechanisms provides a scalable, robust foundation for road surface understanding, particularly relevant for regions where environmental variability and cost constraints limit the adoption of high-end sensing suites.</div></details>
<details class="detail"><summary>中文标题/摘要</summary>
<div class="mono"><b>标题：</b>基于相机-IMU融合的鲁棒路面分类新数据集与框架</div>
<div class="mono" style="margin-top:8px">路面分类是环境感知预测性维护系统的关键技术，但现有方法因传感模式单一及数据集环境多样性不足，难以在狭窄操作条件外泛化。本研究通过提出一种多模态框架应对这些局限：该框架利用轻量级双向交叉注意力模块融合图像与惯性测量数据，并采用自适应门控层在域偏移下调整模态贡献。针对当前基准数据集（尤其是多样性不足的问题），我们引入了ROAD数据集，包含三个互补子集：（i）使用工业级数据记录器同步采集的真实世界多模态RGB-IMU流数据，涵盖多样光照、天气与路面条件；（ii）用于评估恶劣光照及异构采集设置下鲁棒性的大规模纯视觉子集；（iii）为研究实践中难以获取的分布外泛化场景而生成的合成子集。实验表明，该方法在PVS基准上较先前最优结果提升1.4个百分点，在多模态ROAD子集上提升11.6个百分点，且在少数类别上持续获得更高F1分数。该框架在夜间、暴雨及混合路面过渡等挑战性视觉条件下也表现出稳定性能。这些发现表明，将经济型相机与IMU传感器结合多模态注意力机制，可为路面理解提供可扩展且鲁棒的基础，尤其适用于环境多变且成本受限而难以采用高端传感方案的地区。</div>
</details>
<details class="detail"><summary>Summary / 总结</summary>
<div class="mono">This research addresses the limited generalization of road surface classification (RSC) methods, which stems from narrow operational conditions and a lack of diverse datasets. The proposed method introduces a multimodal framework that fuses camera images and IMU data using a lightweight bidirectional cross-attention module and an adaptive gating layer to dynamically adjust modality contributions under domain shifts. To support robust evaluation, the authors also introduce the ROAD dataset, comprising real-world multimodal recordings, a large vision-only subset, and a synthetic subset. Experimental results show the method achieves a +1.4 percentage point improvement over the state-of-the-art on the PVS benchmark and a +11.6 percentage point improvement on the multimodal ROAD subset, with consistently higher F1-scores for minority classes and stable performance under challenging visual conditions like nighttime and heavy rain.</div>
<div class="mono" style="margin-top:8px">路面分类对于预测性维护至关重要，但由于传感模态有限和数据集缺乏环境多样性，现有方法泛化能力较差。本研究提出一种多模态框架，通过轻量级双向交叉注意力模块和自适应门控层融合相机图像与惯性测量数据，以在域偏移下动态调整模态贡献。针对现有数据集的不足，作者引入了ROAD数据集，包含真实世界的多模态记录、用于恶劣条件的大规模视觉子集以及用于分布外测试的合成子集。实验表明，该方法在PVS基准上将最先进性能提升了1.4个百分点，在多模态ROAD子集上提升了11.6个百分点，在少数类别上获得更高的F1分数，并在夜间、暴雨等挑战性条件下保持稳定性能。</div>
</details>
</div>
<div class="card">
<div class="title">$\mathbb{R}^{2k}$ is Theoretically Large Enough for Embedding-based Top-$k$ Retrieval</div>
<div class="meta-line">Authors: Zihao Wang, Hang Yin, Lihui Liu, Hanghang Tong, Yangqiu Song, Ginny Wong, Simon See</div>
<div class="meta-line">First: 2026-01-28T18:45:43+00:00 · Latest: 2026-01-28T18:45:43+00:00</div>
<div class="links" style="margin-top:8px"><a href="https://arxiv.org/abs/2601.20844v1">Abs</a> · <a href="https://arxiv.org/pdf/2601.20844v1">PDF</a> · <a href="https://huggingface.co/huggingface">Code1</a> · <a href="https://huggingface.co/docs/hub/spaces">Code2</a></div>
<details class="detail"><summary>Abstract</summary>
<div class="mono">This paper studies the minimal dimension required to embed subset memberships ($m$ elements and ${m\choose k}$ subsets of at most $k$ elements) into vector spaces, denoted as Minimal Embeddable Dimension (MED). The tight bounds of MED are derived theoretically and supported empirically for various notions of &quot;distances&quot; or &quot;similarities,&quot; including the $\ell_2$ metric, inner product, and cosine similarity. In addition, we conduct numerical simulation in a more achievable setting, where the ${m\choose k}$ subset embeddings are chosen as the centroid of the embeddings of the contained elements. Our simulation easily realizes a logarithmic dependency between the MED and the number of elements to embed. These findings imply that embedding-based retrieval limitations stem primarily from learnability challenges, not geometric constraints, guiding future algorithm design.</div></details>
<details class="detail"><summary>中文标题/摘要</summary>
<div class="mono"><b>标题：</b>理论上 $\mathbb{R}^{2k}$ 足以实现基于嵌入的 Top-$k$ 检索</div>
<div class="mono" style="margin-top:8px">本文研究了将子集成员关系（$m$ 个元素及其最多包含 $k$ 个元素的 ${m\choose k}$ 个子集）嵌入向量空间所需的最小维度，称为最小可嵌入维度（MED）。研究从理论上推导了 MED 的紧致界，并通过实验验证了其在多种“距离”或“相似度”度量（包括 $\ell_2$ 度量、内积和余弦相似度）下的有效性。此外，我们在一个更易实现的设定下进行了数值模拟，其中 ${m\choose k}$ 个子集的嵌入被选为其包含元素嵌入的质心。模拟结果轻松实现了 MED 与待嵌入元素数量之间的对数依赖关系。这些发现表明，基于嵌入的检索限制主要源于可学习性挑战，而非几何约束，从而为未来算法设计提供了指导。</div>
</details>
<details class="detail"><summary>Summary / 总结</summary>
<div class="mono">This research investigates the minimal dimension needed to embed subset memberships into vector spaces, termed Minimal Embeddable Dimension (MED), to understand geometric constraints in embedding-based top-k retrieval. Theoretically, tight bounds for MED are derived for various distance measures, including ℓ₂ metric, inner product, and cosine similarity, and these are empirically validated. Numerical simulations using centroid-based subset embeddings further demonstrate that MED scales logarithmically with the number of elements, indicating that retrieval limitations arise more from learnability issues than inherent geometric restrictions, thus informing future algorithm development.</div>
<div class="mono" style="margin-top:8px">本文研究了用于嵌入子集成员关系的最小维度，即最小可嵌入维度（MED），以支持基于嵌入的top-k检索。理论上，论文推导了在ℓ₂距离、内积和余弦相似度等多种度量下MED的紧致界，并通过实验验证了这些理论结果。在采用中心化子集嵌入的数值模拟中，MED与元素数量呈对数依赖关系，这表明检索的局限性主要源于可学习性问题，而非几何约束。</div>
</details>
</div>
<div class="card">
<div class="title">Deep Researcher with Sequential Plan Reflection and Candidates Crossover (Deep Researcher Reflect Evolve)</div>
<div class="meta-line">Authors: Saurav Prateek</div>
<div class="meta-line">First: 2026-01-28T18:45:39+00:00 · Latest: 2026-01-28T18:45:39+00:00</div>
<div class="meta-line">Comments: 11 pages, 6 figures, 2 tables, source code: https://github.com/SauravP97/deep-researcher-reflect-evolve/</div>
<div class="links" style="margin-top:8px"><a href="https://arxiv.org/abs/2601.20843v1">Abs</a> · <a href="https://arxiv.org/pdf/2601.20843v1">PDF</a> · <a href="https://github.com/SauravP97/deep-researcher-reflect-evolve/">Code1</a> · <a href="https://huggingface.co/huggingface">Code2</a> · <a href="https://huggingface.co/docs/hub/spaces">Code3</a></div>
<details class="detail"><summary>Abstract</summary>
<div class="mono">This paper introduces a novel Deep Researcher architecture designed to generate detailed research reports on complex PhD level topics by addressing the inherent limitations of the Parallel Scaling paradigm. Our system utilizes two key innovations: Sequential Research Plan Refinement via Reflection and a Candidates Crossover algorithm. The sequential refinement process is demonstrated as an efficient method that allows the agent to maintain a centralized Global Research Context, enabling it to look back at current progress, reason about the research plan, and intelligently make changes at runtime. This dynamic adaptation contrasts with parallel approaches, which often suffer from siloed knowledge. The Candidates Crossover algorithm further enhances search efficiency by deploying multiple LLM candidates with varied parameters to explore a larger search space, with their findings synthesized to curate a comprehensive final research response. The process concludes with One Shot Report Generation, ensuring the final document is informed by a unified narrative and high fact density. Powered by the Gemini 2.5 Pro model, our Deep Researcher was evaluated on the DeepResearch Bench, a globally recognized benchmark of 100 doctoral level research tasks. Our architecture achieved an overall score of 46.21, demonstrating superior performance by surpassing leading deep research agents such as Claude Researcher, Nvidia AIQ Research Assistant, Perplexity Research, Kimi Researcher and Grok Deeper Search present on the DeepResearch Bench actively running leaderboard. This performance marginally exceeds our previous work, Static DRA, and reinforces the finding that sequential scaling consistently outperforms the parallel self consistency paradigm.</div></details>
<details class="detail"><summary>中文标题/摘要</summary>
<div class="mono"><b>标题：</b>具备序列化计划反思与候选方案交叉的深度研究架构（Deep Researcher Reflect Evolve）</div>
<div class="mono" style="margin-top:8px">本文提出一种新型深度研究架构，旨在通过解决并行扩展范式的固有局限，生成复杂博士级课题的详细研究报告。该系统采用两项核心创新：基于反思的序列化研究计划优化算法与候选方案交叉算法。序列化优化过程被证明是一种高效方法，使智能体能维持集中化的全局研究上下文，回溯当前进展、推演研究计划，并在运行时智能调整策略。这种动态适应机制与常受知识孤岛制约的并行方法形成鲜明对比。候选方案交叉算法通过部署多组参数各异的LLM候选模型探索更广阔的搜索空间，并综合其发现以构建全面的最终研究响应，从而进一步提升搜索效率。流程以单次报告生成环节收尾，确保最终文档具有连贯的叙事逻辑与高事实密度。基于Gemini 2.5 Pro模型驱动的深度研究系统在DeepResearch Bench（全球公认的100项博士级研究任务基准）上接受评估。该架构以46.21的综合得分，超越了DeepResearch Bench实时排行榜中的Claude Researcher、英伟达AIQ研究助手、Perplexity Research、Kimi Researcher及Grok Deeper Search等领先深度研究智能体，展现出卓越性能。该表现较我们前期工作Static DRA略有提升，并再次验证了序列化扩展范式持续优于并行自洽范式的结论。</div>
</details>
<details class="detail"><summary>Summary / 总结</summary>
<div class="mono">This research addresses the limitations of parallel scaling paradigms in generating detailed PhD-level research reports by introducing a novel Deep Researcher architecture. The method employs two key innovations: Sequential Research Plan Refinement via Reflection, which maintains a Global Research Context for dynamic runtime adaptation, and a Candidates Crossover algorithm that deploys multiple LLM candidates with varied parameters to explore a larger search space before synthesizing findings. Evaluated on the DeepResearch Bench of 100 doctoral-level tasks using the Gemini 2.5 Pro model, the system achieved an overall score of 46.21, surpassing leading deep research agents including Claude Researcher and Nvidia AIQ Research Assistant, and demonstrating that sequential scaling consistently outperforms parallel self-consistency paradigms.</div>
<div class="mono" style="margin-top:8px">本研究旨在克服并行扩展范式在生成博士级别详细研究报告时的固有局限，如知识碎片化。提出的深度研究者架构采用两种核心方法：通过维护全局研究上下文进行动态调整的顺序研究计划细化流程，以及利用多个不同参数的LLM候选者探索更广搜索空间后再综合发现的候选者交叉算法。该系统基于Gemini 2.5 Pro模型，在包含100个博士级任务的DeepResearch Bench上进行评估，取得了46.21的总分，性能超过了Claude Researcher、Nvidia AIQ研究助手等领先研究智能体，验证了顺序扩展优于并行自洽范式。</div>
</details>
</div>
<div class="card">
<div class="title">Reward Models Inherit Value Biases from Pretraining</div>
<div class="meta-line">Authors: Brian Christian, Jessica A. F. Thompson, Elle Michelle Yang, Vincent Adam, Hannah Rose Kirk, Christopher Summerfield, Tsvetomira Dumbalska</div>
<div class="meta-line">First: 2026-01-28T18:40:29+00:00 · Latest: 2026-01-28T18:40:29+00:00</div>
<div class="links" style="margin-top:8px"><a href="https://arxiv.org/abs/2601.20838v1">Abs</a> · <a href="https://arxiv.org/pdf/2601.20838v1">PDF</a> · <a href="https://huggingface.co/huggingface">Code1</a> · <a href="https://huggingface.co/docs/hub/spaces">Code2</a></div>
<details class="detail"><summary>Abstract</summary>
<div class="mono">Reward models (RMs) are central to aligning large language models (LLMs) with human values but have received less attention than pre-trained and post-trained LLMs themselves. Because RMs are initialized from LLMs, they inherit representations that shape their behavior, but the nature and extent of this influence remain understudied. In a comprehensive study of 10 leading open-weight RMs using validated psycholinguistic corpora, we show that RMs exhibit significant differences along multiple dimensions of human value as a function of their base model. Using the &quot;Big Two&quot; psychological axes, we show a robust preference of Llama RMs for &quot;agency&quot; and a corresponding robust preference of Gemma RMs for &quot;communion.&quot; This phenomenon holds even when the preference data and finetuning process are identical, and we trace it back to the logits of the respective instruction-tuned and pre-trained models. These log-probability differences themselves can be formulated as an implicit RM; we derive usable implicit reward scores and show that they exhibit the very same agency/communion difference. We run experiments training RMs with ablations for preference data source and quantity, which demonstrate that this effect is not only repeatable but surprisingly durable. Despite RMs being designed to represent human preferences, our evidence shows that their outputs are influenced by the pretrained LLMs on which they are based. This work underscores the importance of safety and alignment efforts at the pretraining stage, and makes clear that open-source developers&#x27; choice of base model is as much a consideration of values as of performance.</div></details>
<details class="detail"><summary>中文标题/摘要</summary>
<div class="mono"><b>标题：</b>奖励模型从预训练中继承价值偏见</div>
<div class="mono" style="margin-top:8px">奖励模型（RMs）对于将大语言模型（LLMs）与人类价值观对齐至关重要，但其受关注程度低于预训练及后训练的LLMs本身。由于RMs基于LLMs初始化，它们继承了塑造其行为的表征，但这种影响的性质和程度尚未得到充分研究。通过对10个主流开源权重RMs使用经过验证的心理语言学语料库进行综合研究，我们发现RMs在人类价值的多个维度上表现出显著差异，且差异与其基础模型相关。利用“大二”心理轴理论，我们证明Llama系RMs对“能动性”存在稳定偏好，而Gemma系RMs则对“共融性”表现出相应偏好。即使在使用相同偏好数据和微调流程的情况下，该现象依然存在，我们将其溯源至各自指令微调模型和预训练模型的logits输出。这些对数概率差异本身可被构建为隐式RM；我们推导出可用的隐式奖励分数，并证明其表现出完全相同的能动性/共融性差异。通过设计消融实验控制偏好数据来源和数量训练RMs，我们证实该效应不仅可复现且具有惊人的持久性。尽管RMs旨在表征人类偏好，但证据表明其输出仍受所基于的预训练LLMs影响。本研究强调了预训练阶段安全与对齐工作的重要性，并明确指出开源开发者选择基础模型时，价值观考量与性能考量同等重要。</div>
</details>
<details class="detail"><summary>Summary / 总结</summary>
<div class="mono">This study investigates how reward models (RMs), which are crucial for aligning large language models with human preferences, inherit value biases from their underlying pre-trained language models. The researchers conducted a comprehensive analysis of 10 open-weight RMs using psycholinguistic corpora, finding that the choice of base model (e.g., Llama vs. Gemma) leads to systematic and significant differences in value judgments, specifically a robust preference for &quot;agency&quot; in Llama-based RMs and for &quot;communion&quot; in Gemma-based RMs, even when trained on identical preference data. Experimental results, including ablations on data source and quantity, demonstrate that this bias is repeatable, durable, and traceable to the log-probability outputs of the foundational models, highlighting that pretraining choices inherently shape RM values and emphasizing the need for safety considerations at the pretraining stage.</div>
<div class="mono" style="margin-top:8px">奖励模型对于将大语言模型与人类价值观对齐至关重要，但其对底层预训练模型的依赖性尚未得到充分研究。本研究使用心理语言学语料库系统分析了10个开源权重奖励模型，发现奖励模型继承并显著表现出其基础模型的价值偏见，具体表现为基于Llama的奖励模型强烈偏好“能动性”，而基于Gemma的模型则偏好“共生性”，即使在训练数据完全相同的情况下也是如此。研究人员将此效应追溯到指令微调和预训练模型的逻辑值，将这些对数概率差异表述为一种隐式奖励模型，并通过消融实验证实该偏见具有可重复性和持久性。这些发现表明预训练阶段塑造了奖励模型的输出，强调了在预训练阶段考虑安全性的必要性，并且基础模型的选择涉及超越性能的价值判断。</div>
</details>
</div>
<div class="card">
<div class="title">Open-Vocabulary Functional 3D Human-Scene Interaction Generation</div>
<div class="meta-line">Authors: Jie Liu, Yu Sun, Alpar Cseke, Yao Feng, Nicolas Heron, Michael J. Black, Yan Zhang</div>
<div class="meta-line">First: 2026-01-28T18:34:25+00:00 · Latest: 2026-01-28T18:34:25+00:00</div>
<div class="meta-line">Comments: 18 pages</div>
<div class="links" style="margin-top:8px"><a href="https://arxiv.org/abs/2601.20835v1">Abs</a> · <a href="https://arxiv.org/pdf/2601.20835v1">PDF</a> · <a href="https://huggingface.co/huggingface">Code1</a> · <a href="https://huggingface.co/docs/hub/spaces">Code2</a></div>
<details class="detail"><summary>Abstract</summary>
<div class="mono">Generating 3D humans that functionally interact with 3D scenes remains an open problem with applications in embodied AI, robotics, and interactive content creation. The key challenge involves reasoning about both the semantics of functional elements in 3D scenes and the 3D human poses required to achieve functionality-aware interaction. Unfortunately, existing methods typically lack explicit reasoning over object functionality and the corresponding human-scene contact, resulting in implausible or functionally incorrect interactions. In this work, we propose FunHSI, a training-free, functionality-driven framework that enables functionally correct human-scene interactions from open-vocabulary task prompts. Given a task prompt, FunHSI performs functionality-aware contact reasoning to identify functional scene elements, reconstruct their 3D geometry, and model high-level interactions via a contact graph. We then leverage vision-language models to synthesize a human performing the task in the image and estimate proposed 3D body and hand poses. Finally, the proposed 3D body configuration is refined via stage-wise optimization to ensure physical plausibility and functional correctness. In contrast to existing methods, FunHSI not only synthesizes more plausible general 3D interactions, such as &quot;sitting on a sofa&#x27;&#x27;, while supporting fine-grained functional human-scene interactions, e.g., &quot;increasing the room temperature&#x27;&#x27;. Extensive experiments demonstrate that FunHSI consistently generates functionally correct and physically plausible human-scene interactions across diverse indoor and outdoor scenes.</div></details>
<details class="detail"><summary>中文标题/摘要</summary>
<div class="mono"><b>标题：</b>开放词汇功能性三维人-场景交互生成</div>
<div class="mono" style="margin-top:8px">生成与三维场景进行功能性交互的三维人体，在具身人工智能、机器人学和交互式内容创作中具有应用价值，但仍是一个开放性问题。核心挑战在于同时理解三维场景中功能元素的语义，以及实现功能感知交互所需的三维人体姿态。现有方法通常缺乏对物体功能性和相应人-场景接触的显式推理，导致交互不自然或功能错误。本研究提出FunHSI——一个无需训练、功能驱动的框架，能够根据开放词汇任务提示生成功能正确的人-场景交互。给定任务提示后，FunHSI通过功能感知接触推理识别场景功能元素，重建其三维几何结构，并通过接触图建模高层级交互。随后利用视觉-语言模型合成执行任务的图像化人体，并估计提议的三维身体与手部姿态。最后通过分阶段优化细化提议的三维身体构型，确保物理合理性与功能正确性。与现有方法相比，FunHSI不仅能合成更合理的通用三维交互（如“坐在沙发上”），还支持细粒度功能性人-场景交互（如“调高室温”）。大量实验表明，FunHSI能在多样室内外场景中持续生成功能正确且物理合理的人-场景交互。</div>
</details>
<details class="detail"><summary>Summary / 总结</summary>
<div class="mono">The research aims to generate 3D humans that functionally interact with 3D scenes, addressing the limitations of existing methods which often produce implausible interactions due to a lack of explicit reasoning about object functionality and human-scene contact. The proposed method, FunHSI, is a training-free framework that, given an open-vocabulary task prompt, performs functionality-aware contact reasoning to identify functional scene elements, reconstructs their 3D geometry, models interactions via a contact graph, leverages vision-language models to synthesize an image of the human performing the task and estimate 3D poses, and refines the body configuration through stage-wise optimization for physical plausibility. Experimental results show that FunHSI consistently generates functionally correct and physically plausible human-scene interactions across diverse scenes, outperforming existing methods in both general interactions like &quot;sitting on a sofa&quot; and fine-grained tasks like &quot;increasing the room temperature&quot;.</div>
<div class="mono" style="margin-top:8px">该研究旨在生成与3D场景进行功能交互的3D人体，以解决现有方法因缺乏对物体功能和人与场景接触的显式推理而常产生不合理交互的问题。提出的FunHSI框架是无训练且功能驱动的；它通过处理开放词汇任务提示，首先执行功能感知的接触推理以识别场景功能元素并通过接触图建模交互，然后利用视觉语言模型合成执行任务的人体图像并估计3D姿态，接着通过分阶段优化细化3D身体配置以确保物理合理性。实验结果表明，FunHSI在不同室内外场景中能一致地生成功能正确且物理合理的人与场景交互，在如“坐在沙发上”的一般交互和如“调高室温”的细粒度任务上均优于现有方法。</div>
</details>
</div>
<div class="card">
<div class="title">Discrete Variational Autoencoding via Policy Search</div>
<div class="meta-line">Authors: Michael Drolet, Firas Al-Hafez, Aditya Bhatt, Jan Peters, Oleg Arenz</div>
<div class="meta-line">First: 2025-09-29T12:44:05+00:00 · Latest: 2026-01-28T18:33:31+00:00</div>
<div class="links" style="margin-top:8px"><a href="https://arxiv.org/abs/2509.24716v2">Abs</a> · <a href="https://arxiv.org/pdf/2509.24716v2">PDF</a> · <a href="https://huggingface.co/huggingface">Code1</a> · <a href="https://huggingface.co/docs/hub/spaces">Code2</a></div>
<details class="detail"><summary>Abstract</summary>
<div class="mono">Discrete latent bottlenecks in variational autoencoders (VAEs) offer high bit efficiency and can be modeled with autoregressive discrete distributions, enabling parameter-efficient multimodal search with transformers. However, discrete random variables do not allow for exact differentiable parameterization; therefore, discrete VAEs typically rely on approximations, such as Gumbel-Softmax reparameterization or straight-through gradient estimates, or employ high-variance gradient-free methods such as REINFORCE that have had limited success on high-dimensional tasks such as image reconstruction. Inspired by popular techniques in policy search, we propose a training framework for discrete VAEs that leverages the natural gradient of a non-parametric encoder to update the parametric encoder without requiring reparameterization. Our method, combined with automatic step size adaptation and a transformer-based encoder, scales to challenging datasets such as ImageNet and outperforms both approximate reparameterization methods and quantization-based discrete autoencoders in reconstructing high-dimensional data from compact latent spaces.</div></details>
<details class="detail"><summary>中文标题/摘要</summary>
<div class="mono"><b>标题：</b>基于策略搜索的离散变分自编码方法</div>
<div class="mono" style="margin-top:8px">变分自编码器（VAE）中的离散潜在瓶颈具有高比特效率，可通过自回归离散分布建模，实现基于Transformer的参数高效多模态搜索。然而，离散随机变量无法进行精确可微参数化；因此，离散VAE通常依赖近似方法，如Gumbel-Softmax重参数化或直通梯度估计，或采用高方差的无梯度方法（如REINFORCE），这些方法在图像重建等高维任务中成效有限。受策略搜索常用技术启发，我们提出一种离散VAE训练框架，利用非参数编码器的自然梯度更新参数编码器，无需重参数化。该方法结合自动步长调整和基于Transformer的编码器，可扩展至ImageNet等挑战性数据集，在从紧凑潜在空间重建高维数据方面，性能优于近似重参数化方法和基于量化的离散自编码器。</div>
</details>
<details class="detail"><summary>Summary / 总结</summary>
<div class="mono">Discrete latent bottlenecks in variational autoencoders offer bit efficiency and enable multimodal search, but training them is challenging due to the non-differentiability of discrete variables, which often forces reliance on approximate reparameterization or high-variance gradient methods. To address this, the authors propose a training framework inspired by policy search that uses the natural gradient of a non-parametric encoder to update a parametric encoder, eliminating the need for reparameterization; this method incorporates automatic step size adaptation and a transformer-based encoder. Experimental results show that the approach scales effectively to complex datasets like ImageNet and outperforms both approximate reparameterization techniques and quantization-based discrete autoencoders in reconstructing high-dimensional data from compact latent representations.</div>
<div class="mono" style="margin-top:8px">本研究针对高维数据重建中离散变分自编码器（VAE）的训练难题，即离散潜变量阻碍精确的梯度优化。所提出的方法受策略搜索启发，利用非参数编码器的自然梯度来更新基于Transformer的参数编码器，避免了Gumbel-Softmax近似或高方差的REINFORCE梯度估计。实验结果表明，该方法能有效扩展到ImageNet等复杂数据集，在紧凑潜空间的数据重建质量上优于近似重参数化技术和基于量化的离散自编码器。</div>
</details>
</div>
<div class="card">
<div class="title">MemCtrl: Using MLLMs as Active Memory Controllers on Embodied Agents</div>
<div class="meta-line">Authors: Vishnu Sashank Dorbala, Dinesh Manocha</div>
<div class="meta-line">First: 2026-01-28T18:31:17+00:00 · Latest: 2026-01-28T18:31:17+00:00</div>
<div class="links" style="margin-top:8px"><a href="https://arxiv.org/abs/2601.20831v1">Abs</a> · <a href="https://arxiv.org/pdf/2601.20831v1">PDF</a> · <a href="https://huggingface.co/huggingface">Code1</a> · <a href="https://huggingface.co/docs/hub/spaces">Code2</a></div>
<details class="detail"><summary>Abstract</summary>
<div class="mono">Foundation models rely on in-context learning for personalized decision making. The limited size of this context window necessitates memory compression and retrieval systems like RAG. These systems however often treat memory as large offline storage spaces, which is unfavorable for embodied agents that are expected to operate under strict memory and compute constraints, online. In this work, we propose MemCtrl, a novel framework that uses Multimodal Large Language Models (MLLMs) for pruning memory online. MemCtrl augments MLLMs with a trainable memory head μthat acts as a gate to determine which observations or reflections to retain, update, or discard during exploration. We evaluate with training two types of μ, 1) via an offline expert, and 2) via online RL, and observe significant improvement in overall embodied task completion ability on μ-augmented MLLMs. In particular, on augmenting two low performing MLLMs with MemCtrl on multiple subsets of the EmbodiedBench benchmark, we observe that μ-augmented MLLMs show an improvement of around 16% on average, with over 20% on specific instruction subsets. Finally, we present a qualitative analysis on the memory fragments collected by μ, noting the superior performance of μaugmented MLLMs on long and complex instruction types.</div></details>
<details class="detail"><summary>中文标题/摘要</summary>
<div class="mono"><b>标题：</b>MemCtrl：将多模态大语言模型用作具身智能体的主动记忆控制器</div>
<div class="mono" style="margin-top:8px">基础模型依赖上下文学习进行个性化决策，但其有限的上下文窗口需要记忆压缩与检索系统（如RAG）。然而这类系统常将记忆视为大型离线存储空间，不利于需在严格内存与计算约束下在线运行的具身智能体。本研究提出MemCtrl——一种利用多模态大语言模型在线修剪记忆的新框架。MemCtrl通过可训练的记忆头μ增强MLLMs，该记忆头作为门控机制，在探索过程中决定保留、更新或丢弃哪些观测与反思。我们通过两种μ训练方式进行评估：1）通过离线专家训练，2）通过在线强化学习训练，发现μ增强的MLLMs在整体具身任务完成能力上均有显著提升。特别是在EmbodiedBench基准的多个子集上，对两个低性能MLLMs应用MemCtrl后，μ增强的MLLMs平均提升约16%，在特定指令子集上提升超20%。最后，我们对μ收集的记忆片段进行定性分析，发现μ增强的MLLMs在长而复杂的指令类型上表现尤为优异。</div>
</details>
<details class="detail"><summary>Summary / 总结</summary>
<div class="mono">To address the challenge of enabling embodied agents to operate under strict memory and computational constraints online, this work introduces MemCtrl, a framework that uses Multimodal Large Language Models (MLLMs) as active controllers for online memory pruning. The method augments an MLLM with a trainable memory head (μ) that acts as a gate to dynamically decide which observations or reflections to retain, update, or discard during exploration; this head is trained either via an offline expert or through online reinforcement learning. Experimental evaluation on the EmbodiedBench benchmark shows that augmenting two low-performing MLLMs with MemCtrl leads to an average improvement of around 16% in task completion, with gains exceeding 20% on specific instruction subsets, and qualitative analysis indicates superior handling of long and complex instructions.</div>
<div class="mono" style="margin-top:8px">该研究旨在解决具身智能体在严格内存和计算约束下进行个性化决策的挑战，传统检索增强生成（RAG）系统将内存视为大型离线存储，不利于在线操作。提出的方法MemCtrl引入了一个新颖框架，使用多模态大语言模型（MLLMs）作为主动内存控制器，并通过一个可训练的内存头μ来动态修剪内存，在探索过程中决定保留、更新或丢弃哪些观察或反思。在EmbodiedBench基准测试上的实验结果表明，μ增强的MLLMs在任务完成能力上平均提升了约16%，在特定指令子集上超过20%，定性分析显示其在长而复杂的指令类型上表现更优。</div>
</details>
</div>
<div class="card">
<div class="title">Training Reasoning Models on Saturated Problems via Failure-Prefix Conditioning</div>
<div class="meta-line">Authors: Minwu Kim, Safal Shrestha, Keith Ross</div>
<div class="meta-line">First: 2026-01-28T18:29:21+00:00 · Latest: 2026-01-28T18:29:21+00:00</div>
<div class="meta-line">Comments: 16 pages</div>
<div class="links" style="margin-top:8px"><a href="https://arxiv.org/abs/2601.20829v1">Abs</a> · <a href="https://arxiv.org/pdf/2601.20829v1">PDF</a> · <a href="https://huggingface.co/huggingface">Code1</a> · <a href="https://huggingface.co/docs/hub/spaces">Code2</a></div>
<details class="detail"><summary>Abstract</summary>
<div class="mono">Reinforcement Learning with Verifiable Rewards (RLVR) has substantially improved the reasoning abilities of large language models (LLMs), yet training often stalls as problems become saturated. We identify the core challenge as the poor accessibility of informative failures: learning signals exist but are rarely encountered during standard rollouts. To address this, we propose failure-prefix conditioning, a simple and effective method for learning from saturated problems. Rather than starting from the original question, our approach reallocates exploration by conditioning training on prefixes derived from rare incorrect reasoning trajectories, thereby exposing the model to failure-prone states. We observe that failure-prefix conditioning yields performance gains matching those of training on medium-difficulty problems, while preserving token efficiency. Furthermore, we analyze the model&#x27;s robustness, finding that our method reduces performance degradation under misleading failure prefixes, albeit with a mild trade-off in adherence to correct early reasoning. Finally, we demonstrate that an iterative approach, which refreshes failure prefixes during training, unlocks additional gains after performance plateaus. Overall, our results suggest that failure-prefix conditioning offers an effective pathway to extend RLVR training on saturated problems.</div></details>
<details class="detail"><summary>中文标题/摘要</summary>
<div class="mono"><b>标题：</b>基于失败前缀条件化的饱和问题推理模型训练</div>
<div class="mono" style="margin-top:8px">可验证奖励强化学习（RLVR）显著提升了大型语言模型（LLM）的推理能力，但随着问题趋于饱和，训练常陷入停滞。我们发现核心挑战在于信息性失败的可及性差：学习信号存在，但在标准推演中极少出现。为此，我们提出失败前缀条件化——一种从饱和问题中学习的简洁高效方法。该方法不再从原始问题出发，而是通过将训练条件化于罕见错误推理轨迹衍生的前缀，重新分配探索空间，使模型暴露于易失败状态。实验表明，失败前缀条件化带来的性能提升与中等难度问题训练相当，同时保持标记效率。进一步分析模型鲁棒性发现，该方法能降低误导性失败前缀下的性能衰减，尽管对早期正确推理的遵循度略有折衷。最后，我们证明在训练中迭代更新失败前缀的策略，能在性能平台期后实现额外增益。总体而言，本研究结果表明失败前缀条件化为RLVR在饱和问题上的持续训练提供了有效路径。</div>
</details>
<details class="detail"><summary>Summary / 总结</summary>
<div class="mono">Reinforcement Learning with Verifiable Rewards (RLVR) improves LLM reasoning but struggles when problems become saturated, as informative failure signals are rarely encountered. The proposed method, failure-prefix conditioning, addresses this by reallocating exploration: instead of starting from the original question, training is conditioned on prefixes derived from rare incorrect reasoning trajectories, exposing the model to failure-prone states. Experiments show this method yields performance gains comparable to training on medium-difficulty problems while maintaining token efficiency, reduces performance degradation under misleading prefixes, and an iterative approach that refreshes failure prefixes unlocks further gains after plateaus.</div>
<div class="mono" style="margin-top:8px">基于可验证奖励的强化学习（RLVR）能提升大语言模型的推理能力，但在问题趋于饱和时训练常陷入停滞，因为标准训练过程中难以遇到具有学习价值的失败信号。为解决该问题，本文提出失败前缀条件化方法，通过将训练过程条件化于从罕见错误推理轨迹中提取的前缀，使模型暴露于易失败状态。实验结果表明，该方法在保持标记效率的同时，取得了与在中等难度问题上训练相当的性能提升；它增强了模型鲁棒性，减少了在误导性前缀下的性能下降；并且通过迭代更新失败前缀，能在性能平台期后实现进一步增益。</div>
</details>
</div>
<div class="card">
<div class="title">Neural Theorem Proving for Verification Conditions: A Real-World Benchmark</div>
<div class="meta-line">Authors: Qiyuan Xu, Xiaokun Luan, Renxi Wang, Joshua Ong Jun Leang, Peixin Wang, Haonan Li, Wenda Li, Conrad Watt</div>
<div class="meta-line">Venue: ICLR</div>
<div class="meta-line">First: 2026-01-26T20:37:11+00:00 · Latest: 2026-01-28T18:25:21+00:00</div>
<div class="meta-line">Comments: Accepted in ICLR&#x27;26</div>
<div class="links" style="margin-top:8px"><a href="https://arxiv.org/abs/2601.18944v2">Abs</a> · <a href="https://arxiv.org/pdf/2601.18944v2">PDF</a> · <a href="https://huggingface.co/huggingface">Code1</a> · <a href="https://huggingface.co/docs/hub/spaces">Code2</a></div>
<details class="detail"><summary>Abstract</summary>
<div class="mono">Theorem proving is fundamental to program verification, where the automated proof of Verification Conditions (VCs) remains a primary bottleneck. Real-world program verification frequently encounters hard VCs that existing Automated Theorem Provers (ATPs) cannot prove, leading to a critical need for extensive manual proofs that burden practical application. While Neural Theorem Proving (NTP) has achieved significant success in mathematical competitions, demonstrating the potential of machine learning approaches to formal reasoning, its application to program verification--particularly VC proving--remains largely unexplored. Despite existing work on annotation synthesis and verification-related theorem proving, no benchmark has specifically targeted this fundamental bottleneck: automated VC proving. This work introduces Neural Theorem Proving for Verification Conditions (NTP4VC), presenting the first real-world multi-language benchmark for this task. From real-world projects such as Linux and Contiki-OS kernel, our benchmark leverages industrial pipelines (Why3 and Frama-C) to generate semantically equivalent test cases across formal languages of Isabelle, Lean, and Rocq. We evaluate large language models (LLMs), both general-purpose and those fine-tuned for theorem proving, on NTP4VC. Results indicate that although LLMs show promise in VC proving, significant challenges remain for program verification, highlighting a large gap and opportunity for future research.</div></details>
<details class="detail"><summary>中文标题/摘要</summary>
<div class="mono"><b>标题：</b>验证条件的神经定理证明：一个现实世界基准</div>
<div class="mono" style="margin-top:8px">定理证明是程序验证的基础，其中验证条件（VCs）的自动证明仍是主要瓶颈。现实世界的程序验证常遇到现有自动定理证明器（ATPs）无法证明的困难VCs，导致亟需大量人工证明，给实际应用带来负担。虽然神经定理证明（NTP）在数学竞赛中取得显著成功，展示了机器学习方法在形式推理中的潜力，但其在程序验证（特别是VC证明）中的应用仍基本未被探索。尽管现有研究涉及标注合成和验证相关定理证明，但尚未有基准专门针对这一根本瓶颈：自动VC证明。本文提出验证条件的神经定理证明（NTP4VC），首次为此任务构建了现实世界的多语言基准。基于Linux和Contiki-OS内核等现实项目，该基准利用工业级工具链（Why3和Frama-C）生成Isabelle、Lean和Rocq等形式语言中语义等效的测试用例。我们在NTP4VC上评估了通用大语言模型（LLMs）及针对定理证明微调的LLMs。结果表明，尽管LLMs在VC证明中展现出潜力，但程序验证仍面临重大挑战，凸显了未来研究的巨大差距与机遇。</div>
</details>
<details class="detail"><summary>Summary / 总结</summary>
<div class="mono">The research addresses the bottleneck in program verification where automated theorem provers often fail to prove hard Verification Conditions (VCs), necessitating labor-intensive manual proofs. The authors introduce NTP4VC, the first real-world multi-language benchmark for neural theorem proving on VCs, constructed from industrial projects like Linux and Contiki-OS kernels using Why3 and Frama-C pipelines to generate semantically equivalent test cases across Isabelle, Lean, and Rocq formal languages. Experimental evaluation of both general-purpose and theorem-proving fine-tuned large language models demonstrates that while LLMs show initial promise in VC proving, substantial performance gaps remain, revealing significant challenges and research opportunities for applying neural methods to practical program verification.</div>
<div class="mono" style="margin-top:8px">该研究的动机在于程序验证中存在瓶颈，即自动定理证明器常常无法证明困难的验证条件，导致需要大量手动证明。方法上，研究提出了首个面向验证条件的真实世界多语言基准NTP4VC，该基准利用工业级工具链从Linux和Contiki-OS等项目中生成在Isabelle、Lean和Rocq中语义等价的测试用例。主要实验结果表明，尽管包括针对定理证明微调的大语言模型在该基准上显示出一定潜力，但其性能仍存在显著差距，凸显了将神经方法应用于实际程序验证所面临的重大挑战与研究机遇。</div>
</details>
</div>
<div class="card">
<div class="title">AI Annotation Orchestration: Evaluating LLM verifiers to Improve the Quality of LLM Annotations in Learning Analytics</div>
<div class="meta-line">Authors: Bakhtawar Ahtisham, Kirk Vanacore, Jinsook Lee, Zhuqian Zhou, Doug Pietrzak, Rene F. Kizilcec</div>
<div class="meta-line">First: 2025-11-12T22:35:36+00:00 · Latest: 2026-01-28T18:09:36+00:00</div>
<div class="links" style="margin-top:8px"><a href="https://arxiv.org/abs/2511.09785v2">Abs</a> · <a href="https://arxiv.org/pdf/2511.09785v2">PDF</a> · <a href="https://huggingface.co/huggingface">Code1</a> · <a href="https://huggingface.co/docs/hub/spaces">Code2</a></div>
<details class="detail"><summary>Abstract</summary>
<div class="mono">Large Language Models (LLMs) are increasingly used to annotate learning interactions, yet concerns about reliability limit their utility. We test whether verification-oriented orchestration-prompting models to check their own labels (self-verification) or audit one another (cross-verification)-improves qualitative coding of tutoring discourse. Using transcripts from 30 one-to-one math sessions, we compare three production LLMs (GPT, Claude, Gemini) under three conditions: unverified annotation, self-verification, and cross-verification across all orchestration configurations. Outputs are benchmarked against a blinded, disagreement-focused human adjudication using Cohen&#x27;s kappa. Overall, orchestration yields a 58 percent improvement in kappa. Self-verification nearly doubles agreement relative to unverified baselines, with the largest gains for challenging tutor moves. Cross-verification achieves a 37 percent improvement on average, with pair- and construct-dependent effects: some verifier-annotator pairs exceed self-verification, while others reduce alignment, reflecting differences in verifier strictness. We contribute: (1) a flexible orchestration framework instantiating control, self-, and cross-verification; (2) an empirical comparison across frontier LLMs on authentic tutoring data with blinded human &quot;gold&quot; labels; and (3) a concise notation, verifier(annotator) (e.g., Gemini(GPT) or Claude(Claude)), to standardize reporting and make directional effects explicit for replication. Results position verification as a principled design lever for reliable, scalable LLM-assisted annotation in Learning Analytics.</div></details>
<details class="detail"><summary>中文标题/摘要</summary>
<div class="mono"><b>标题：</b>AI标注编排：评估LLM验证器以提升学习分析中LLM标注质量</div>
<div class="mono" style="margin-top:8px">大语言模型（LLMs）日益广泛用于学习交互标注，但其可靠性问题限制了实际应用。本研究通过验证导向的编排策略——让模型自查标注（自我验证）或相互审核（交叉验证）——检验其能否提升辅导话语的质性编码质量。基于30场一对一数学辅导转录文本，我们在三种编排配置下比较了三种主流LLM（GPT、Claude、Gemini）：无验证标注、自我验证及全编排配置的交叉验证。输出结果采用科恩卡帕系数，以盲审、聚焦分歧的人工裁定为基准。总体而言，编排策略使卡帕系数提升58%。自我验证较无验证基线将一致性提升近一倍，在复杂辅导行为上增益最大。交叉验证平均提升37%，其效果呈现配对与结构依赖性：部分验证器-标注器组合优于自我验证，另一些则降低一致性，反映了验证器严格度的差异。本研究贡献在于：（1）提出融合控制、自我与交叉验证的灵活编排框架；（2）基于真实辅导数据与盲审人工“金标准”，对前沿LLM进行实证比较；（3）建立简明标注体系verifier(annotator)（如Gemini(GPT)或Claude(Claude)），以标准化报告并明确方向性效应。研究结果确立了验证机制作为学习分析中实现可靠、可扩展LLM辅助标注的原则性设计杠杆。</div>
</details>
<details class="detail"><summary>Summary / 总结</summary>
<div class="mono">The research addresses reliability concerns in using Large Language Models (LLMs) for annotating learning interactions, which limits their utility in Learning Analytics. The method tests a verification-oriented orchestration framework where models either check their own labels (self-verification) or audit one another&#x27;s labels (cross-verification) to improve the qualitative coding of tutoring discourse. Experimental results on transcripts from 30 math tutoring sessions, comparing three LLMs (GPT, Claude, Gemini), show that orchestration yields an overall 58% improvement in agreement (Cohen&#x27;s kappa) with blinded human adjudication; self-verification nearly doubles agreement relative to unverified baselines, with the largest gains for challenging tutor moves, while cross-verification achieves a 37% average improvement, though its effectiveness varies by specific model pairs and coding constructs.</div>
<div class="mono" style="margin-top:8px">针对使用大语言模型标注学习互动时存在的可靠性问题，本研究探讨了基于验证的编排策略是否能提升辅导话语定性编码的质量。研究方法包括在30段一对一数学辅导对话转录文本上，测试三种主流大语言模型在三种条件下的表现：无验证标注、自我验证（模型检查自身标签）和交叉验证（模型相互审核标签），所有输出均以盲审人工裁决为基准，使用科恩卡帕系数进行评估。主要实验结果表明，编排策略整体使卡帕系数提升了58%，其中自我验证相较于无验证基线几乎将一致性提高了一倍，尤其在困难辅导行为上效果显著；交叉验证平均提升了37%，但其效果因模型配对和标注结构而异，反映了验证器严格度的差异。</div>
</details>
</div>
<div class="card">
<div class="title">ProToken: Token-Level Attribution for Federated Large Language Models</div>
<div class="meta-line">Authors: Waris Gill, Ahmad Humayun, Ali Anwar, Muhammad Ali Gulzar</div>
<div class="meta-line">First: 2026-01-27T14:53:12+00:00 · Latest: 2026-01-28T18:05:55+00:00</div>
<div class="links" style="margin-top:8px"><a href="https://arxiv.org/abs/2601.19672v2">Abs</a> · <a href="https://arxiv.org/pdf/2601.19672v2">PDF</a> · <a href="https://huggingface.co/huggingface">Code1</a> · <a href="https://huggingface.co/docs/hub/spaces">Code2</a></div>
<details class="detail"><summary>Abstract</summary>
<div class="mono">Federated Learning (FL) enables collaborative training of Large Language Models (LLMs) across distributed data sources while preserving privacy. However, when federated LLMs are deployed in critical applications, it remains unclear which client(s) contributed to specific generated responses, hindering debugging, malicious client identification, fair reward allocation, and trust verification. We present ProToken, a novel Provenance methodology for Token-level attribution in federated LLMs that addresses client attribution during autoregressive text generation while maintaining FL privacy constraints. ProToken leverages two key insights to enable provenance at each token: (1) transformer architectures concentrate task-specific signals in later blocks, enabling strategic layer selection for computational tractability, and (2) gradient-based relevance weighting filters out irrelevant neural activations, focusing attribution on neurons that directly influence token generation. We evaluate ProToken across 16 configurations spanning four LLM architectures (Gemma, Llama, Qwen, SmolLM) and four domains (medical, financial, mathematical, coding). ProToken achieves 98% average attribution accuracy in correctly localizing responsible client(s), and maintains high accuracy when the number of clients are scaled, validating its practical viability for real-world deployment settings.</div></details>
<details class="detail"><summary>中文标题/摘要</summary>
<div class="mono"><b>标题：</b>ProToken：联邦大语言模型的词元级贡献溯源方法</div>
<div class="mono" style="margin-top:8px">联邦学习（FL）支持基于分布式数据源协同训练大语言模型（LLM）并保护数据隐私。然而，当联邦LLM部署于关键应用时，特定生成响应究竟由哪些客户端贡献仍不明确，这阻碍了调试、恶意客户端识别、公平奖励分配与可信度验证。本文提出ProToken，一种面向联邦LLM词元级溯源的全新归因方法，在自回归文本生成过程中实现客户端贡献溯源，同时严格遵守联邦学习的隐私约束。ProToken基于两个关键洞见实现逐词元溯源：（1）Transformer架构将任务相关信号集中于深层模块，可通过策略性选择网络层实现计算可行性；（2）基于梯度的相关性加权机制能过滤无关神经激活，将归因聚焦于直接影响词元生成的神经元。我们在涵盖四种LLM架构（Gemma、Llama、Qwen、SmolLM）与四个领域（医疗、金融、数学、编程）的16种配置中评估ProToken。该方法在准确定位责任客户端方面达到98%的平均归因准确率，且在客户端数量增加时仍保持高精度，验证了其在实际部署场景中的可行性。</div>
</details>
<details class="detail"><summary>Summary / 总结</summary>
<div class="mono">Federated Learning enables collaborative training of Large Language Models across distributed data sources while preserving privacy, but attributing specific generated responses to contributing clients remains a challenge for debugging, fairness, and trust. To address this, ProToken introduces a novel provenance methodology for token-level client attribution during autoregressive text generation, leveraging the insight that transformer architectures concentrate task-specific signals in later layers and employing gradient-based relevance weighting to filter irrelevant neural activations. Experimental evaluation across 16 configurations involving four LLM architectures and four domains demonstrates that ProToken achieves an average attribution accuracy of 98% in correctly identifying responsible clients and maintains high accuracy as the number of clients scales, validating its practical viability.</div>
<div class="mono" style="margin-top:8px">联邦学习支持在分布式数据源上协作训练大语言模型并保护隐私，但将特定生成结果归因于贡献客户端仍是一个挑战，影响了调试、安全和公平性。为此，ProToken提出了一种新颖的溯源方法，用于实现细粒度的客户端归因，其核心方法是策略性地选择任务信号集中的深层Transformer层，并应用基于梯度的相关性加权来过滤不相关的神经激活。在涵盖四种大语言模型架构和四个领域的16种配置上的实验评估表明，ProToken在正确识别责任客户端方面达到了98%的平均归因准确率，并且在客户端数量增加时仍能保持高准确率。</div>
</details>
</div>
<div class="card">
<div class="title">GNN Explanations that do not Explain and How to find Them</div>
<div class="meta-line">Authors: Steve Azzolin, Stefano Teso, Bruno Lepri, Andrea Passerini, Sagar Malhotra</div>
<div class="meta-line">First: 2026-01-28T18:05:17+00:00 · Latest: 2026-01-28T18:05:17+00:00</div>
<div class="links" style="margin-top:8px"><a href="https://arxiv.org/abs/2601.20815v1">Abs</a> · <a href="https://arxiv.org/pdf/2601.20815v1">PDF</a> · <a href="https://huggingface.co/huggingface">Code1</a> · <a href="https://huggingface.co/docs/hub/spaces">Code2</a></div>
<details class="detail"><summary>Abstract</summary>
<div class="mono">Explanations provided by Self-explainable Graph Neural Networks (SE-GNNs) are fundamental for understanding the model&#x27;s inner workings and for identifying potential misuse of sensitive attributes. Although recent works have highlighted that these explanations can be suboptimal and potentially misleading, a characterization of their failure cases is unavailable. In this work, we identify a critical failure of SE-GNN explanations: explanations can be unambiguously unrelated to how the SE-GNNs infer labels. We show that, on the one hand, many SE-GNNs can achieve optimal true risk while producing these degenerate explanations, and on the other, most faithfulness metrics can fail to identify these failure modes. Our empirical analysis reveals that degenerate explanations can be maliciously planted (allowing an attacker to hide the use of sensitive attributes) and can also emerge naturally, highlighting the need for reliable auditing. To address this, we introduce a novel faithfulness metric that reliably marks degenerate explanations as unfaithful, in both malicious and natural settings. Our code is available in the supplemental.</div></details>
<details class="detail"><summary>中文标题/摘要</summary>
<div class="mono"><b>标题：</b>无法解释的图神经网络解释及其发现方法</div>
<div class="mono" style="margin-top:8px">自解释图神经网络（SE-GNNs）提供的解释对于理解模型内部机制及识别敏感属性的潜在误用至关重要。尽管近期研究指出这些解释可能并非最优且具有误导性，但其失效案例的特征尚未明确。本研究揭示了SE-GNN解释的一个关键缺陷：解释可能与SE-GNN推理标签的方式完全无关。我们证明，一方面许多SE-GNN在产生这些退化解释时仍能实现最优真实风险；另一方面，多数忠实性度量方法无法识别这些失效模式。实证分析表明，退化解释既可能被恶意植入（使攻击者得以隐藏敏感属性的使用），也可能自然产生，这凸显了可靠审计的必要性。为此，我们提出一种新颖的忠实性度量方法，能在恶意和自然场景下均可靠地将退化解释标记为不忠实。代码已附于补充材料。</div>
</details>
<details class="detail"><summary>Summary / 总结</summary>
<div class="mono">This research addresses the critical issue that self-explainable graph neural networks (SE-GNNs) can produce degenerate explanations that are completely unrelated to the model&#x27;s actual inference process, which undermines trust and can hide the misuse of sensitive attributes. The method involves characterizing this failure mode and demonstrating that SE-GNNs can achieve optimal accuracy while generating such misleading explanations, and that existing faithfulness metrics often fail to detect them. Key experimental findings reveal that these degenerate explanations can arise both from malicious manipulation to conceal sensitive attribute usage and naturally during training, prompting the need for better auditing; the authors consequently propose a novel faithfulness metric that effectively identifies these unfaithful explanations in both scenarios.</div>
<div class="mono" style="margin-top:8px">本研究针对自解释图神经网络（SE-GNN）可能产生与模型实际推理过程无关的解释这一关键问题展开，这对模型透明度和检测敏感属性滥用构成了挑战。作者描述了这种失效模式，证明了SE-GNN在生成此类退化解释的同时仍能保持最优性能，而现有的忠实度度量方法往往无法识别它们。实证分析表明，这些误导性解释既可能被恶意植入以隐藏敏感特征的使用，也可能自然产生，这凸显了可靠审计的必要性。为此，他们提出了一种新的忠实度度量方法，能在恶意和自然两种场景下有效标记出退化解释。</div>
</details>
</div>
<div class="card">
<div class="title">Helping Johnny Make Sense of Privacy Policies with LLMs</div>
<div class="meta-line">Authors: Vincent Freiberger, Arthur Fleig, Erik Buchmann</div>
<div class="meta-line">First: 2025-01-27T13:27:04+00:00 · Latest: 2026-01-28T17:54:54+00:00</div>
<div class="meta-line">Comments: 21 pages, 3 figures, 3 tables, ACM CHI 2026</div>
<div class="links" style="margin-top:8px"><a href="https://arxiv.org/abs/2501.16033v2">Abs</a> · <a href="https://arxiv.org/pdf/2501.16033v2">PDF</a> · <a href="https://huggingface.co/huggingface">Code1</a> · <a href="https://huggingface.co/docs/hub/spaces">Code2</a></div>
<details class="detail"><summary>Abstract</summary>
<div class="mono">Understanding and engaging with privacy policies is crucial for online privacy, yet these documents remain notoriously complex and difficult to navigate. We present PRISMe, an interactive browser extension that combines LLM-based policy assessment with a dashboard and customizable chat interface, enabling users to skim quick overviews or explore policy details in depth while browsing. We conduct a user study (N=22) with participants of diverse privacy knowledge to investigate how users interpret the tool&#x27;s explanations and how it shapes their engagement with privacy policies, identifying distinct interaction patterns. Participants valued the clear overviews and conversational depth, but flagged some issues, particularly adversarial robustness and hallucination risks. Thus, we investigate how a retrieval-augmented generation (RAG) approach can alleviate issues by re-running the chat queries from the study. Our findings surface design challenges as well as technical trade-offs, contributing actionable insights for developing future user-centered, trustworthy privacy policy analysis tools.</div></details>
<details class="detail"><summary>中文标题/摘要</summary>
<div class="mono"><b>标题：</b>利用大语言模型助力用户理解隐私政策</div>
<div class="mono" style="margin-top:8px">理解并参与隐私政策对在线隐私保护至关重要，但这些文件素以复杂难懂著称。我们推出PRISMe——一款结合大语言模型政策评估、可视化仪表盘与可定制聊天界面的交互式浏览器扩展，支持用户在浏览时快速概览或深度探究政策细节。通过对22名不同隐私知识背景的参与者开展用户研究，我们分析了用户对工具解释的理解方式及其对隐私政策参与度的影响，识别出独特的交互模式。参与者肯定其清晰概览与对话深度，但也指出对抗鲁棒性和幻觉风险等问题。为此，我们探究了检索增强生成方法如何通过重跑研究中的聊天查询来缓解问题。研究结果揭示了设计挑战与技术权衡，为开发未来以用户为中心、可信赖的隐私政策分析工具提供了可行见解。</div>
</details>
<details class="detail"><summary>Summary / 总结</summary>
<div class="mono">To address the challenge that privacy policies are complex and difficult for users to understand, this research introduces PRISMe, an interactive browser extension that uses large language models (LLMs) to assess policies and provides a dashboard with a customizable chat interface for exploring policy details. A user study with 22 participants of diverse privacy knowledge revealed that while users valued the tool&#x27;s clear overviews and conversational depth, they also identified issues such as adversarial robustness and hallucination risks. The authors further investigated a retrieval-augmented generation (RAG) approach to mitigate these problems, surfacing both design challenges and technical trade-offs for future privacy policy analysis tools.</div>
<div class="mono" style="margin-top:8px">为解决隐私政策复杂难懂这一长期存在的用户挑战，本研究提出了PRISMe，一款利用大语言模型评估政策并提供仪表盘与可定制聊天界面的交互式浏览器扩展，使用户能够快速浏览概览或深入探索细节。通过一项涉及22名不同隐私知识背景参与者的用户研究进行评估，该方法识别了不同的交互模式，发现用户重视清晰的概览和对话深度，但也指出了对抗性鲁棒性和幻觉风险等问题。研究进一步探讨了检索增强生成方法，通过重新运行聊天查询来缓解这些问题，揭示了设计挑战和技术权衡，为未来开发以用户为中心的可信隐私政策分析工具提供了可行见解。</div>
</details>
</div>
<div class="card">
<div class="title">Reinforcement Learning via Self-Distillation</div>
<div class="meta-line">Authors: Jonas Hübotter, Frederike Lübeck, Lejs Behric, Anton Baumann, Marco Bagatella, Daniel Marta, Ido Hakimi, Idan Shenfeld, Thomas Kleine Buening, Carlos Guestrin, Andreas Krause</div>
<div class="meta-line">First: 2026-01-28T17:45:12+00:00 · Latest: 2026-01-28T17:45:12+00:00</div>
<div class="links" style="margin-top:8px"><a href="https://arxiv.org/abs/2601.20802v1">Abs</a> · <a href="https://arxiv.org/pdf/2601.20802v1">PDF</a> · <a href="https://huggingface.co/huggingface">Code1</a> · <a href="https://huggingface.co/docs/hub/spaces">Code2</a></div>
<details class="detail"><summary>Abstract</summary>
<div class="mono">Large language models are increasingly post-trained with reinforcement learning in verifiable domains such as code and math. Yet, current methods for reinforcement learning with verifiable rewards (RLVR) learn only from a scalar outcome reward per attempt, creating a severe credit-assignment bottleneck. Many verifiable environments actually provide rich textual feedback, such as runtime errors or judge evaluations, that explain why an attempt failed. We formalize this setting as reinforcement learning with rich feedback and introduce Self-Distillation Policy Optimization (SDPO), which converts tokenized feedback into a dense learning signal without any external teacher or explicit reward model. SDPO treats the current model conditioned on feedback as a self-teacher and distills its feedback-informed next-token predictions back into the policy. In this way, SDPO leverages the model&#x27;s ability to retrospectively identify its own mistakes in-context. Across scientific reasoning, tool use, and competitive programming on LiveCodeBench v6, SDPO improves sample efficiency and final accuracy over strong RLVR baselines. Notably, SDPO also outperforms baselines in standard RLVR environments that only return scalar feedback by using successful rollouts as implicit feedback for failed attempts. Finally, applying SDPO to individual questions at test time accelerates discovery on difficult binary-reward tasks, achieving the same discovery probability as best-of-k sampling or multi-turn conversations with 3x fewer attempts.</div></details>
<details class="detail"><summary>中文标题/摘要</summary>
<div class="mono"><b>标题：</b>基于自蒸馏的强化学习</div>
<div class="mono" style="margin-top:8px">大型语言模型在代码和数学等可验证领域越来越多地通过强化学习进行后训练。然而，当前基于可验证奖励的强化学习方法仅从每次尝试的标量结果奖励中学习，形成了严重的信用分配瓶颈。许多可验证环境实际提供丰富的文本反馈（如运行时错误或评判评估），用以解释尝试失败的原因。我们将此设定形式化为带丰富反馈的强化学习，并提出自蒸馏策略优化方法，该方法将标记化反馈转化为密集学习信号，无需外部教师或显式奖励模型。SDPO将基于反馈调节的当前模型视为自教师，并将其反馈感知的下一标记预测蒸馏回策略中。通过这种方式，SDPO利用了模型在上下文中回溯识别自身错误的能力。在科学推理、工具使用和LiveCodeBench v6的竞技编程任务中，SDPO相比强RLVR基线显著提升了样本效率和最终准确率。值得注意的是，在仅返回标量反馈的标准RLVR环境中，SDPO通过将成功轨迹作为失败尝试的隐式反馈，同样超越了基线方法。最后，在测试时对单个问题应用SDPO可加速困难二元奖励任务的探索，仅需最佳k采样或多轮对话三分之一的尝试次数即可达到相同的发现概率。</div>
</details>
<details class="detail"><summary>Summary / 总结</summary>
<div class="mono">The research is motivated by the limitation of current reinforcement learning with verifiable rewards (RLVR) methods, which rely solely on scalar outcome rewards and suffer from a credit-assignment bottleneck, despite many verifiable environments providing rich textual feedback like runtime errors. To address this, the authors formalize reinforcement learning with rich feedback and introduce Self-Distillation Policy Optimization (SDPO), a method that converts tokenized feedback into a dense learning signal without external teachers or explicit reward models by treating the current model conditioned on feedback as a self-teacher and distilling its feedback-informed next-token predictions back into the policy. Experimental results across scientific reasoning, tool use, and competitive programming on LiveCodeBench v6 show that SDPO improves sample efficiency and final accuracy over strong RLVR baselines, outperforms them even in standard RLVR environments by using successful rollouts as implicit feedback, and accelerates discovery on difficult binary-reward tasks at test time, achieving the same discovery probability as best-of-k sampling or multi-turn conversations with three times fewer attempts.</div>
<div class="mono" style="margin-top:8px">本研究针对可验证奖励强化学习（RLVR）中仅使用标量结果奖励导致的信用分配瓶颈问题，提出利用可验证领域（如代码和数学）中常提供的丰富文本反馈（如运行时错误）。方法上引入了自蒸馏策略优化（SDPO），该方法将当前模型在文本反馈条件下的输出作为自教师，将其反馈感知的下一个词预测蒸馏回策略中，从而无需外部监督即可将反馈转化为密集学习信号。在科学推理、工具使用和LiveCodeBench v6竞争性编程上的实验表明，SDPO相比强RLVR基线提高了样本效率和最终准确率；在仅提供标量反馈的标准RLVR环境中，通过使用成功轨迹作为失败尝试的隐式反馈，SDPO也优于基线；此外，在测试时对单个问题应用SDPO可加速困难二元奖励任务的探索，以比最佳k采样少三倍的尝试次数达到相同的发现概率。</div>
</details>
</div>
<div class="card">
<div class="title">Conditional PED-ANOVA: Hyperparameter Importance in Hierarchical &amp; Dynamic Search Spaces</div>
<div class="meta-line">Authors: Kaito Baba, Yoshihiko Ozaki, Shuhei Watanabe</div>
<div class="meta-line">First: 2026-01-28T17:44:36+00:00 · Latest: 2026-01-28T17:44:36+00:00</div>
<div class="meta-line">Comments: 16 pages, 9 figures</div>
<div class="links" style="margin-top:8px"><a href="https://arxiv.org/abs/2601.20800v1">Abs</a> · <a href="https://arxiv.org/pdf/2601.20800v1">PDF</a> · <a href="https://huggingface.co/huggingface">Code1</a> · <a href="https://huggingface.co/docs/hub/spaces">Code2</a></div>
<details class="detail"><summary>Abstract</summary>
<div class="mono">We propose conditional PED-ANOVA (condPED-ANOVA), a principled framework for estimating hyperparameter importance (HPI) in conditional search spaces, where the presence or domain of a hyperparameter can depend on other hyperparameters. Although the original PED-ANOVA provides a fast and efficient way to estimate HPI within the top-performing regions of the search space, it assumes a fixed, unconditional search space and therefore cannot properly handle conditional hyperparameters. To address this, we introduce a conditional HPI for top-performing regions and derive a closed-form estimator that accurately reflects conditional activation and domain changes. Experiments show that naive adaptations of existing HPI estimators yield misleading or uninterpretable importance estimates in conditional settings, whereas condPED-ANOVA consistently provides meaningful importances that reflect the underlying conditional structure.</div></details>
<details class="detail"><summary>中文标题/摘要</summary>
<div class="mono"><b>标题：</b>条件PED-ANOVA：层次与动态搜索空间中的超参数重要性分析</div>
<div class="mono" style="margin-top:8px">本文提出条件PED-ANOVA（condPED-ANOVA），这是一个用于估计条件搜索空间中超参数重要性（HPI）的原则性框架。在条件搜索空间中，超参数的存在或定义域可能依赖于其他超参数。尽管原始PED-ANOVA能在搜索空间的高性能区域快速有效地估计HPI，但其假设搜索空间固定且无条件，因此无法正确处理条件超参数。为解决此问题，我们针对高性能区域提出了条件HPI概念，并推导出能准确反映条件激活与定义域变化的闭式估计器。实验表明，现有HPI估计器的简单适配在条件设置中会产生误导性或不可解释的重要性估计，而condPED-ANOVA始终能提供反映底层条件结构的有意义重要性度量。</div>
</details>
<details class="detail"><summary>Summary / 总结</summary>
<div class="mono">The research addresses the limitation of existing hyperparameter importance (HPI) estimators, which assume fixed search spaces and fail to properly handle conditional hyperparameters whose presence or domain depends on other hyperparameters. The method introduces conditional PED-ANOVA, a framework that defines a conditional HPI for top-performing regions and derives a closed-form estimator to account for conditional activation and domain changes. Experimental results demonstrate that naive adaptations of prior estimators produce misleading importance scores in conditional settings, while the proposed condPED-ANOVA consistently yields meaningful importance estimates that accurately reflect the underlying conditional structure.</div>
<div class="mono" style="margin-top:8px">本研究针对现有超参数重要性（HPI）估计器的局限性，这些估计器假设搜索空间固定，无法正确处理存在性或定义域依赖于其他超参数的条件超参数。所提出的方法——条件PED-ANOVA（condPED-ANOVA）——扩展了原始PED-ANOVA框架，引入了针对高性能区域的条件HPI定义，并推导出一个闭式估计器，能准确反映条件激活和定义域变化。实验结果表明，在条件设置下，对现有HPI估计器的简单适配会产生误导性或不可解释的重要性估计，而condPED-ANOVA则能始终提供有意义的重要性估计，正确反映底层的条件结构。</div>
</details>
</div>
<div class="card">
<div class="title">EVEREST: An Evidential, Tail-Aware Transformer for Rare-Event Time-Series Forecasting</div>
<div class="meta-line">Authors: Antanas Zilinskas, Robert N. Shorten, Jakub Marecek</div>
<div class="meta-line">Venue: 14th International Conference on Learning Representations, 2026</div>
<div class="meta-line">First: 2026-01-26T23:15:20+00:00 · Latest: 2026-01-28T17:40:06+00:00</div>
<div class="meta-line">Comments: Updated author affiliation. No changes to technical content</div>
<div class="links" style="margin-top:8px"><a href="https://arxiv.org/abs/2601.19022v2">Abs</a> · <a href="https://arxiv.org/pdf/2601.19022v2">PDF</a> · <a href="https://huggingface.co/huggingface">Code1</a> · <a href="https://huggingface.co/docs/hub/spaces">Code2</a></div>
<details class="detail"><summary>Abstract</summary>
<div class="mono">Forecasting rare events in multivariate time-series data is challenging due to severe class imbalance, long-range dependencies, and distributional uncertainty. We introduce EVEREST, a transformer-based architecture for probabilistic rare-event forecasting that delivers calibrated predictions and tail-aware risk estimation, with auxiliary interpretability via attention-based signal attribution. EVEREST integrates four components: (i) a learnable attention bottleneck for soft aggregation of temporal dynamics; (ii) an evidential head for estimating aleatoric and epistemic uncertainty via a Normal--Inverse--Gamma distribution; (iii) an extreme-value head that models tail risk using a Generalized Pareto Distribution; and (iv) a lightweight precursor head for early-event detection. These modules are jointly optimized with a composite loss (focal loss, evidential NLL, and a tail-sensitive EVT penalty) and act only at training time; deployment uses a single classification head with no inference overhead (approximately 0.81M parameters). On a decade of space-weather data, EVEREST achieves state-of-the-art True Skill Statistic (TSS) of 0.973/0.970/0.966 at 24/48/72-hour horizons for C-class flares. The model is compact, efficient to train on commodity hardware, and applicable to high-stakes domains such as industrial monitoring, weather, and satellite diagnostics. Limitations include reliance on fixed-length inputs and exclusion of image-based modalities, motivating future extensions to streaming and multimodal forecasting.</div></details>
<details class="detail"><summary>中文标题/摘要</summary>
<div class="mono"><b>标题：</b>EVEREST：一种用于罕见事件时间序列预测的证据性尾部感知Transformer</div>
<div class="mono" style="margin-top:8px">由于严重的类别不平衡、长程依赖性和分布不确定性，多元时间序列数据中的罕见事件预测具有挑战性。我们提出EVEREST，一种基于Transformer的概率性罕见事件预测架构，能够提供校准预测和尾部感知风险估计，并通过基于注意力的信号归因实现辅助可解释性。EVEREST集成四个组件：(i) 可学习的注意力瓶颈用于时间动态的软聚合；(ii) 证据性头部通过正态-逆伽马分布估计偶然性和认知不确定性；(iii) 极值头部使用广义帕累托分布建模尾部风险；(iv) 轻量级前兆头部用于早期事件检测。这些模块通过复合损失函数（焦点损失、证据性负对数似然和尾部敏感极值理论惩罚）联合优化，仅在训练时激活；部署时使用单一分类头部且无推理开销（约81万参数）。在十年空间天气数据上，EVEREST对C级耀斑在24/48/72小时预测窗口实现了0.973/0.970/0.966的最优真技巧统计量。该模型紧凑、可在商用硬件上高效训练，适用于工业监测、气象和卫星诊断等高风险领域。局限性包括依赖固定长度输入及未纳入图像模态，为未来扩展到流式和多模态预测提供方向。</div>
</details>
<details class="detail"><summary>Summary / 总结</summary>
<div class="mono">The research addresses the challenge of forecasting rare events in multivariate time-series data, which is hindered by severe class imbalance, long-range dependencies, and distributional uncertainty. The method introduces EVEREST, a transformer-based architecture that integrates a learnable attention bottleneck for temporal dynamics, an evidential head for uncertainty estimation via a Normal-Inverse-Gamma distribution, an extreme-value head for tail risk modeling with a Generalized Pareto Distribution, and a lightweight precursor head for early detection; these components are jointly optimized with a composite loss during training, while deployment uses a single classification head without inference overhead. Key experimental results on a decade of space-weather data show state-of-the-art performance, achieving True Skill Statistic scores of 0.973, 0.970, and 0.966 at 24-, 48-, and 72-hour horizons for C-class flares, with the model being compact and efficient to train on commodity hardware.</div>
<div class="mono" style="margin-top:8px">该研究针对多元时间序列数据中罕见事件预测的挑战，这些挑战包括严重的类别不平衡、长程依赖性和分布不确定性。方法提出了EVEREST，一种基于Transformer的架构，它集成了一个可学习的注意力瓶颈用于时序动态聚合、一个证据头通过正态-逆伽马分布进行不确定性估计、一个极值头使用广义帕累托分布建模尾部风险，以及一个前兆头用于早期检测；这些组件在训练期间通过复合损失联合优化，而部署时使用单一分类头且无推理开销。在长达十年的空间天气数据上的关键实验结果表明，该模型在C级耀斑的24小时、48小时和72小时预测范围内，分别取得了0.973、0.970和0.966的真实技巧统计分数，达到了最先进的性能，且模型紧凑，可在商用硬件上高效训练。</div>
</details>
</div>
<div class="card">
<div class="title">LLMBind: A Unified Modality-Task Integration Framework</div>
<div class="meta-line">Authors: Bin Zhu, Munan Ning, Peng Jin, Bin Lin, Jinfa Huang, Qi Song, Junwu Zhang, Zhenyu Tang, Mingjun Pan, Li Yuan</div>
<div class="meta-line">First: 2024-02-22T12:36:31+00:00 · Latest: 2026-01-28T17:35:06+00:00</div>
<div class="links" style="margin-top:8px"><a href="https://arxiv.org/abs/2402.14891v6">Abs</a> · <a href="https://arxiv.org/pdf/2402.14891v6">PDF</a> · <a href="https://huggingface.co/huggingface">Code1</a> · <a href="https://huggingface.co/docs/hub/spaces">Code2</a></div>
<details class="detail"><summary>Abstract</summary>
<div class="mono">Despite recent progress in Multi-Modal Large Language Models (MLLMs), it remains challenging to integrate diverse tasks ranging from pixel-level perception to high-fidelity generation. Existing approaches often suffer from either restricted task extensibility or severe performance degradation due to modality interference. n this paper, we present LLMBind, an extensible framework that unifies multimodal tasks through a dual-pathway mechanism: In-Situ semantic embeddings for localization-sensitive tasks like semantic segmentation and Ex-Situ task-prompts for generation across image, video, and audio modalities. Additionally, we employ a Mixture-of-Experts (MoE) architecture to route task-specific tokens, thereby achieving modality disentanglement and mitigating negative transfer. We also curate a 400k multi-turn interactive dataset focused on iterative visual refinement to enable human-like interaction. Extensive experiments demonstrate that LLMBind achieves excellent performance across multiple perception and generation benchmarks while maintaining superior expandability.</div></details>
<details class="detail"><summary>中文标题/摘要</summary>
<div class="mono"><b>标题：</b>LLMBind：统一模态-任务集成框架</div>
<div class="mono" style="margin-top:8px">尽管多模态大语言模型（MLLMs）近期取得进展，但整合从像素级感知到高保真生成的多样化任务仍具挑战。现有方法常受限于任务可扩展性不足或模态干扰导致的性能严重下降。本文提出LLMBind——一个通过双路径机制统一多模态任务的可扩展框架：针对语义分割等定位敏感任务采用原位语义嵌入，针对图像、视频和音频模态的生成任务采用异位任务提示。此外，我们采用混合专家（MoE）架构路由任务特定令牌，实现模态解耦并缓解负迁移。我们还构建了一个包含40万轮次、专注于迭代视觉优化的多轮交互数据集，以支持类人交互。大量实验表明，LLMBind在多项感知与生成基准测试中均取得优异性能，同时保持卓越的可扩展性。</div>
</details>
<details class="detail"><summary>Summary / 总结</summary>
<div class="mono">The research addresses the challenge of integrating diverse multimodal tasks, from pixel-level perception to high-fidelity generation, within a single Multi-Modal Large Language Model (MLLM), as existing methods often face limited task extensibility or performance degradation due to modality interference. The proposed LLMBind framework introduces a dual-pathway mechanism using In-Situ semantic embeddings for localization-sensitive tasks like semantic segmentation and Ex-Situ task-prompts for generation across image, video, and audio, alongside a Mixture-of-Experts (MoE) architecture to route task-specific tokens for modality disentanglement and to mitigate negative transfer; it also utilizes a curated 400k multi-turn interactive dataset for iterative visual refinement. Experimental results show that LLMBind achieves strong performance across multiple perception and generation benchmarks while maintaining superior expandability.</div>
<div class="mono" style="margin-top:8px">本研究旨在解决在单一多模态大语言模型（MLLM）中整合从像素级感知到高保真生成的多样化任务所面临的挑战，因为现有方法常因模态干扰而存在任务可扩展性有限或性能下降的问题。所提出的方法LLMBind引入了一个统一框架，采用双路径机制——使用原位语义嵌入处理如语义分割等定位敏感任务，以及使用异位任务提示进行跨图像、视频和音频的生成——并结合混合专家（MoE）架构来路由任务特定令牌，以实现模态解耦并减轻负迁移。关键实验结果表明，LLMBind在多个感知和生成基准测试中取得了优异性能，同时保持了卓越的可扩展性，该研究还构建了一个包含40万轮次的多轮交互数据集以支持迭代视觉细化。</div>
</details>
</div>
<div class="card">
<div class="title">FAIRT2V: Training-Free Debiasing for Text-to-Video Diffusion Models</div>
<div class="meta-line">Authors: Haonan Zhong, Wei Song, Tingxu Han, Maurice Pagnucco, Jingling Xue, Yang Song</div>
<div class="meta-line">First: 2026-01-28T17:29:53+00:00 · Latest: 2026-01-28T17:29:53+00:00</div>
<div class="links" style="margin-top:8px"><a href="https://arxiv.org/abs/2601.20791v1">Abs</a> · <a href="https://arxiv.org/pdf/2601.20791v1">PDF</a> · <a href="https://huggingface.co/huggingface">Code1</a> · <a href="https://huggingface.co/docs/hub/spaces">Code2</a></div>
<details class="detail"><summary>Abstract</summary>
<div class="mono">Text-to-video (T2V) diffusion models have achieved rapid progress, yet their demographic biases, particularly gender bias, remain largely unexplored. We present FairT2V, a training-free debiasing framework for text-to-video generation that mitigates encoder-induced bias without finetuning. We first analyze demographic bias in T2V models and show that it primarily originates from pretrained text encoders, which encode implicit gender associations even for neutral prompts. We quantify this effect with a gender-leaning score that correlates with bias in generated videos.
  Based on this insight, FairT2V mitigates demographic bias by neutralizing prompt embeddings via anchor-based spherical geodesic transformations while preserving semantics. To maintain temporal coherence, we apply debiasing only during early identity-forming steps through a dynamic denoising schedule. We further propose a video-level fairness evaluation protocol combining VideoLLM-based reasoning with human verification. Experiments on the modern T2V model Open-Sora show that FairT2V substantially reduces demographic bias across occupations with minimal impact on video quality.</div></details>
<details class="detail"><summary>中文标题/摘要</summary>
<div class="mono"><b>标题：</b>FAIRT2V：面向文本到视频扩散模型的无训练去偏方法</div>
<div class="mono" style="margin-top:8px">文本到视频（T2V）扩散模型发展迅速，但其人口统计学偏见（尤其是性别偏见）尚未得到充分研究。本文提出FairT2V，一种无需训练即可缓解编码器引发偏见的文本到视频生成去偏框架。我们首先分析了T2V模型中的人口统计学偏见，发现其主要源于预训练文本编码器——即使对中性提示词也会编码隐含的性别关联。我们通过性别倾向评分量化该效应，该评分与生成视频中的偏见程度相关。基于此发现，FairT2V通过基于锚点的球面测地变换对提示嵌入进行去偏处理，同时保持语义完整性。为保障时序连贯性，我们通过动态去噪调度仅在早期身份形成阶段实施去偏。进一步提出结合VideoLLM推理与人工验证的视频级公平性评估方案。在现代T2V模型Open-Sora上的实验表明，FairT2V能显著降低跨职业人口统计学偏见，且对视频质量影响极小。</div>
</details>
<details class="detail"><summary>Summary / 总结</summary>
<div class="mono">This research addresses the unexplored demographic biases, particularly gender bias, in text-to-video (T2V) diffusion models. The method, FairT2V, is a training-free framework that identifies the primary source of bias as the pretrained text encoder and mitigates it by applying anchor-based spherical geodesic transformations to neutralize prompt embeddings while preserving semantics; temporal coherence is maintained via a dynamic denoising schedule that applies debiasing only during early identity-forming steps. Experimental results on the Open-Sora model demonstrate that FairT2V substantially reduces demographic bias across various occupations with minimal impact on video quality, as validated by a proposed evaluation protocol combining VideoLLM-based reasoning with human verification.</div>
<div class="mono" style="margin-top:8px">本研究针对文本到视频扩散模型中尚未被充分探索的人口统计学偏见（特别是性别偏见）问题展开。提出的FairT2V是一个无需训练的去偏框架，其发现偏见主要源于预训练文本编码器，并通过性别倾向分数进行量化。该方法采用基于锚点的球面测地变换来中和提示词嵌入的偏见，同时保持语义信息；为确保时间一致性，仅通过动态去噪计划在早期生成步骤应用去偏。在Open-Sora模型上的实验表明，结合新提出的基于VideoLLM的公平性评估协议，FairT2V能显著减少不同职业提示下的性别偏见，且对视频质量影响极小。</div>
</details>
</div>
<div class="card">
<div class="title">LogogramNLP: Comparing Visual and Textual Representations of Ancient Logographic Writing Systems for NLP</div>
<div class="meta-line">Authors: Danlu Chen, Freda Shi, Aditi Agarwal, Jacobo Myerston, Taylor Berg-Kirkpatrick</div>
<div class="meta-line">Venue: ACL 2024 long</div>
<div class="meta-line">First: 2024-08-08T17:58:06+00:00 · Latest: 2026-01-28T17:27:29+00:00</div>
<div class="meta-line">Comments: correct wrong refs, typos</div>
<div class="links" style="margin-top:8px"><a href="https://arxiv.org/abs/2408.04628v2">Abs</a> · <a href="https://arxiv.org/pdf/2408.04628v2">PDF</a> · <a href="https://huggingface.co/huggingface">Code1</a> · <a href="https://huggingface.co/docs/hub/spaces">Code2</a></div>
<details class="detail"><summary>Abstract</summary>
<div class="mono">Standard natural language processing (NLP) pipelines operate on symbolic representations of language, which typically consist of sequences of discrete tokens. However, creating an analogous representation for ancient logographic writing systems is an extremely labor intensive process that requires expert knowledge. At present, a large portion of logographic data persists in a purely visual form due to the absence of transcription -- this issue poses a bottleneck for researchers seeking to apply NLP toolkits to study ancient logographic languages: most of the relevant data are images of writing.
  This paper investigates whether direct processing of visual representations of language offers a potential solution. We introduce LogogramNLP, the first benchmark enabling NLP analysis of ancient logographic languages, featuring both transcribed and visual datasets for four writing systems along with annotations for tasks like classification, translation, and parsing. Our experiments compare systems that employ recent visual and text encoding strategies as backbones. The results demonstrate that visual representations outperform textual representations for some investigated tasks, suggesting that visual processing pipelines may unlock a large amount of cultural heritage data of logographic languages for NLP-based analyses.</div></details>
<details class="detail"><summary>中文标题/摘要</summary>
<div class="mono"><b>标题：</b>LogogramNLP：比较古代表意文字系统的视觉与文本表征用于自然语言处理</div>
<div class="mono" style="margin-top:8px">标准的自然语言处理（NLP）流程基于语言的符号表征运行，这些表征通常由离散标记序列构成。然而，为古代表意文字系统创建类似的表征是一个极其耗费人力的过程，需要专业知识。目前，由于缺乏转写，大量表意文字数据仍以纯视觉形式存在——这一问题对希望应用NLP工具包研究古代表意语言的研究者构成了瓶颈：大部分相关数据是文字图像。本文探讨直接处理语言的视觉表征是否提供了一种潜在解决方案。我们介绍了LogogramNLP，这是首个支持对古代表意语言进行NLP分析的基准，包含四种文字系统的转写和视觉数据集，以及分类、翻译和解析等任务的标注。我们的实验比较了采用近期视觉与文本编码策略作为骨干的系统。结果表明，在某些研究任务中，视觉表征优于文本表征，这表明视觉处理流程可能为基于NLP的分析解锁大量表意语言的文化遗产数据。</div>
</details>
<details class="detail"><summary>Summary / 总结</summary>
<div class="mono">This research addresses the bottleneck in applying NLP to ancient logographic languages, where data often exists only as images due to the labor-intensive nature of transcription. The authors introduce LogogramNLP, a benchmark with transcribed and visual datasets for four writing systems, and compare systems using visual and textual encoding backbones for tasks like classification and translation. Experimental results show that visual representations can outperform textual ones on certain tasks, indicating that visual processing could unlock more cultural heritage data for NLP analysis.</div>
<div class="mono" style="margin-top:8px">本研究旨在解决将自然语言处理应用于古代语标文字时遇到的瓶颈，这些文字的数据常因转录工作繁重而仅以图像形式存在。作者提出了LogogramNLP，这是一个包含四种文字系统转录和视觉数据集的基准，并比较了使用视觉和文本编码主干系统在分类和翻译等任务上的表现。实验结果表明，在某些任务上，视觉表征优于文本表征，这表明视觉处理流程可以为基于自然语言处理的分析解锁大量语标文字的文化遗产数据。</div>
</details>
</div>
<div class="card">
<div class="title">DaMO: A Data-Efficient Multimodal Orchestrator for Temporal Reasoning with Video LLMs</div>
<div class="meta-line">Authors: Bo-Cheng Chiu, Jen-Jee Chen, Yu-Chee Tseng, Feng-Chi Chen, An-Zi Yen</div>
<div class="meta-line">First: 2025-06-13T08:13:05+00:00 · Latest: 2026-01-28T17:24:42+00:00</div>
<div class="links" style="margin-top:8px"><a href="https://arxiv.org/abs/2506.11558v4">Abs</a> · <a href="https://arxiv.org/pdf/2506.11558v4">PDF</a> · <a href="https://huggingface.co/huggingface">Code1</a> · <a href="https://huggingface.co/docs/hub/spaces">Code2</a></div>
<details class="detail"><summary>Abstract</summary>
<div class="mono">Large Language Models (LLMs) have recently been extended to the video domain, enabling sophisticated video-language understanding. However, existing Video LLMs often exhibit limitations in fine-grained temporal reasoning, restricting their ability to precisely attribute responses to specific video moments, especially under constrained supervision. We introduce DaMO, a data-efficient Video LLM explicitly designed for accurate temporal reasoning and multimodal understanding. At its core, the proposed Temporal-aware Fuseformer employs a hierarchical dual-stream architecture that progressively captures temporal dynamics within each modality and effectively fuses complementary visual and audio information. To further enhance computational efficiency, DaMO integrates a global residual that reduces spatial redundancy while preserving essential semantic details. We train DaMO via a structured four-stage progressive training paradigm, incrementally equipping the model with multimodal alignment, semantic grounding, and temporal reasoning capabilities. This work also contributes multiple datasets augmented from existing ones with LLM-generated temporally grounded QA pairs for tasks requiring temporal supervision. Comprehensive experiments on temporal grounding and video QA benchmarks demonstrate that DaMO consistently surpasses prior methods, particularly in tasks demanding precise temporal alignment and reasoning. Our work establishes a promising direction for data-efficient video-language modeling.</div></details>
<details class="detail"><summary>中文标题/摘要</summary>
<div class="mono"><b>标题：</b>DaMO：面向视频大语言模型时序推理的数据高效多模态编排器</div>
<div class="mono" style="margin-top:8px">大语言模型（LLMs）近期已扩展至视频领域，实现了复杂的视频-语言理解。然而，现有视频大语言模型在细粒度时序推理方面常显不足，难以将响应精确关联至特定视频片段，尤其在有限监督条件下。本文提出DaMO——一种专为精准时序推理与多模态理解设计的数据高效视频大语言模型。其核心时序感知融合变换器采用分层双流架构，渐进捕获各模态内时序动态并有效融合互补的视觉与音频信息。为提升计算效率，DaMO引入全局残差机制以降低空间冗余同时保留关键语义细节。通过结构化四阶段渐进训练范式，逐步赋予模型多模态对齐、语义 grounding 及时序推理能力。本研究还贡献了多个基于现有数据集增强的时序标注问答对数据集，适用于需时序监督的任务。在时序定位与视频问答基准测试中，DaMO持续超越现有方法，尤其在需要精准时序对齐与推理的任务中表现突出。本工作为数据高效视频-语言建模开辟了前景广阔的研究方向。</div>
</details>
<details class="detail"><summary>Summary / 总结</summary>
<div class="mono">The research addresses the limitations of existing Video LLMs in fine-grained temporal reasoning, particularly in precisely attributing responses to specific video moments under constrained supervision. The proposed method, DaMO, employs a Temporal-aware Fuseformer with a hierarchical dual-stream architecture to capture temporal dynamics and fuse visual and audio information, alongside a global residual for computational efficiency, and is trained via a four-stage progressive paradigm. Experimental results on temporal grounding and video QA benchmarks show that DaMO consistently outperforms prior methods, especially in tasks requiring precise temporal alignment and reasoning.</div>
<div class="mono" style="margin-top:8px">现有的视频大语言模型通常在细粒度时序推理方面存在局限，难以将回答精确关联到特定视频时刻，尤其在监督有限的情况下。为此，研究者提出了DaMO，一种数据高效的多模态编排器，其核心是采用分层双流架构的时序感知融合模块，以捕捉模态内时序动态并有效融合视觉与音频信息，同时集成全局残差机制以减少空间冗余并保持关键语义细节。模型通过结构化的四阶段渐进式训练范式进行训练，逐步获得多模态对齐和时序推理能力，并使用了由大语言模型生成的带时序标注问答对增强的数据集。在时序定位和视频问答基准上的综合实验表明，DaMO持续超越先前方法，尤其在需要精确时序对齐的任务中表现出色。</div>
</details>
</div></div>
    <details style="margin-top:16px" class="detail"><summary>History</summary>
      <div class="history-list"><a href="archive/20260129_0630.html">20260129_0630</a>
<a href="archive/20260129_0536.html">20260129_0536</a>
<a href="archive/20260129_0450.html">20260129_0450</a>
<a href="archive/20260129_0336.html">20260129_0336</a>
<a href="archive/20260128_0625.html">20260128_0625</a>
<a href="archive/20260128_0439.html">20260128_0439</a>
<a href="archive/20260128_0334.html">20260128_0334</a>
<a href="archive/20260127_0627.html">20260127_0627</a>
<a href="archive/20260127_0529.html">20260127_0529</a>
<a href="archive/20260127_0439.html">20260127_0439</a>
<a href="archive/20260127_0333.html">20260127_0333</a>
<a href="archive/20260126_0626.html">20260126_0626</a>
<a href="archive/20260126_0526.html">20260126_0526</a>
<a href="archive/20260126_0327.html">20260126_0327</a>
<a href="archive/20260125_0624.html">20260125_0624</a>
<a href="archive/20260125_0524.html">20260125_0524</a>
<a href="archive/20260125_0440.html">20260125_0440</a>
<a href="archive/20260125_0325.html">20260125_0325</a>
<a href="archive/20260124_0627.html">20260124_0627</a>
<a href="archive/20260124_0526.html">20260124_0526</a>
<a href="archive/20260124_0444.html">20260124_0444</a>
<a href="archive/20260124_0334.html">20260124_0334</a>
<a href="archive/20260123_0627.html">20260123_0627</a>
<a href="archive/20260123_0529.html">20260123_0529</a>
<a href="archive/20260123_0446.html">20260123_0446</a>
<a href="archive/20260123_0334.html">20260123_0334</a>
<a href="archive/20260122_2019.html">20260122_2019</a>
<a href="archive/20260122_2013.html">20260122_2013</a>
<a href="archive/20260122_2008.html">20260122_2008</a>
<a href="archive/20260122_2001.html">20260122_2001</a>
<a href="archive/20260122_0629.html">20260122_0629</a>
<a href="archive/20260122_0535.html">20260122_0535</a>
<a href="archive/20260122_0449.html">20260122_0449</a>
<a href="archive/20260122_0336.html">20260122_0336</a>
<a href="archive/20260121_0625.html">20260121_0625</a>
<a href="archive/20260121_0529.html">20260121_0529</a>
<a href="archive/20260121_0450.html">20260121_0450</a>
<a href="archive/20260121_0423.html">20260121_0423</a>
<a href="archive/20260120_0626.html">20260120_0626</a>
<a href="archive/20260120_0528.html">20260120_0528</a>
<a href="archive/20260120_0443.html">20260120_0443</a>
<a href="archive/20260120_0330.html">20260120_0330</a>
<a href="archive/20260119_0624.html">20260119_0624</a>
<a href="archive/20260119_0525.html">20260119_0525</a>
<a href="archive/20260119_0440.html">20260119_0440</a>
<a href="archive/20260119_0325.html">20260119_0325</a>
<a href="archive/20260118_2225.html">20260118_2225</a>
<a href="archive/20260118_2159.html">20260118_2159</a>
<a href="archive/20260118_2135.html">20260118_2135</a>
<a href="archive/20260118_2040.html">20260118_2040</a>
<a href="archive/20260118_1953.html">20260118_1953</a>
<a href="archive/20260118_1907.html">20260118_1907</a>
<a href="archive/20260118_0327.html">20260118_0327</a>
<a href="archive/20260117_0332.html">20260117_0332</a>
<a href="archive/20260116_0339.html">20260116_0339</a>
<a href="archive/20260115_0334.html">20260115_0334</a>
<a href="archive/20260114_0333.html">20260114_0333</a>
<a href="archive/20260113_0334.html">20260113_0334</a>
<a href="archive/20260112_0331.html">20260112_0331</a>
<a href="archive/20260111_0329.html">20260111_0329</a>
<a href="archive/20260110_0333.html">20260110_0333</a>
<a href="archive/20260109_0334.html">20260109_0334</a>
<a href="archive/20260108_0335.html">20260108_0335</a>
<a href="archive/20260107_0330.html">20260107_0330</a>
<a href="archive/20260106_0336.html">20260106_0336</a>
<a href="archive/20260105_0328.html">20260105_0328</a>
<a href="archive/20260104_0328.html">20260104_0328</a>
<a href="archive/20260103_0325.html">20260103_0325</a>
<a href="archive/20260102_0339.html">20260102_0339</a>
<a href="archive/20260101_0329.html">20260101_0329</a>
<a href="archive/20251231_0333.html">20251231_0333</a>
<a href="archive/20251230_0332.html">20251230_0332</a>
<a href="archive/20251229_0329.html">20251229_0329</a>
<a href="archive/20251228_0332.html">20251228_0332</a>
<a href="archive/20251227_0329.html">20251227_0329</a>
<a href="archive/20251226_0330.html">20251226_0330</a>
<a href="archive/20251225_0329.html">20251225_0329</a>
<a href="archive/20251224_0331.html">20251224_0331</a>
<a href="archive/20251223_0332.html">20251223_0332</a>
<a href="archive/20251222_0328.html">20251222_0328</a>
<a href="archive/20251221_0329.html">20251221_0329</a>
<a href="archive/20251220_0330.html">20251220_0330</a>
<a href="archive/20251219_0330.html">20251219_0330</a>
<a href="archive/20251218_0345.html">20251218_0345</a>
<a href="archive/20251217_0332.html">20251217_0332</a>
<a href="archive/20251216_0333.html">20251216_0333</a>
<a href="archive/20251215_0333.html">20251215_0333</a>
<a href="archive/20251214_0327.html">20251214_0327</a>
<a href="archive/20251212_0333.html">20251212_0333</a>
<a href="archive/20251211_0331.html">20251211_0331</a>
<a href="archive/20251210_0332.html">20251210_0332</a>
<a href="archive/20251209_0331.html">20251209_0331</a>
<a href="archive/20251208_0328.html">20251208_0328</a>
<a href="archive/20251207_0327.html">20251207_0327</a>
<a href="archive/20251206_0330.html">20251206_0330</a>
<a href="archive/20251205_0331.html">20251205_0331</a>
<a href="archive/20251204_0331.html">20251204_0331</a>
<a href="archive/20251203_0333.html">20251203_0333</a>
<a href="archive/20251202_0335.html">20251202_0335</a>
<a href="archive/20251201_0328.html">20251201_0328</a></div>
    </details>
    <div class="footer">Generated by arxiv-tracker</div>
  </div>
</body></html>
