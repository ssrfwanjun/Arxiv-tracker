<!doctype html>
<html><head><meta charset="utf-8"><meta name="viewport" content="width=device-width,initial-scale=1">
<title>arXiv 论文速递</title><style>
:root {
  --bg:#f8fafc; --card:#ffffff; --text:#0f172a; --muted:#667085; --border:#e5e7eb; --acc:#2563eb;
}
:root[data-theme="dark"] {
  --bg:#0b0f17; --card:#111827; --text:#e5e7eb; --muted:#9ca3af; --border:#1f2937; --acc:#2563eb;
}
*{box-sizing:border-box} body{margin:0;background:var(--bg);color:var(--text);
  font-family:ui-sans-serif,system-ui,-apple-system,Segoe UI,Roboto,Helvetica,Arial;line-height:1.6;}
.container{max-width:900px;margin:0 auto;padding:18px;}
.header{display:flex;gap:10px;justify-content:space-between;align-items:center;margin:8px 0 16px;flex-wrap:wrap}
h1{font-size:22px;margin:0}
.badge{font-size:12px;color:#111827;background:var(--acc);padding:2px 8px;border-radius:999px}
.card{background:var(--card);border:1px solid var(--border);border-radius:16px;padding:16px 18px;margin:14px 0;box-shadow:0 1px 2px rgba(0,0,0,.04)}
.title{font-weight:700;margin:0 0 6px 0;font-size:18px}
.meta-line{color:var(--muted);font-size:13px;margin:2px 0}
.links a{color:var(--acc);text-decoration:none;margin-right:12px}
.detail{margin-top:10px;background:rgba(2,6,23,.03);border:1px solid var(--border);border-radius:10px;padding:8px 10px}
summary{cursor:pointer;color:var(--acc)}
.mono{white-space:pre-wrap;background:rgba(2,6,23,.03);border:1px solid var(--border);padding:10px;border-radius:10px}
.row{display:grid;grid-template-columns:1fr;gap:12px}
@media (min-width: 860px) {
  .row-2{grid-template-columns:1fr 1fr}
}
.footer{color:var(--muted);font-size:13px;margin:20px 0 10px}
.hr{height:1px;background:var(--border);margin:14px 0}
.history-list a{display:block;color:var(--acc);text-decoration:none;margin:4px 0}
.controls{display:flex;gap:8px;align-items:center}
.btn{border:1px solid var(--border);background:var(--card);padding:6px 10px;border-radius:10px;cursor:pointer;color:var(--text)}
.btn:hover{border-color:var(--acc)}
</style>
<script>
(function() {
  const root = document.documentElement;
  function apply(t) {
    if (t==='dark') root.setAttribute('data-theme','dark');
    else if (t==='light') root.removeAttribute('data-theme');
    else {
      if (window.matchMedia && window.matchMedia('(prefers-color-scheme: dark)').matches)
        root.setAttribute('data-theme','dark');
      else root.removeAttribute('data-theme');
    }
  }
  let t = localStorage.getItem('theme') || 'light';
  if (!['light','dark','auto'].includes(t)) t='light';
  apply(t);
  window.__toggleTheme = function() {
    let cur = localStorage.getItem('theme') || 'light';
    if (cur==='light') cur='dark';
    else if (cur==='dark') cur='auto';
    else cur='light';
    localStorage.setItem('theme', cur);
    apply(cur);
    const el=document.getElementById('theme-label');
    if(el) el.textContent = cur.toUpperCase();
  }
  window.__expandAll = function(open) {
    document.querySelectorAll('details').forEach(d => d.open = !!open);
  }
})();
</script>
</head>
<body>
  <div class="container">
    <div class="header">
      <h1>arXiv 论文速递</h1>
      <div style="display:flex;gap:10px;align-items:center">
        
<div class="controls">
  <button class="btn" onclick="__toggleTheme()">Theme: <span id="theme-label" style="margin-left:6px">AUTO</span></button>
  <button class="btn" onclick="__expandAll(true)">Expand All</button>
  <button class="btn" onclick="__expandAll(false)">Collapse All</button>
</div>

        <span class="badge">2026-02-04 03:54</span>
      </div>
    </div>
    <div class="hr"></div>
    <div>Snapshot: 20260204_0354</div>
    <div class="row"><div class="card">
<div class="title">Reward-free Alignment for Conflicting Objectives</div>
<div class="meta-line">Authors: Peter Chen, Xiaopeng Li, Xi Chen, Tianyi Lin</div>
<div class="meta-line">First: 2026-02-02T18:59:52+00:00 · Latest: 2026-02-02T18:59:52+00:00</div>
<div class="meta-line">Comments: 27 pages</div>
<div class="links" style="margin-top:8px"><a href="https://arxiv.org/abs/2602.02495v1">Abs</a> · <a href="https://arxiv.org/pdf/2602.02495v1">PDF</a> · <a href="https://huggingface.co/huggingface">Code1</a> · <a href="https://huggingface.co/docs/hub/spaces">Code2</a></div>
<details class="detail"><summary>Abstract</summary>
<div class="mono">Direct alignment methods are increasingly used to align large language models (LLMs) with human preferences. However, many real-world alignment problems involve multiple conflicting objectives, where naive aggregation of preferences can lead to unstable training and poor trade-offs. In particular, weighted loss methods may fail to identify update directions that simultaneously improve all objectives, and existing multi-objective approaches often rely on explicit reward models, introducing additional complexity and distorting user-specified preferences. The contributions of this paper are two-fold. First, we propose a Reward-free Alignment framework for Conflicted Objectives (RACO) that directly leverages pairwise preference data and resolves gradient conflicts via a novel clipped variant of conflict-averse gradient descent. We provide convergence guarantees to Pareto-critical points that respect user-specified objective weights, and further show that clipping can strictly improve convergence rate in the two-objective setting. Second, we improve our method using some heuristics and conduct experiments to demonstrate the compatibility of the proposed framework for LLM alignment. Both qualitative and quantitative evaluations on multi-objective summarization and safety alignment tasks across multiple LLM families (Qwen 3, Llama 3, Gemma 3) show that our method consistently achieves better Pareto trade-offs compared to existing multi-objective alignment baselines.</div></details>
<details class="detail"><summary>中文标题/摘要</summary>
<div class="mono"><b>标题：</b>面向冲突目标的无奖励对齐方法</div>
<div class="mono" style="margin-top:8px">直接对齐方法正日益广泛地用于将大语言模型（LLM）与人类偏好对齐。然而，许多现实世界的对齐问题涉及多个相互冲突的目标，其中对偏好的简单聚合可能导致训练不稳定和权衡效果不佳。具体而言，加权损失方法可能无法识别同时改进所有目标的更新方向，而现有的多目标方法通常依赖显式奖励模型，这引入了额外的复杂性并可能扭曲用户指定的偏好。本文的贡献包括两方面：首先，我们提出了一种面向冲突目标的无奖励对齐框架（RACO），该框架直接利用成对偏好数据，并通过一种新颖的冲突规避梯度下降剪裁变体来解决梯度冲突。我们提供了收敛到尊重用户指定目标权重的帕累托临界点的理论保证，并进一步证明在双目标场景中剪裁操作能严格提升收敛速率。其次，我们通过启发式方法改进该算法，并进行实验验证所提框架在LLM对齐任务中的适用性。在多目标摘要生成和安全对齐任务上，对多个LLM系列（Qwen 3、Llama 3、Gemma 3）的定性与定量评估均表明，相较于现有多目标对齐基线方法，我们的方法能持续实现更优的帕累托权衡。</div>
</details>
<details class="detail"><summary>Summary / 总结</summary>
<div class="mono">This research addresses the challenge of aligning large language models with multiple conflicting human preferences, where naive aggregation can cause unstable training and suboptimal trade-offs. The authors propose a reward-free alignment framework called RACO, which directly uses pairwise preference data and resolves gradient conflicts through a novel clipped variant of conflict-averse gradient descent, offering convergence guarantees to Pareto-critical points that respect user-specified weights. Experimental evaluations on multi-objective summarization and safety alignment tasks across models like Qwen 3, Llama 3, and Gemma 3 demonstrate that RACO consistently achieves better Pareto trade-offs compared to existing baselines.</div>
<div class="mono" style="margin-top:8px">本研究针对大语言模型与多个冲突的人类偏好进行对齐的挑战，其中简单的偏好聚合方法可能导致训练不稳定和次优权衡。作者提出了RACO，一种无需奖励模型的对齐框架，直接利用成对偏好数据，并通过一种新颖的裁剪式冲突规避梯度下降法来解决梯度冲突，理论上保证了收敛到帕累托临界点。在多目标摘要和安全对齐任务上对Qwen 3、Llama 3和Gemma 3等模型的实验评估表明，该方法相比现有基线能持续实现更好的帕累托权衡。</div>
</details>
</div>
<div class="card">
<div class="title">PixelGen: Pixel Diffusion Beats Latent Diffusion with Perceptual Loss</div>
<div class="meta-line">Authors: Zehong Ma, Ruihan Xu, Shiliang Zhang</div>
<div class="meta-line">First: 2026-02-02T18:59:42+00:00 · Latest: 2026-02-02T18:59:42+00:00</div>
<div class="meta-line">Comments: Project Pages: https://zehong-ma.github.io/PixelGen/</div>
<div class="links" style="margin-top:8px"><a href="https://arxiv.org/abs/2602.02493v1">Abs</a> · <a href="https://arxiv.org/pdf/2602.02493v1">PDF</a> · <a href="https://github.com/Zehong-Ma/PixelGen">Code1</a> · <a href="https://huggingface.co/huggingface">Code2</a> · <a href="https://huggingface.co/docs/hub/spaces">Code3</a> · <a href="https://zehong-ma.github.io/PixelGen/">Project1</a></div>
<details class="detail"><summary>Abstract</summary>
<div class="mono">Pixel diffusion generates images directly in pixel space in an end-to-end manner, avoiding the artifacts and bottlenecks introduced by VAEs in two-stage latent diffusion. However, it is challenging to optimize high-dimensional pixel manifolds that contain many perceptually irrelevant signals, leaving existing pixel diffusion methods lagging behind latent diffusion models. We propose PixelGen, a simple pixel diffusion framework with perceptual supervision. Instead of modeling the full image manifold, PixelGen introduces two complementary perceptual losses to guide diffusion model towards learning a more meaningful perceptual manifold. An LPIPS loss facilitates learning better local patterns, while a DINO-based perceptual loss strengthens global semantics. With perceptual supervision, PixelGen surpasses strong latent diffusion baselines. It achieves an FID of 5.11 on ImageNet-256 without classifier-free guidance using only 80 training epochs, and demonstrates favorable scaling performance on large-scale text-to-image generation with a GenEval score of 0.79. PixelGen requires no VAEs, no latent representations, and no auxiliary stages, providing a simpler yet more powerful generative paradigm. Codes are publicly available at https://github.com/Zehong-Ma/PixelGen.</div></details>
<details class="detail"><summary>中文标题/摘要</summary>
<div class="mono"><b>标题：</b>PixelGen：基于感知损失的像素扩散超越潜在扩散</div>
<div class="mono" style="margin-top:8px">像素扩散以端到端方式直接在像素空间生成图像，避免了变分自编码器在两阶段潜在扩散中引入的伪影和瓶颈。然而，优化包含大量感知无关信号的高维像素流形具有挑战性，导致现有像素扩散方法落后于潜在扩散模型。我们提出PixelGen，一种带有感知监督的简单像素扩散框架。PixelGen不建模完整图像流形，而是引入两种互补的感知损失来引导扩散模型学习更具意义的感知流形：LPIPS损失促进学习更好的局部模式，而基于DINO的感知损失增强全局语义。通过感知监督，PixelGen超越了强潜在扩散基线——在仅80个训练周期且无需无分类器引导的情况下，于ImageNet-256上取得5.11的FID分数；在大规模文本到图像生成中展现出0.79的GenEval评分，具备优越的扩展性能。PixelGen无需变分自编码器、潜在表示或辅助阶段，提供了一种更简单却更强大的生成范式。代码已公开于https://github.com/Zehong-Ma/PixelGen。</div>
</details>
<details class="detail"><summary>Summary / 总结</summary>
<div class="mono">Pixel diffusion models generate images directly in pixel space, avoiding artifacts from two-stage latent diffusion, but struggle with high-dimensional pixel manifolds containing perceptually irrelevant signals. To address this, PixelGen introduces a simple pixel diffusion framework with perceptual supervision, using an LPIPS loss to improve local patterns and a DINO-based loss to enhance global semantics. Experiments show PixelGen outperforms latent diffusion baselines, achieving an FID of 5.11 on ImageNet-256 without classifier-free guidance in 80 epochs and a GenEval score of 0.79 in text-to-image generation, offering a simpler yet more powerful generative paradigm without VAEs or auxiliary stages.</div>
<div class="mono" style="margin-top:8px">像素扩散模型直接在像素空间中生成图像，避免了潜在扩散中变分自编码器引入的伪影，但由于感知无关信号的存在，优化高维像素流形具有挑战性。为此，PixelGen提出了一种简单的像素扩散框架，通过两种互补的感知损失进行监督：LPIPS损失用于改善局部模式，基于DINO的损失用于增强全局语义，从而引导模型学习更有意义的感知流形。实验表明，PixelGen超越了潜在扩散基线，在仅80个训练周期内，无需分类器引导即在ImageNet-256上实现了5.11的FID，在文本到图像生成中获得了0.79的GenEval分数，提供了一种无需VAE或辅助阶段的更简单且更强大的生成范式。</div>
</details>
</div>
<div class="card">
<div class="title">RE-TRAC: REcursive TRAjectory Compression for Deep Search Agents</div>
<div class="meta-line">Authors: Jialiang Zhu, Gongrui Zhang, Xiaolong Ma, Lin Xu, Miaosen Zhang, Ruiqi Yang, Song Wang, Kai Qiu, Zhirong Wu, Qi Dai, Ruichun Ma, Bei Liu, Yifan Yang, Chong Luo, Zhengyuan Yang, Linjie Li, Lijuan Wang, Weizhu Chen, Xin Geng, Baining Guo</div>
<div class="meta-line">First: 2026-02-02T18:58:07+00:00 · Latest: 2026-02-02T18:58:07+00:00</div>
<div class="links" style="margin-top:8px"><a href="https://arxiv.org/abs/2602.02486v1">Abs</a> · <a href="https://arxiv.org/pdf/2602.02486v1">PDF</a> · <a href="https://huggingface.co/huggingface">Code1</a> · <a href="https://huggingface.co/docs/hub/spaces">Code2</a></div>
<details class="detail"><summary>Abstract</summary>
<div class="mono">LLM-based deep research agents are largely built on the ReAct framework. This linear design makes it difficult to revisit earlier states, branch into alternative search directions, or maintain global awareness under long contexts, often leading to local optima, redundant exploration, and inefficient search. We propose Re-TRAC, an agentic framework that performs cross-trajectory exploration by generating a structured state representation after each trajectory to summarize evidence, uncertainties, failures, and future plans, and conditioning subsequent trajectories on this state representation. This enables iterative reflection and globally informed planning, reframing research as a progressive process. Empirical results show that Re-TRAC consistently outperforms ReAct by 15-20% on BrowseComp with frontier LLMs. For smaller models, we introduce Re-TRAC-aware supervised fine-tuning, achieving state-of-the-art performance at comparable scales. Notably, Re-TRAC shows a monotonic reduction in tool calls and token usage across rounds, indicating progressively targeted exploration driven by cross-trajectory reflection rather than redundant search.</div></details>
<details class="detail"><summary>中文标题/摘要</summary>
<div class="mono"><b>标题：</b>RE-TRAC：面向深度搜索智能体的递归轨迹压缩框架</div>
<div class="mono" style="margin-top:8px">基于大语言模型的深度研究智能体主要构建于ReAct框架之上。这种线性设计难以回溯早期状态、分支探索替代路径或在长上下文下保持全局感知，常导致局部最优、冗余探索和低效搜索。我们提出Re-TRAC智能体框架，通过在每个轨迹后生成结构化状态表示来总结证据、不确定性、失败案例与未来计划，并基于该状态表示引导后续轨迹，实现跨轨迹探索。这支持迭代反思与全局知情规划，将研究重构为渐进过程。实证结果表明，在BrowseComp基准上，Re-TRAC使用前沿大语言模型时持续优于ReAct框架15-20%。针对较小模型，我们引入Re-TRAC感知的监督微调方法，在同等规模下达到最先进性能。值得注意的是，Re-TRAC在多轮迭代中呈现工具调用次数与令牌用量的单调递减，表明其通过跨轨迹反思驱动渐进式定向探索，而非冗余搜索。</div>
</details>
<details class="detail"><summary>Summary / 总结</summary>
<div class="mono">The research addresses limitations in LLM-based deep research agents built on the ReAct framework, which suffers from linear trajectories that hinder revisiting earlier states, branching into alternatives, and maintaining global awareness, often resulting in local optima and redundant exploration. The proposed method, Re-TRAC, introduces a framework that performs cross-trajectory exploration by generating a structured state representation after each trajectory to summarize evidence, uncertainties, failures, and future plans, and conditions subsequent trajectories on this representation to enable iterative reflection and globally informed planning. Experimental results demonstrate that Re-TRAC consistently outperforms ReAct by 15-20% on BrowseComp with frontier LLMs, and for smaller models, Re-TRAC-aware supervised fine-tuning achieves state-of-the-art performance at comparable scales, while also showing a monotonic reduction in tool calls and token usage across rounds, indicating progressively targeted exploration.</div>
<div class="mono" style="margin-top:8px">该研究的动机源于基于大语言模型的深度研究智能体所采用的线性ReAct框架存在局限性，难以回溯早期状态、探索替代搜索方向以及在长上下文中保持全局意识，常导致局部最优、冗余探索和低效搜索。提出的方法Re-TRAC引入了一个智能体框架，通过在每个轨迹后生成结构化的状态表示来总结证据、不确定性、失败和未来计划，并以此表示条件化后续轨迹，从而实现迭代反思和全局知情规划。实验结果表明，在BrowseComp任务上，Re-TRAC使用前沿大语言模型时持续优于ReAct 15-20%；对于较小模型，通过Re-TRAC感知的监督微调在可比规模上达到了最先进的性能，同时工具调用和令牌使用量在多轮中单调减少，表明探索逐步更具针对性。</div>
</details>
</div>
<div class="card">
<div class="title">Flow Policy Gradients for Robot Control</div>
<div class="meta-line">Authors: Brent Yi, Hongsuk Choi, Himanshu Gaurav Singh, Xiaoyu Huang, Takara E. Truong, Carmelo Sferrazza, Yi Ma, Rocky Duan, Pieter Abbeel, Guanya Shi, Karen Liu, Angjoo Kanazawa</div>
<div class="meta-line">First: 2026-02-02T18:56:49+00:00 · Latest: 2026-02-02T18:56:49+00:00</div>
<div class="meta-line">Comments: Project webpage: https://hongsukchoi.github.io/fpo-control</div>
<div class="links" style="margin-top:8px"><a href="https://arxiv.org/abs/2602.02481v1">Abs</a> · <a href="https://arxiv.org/pdf/2602.02481v1">PDF</a> · <a href="https://huggingface.co/huggingface">Code1</a> · <a href="https://huggingface.co/docs/hub/spaces">Code2</a> · <a href="https://hongsukchoi.github.io/fpo-control">Project1</a></div>
<details class="detail"><summary>Abstract</summary>
<div class="mono">Likelihood-based policy gradient methods are the dominant approach for training robot control policies from rewards. These methods rely on differentiable action likelihoods, which constrain policy outputs to simple distributions like Gaussians. In this work, we show how flow matching policy gradients -- a recent framework that bypasses likelihood computation -- can be made effective for training and fine-tuning more expressive policies in challenging robot control settings. We introduce an improved objective that enables success in legged locomotion, humanoid motion tracking, and manipulation tasks, as well as robust sim-to-real transfer on two humanoid robots. We then present ablations and analysis on training dynamics. Results show how policies can exploit the flow representation for exploration when training from scratch, as well as improved fine-tuning robustness over baselines.</div></details>
<details class="detail"><summary>中文标题/摘要</summary>
<div class="mono"><b>标题：</b>机器人控制的流策略梯度方法</div>
<div class="mono" style="margin-top:8px">基于似然的策略梯度方法是当前从奖励训练机器人控制策略的主流方法。这类方法依赖可微分的动作似然，将策略输出限制在高斯分布等简单分布上。本研究展示了流匹配策略梯度——一种绕过似然计算的新近框架——如何在具有挑战性的机器人控制场景中有效训练和微调更具表达能力的策略。我们提出了一种改进的目标函数，使其在足式运动、人形机器人运动跟踪和操作任务中取得成功，并在两台人形机器人上实现了稳健的仿真到现实迁移。随后我们通过消融实验对训练动态进行了分析。结果表明，策略可利用流表示进行探索性训练，并在微调鲁棒性上优于基线方法。</div>
</details>
<details class="detail"><summary>Summary / 总结</summary>
<div class="mono">The research is motivated by the limitations of likelihood-based policy gradient methods in robot control, which rely on differentiable action likelihoods and thus restrict policies to simple distributions like Gaussians. The method introduces flow matching policy gradients, a framework that bypasses likelihood computation, and proposes an improved objective to train more expressive policies. Experimental results demonstrate effectiveness in legged locomotion, humanoid motion tracking, and manipulation tasks, with successful sim-to-real transfer on two humanoid robots, showing enhanced exploration and fine-tuning robustness compared to baselines.</div>
<div class="mono" style="margin-top:8px">本研究旨在解决基于似然的策略梯度方法在机器人控制中的局限性，这些方法依赖可微的动作似然，从而将策略输出限制于高斯分布等简单分布。该方法采用流匹配策略梯度框架，绕过似然计算，并提出了改进的目标函数来训练和微调更具表达能力的策略。关键实验结果在腿式运动、人形运动跟踪和操作等挑战性任务中验证了有效性，并在两台人形机器人上实现了成功的仿真到现实迁移，显示出相比基线方法更强的探索能力和微调鲁棒性。</div>
</details>
</div>
<div class="card">
<div class="title">AgentRx: Diagnosing AI Agent Failures from Execution Trajectories</div>
<div class="meta-line">Authors: Shraddha Barke, Arnav Goyal, Alind Khare, Avaljot Singh, Suman Nath, Chetan Bansal</div>
<div class="meta-line">First: 2026-02-02T18:54:07+00:00 · Latest: 2026-02-02T18:54:07+00:00</div>
<div class="links" style="margin-top:8px"><a href="https://arxiv.org/abs/2602.02475v1">Abs</a> · <a href="https://arxiv.org/pdf/2602.02475v1">PDF</a> · <a href="https://huggingface.co/huggingface">Code1</a> · <a href="https://huggingface.co/docs/hub/spaces">Code2</a></div>
<details class="detail"><summary>Abstract</summary>
<div class="mono">AI agents often fail in ways that are difficult to localize because executions are probabilistic, long-horizon, multi-agent, and mediated by noisy tool outputs. We address this gap by manually annotating failed agent runs and release a novel benchmark of 115 failed trajectories spanning structured API workflows, incident management, and open-ended web/file tasks. Each trajectory is annotated with a critical failure step and a category from a grounded-theory derived, cross-domain failure taxonomy. To mitigate the human cost of failure attribution, we present AGENTRX, an automated domain-agnostic diagnostic framework that pinpoints the critical failure step in a failed agent trajectory. It synthesizes constraints, evaluates them step-by-step, and produces an auditable validation log of constraint violations with associated evidence; an LLM-based judge uses this log to localize the critical step and category. Our framework improves step localization and failure attribution over existing baselines across three domains.</div></details>
<details class="detail"><summary>中文标题/摘要</summary>
<div class="mono"><b>标题：</b>AgentRx：基于执行轨迹诊断AI智能体故障</div>
<div class="mono" style="margin-top:8px">AI智能体的执行过程具有概率性、长周期、多智能体协作及受噪声工具输出影响等特点，导致其故障难以定位。为填补这一研究空白，我们通过人工标注故障运行轨迹，构建了一个包含115条故障轨迹的新型基准数据集，涵盖结构化API工作流、事件管理及开放式网页/文件任务。每条轨迹均标注了关键故障步骤，并依据扎根理论推导的跨领域故障分类体系进行分类。为降低人工归因成本，我们提出了AGENTRX——一种自动化领域无关的诊断框架，可精准定位故障轨迹中的关键失败步骤。该框架通过综合约束条件、逐步评估执行过程，生成包含约束违反证据的可审计验证日志；基于大语言模型的判定器利用此日志定位关键步骤及故障类别。实验表明，该框架在三个不同领域中，其步骤定位与故障归因能力均优于现有基线方法。</div>
</details>
<details class="detail"><summary>Summary / 总结</summary>
<div class="mono">The research addresses the challenge of diagnosing failures in AI agents, which are difficult to localize due to probabilistic, long-horizon, and multi-agent executions mediated by noisy tools. The method involves creating a manually annotated benchmark of 115 failed trajectories across three domains and introducing AGENTRX, an automated diagnostic framework that synthesizes constraints, evaluates them step-by-step to produce an auditable validation log, and uses an LLM-based judge to pinpoint the critical failure step and category. Experimental results show that the framework improves step localization and failure attribution over existing baselines across structured API workflows, incident management, and open-ended web/file tasks.</div>
<div class="mono" style="margin-top:8px">本研究旨在解决AI智能体故障诊断的挑战，这些故障由于执行过程具有概率性、长时程、多智能体以及受噪声工具输出影响而难以定位。方法包括创建包含三个领域115条手动标注故障轨迹的基准，并提出了AGENTRX这一自动化诊断框架，该框架综合约束条件、逐步评估以生成可审计的验证日志，并利用基于大语言模型的判断器来精确定位关键故障步骤和类别。实验结果表明，在结构化API工作流、事件管理和开放式网页/文件任务中，该框架在步骤定位和故障归因方面优于现有基线方法。</div>
</details>
</div>
<div class="card">
<div class="title">MemSkill: Learning and Evolving Memory Skills for Self-Evolving Agents</div>
<div class="meta-line">Authors: Haozhen Zhang, Quanyu Long, Jianzhu Bao, Tao Feng, Weizhi Zhang, Haodong Yue, Wenya Wang</div>
<div class="meta-line">First: 2026-02-02T18:53:28+00:00 · Latest: 2026-02-02T18:53:28+00:00</div>
<div class="meta-line">Comments: Code is available at https://github.com/ViktorAxelsen/MemSkill</div>
<div class="links" style="margin-top:8px"><a href="https://arxiv.org/abs/2602.02474v1">Abs</a> · <a href="https://arxiv.org/pdf/2602.02474v1">PDF</a> · <a href="https://github.com/ViktorAxelsen/MemSkill">Code1</a> · <a href="https://huggingface.co/huggingface">Code2</a> · <a href="https://huggingface.co/docs/hub/spaces">Code3</a></div>
<details class="detail"><summary>Abstract</summary>
<div class="mono">Most Large Language Model (LLM) agent memory systems rely on a small set of static, hand-designed operations for extracting memory. These fixed procedures hard-code human priors about what to store and how to revise memory, making them rigid under diverse interaction patterns and inefficient on long histories. To this end, we present \textbf{MemSkill}, which reframes these operations as learnable and evolvable memory skills, structured and reusable routines for extracting, consolidating, and pruning information from interaction traces. Inspired by the design philosophy of agent skills, MemSkill employs a \emph{controller} that learns to select a small set of relevant skills, paired with an LLM-based \emph{executor} that produces skill-guided memories. Beyond learning skill selection, MemSkill introduces a \emph{designer} that periodically reviews hard cases where selected skills yield incorrect or incomplete memories, and evolves the skill set by proposing refinements and new skills. Together, MemSkill forms a closed-loop procedure that improves both the skill-selection policy and the skill set itself. Experiments on LoCoMo, LongMemEval, HotpotQA, and ALFWorld demonstrate that MemSkill improves task performance over strong baselines and generalizes well across settings. Further analyses shed light on how skills evolve, offering insights toward more adaptive, self-evolving memory management for LLM agents.</div></details>
<details class="detail"><summary>中文标题/摘要</summary>
<div class="mono"><b>标题：</b>MemSkill：面向自进化智能体的记忆技能学习与演化</div>
<div class="mono" style="margin-top:8px">现有大语言模型智能体记忆系统多依赖少量静态人工设计的记忆提取操作。这些固定流程将人类对存储内容和记忆修订方式的先验知识硬编码其中，导致其在多样化交互模式中缺乏灵活性，且对长历史记录处理效率低下。为此，我们提出\textbf{MemSkill}，将记忆操作重构为可学习、可演化的记忆技能——即结构化、可复用的交互轨迹信息提取、整合与剪枝例程。受智能体技能设计理念启发，MemSkill采用\emph{控制器}学习选择少量相关技能，并配合基于大语言模型的\emph{执行器}生成技能引导的记忆。除学习技能选择外，MemSkill引入\emph{设计器}定期审查因所选技能产生错误或不完整记忆的困难案例，通过提出改进方案和新技能来演化技能集合。MemSkill由此形成同时优化技能选择策略与技能集合的闭环流程。在LoCoMo、LongMemEval、HotpotQA和ALFWorld上的实验表明，MemSkill在任务性能上超越强基线模型，并具备良好的跨场景泛化能力。进一步分析揭示了技能的演化机制，为构建更具适应性的大语言模型智能体自进化记忆管理系统提供了新见解。</div>
</details>
<details class="detail"><summary>Summary / 总结</summary>
<div class="mono">Current LLM agent memory systems often depend on static, manually designed operations for memory extraction, which can be inflexible and inefficient across varied interactions and long histories. To address this, MemSkill introduces learnable and evolvable memory skills—structured routines for extracting, consolidating, and pruning information—using a controller to select relevant skills and an LLM-based executor to produce skill-guided memories, along with a designer that refines and creates new skills based on hard cases. Experimental results on benchmarks including LoCoMo, LongMemEval, HotpotQA, and ALFWorld show that MemSkill outperforms strong baselines in task performance and generalizes effectively, with analyses revealing how skills evolve to enable more adaptive memory management.</div>
<div class="mono" style="margin-top:8px">现有大型语言模型智能体记忆系统通常依赖少量静态、人工设计的记忆提取操作，这在不同交互模式和长历史记录中显得僵化且低效。为此，MemSkill将记忆操作重构为可学习和进化的记忆技能——即用于提取、整合和修剪信息的结构化可重用例程，它采用控制器选择相关技能，结合基于LLM的执行器生成技能引导的记忆，并引入设计器定期审查技能选择导致错误或不完整记忆的困难案例，通过改进和新增技能来进化技能集。在LoCoMo、LongMemEval、HotpotQA和ALFWorld等基准上的实验表明，MemSkill在任务性能上优于强基线且泛化良好，进一步分析揭示了技能如何进化，为更自适应、自进化的LLM智能体记忆管理提供了见解。</div>
</details>
</div>
<div class="card">
<div class="title">Multi-head automated segmentation by incorporating detection head into the contextual layer neural network</div>
<div class="meta-line">Authors: Edwin Kys, Febian Febian</div>
<div class="meta-line">First: 2026-02-02T18:51:25+00:00 · Latest: 2026-02-02T18:51:25+00:00</div>
<div class="meta-line">Comments: 8 pages, 3 figures, 1 table</div>
<div class="links" style="margin-top:8px"><a href="https://arxiv.org/abs/2602.02471v1">Abs</a> · <a href="https://arxiv.org/pdf/2602.02471v1">PDF</a> · <a href="https://huggingface.co/huggingface">Code1</a> · <a href="https://huggingface.co/docs/hub/spaces">Code2</a></div>
<details class="detail"><summary>Abstract</summary>
<div class="mono">Deep learning based auto segmentation is increasingly used in radiotherapy, but conventional models often produce anatomically implausible false positives, or hallucinations, in slices lacking target structures. We propose a gated multi-head Transformer architecture based on Swin U-Net, augmented with inter-slice context integration and a parallel detection head, which jointly performs slice-level structure detection via a multi-layer perceptron and pixel-level segmentation through a context-enhanced stream. Detection outputs gate the segmentation predictions to suppress false positives in anatomically invalid slices, and training uses slice-wise Tversky loss to address class imbalance. Experiments on the Prostate-Anatomical-Edge-Cases dataset from The Cancer Imaging Archive demonstrate that the gated model substantially outperforms a non-gated segmentation-only baseline, achieving a mean Dice loss of $0.013 \pm 0.036$ versus $0.732 \pm 0.314$, with detection probabilities strongly correlated with anatomical presence, effectively eliminating spurious segmentations. In contrast, the non-gated model exhibited higher variability and persistent false positives across all slices. These results indicate that detection-based gating enhances robustness and anatomical plausibility in automated segmentation applications, reducing hallucinated predictions without compromising segmentation quality in valid slices, and offers a promising approach for improving the reliability of clinical radiotherapy auto-contouring workflows.</div></details>
<details class="detail"><summary>中文标题/摘要</summary>
<div class="mono"><b>标题：</b>通过将检测头融入上下文层神经网络实现多头自动分割</div>
<div class="mono" style="margin-top:8px">基于深度学习的自动分割在放射治疗中应用日益广泛，但传统模型常在没有目标结构的切片中产生解剖学上不合理的假阳性（即幻觉）。我们提出一种基于Swin U-Net的门控多头Transformer架构，通过切片间上下文整合与并行检测头增强，联合执行多层感知机的切片级结构检测和上下文增强流的像素级分割。检测输出通过门控机制抑制解剖无效切片的假阳性分割预测，训练采用切片级Tversky损失以处理类别不平衡。在癌症影像档案库的前列腺解剖边缘案例数据集上的实验表明，门控模型显著优于非门控纯分割基线，平均Dice损失为$0.013 \pm 0.036$（对比$0.732 \pm 0.314$），检测概率与解剖存在性高度相关，有效消除虚假分割。非门控模型则表现出更高变异性和所有切片中的持续假阳性。这些结果表明基于检测的门控机制能提升自动分割应用的鲁棒性与解剖合理性，在保持有效切片分割质量的同时减少幻觉预测，为提升临床放疗自动勾画工作流程的可靠性提供了可行方案。</div>
</details>
<details class="detail"><summary>Summary / 总结</summary>
<div class="mono">To address the problem of anatomically implausible false positives (hallucinations) in deep learning-based auto-segmentation for radiotherapy, particularly in slices where target structures are absent, this work proposes a gated multi-head Transformer architecture. The method builds upon Swin U-Net, integrating inter-slice context and a parallel detection head that performs joint slice-level structure detection and pixel-level segmentation; the detection output gates the segmentation predictions to suppress false positives. Experimental evaluation on the Prostate-Anatomical-Edge-Cases dataset shows the gated model significantly outperforms a segmentation-only baseline, reducing the mean Dice loss to 0.013 ± 0.036 from 0.732 ± 0.314, with detection probabilities strongly correlated to anatomical presence and effective elimination of spurious segmentations, thereby enhancing robustness and anatomical plausibility for clinical auto-contouring.</div>
<div class="mono" style="margin-top:8px">为解决基于深度学习的放疗自动分割中存在的解剖学上不合理的假阳性（幻觉）问题，特别是在目标结构缺失的切片中，本研究提出了一种基于门控的多头Transformer架构。该方法以Swin U-Net为基础，整合了切片间上下文信息和一个并行的检测头，该检测头联合执行切片级结构检测和像素级分割；检测输出用于门控分割预测以抑制假阳性。在前列腺解剖边缘案例数据集上的实验评估表明，该门控模型显著优于仅分割的基线模型，其平均Dice损失为0.013 ± 0.036，而基线为0.732 ± 0.314，检测概率与解剖结构存在强相关，有效消除了虚假分割，从而增强了临床自动勾画工作流程的鲁棒性和解剖合理性。</div>
</details>
</div>
<div class="card">
<div class="title">Breaking the Reversal Curse in Autoregressive Language Models via Identity Bridge</div>
<div class="meta-line">Authors: Xutao Ma, Yixiao Huang, Hanlin Zhu, Somayeh Sojoudi</div>
<div class="meta-line">First: 2026-02-02T18:50:57+00:00 · Latest: 2026-02-02T18:50:57+00:00</div>
<div class="links" style="margin-top:8px"><a href="https://arxiv.org/abs/2602.02470v1">Abs</a> · <a href="https://arxiv.org/pdf/2602.02470v1">PDF</a> · <a href="https://huggingface.co/huggingface">Code1</a> · <a href="https://huggingface.co/docs/hub/spaces">Code2</a></div>
<details class="detail"><summary>Abstract</summary>
<div class="mono">Autoregressive large language models (LLMs) have achieved remarkable success in many complex tasks, yet they can still fail in very simple logical reasoning such as the &quot;reversal curse&quot; -- when trained on forward knowledge data of the form &quot;$A \rightarrow B$&quot; (e.g., Alice&#x27;s husband is Bob), the model is unable to deduce the reversal knowledge &quot;$B \leftarrow A$&quot; (e.g., Bob&#x27;s wife is Alice) during test. Extensive prior research suggests that this failure is an inherent, fundamental limit of autoregressive causal LLMs, indicating that these models tend to memorize factual-level knowledge rather than capture higher-level rules. In this paper, we challenge this view by showing that this seemingly fundamental limit can be mitigated by slightly tweaking the training data with a simple regularization data recipe called the Identity Bridge of the form &quot;$A \to A$&quot; (e.g., The name of Alice is Alice). Theoretically, we prove that under this recipe, even a one-layer transformer can break the reversal curse by analyzing the implicit bias of gradient descent. Empirically, we show that a 1B pretrained language model finetuned with the proposed data recipe achieves a 40% success rate on reversal tasks, in stark contrast to a near-zero success rate when trained solely on forward-knowledge data. Our work provides a novel theoretical foundation for the reversal curse and offers a principled, low-cost path to encouraging LLMs to learn higher-level rules from data.</div></details>
<details class="detail"><summary>中文标题/摘要</summary>
<div class="mono"><b>标题：</b>通过身份桥打破自回归语言模型中的逆转诅咒</div>
<div class="mono" style="margin-top:8px">自回归大语言模型（LLMs）在许多复杂任务中取得了显著成功，但在极简单的逻辑推理中仍可能失败，例如“逆转诅咒”——当模型在形式为“$A \rightarrow B$”（例如：爱丽丝的丈夫是鲍勃）的前向知识数据上训练后，在测试时无法推导出逆转知识“$B \leftarrow A$”（例如：鲍勃的妻子是爱丽丝）。大量先前研究表明，这种失败是自回归因果LLMs固有的根本性局限，表明这些模型倾向于记忆事实层面的知识而非捕捉更高层次的规则。本文通过证明这种看似根本的局限可以通过微调训练数据来缓解，从而挑战了这一观点。我们提出一种名为“身份桥”的简单正则化数据方案，其形式为“$A \to A$”（例如：爱丽丝的名字是爱丽丝）。理论上，我们通过分析梯度下降的隐式偏差，证明在此方案下，即使是单层Transformer也能打破逆转诅咒。实证表明，采用该数据方案微调的10亿参数预训练语言模型在逆转任务上取得了40%的成功率，与仅使用前向知识数据训练时接近零的成功率形成鲜明对比。我们的工作为逆转诅咒提供了新的理论基础，并为鼓励LLMs从数据中学习更高层次规则提供了一条原则性、低成本的路径。</div>
</details>
<details class="detail"><summary>Summary / 总结</summary>
<div class="mono">The study addresses the reversal curse in autoregressive language models, where models trained on forward knowledge (e.g., &#x27;Alice&#x27;s husband is Bob&#x27;) fail to infer the reverse relation (e.g., &#x27;Bob&#x27;s wife is Alice&#x27;), a limitation previously considered inherent. The method introduces an Identity Bridge regularization data recipe, adding simple identity statements (e.g., &#x27;The name of Alice is Alice&#x27;) to training data, which theoretically enables even a one-layer transformer to overcome this curse by guiding gradient descent toward learning relational rules. Experimentally, fine-tuning a 1B parameter model with this approach achieved a 40% success rate on reversal tasks, compared to near-zero rates without it, demonstrating a low-cost way to enhance logical reasoning.</div>
<div class="mono" style="margin-top:8px">本研究针对自回归语言模型中的逆转诅咒问题展开，该问题指模型在训练了前向知识（如“爱丽丝的丈夫是鲍勃”）后，无法推断逆向关系（如“鲍勃的妻子是爱丽丝”），这一局限此前被认为是模型固有的根本缺陷。所提出的方法引入了一种称为“身份桥”的简单数据正则化方案，即在训练数据中添加“A是A”形式的自指陈述。理论分析表明，通过梯度下降的隐式偏差，即使单层Transformer也能借此克服逆转诅咒。实验结果表明，使用该方案微调一个10亿参数模型后，其在逆转任务上的成功率达到了40%，与仅使用前向知识训练时接近零的成功率形成了鲜明对比。</div>
</details>
</div>
<div class="card">
<div class="title">Avenir-Web: Human-Experience-Imitating Multimodal Web Agents with Mixture of Grounding Experts</div>
<div class="meta-line">Authors: Aiden Yiliu Li, Xinyue Hao, Shilong Liu, Mengdi Wang</div>
<div class="meta-line">First: 2026-02-02T18:50:07+00:00 · Latest: 2026-02-02T18:50:07+00:00</div>
<div class="links" style="margin-top:8px"><a href="https://arxiv.org/abs/2602.02468v1">Abs</a> · <a href="https://arxiv.org/pdf/2602.02468v1">PDF</a> · <a href="https://huggingface.co/huggingface">Code1</a> · <a href="https://huggingface.co/docs/hub/spaces">Code2</a></div>
<details class="detail"><summary>Abstract</summary>
<div class="mono">Despite advances in multimodal large language models, autonomous web agents still struggle to reliably execute long-horizon tasks on complex and dynamic web interfaces. Existing agents often suffer from inaccurate element grounding, the absence of site-specific procedural knowledge, and unstable long-term task tracking and memory, particularly when operating over complex Document Object Model structures. To address these limitations, we introduce Avenir-Web, a web agent that achieves a new open-source state of the art on the Online-Mind2Web benchmark in real-world deployment. Avenir-Web leverages a Mixture of Grounding Experts, Experience-Imitation Planning for incorporating procedural priors, and a task-tracking checklist combined with adaptive memory to enable robust and seamless interaction across diverse user interface paradigms. We evaluate Avenir-Web on Online-Mind2Web, a rigorous benchmark of live and user-centered web tasks. Our results demonstrate that Avenir-Web significantly surpasses prior open-source agents and attains performance parity with top-tier proprietary models, thereby establishing a new open-source state of the art for reliable web agents on live websites.</div></details>
<details class="detail"><summary>中文标题/摘要</summary>
<div class="mono"><b>标题：</b>Avenir-Web：基于混合定位专家机制的人机体验仿生多模态网络代理</div>
<div class="mono" style="margin-top:8px">尽管多模态大语言模型取得进展，自主网络代理在复杂动态网页界面上执行长周期任务仍存在可靠性不足的问题。现有代理常面临元素定位不准、缺乏站点特定流程知识、长期任务跟踪与记忆不稳定等挑战，尤其在处理复杂文档对象模型结构时更为突出。为突破这些局限，我们提出Avenir-Web网络代理，该代理在真实场景部署中于Online-Mind2Web基准测试创下开源领域新标杆。Avenir-Web融合三大核心技术：混合定位专家机制、融入流程先验的体验仿生规划、结合自适应记忆的任务追踪清单，从而实现对多样化用户界面范式的鲁棒无缝交互。我们在以实时用户为中心构建的严格基准Online-Mind2Web上评估Avenir-Web，结果表明其显著超越现有开源代理，并与顶级专有模型达到性能持平，由此为实时网站可靠网络代理确立了开源领域的新技术标杆。</div>
</details>
<details class="detail"><summary>Summary / 总结</summary>
<div class="mono">To address the challenges of inaccurate element grounding, lack of site-specific procedural knowledge, and unstable long-term task tracking in autonomous web agents operating on complex web interfaces, this paper introduces Avenir-Web. The method employs a Mixture of Grounding Experts for precise element identification, Experience-Imitation Planning to incorporate procedural priors, and a task-tracking checklist with adaptive memory for robust interaction. Experimental evaluation on the Online-Mind2Web benchmark shows that Avenir-Web significantly outperforms prior open-source agents and achieves performance comparable to top-tier proprietary models, setting a new open-source state of the art for executing tasks on live websites.</div>
<div class="mono" style="margin-top:8px">自主网络代理在处理复杂动态网页界面的长时程任务时，常因元素定位不准、缺乏站点特定程序知识以及任务跟踪与记忆不稳定而失败。为解决这些局限，研究提出了Avenir-Web，它采用混合定位专家机制进行精确元素识别，通过经验模仿规划融入程序先验，并结合任务跟踪清单与自适应记忆以实现稳健交互。在基于真实网站的Online-Mind2Web基准测试中，Avenir-Web显著超越了先前开源代理，并达到了与顶级专有模型相当的性能，从而确立了开源网络代理在真实网站上的新最优水平。</div>
</details>
</div>
<div class="card">
<div class="title">MentisOculi: Revealing the Limits of Reasoning with Mental Imagery</div>
<div class="meta-line">Authors: Jana Zeller, Thaddäus Wiedemer, Fanfei Li, Thomas Klein, Prasanna Mayilvahanan, Matthias Bethge, Felix Wichmann, Ryan Cotterell, Wieland Brendel</div>
<div class="meta-line">First: 2026-02-02T18:49:06+00:00 · Latest: 2026-02-02T18:49:06+00:00</div>
<div class="meta-line">Comments: 9 pages, 8 figures</div>
<div class="links" style="margin-top:8px"><a href="https://arxiv.org/abs/2602.02465v1">Abs</a> · <a href="https://arxiv.org/pdf/2602.02465v1">PDF</a> · <a href="https://huggingface.co/huggingface">Code1</a> · <a href="https://huggingface.co/docs/hub/spaces">Code2</a></div>
<details class="detail"><summary>Abstract</summary>
<div class="mono">Frontier models are transitioning from multimodal large language models (MLLMs) that merely ingest visual information to unified multimodal models (UMMs) capable of native interleaved generation. This shift has sparked interest in using intermediate visualizations as a reasoning aid, akin to human mental imagery. Central to this idea is the ability to form, maintain, and manipulate visual representations in a goal-oriented manner. To evaluate and probe this capability, we develop MentisOculi, a procedural, stratified suite of multi-step reasoning problems amenable to visual solution, tuned to challenge frontier models. Evaluating visual strategies ranging from latent tokens to explicit generated imagery, we find they generally fail to improve performance. Analysis of UMMs specifically exposes a critical limitation: While they possess the textual reasoning capacity to solve a task and can sometimes generate correct visuals, they suffer from compounding generation errors and fail to leverage even ground-truth visualizations. Our findings suggest that despite their inherent appeal, visual thoughts do not yet benefit model reasoning. MentisOculi establishes the necessary foundation to analyze and close this gap across diverse model families.</div></details>
<details class="detail"><summary>中文标题/摘要</summary>
<div class="mono"><b>标题：</b>MentisOculi：揭示心智意象推理的局限性</div>
<div class="mono" style="margin-top:8px">前沿模型正从仅接收视觉信息的多模态大语言模型（MLLMs）向具备原生交错生成能力的统一多模态模型（UMMs）演进。这一转变引发了利用中间可视化作为推理辅助工具的兴趣，类似于人类的心智意象。该能力的核心在于以目标导向的方式形成、维持和操控视觉表征。为评估和探究此能力，我们开发了MentisOculi——一套程序化、分层化的多步骤推理问题集，适用于视觉化解决方案，并针对前沿模型的挑战性进行调优。通过评估从潜在标记到显式生成图像等多种视觉策略，我们发现它们普遍未能提升模型性能。对UMMs的专项分析揭示了一个关键局限：尽管它们具备解决任务的文本推理能力，有时也能生成正确视觉内容，但存在生成误差累积问题，且无法有效利用甚至完全准确的视觉化信息。我们的研究表明，尽管视觉思维具有内在吸引力，但目前尚未对模型推理产生助益。MentisOculi为分析和弥合不同模型家族间的这一差距奠定了必要基础。</div>
</details>
<details class="detail"><summary>Summary / 总结</summary>
<div class="mono">The research is motivated by the shift from multimodal large language models to unified multimodal models capable of generating interleaved content, which raises the question of whether using intermediate visualizations as a reasoning aid, similar to human mental imagery, can enhance model performance. The method involves developing MentisOculi, a procedural and stratified benchmark suite of multi-step reasoning problems designed to challenge frontier models, and evaluating various visual reasoning strategies, including latent tokens and explicit generated imagery. Key experimental findings reveal that these visual strategies generally fail to improve performance; specifically, unified multimodal models, despite having the textual reasoning capacity and sometimes generating correct visuals, suffer from compounding generation errors and cannot effectively leverage even ground-truth visualizations, indicating that visual thoughts do not yet benefit model reasoning.</div>
<div class="mono" style="margin-top:8px">从仅能处理视觉信息的多模态大语言模型向能够原生交错生成的统一多模态模型的转变，引发了人们对使用中间可视化作为推理辅助（类似于人类心理意象）的兴趣。为了评估这种能力，作者开发了MentisOculi，这是一个程序化的、分层的多步骤视觉推理问题集，旨在挑战前沿模型。实验结果表明，从潜在标记到显式生成图像的各种视觉策略通常无法提升性能；分析发现，即使模型具备解决任务的文本推理能力并能有时生成正确的视觉内容，它们也会受到生成错误累积的影响，且无法有效利用可视化信息，这表明视觉思维目前尚不能有益于模型的推理。</div>
</details>
</div>
<div class="card">
<div class="title">Abstract Activation Spaces for Content-Invariant Reasoning in Large Language Models</div>
<div class="meta-line">Authors: Gabriele Maraia, Marco Valentino, Fabio Massimo Zanzotto, Leonardo Ranaldi</div>
<div class="meta-line">First: 2026-02-02T18:48:44+00:00 · Latest: 2026-02-02T18:48:44+00:00</div>
<div class="links" style="margin-top:8px"><a href="https://arxiv.org/abs/2602.02462v1">Abs</a> · <a href="https://arxiv.org/pdf/2602.02462v1">PDF</a> · <a href="https://huggingface.co/huggingface">Code1</a> · <a href="https://huggingface.co/docs/hub/spaces">Code2</a></div>
<details class="detail"><summary>Abstract</summary>
<div class="mono">Large Language Models (LLMs) often struggle with deductive judgment in syllogistic reasoning, systematically conflating semantic plausibility with formal validity a phenomenon known as content effect. This bias persists even when models generate step-wise explanations, indicating that intermediate rationales may inherit the same semantic shortcuts that affect answers. Recent approaches propose mitigating this issue by increasing inference-time structural constraints, either by encouraging abstract intermediate representations or by intervening directly in the model&#x27;s internal computations; however, reliably suppressing semantic interference remains an open challenge. To make formal deduction less sensitive to semantic content, we introduce a framework for abstraction-guided reasoning that explicitly separates structural inference from lexical semantics. We construct paired content-laden and abstract syllogisms and use the model&#x27;s activations on abstract inputs to define an abstract reasoning space. We then learn lightweight Abstractors that, from content-conditioned residual-stream states, predict representations aligned with this space and integrate these predictions via multi-layer interventions during the forward pass. Using cross-lingual transfer as a test bed, we show that abstraction-aligned steering reduces content-driven errors and improves validity-sensitive performance. Our results position activation-level abstraction as a scalable mechanism for enhancing the robustness of formal reasoning in LLMs against semantic interference.</div></details>
<details class="detail"><summary>中文标题/摘要</summary>
<div class="mono"><b>标题：</b>大语言模型内容不变推理的抽象激活空间</div>
<div class="mono" style="margin-top:8px">大语言模型（LLMs）在三段论推理中常难以进行演绎判断，系统性地混淆语义合理性与形式有效性，这一现象称为内容效应。即使模型生成逐步解释，这种偏见依然存在，表明中间推理可能继承了影响答案的语义捷径。近期方法提出通过增强推理时的结构约束来缓解此问题，例如鼓励抽象中间表示或直接干预模型内部计算，但可靠抑制语义干扰仍是开放挑战。为使形式推理对语义内容更不敏感，我们引入一种抽象引导推理框架，明确将结构推理与词汇语义分离。我们构建成对的内容丰富与抽象三段论，并利用模型在抽象输入上的激活定义抽象推理空间。随后训练轻量级抽象器，从内容条件化的残差流状态预测与该空间对齐的表示，并通过前向传播中的多层干预整合这些预测。以跨语言迁移为测试平台，我们证明抽象对齐的引导能减少内容驱动错误，提升有效性敏感性能。研究结果将激活级抽象定位为增强LLMs形式推理对语义干扰鲁棒性的可扩展机制。</div>
</details>
<details class="detail"><summary>Summary / 总结</summary>
<div class="mono">Large Language Models (LLMs) frequently confuse semantic plausibility with logical validity in syllogistic reasoning, a bias that persists even in their step-by-step explanations. To address this, the authors propose an abstraction-guided reasoning framework that separates structural inference from lexical semantics by constructing paired content-laden and abstract syllogisms. They define an abstract reasoning space from model activations on abstract inputs and train lightweight Abstractors to predict representations aligned with this space, which are then integrated via multi-layer interventions during forward passes. Experiments using cross-lingual transfer demonstrate that this activation-level steering reduces content-driven errors and improves performance based on logical validity, offering a scalable method to enhance the robustness of formal reasoning in LLMs against semantic interference.</div>
<div class="mono" style="margin-top:8px">大型语言模型在演绎推理中常混淆语义合理性与逻辑有效性，这种偏见即使在逐步解释中也会持续存在。为解决该问题，研究者提出了一个抽象引导的推理框架，通过构建包含具体内容和抽象内容的三段论对，将结构推理与词汇语义分离开来。他们基于模型在抽象输入上的激活定义了一个抽象推理空间，并训练轻量级抽象器，在推理过程中通过多层干预，从内容条件化的残差流状态预测并注入与抽象空间对齐的表征。在跨语言迁移的实验环境中，结果表明这种激活层面的引导减少了内容驱动的错误，并提升了基于逻辑有效性的性能，为增强大型语言模型形式推理对抗语义干扰的鲁棒性提供了一种可扩展的方法。</div>
</details>
</div>
<div class="card">
<div class="title">Drift-Bench: Diagnosing Cooperative Breakdowns in LLM Agents under Input Faults via Multi-Turn Interaction</div>
<div class="meta-line">Authors: Han Bao, Zheyuan Zhang, Pengcheng Jing, Zhengqing Yuan, Kaiwen Shi, Yanfang Ye</div>
<div class="meta-line">First: 2026-02-02T18:46:16+00:00 · Latest: 2026-02-02T18:46:16+00:00</div>
<div class="meta-line">Comments: 65 pages, 40 figures</div>
<div class="links" style="margin-top:8px"><a href="https://arxiv.org/abs/2602.02455v1">Abs</a> · <a href="https://arxiv.org/pdf/2602.02455v1">PDF</a> · <a href="https://huggingface.co/huggingface">Code1</a> · <a href="https://huggingface.co/docs/hub/spaces">Code2</a></div>
<details class="detail"><summary>Abstract</summary>
<div class="mono">As Large Language Models transition to autonomous agents, user inputs frequently violate cooperative assumptions (e.g., implicit intent, missing parameters, false presuppositions, or ambiguous expressions), creating execution risks that text-only evaluations do not capture. Existing benchmarks typically assume well-specified instructions or restrict evaluation to text-only, single-turn clarification, and thus do not measure multi-turn disambiguation under grounded execution risk. We introduce \textbf{Drift-Bench}, the first diagnostic benchmark that evaluates agentic pragmatics under input faults through multi-turn clarification across state-oriented and service-oriented execution environments. Grounded in classical theories of communication, \textbf{Drift-Bench} provides a unified taxonomy of cooperative breakdowns and employs a persona-driven user simulator with the \textbf{Rise} evaluation protocol. Experiments show substantial performance drops under these faults, with clarification effectiveness varying across user personas and fault types. \MethodName bridges clarification research and agent safety evaluation, enabling systematic diagnosis of failures that can lead to unsafe executions.</div></details>
<details class="detail"><summary>中文标题/摘要</summary>
<div class="mono"><b>标题：</b>Drift-Bench：基于多轮交互诊断输入故障下大语言模型智能体的协作失效</div>
<div class="mono" style="margin-top:8px">随着大语言模型向自主智能体演进，用户输入常违反协作假设（如隐含意图、参数缺失、错误预设或模糊表达），产生纯文本评估无法捕捉的执行风险。现有基准通常假设指令明确或仅限于纯文本单轮澄清评估，未能衡量具身执行风险下的多轮消歧能力。我们提出首个诊断性基准\textbf{Drift-Bench}，通过在状态导向与服务导向的执行环境中进行多轮澄清对话，评估输入故障下的智能体语用能力。该基准植根于经典传播理论，提供协作失效的统一分类体系，并采用角色驱动的用户模拟器与\textbf{Rise}评估协议。实验表明这些故障会导致性能显著下降，且澄清效果随用户角色与故障类型呈现差异。本方法连接了澄清研究与智能体安全评估，为可能导致不安全执行的系统性故障诊断提供支持。</div>
</details>
<details class="detail"><summary>Summary / 总结</summary>
<div class="mono">The research addresses the risk that large language model agents face when user inputs violate cooperative communication assumptions, such as implicit intent or ambiguous expressions, which text-only evaluations fail to capture. The authors introduce Drift-Bench, a diagnostic benchmark that evaluates agent pragmatics under input faults through multi-turn clarification dialogues in both state-oriented and service-oriented execution environments, grounded in communication theory and using a persona-driven user simulator with the Rise evaluation protocol. Experimental results reveal significant performance drops under these faults, with the effectiveness of clarification varying substantially across different user personas and types of cooperative breakdowns, highlighting risks that could lead to unsafe executions.</div>
<div class="mono" style="margin-top:8px">该研究的动机在于需要诊断大型语言模型（LLM）智能体如何处理违反合作性沟通原则的用户输入（如隐含意图或模糊表达），这些输入会带来标准纯文本基准无法捕捉的执行风险。方法上，研究引入了Drift-Bench这一诊断性基准，通过在状态导向和服务导向的执行环境中进行多轮澄清对话来评估智能体的语用能力，它采用了一个统一的合作性故障分类法以及一个基于人物角色的用户模拟器与Rise评估协议。关键实验结果表明，在输入故障下智能体性能大幅下降，且澄清效果因用户角色和故障类型的不同而有显著差异，这揭示了可能导致不安全执行的风险。</div>
</details>
</div>
<div class="card">
<div class="title">World-Gymnast: Training Robots with Reinforcement Learning in a World Model</div>
<div class="meta-line">Authors: Ansh Kumar Sharma, Yixiang Sun, Ninghao Lu, Yunzhe Zhang, Jiarao Liu, Sherry Yang</div>
<div class="meta-line">First: 2026-02-02T18:44:45+00:00 · Latest: 2026-02-02T18:44:45+00:00</div>
<div class="meta-line">Comments: https://world-gymnast.github.io/</div>
<div class="links" style="margin-top:8px"><a href="https://arxiv.org/abs/2602.02454v1">Abs</a> · <a href="https://arxiv.org/pdf/2602.02454v1">PDF</a> · <a href="https://huggingface.co/huggingface">Code1</a> · <a href="https://huggingface.co/docs/hub/spaces">Code2</a> · <a href="https://world-gymnast.github.io/">Project1</a></div>
<details class="detail"><summary>Abstract</summary>
<div class="mono">Robot learning from interacting with the physical world is fundamentally bottlenecked by the cost of physical interaction. The two alternatives, supervised finetuning (SFT) from expert demonstrations and reinforcement learning (RL) in a software-based simulator, are limited by the amount of expert data available and the sim-to-real gap for manipulation. With the recent emergence of world models learned from real-world video-action data, we ask the question of whether training a policy in a world model can be more effective than supervised learning or software simulation in achieving better real-robot performance. We propose World-Gymnast, which performs RL finetuning of a vision-language-action (VLA) policy by rolling out the policy in an action-conditioned video world model and rewarding the rollouts with a vision-language model (VLM). On the Bridge robot setup, World-Gymnast outperforms SFT by as much as 18x and outperforms software simulator by as much as 2x. More importantly, World-Gymnast demonstrates intriguing capabilities of RL with a world model, including training on diverse language instructions and novel scenes from the world model, test-time training in a novel scene, and online iterative world model and policy improvement. Our results suggest learning a world model and training robot policies in the cloud could be the key to bridging the gap between robots that work in demonstrations and robots that can work in anyone&#x27;s household.</div></details>
<details class="detail"><summary>中文标题/摘要</summary>
<div class="mono"><b>标题：</b>World-Gymnast：在世界模型中通过强化学习训练机器人</div>
<div class="mono" style="margin-top:8px">机器人与物理世界交互学习从根本上受限于物理交互成本。两种替代方案——基于专家演示的监督微调（SFT）与基于软件模拟器的强化学习（RL）——分别受限于可用专家数据量和操作任务的模拟到现实差距。随着从真实世界视频-动作数据学习的世界模型近期兴起，我们探讨了在世界模型中训练策略是否比监督学习或软件模拟更能有效提升真实机器人性能。我们提出World-Gymnast方法，通过在动作条件视频世界模型中展开策略、并利用视觉语言模型（VLM）对推演结果进行奖励，实现对视觉-语言-动作（VLA）策略的强化学习微调。在Bridge机器人实验平台上，World-Gymnast性能超越SFT达18倍，超越软件模拟器达2倍。更重要的是，该方法展现了世界模型强化学习的独特能力：包括基于世界模型对多样化语言指令和新场景进行训练、在新场景中进行测试时训练、以及在线迭代优化世界模型与策略。我们的研究表明，学习世界模型并在云端训练机器人策略，可能是弥合演示型机器人与家用普适型机器人之间鸿沟的关键。</div>
</details>
<details class="detail"><summary>Summary / 总结</summary>
<div class="mono">The research is motivated by the high cost and limitations of physical robot interaction, which is bottlenecked by expensive real-world trials, scarce expert demonstration data for supervised fine-tuning, and the sim-to-real gap in software simulators. The method, World-Gymnast, addresses this by performing reinforcement learning (RL) fine-tuning of a vision-language-action policy within an action-conditioned video world model learned from real-world data, using a vision-language model to reward policy rollouts. Key experimental results on the Bridge robot setup show that World-Gymnast outperforms supervised fine-tuning by up to 18x and software simulation by up to 2x, while also demonstrating capabilities such as training on diverse language instructions and novel scenes, test-time training, and online iterative improvement of both the world model and policy.</div>
<div class="mono" style="margin-top:8px">该研究的动机在于物理机器人交互的高成本，以及现有替代方案的局限性：监督微调受限于稀缺的专家演示数据，而在软件模拟器中进行强化学习则存在仿真到现实的差距。该方法，即World-Gymnast，通过在一个从真实世界数据学习得到的动作条件视频世界模型中，对视觉-语言-动作策略进行强化学习微调，并使用视觉-语言模型对策略展开进行奖励，从而解决了上述问题。在Bridge机器人设置上的关键实验结果表明，World-Gymnast的性能最高可达监督微调的18倍和软件模拟的2倍，同时还展示了从世界模型中对多样化语言指令和新场景进行训练、测试时训练以及在线迭代改进等新颖能力。</div>
</details>
</div>
<div class="card">
<div class="title">Thinking with Comics: Enhancing Multimodal Reasoning through Structured Visual Storytelling</div>
<div class="meta-line">Authors: Andong Chen, Wenxin Zhu, Qiuyu Ding, Yuchen Song, Muyun Yang, Tiejun Zhao</div>
<div class="meta-line">First: 2026-02-02T18:43:57+00:00 · Latest: 2026-02-02T18:43:57+00:00</div>
<div class="meta-line">Comments: Working paper</div>
<div class="links" style="margin-top:8px"><a href="https://arxiv.org/abs/2602.02453v1">Abs</a> · <a href="https://arxiv.org/pdf/2602.02453v1">PDF</a> · <a href="https://huggingface.co/huggingface">Code1</a> · <a href="https://huggingface.co/docs/hub/spaces">Code2</a></div>
<details class="detail"><summary>Abstract</summary>
<div class="mono">Chain-of-Thought reasoning has driven large language models to extend from thinking with text to thinking with images and videos. However, different modalities still have clear limitations: static images struggle to represent temporal structure, while videos introduce substantial redundancy and computational cost. In this work, we propose Thinking with Comics, a visual reasoning paradigm that uses comics as a high information-density medium positioned between images and videos. Comics preserve temporal structure, embedded text, and narrative coherence while requiring significantly lower reasoning cost. We systematically study two reasoning paths based on comics and evaluate them on a range of reasoning tasks and long-context understanding tasks. Experimental results show that Thinking with Comics outperforms Thinking with Images on multi-step temporal and causal reasoning tasks, while remaining substantially more efficient than Thinking with Video. Further analysis indicates that different comic narrative structures and styles consistently affect performance across tasks, suggesting that comics serve as an effective intermediate visual representation for improving multimodal reasoning.</div></details>
<details class="detail"><summary>中文标题/摘要</summary>
<div class="mono"><b>标题：</b>漫画思维：通过结构化视觉叙事增强多模态推理能力</div>
<div class="mono" style="margin-top:8px">思维链推理已推动大语言模型从文本思维扩展到图像与视频思维。然而，不同模态仍存在明显局限：静态图像难以表征时序结构，而视频则引入大量冗余与计算成本。本研究提出“漫画思维”这一视觉推理范式，将漫画作为介于图像与视频之间的高信息密度媒介。漫画在显著降低推理成本的同时，保留了时序结构、嵌入式文本与叙事连贯性。我们系统研究了基于漫画的两种推理路径，并在系列推理任务与长上下文理解任务中进行了评估。实验结果表明：在多步骤时序与因果推理任务上，漫画思维优于图像思维，同时仍比视频思维显著高效。进一步分析表明，不同漫画叙事结构与风格对各类任务性能产生持续影响，这提示漫画可作为提升多模态推理能力的有效中间视觉表征。</div>
</details>
<details class="detail"><summary>Summary / 总结</summary>
<div class="mono">To address the limitations of static images in representing temporal structure and the high computational cost of videos in multimodal reasoning, this work introduces Thinking with Comics, a paradigm that uses comics as a structured, information-dense visual medium. The method systematically explores reasoning paths based on comics and evaluates them on multi-step temporal, causal, and long-context understanding tasks. Experiments demonstrate that this approach outperforms image-based reasoning on temporal and causal tasks and is significantly more efficient than video-based reasoning, with performance consistently influenced by comic narrative structures and styles.</div>
<div class="mono" style="margin-top:8px">针对静态图像缺乏时序结构、视频计算成本高且冗余的问题，本研究提出了“漫画思维”作为多模态推理范式。该方法将漫画作为介于图像和视频之间的高信息密度媒介，系统研究了基于其结构化视觉叙事的推理路径。在推理和长上下文理解任务上的实验表明，该方法在时序和因果推理上优于基于图像的方法，同时比基于视频的方法更高效，且漫画的叙事结构和风格持续影响任务性能。</div>
</details>
</div>
<div class="card">
<div class="title">Active Causal Experimentalist (ACE): Learning Intervention Strategies via Direct Preference Optimization</div>
<div class="meta-line">Authors: Patrick Cooper, Alvaro Velasquez</div>
<div class="meta-line">First: 2026-02-02T18:43:52+00:00 · Latest: 2026-02-02T18:43:52+00:00</div>
<div class="meta-line">Comments: 9 pages, 5 figures</div>
<div class="links" style="margin-top:8px"><a href="https://arxiv.org/abs/2602.02451v1">Abs</a> · <a href="https://arxiv.org/pdf/2602.02451v1">PDF</a> · <a href="https://huggingface.co/huggingface">Code1</a> · <a href="https://huggingface.co/docs/hub/spaces">Code2</a></div>
<details class="detail"><summary>Abstract</summary>
<div class="mono">Discovering causal relationships requires controlled experiments, but experimentalists face a sequential decision problem: each intervention reveals information that should inform what to try next. Traditional approaches such as random sampling, greedy information maximization, and round-robin coverage treat each decision in isolation, unable to learn adaptive strategies from experience. We propose Active Causal Experimentalist (ACE), which learns experimental design as a sequential policy. Our key insight is that while absolute information gains diminish as knowledge accumulates (making value-based RL unstable), relative comparisons between candidate interventions remain meaningful throughout. ACE exploits this via Direct Preference Optimization, learning from pairwise intervention comparisons rather than non-stationary reward magnitudes. Across synthetic benchmarks, physics simulations, and economic data, ACE achieves 70-71% improvement over baselines at equal intervention budgets (p &lt; 0.001, Cohen&#x27;s d ~ 2). Notably, the learned policy autonomously discovers that collider mechanisms require concentrated interventions on parent variables, a theoretically-grounded strategy that emerges purely from experience. This suggests preference-based learning can recover principled experimental strategies, complementing theory with learned domain adaptation.</div></details>
<details class="detail"><summary>中文标题/摘要</summary>
<div class="mono"><b>标题：</b>主动因果实验者（ACE）：通过直接偏好优化学习干预策略</div>
<div class="mono" style="margin-top:8px">发现因果关系需要受控实验，但实验者面临序贯决策问题：每次干预揭示的信息都应指导后续尝试。传统方法（如随机抽样、贪婪信息最大化、轮询覆盖）孤立处理每个决策，无法从经验中学习自适应策略。我们提出主动因果实验者（ACE），将实验设计学习为序贯策略。核心洞见是：虽然绝对信息增益随知识积累而递减（导致基于价值的强化学习不稳定），但候选干预间的相对比较始终具有意义。ACE通过直接偏好优化利用这一特性，从成对干预比较中学习而非依赖非平稳的奖励幅度。在合成基准测试、物理模拟和经济数据中，ACE在相同干预预算下较基线提升70-71%（p &lt; 0.001，Cohen&#x27;s d ~ 2）。值得注意的是，习得策略自主发现碰撞机制需对父变量集中干预——这一理论支撑的策略完全从经验中涌现。这表明基于偏好的学习能恢复原则性实验策略，通过习得的领域自适应补充理论。</div>
</details>
<details class="detail"><summary>Summary / 总结</summary>
<div class="mono">The research addresses the sequential decision-making challenge in causal discovery, where traditional methods like random sampling or greedy information gain fail to learn adaptive intervention strategies from experience. The proposed Active Causal Experimentalist (ACE) learns an experimental design policy by framing intervention selection as a sequential problem and employing Direct Preference Optimization, which stabilizes learning by using pairwise comparisons between candidate interventions instead of non-stationary reward magnitudes. Experimental results across synthetic benchmarks, physics simulations, and economic data show ACE achieves a 70-71% improvement over baselines at equal intervention budgets, with the learned policy autonomously discovering theoretically-grounded strategies, such as concentrating interventions on parent variables for collider mechanisms.</div>
<div class="mono" style="margin-top:8px">该研究针对因果发现中的序贯实验设计挑战，传统方法如随机采样或贪婪信息最大化无法从经验中学习自适应策略。作者提出了主动因果实验者（ACE），将实验设计构建为序贯策略，并利用直接偏好优化从候选干预的成对比较中学习，避免了基于奖励的强化学习的不稳定性。在合成基准、物理模拟和经济数据上的实验结果表明，在相同干预预算下，ACE相比基线方法实现了70-71%的性能提升，且学习到的策略自主发现了理论支持的策略，例如在碰撞机制中集中干预父变量。</div>
</details>
</div>
<div class="card">
<div class="title">UniReason 1.0: A Unified Reasoning Framework for World Knowledge Aligned Image Generation and Editing</div>
<div class="meta-line">Authors: Dianyi Wang, Chaofan Ma, Feng Han, Size Wu, Wei Song, Yibin Wang, Zhixiong Zhang, Tianhang Wang, Siyuan Wang, Zhongyu Wei, Jiaqi Wang</div>
<div class="meta-line">First: 2026-02-02T18:34:35+00:00 · Latest: 2026-02-02T18:34:35+00:00</div>
<div class="links" style="margin-top:8px"><a href="https://arxiv.org/abs/2602.02437v1">Abs</a> · <a href="https://arxiv.org/pdf/2602.02437v1">PDF</a> · <a href="https://huggingface.co/huggingface">Code1</a> · <a href="https://huggingface.co/docs/hub/spaces">Code2</a></div>
<details class="detail"><summary>Abstract</summary>
<div class="mono">Unified multimodal models often struggle with complex synthesis tasks that demand deep reasoning, and typically treat text-to-image generation and image editing as isolated capabilities rather than interconnected reasoning steps. To address this, we propose UniReason, a unified framework that harmonizes these two tasks through a dual reasoning paradigm. We formulate generation as world knowledge-enhanced planning to inject implicit constraints, and leverage editing capabilities for fine-grained visual refinement to further correct visual errors via self-reflection. This approach unifies generation and editing within a shared representation, mirroring the human cognitive process of planning followed by refinement. We support this framework by systematically constructing a large-scale reasoning-centric dataset (~300k samples) covering five major knowledge domains (e.g., cultural commonsense, physics, etc.) for planning, alongside an agent-generated corpus for visual self-correction. Extensive experiments demonstrate that UniReason achieves advanced performance on reasoning-intensive benchmarks such as WISE, KrisBench and UniREditBench, while maintaining superior general synthesis capabilities.</div></details>
<details class="detail"><summary>中文标题/摘要</summary>
<div class="mono"><b>标题：</b>UniReason 1.0：面向世界知识对齐图像生成与编辑的统一推理框架</div>
<div class="mono" style="margin-top:8px">统一多模态模型在处理需要深度推理的复杂合成任务时常面临困难，且通常将文本到图像生成和图像编辑视为孤立能力而非相互关联的推理步骤。为此，我们提出UniReason——一个通过双重推理范式协调这两项任务的统一框架。我们将生成任务构建为世界知识增强的规划过程以注入隐式约束，并利用编辑能力进行细粒度视觉优化，通过自反思机制进一步修正视觉误差。该方法在共享表征中统一了生成与编辑，模拟了人类“先规划后优化”的认知过程。我们通过系统构建大规模以推理为中心的数据集（约30万样本）支持该框架，涵盖文化常识、物理等五大知识领域用于规划，同时配备智能体生成的视觉自校正语料库。大量实验表明，UniReason在WISE、KrisBench和UniREditBench等推理密集型基准测试中取得先进性能，同时保持卓越的通用合成能力。</div>
</details>
<details class="detail"><summary>Summary / 总结</summary>
<div class="mono">The research addresses the limitation of unified multimodal models in handling complex synthesis tasks requiring deep reasoning, where text-to-image generation and image editing are typically treated as isolated capabilities rather than interconnected reasoning steps. The proposed UniReason framework harmonizes these two tasks through a dual reasoning paradigm: formulating generation as world knowledge-enhanced planning to inject implicit constraints, and leveraging editing capabilities for fine-grained visual refinement via self-reflection to correct errors. This approach unifies generation and editing within a shared representation, mirroring human cognitive processes. Experiments demonstrate that UniReason achieves advanced performance on reasoning-intensive benchmarks including WISE, KrisBench and UniREditBench while maintaining superior general synthesis capabilities, supported by a systematically constructed large-scale reasoning-centric dataset covering five major knowledge domains.</div>
<div class="mono" style="margin-top:8px">针对统一多模态模型在需要深度推理的复杂合成任务中的局限性，以及将文本到图像生成和图像编辑视为孤立能力的问题，本研究提出了UniReason框架，通过双重推理范式协调这两项任务。该方法将生成制定为世界知识增强的规划以注入隐式约束，并利用编辑能力通过自我修正进行细粒度视觉优化，在共享表示中统一两者。关键实验结果表明，UniReason在WISE、KrisBench和UniREditBench等推理密集型基准测试中取得了先进性能，同时保持了卓越的通用合成能力，其支撑是一个系统构建的大规模以推理为中心的数据集。</div>
</details>
</div>
<div class="card">
<div class="title">Poly-attention: a general scheme for higher-order self-attention</div>
<div class="meta-line">Authors: Sayak Chakrabarti, Toniann Pitassi, Josh Alman</div>
<div class="meta-line">First: 2026-02-02T18:24:53+00:00 · Latest: 2026-02-02T18:24:53+00:00</div>
<div class="links" style="margin-top:8px"><a href="https://arxiv.org/abs/2602.02422v1">Abs</a> · <a href="https://arxiv.org/pdf/2602.02422v1">PDF</a> · <a href="https://huggingface.co/huggingface">Code1</a> · <a href="https://huggingface.co/docs/hub/spaces">Code2</a></div>
<details class="detail"><summary>Abstract</summary>
<div class="mono">The self-attention mechanism, at the heart of the Transformer model, is able to effectively model pairwise interactions between tokens. However, numerous recent works have shown that it is unable to perform basic tasks involving detecting triples of correlated tokens, or compositional tasks where multiple input tokens need to be referenced to generate a result. Some higher-dimensional alternatives to self-attention have been proposed to address this, including higher-order attention and Strassen attention, which can perform some of these polyadic tasks in exchange for slower, superquadratic running times.
  In this work, we define a vast class of generalizations of self-attention, which we call poly-attention mechanisms. Our mechanisms can incorporate arbitrary higher-order (tensor) computations as well as arbitrary relationship structures between the input tokens, and they include the aforementioned alternatives as special cases. We then systematically study their computational complexity and representational strength, including giving new algorithms and matching complexity-theoretic lower bounds on the time complexity of computing the attention matrix exactly as well as approximately, and tightly determining which polyadic tasks they can each perform. Our results give interesting trade-offs between different desiderata for these mechanisms, including a tight relationship between how expressive a mechanism is, and how large the coefficients in the model may be so that the mechanism can be approximated in almost-linear time.
  Notably, we give a new attention mechanism which can be computed exactly in quadratic time, and which can perform function composition for any fixed number of functions. Prior mechanisms, even for just composing two functions, could only be computed in superquadratic time, and our new lower bounds show that faster algorithms for them are not possible.</div></details>
<details class="detail"><summary>中文标题/摘要</summary>
<div class="mono"><b>标题：</b>多注意力机制：高阶自注意力的一般化框架</div>
<div class="mono" style="margin-top:8px">作为Transformer模型核心的自注意力机制能有效建模词元间的成对交互，但近期多项研究表明其无法处理涉及三元相关词元检测的基础任务，或需要参照多个输入词元才能生成结果的组合任务。为应对此局限，学界提出了若干高阶替代方案，如高阶注意力和Strassen注意力，这些方法虽能执行部分多元任务，却需以超二次方时间复杂度为代价。本文定义了一类广泛的自注意力泛化形式——多注意力机制，该框架可纳入任意高阶张量计算及输入词元间的任意关系结构，并将前述替代方案涵盖为特例。我们系统研究了其计算复杂度与表征能力：提出新算法并给出匹配的计算复杂度理论下界（包括精确与近似计算注意力矩阵的时间复杂度），严格界定了各类机制可执行的多元任务范围。研究结果揭示了这些机制在不同需求间的权衡关系，特别是机制表达能力与模型系数规模之间的紧致关联——后者决定了机制能否在近线性时间内被近似计算。值得注意的是，我们提出了一种可在二次时间内精确计算的新注意力机制，该机制能执行任意固定数量函数的组合运算。而此前即使仅组合两个函数的机制也需超二次时间计算，我们的新下界证明其不存在更快的算法。</div>
</details>
<details class="detail"><summary>Summary / 总结</summary>
<div class="mono">The self-attention mechanism in Transformers is limited to pairwise token interactions, failing at tasks requiring detection of triples or compositional operations. To address this, the paper introduces poly-attention, a broad class of higher-order attention mechanisms that incorporate tensor computations and arbitrary token relationship structures, encompassing prior proposals. Through systematic analysis of computational complexity and representational strength, the work provides new algorithms and matching lower bounds, revealing trade-offs between expressivity and efficient approximation. Notably, it presents a novel quadratic-time exact attention mechanism capable of composing any fixed number of functions, outperforming prior superquadratic-time methods for which faster algorithms are proven impossible.</div>
<div class="mono" style="margin-top:8px">Transformer中的自注意力机制能有效建模令牌间的成对交互，但在需要检测相关令牌三元组或引用多个令牌的组合任务上存在不足。本研究提出了一类广泛的多元注意力机制，将自注意力推广至任意高阶张量计算和令牌关系结构，涵盖了先前的高阶注意力变体。通过对计算复杂性和表示能力的系统分析，包括新算法和匹配的下界，研究揭示了表达力与高效近似之间的权衡，并特别提出了一种新的可在二次时间内精确计算且能执行固定深度函数组合的注意力机制，优于先前需要超二次时间的方法。</div>
</details>
</div>
<div class="card">
<div class="title">How to Train Your Advisor: Steering Black-Box LLMs with Advisor Models</div>
<div class="meta-line">Authors: Parth Asawa, Alan Zhu, Abby O&#x27;Neill, Matei Zaharia, Alexandros G. Dimakis, Joseph E. Gonzalez</div>
<div class="meta-line">First: 2025-10-02T18:02:39+00:00 · Latest: 2026-02-02T18:23:32+00:00</div>
<div class="links" style="margin-top:8px"><a href="https://arxiv.org/abs/2510.02453v2">Abs</a> · <a href="https://arxiv.org/pdf/2510.02453v2">PDF</a> · <a href="https://huggingface.co/huggingface">Code1</a> · <a href="https://huggingface.co/docs/hub/spaces">Code2</a></div>
<details class="detail"><summary>Abstract</summary>
<div class="mono">Frontier language models are deployed as black-box services, where model weights cannot be modified and customization is limited to prompting. We introduce Advisor Models, a method to train small open-weight models to generate dynamic, per-instance natural language advice that improves the capabilities of black-box frontier models. Advisor Models improve GPT-5&#x27;s performance on RuleArena (Taxes) by 71%, reduce Gemini 3 Pro&#x27;s steps taken in SWE agent tasks by 24.6%, and outperform static prompt optimizers in personalizing GPT-5 to user preferences (85-100% vs. 40-60%). We also find that advisors are transferable: an advisor trained with a low-cost student model still transfers improvements to a frontier model. Moreover, Advisor Models are robust: we observe no degradation on other benchmarks than the pipeline is trained on. Our method shows how to perform parametric optimization for black-box frontier models in a practical and cost-effective way.</div></details>
<details class="detail"><summary>中文标题/摘要</summary>
<div class="mono"><b>标题：</b>如何训练你的顾问模型：利用顾问模型引导黑盒大语言模型</div>
<div class="mono" style="margin-top:8px">前沿语言模型通常以黑盒服务形式部署，其模型权重无法修改，定制化仅限于提示工程。我们提出顾问模型方法，通过训练小型开源权重模型来生成动态的、针对每个实例的自然语言建议，从而提升黑盒前沿模型的能力。该方法使GPT-5在RuleArena（税务）任务上的性能提升71%，使Gemini 3 Pro在SWE智能体任务中的步骤减少24.6%，并在个性化GPT-5适应用户偏好方面显著优于静态提示优化器（85-100%对比40-60%）。我们还发现顾问模型具有可迁移性：使用低成本学生模型训练的顾问仍能为前沿模型带来改进。此外，顾问模型具有鲁棒性：在训练流程未涉及的其他基准测试中未观察到性能下降。本方法展示了如何以实用且经济高效的方式对黑盒前沿模型进行参数化优化。</div>
</details>
<details class="detail"><summary>Summary / 总结</summary>
<div class="mono">The research addresses the limitation of customizing black-box frontier language models, where only prompting is available. The method introduces Advisor Models, which train small open-weight models to generate dynamic natural language advice per instance to steer black-box models. Experiments show that Advisor Models improve GPT-5&#x27;s performance on RuleArena (Taxes) by 71%, reduce Gemini 3 Pro&#x27;s steps in SWE agent tasks by 24.6%, outperform static prompt optimizers in personalizing GPT-5 to user preferences (85-100% vs. 40-60%), and demonstrate transferability and robustness without degrading performance on other benchmarks.</div>
<div class="mono" style="margin-top:8px">该研究针对黑盒前沿语言模型仅支持基于提示的定制这一局限性，提出了一种方法：训练小型开放权重模型作为顾问模型，为每个实例生成动态的自然语言建议以增强黑盒模型能力。实验结果表明，顾问模型将GPT-5在RuleArena（Taxes）上的性能提升了71%，使Gemini 3 Pro在SWE代理任务中的步骤减少了24.6%，在个性化GPT-5适应用户偏好方面优于静态提示优化器（85-100%对比40-60%），并展现出可迁移性和鲁棒性，在其他基准测试上未出现性能下降。</div>
</details>
</div>
<div class="card">
<div class="title">SafeGround: Know When to Trust GUI Grounding Models via Uncertainty Calibration</div>
<div class="meta-line">Authors: Qingni Wang, Yue Fan, Xin Eric Wang</div>
<div class="meta-line">First: 2026-02-02T18:22:45+00:00 · Latest: 2026-02-02T18:22:45+00:00</div>
<div class="links" style="margin-top:8px"><a href="https://arxiv.org/abs/2602.02419v1">Abs</a> · <a href="https://arxiv.org/pdf/2602.02419v1">PDF</a> · <a href="https://huggingface.co/huggingface">Code1</a> · <a href="https://huggingface.co/docs/hub/spaces">Code2</a></div>
<details class="detail"><summary>Abstract</summary>
<div class="mono">Graphical User Interface (GUI) grounding aims to translate natural language instructions into executable screen coordinates, enabling automated GUI interaction. Nevertheless, incorrect grounding can result in costly, hard-to-reverse actions (e.g., erroneous payment approvals), raising concerns about model reliability. In this paper, we introduce SafeGround, an uncertainty-aware framework for GUI grounding models that enables risk-aware predictions through calibrations before testing. SafeGround leverages a distribution-aware uncertainty quantification method to capture the spatial dispersion of stochastic samples from outputs of any given model. Then, through the calibration process, SafeGround derives a test-time decision threshold with statistically guaranteed false discovery rate (FDR) control. We apply SafeGround on multiple GUI grounding models for the challenging ScreenSpot-Pro benchmark. Experimental results show that our uncertainty measure consistently outperforms existing baselines in distinguishing correct from incorrect predictions, while the calibrated threshold reliably enables rigorous risk control and potentials of substantial system-level accuracy improvements. Across multiple GUI grounding models, SafeGround improves system-level accuracy by up to 5.38\% percentage points over Gemini-only inference.</div></details>
<details class="detail"><summary>中文标题/摘要</summary>
<div class="mono"><b>标题：</b>SafeGround：通过不确定性校准判断GUI基础模型的可靠时机</div>
<div class="mono" style="margin-top:8px">图形用户界面（GUI）基础模型旨在将自然语言指令转化为可执行的屏幕坐标，实现自动化GUI交互。然而，错误的基础定位可能导致代价高昂且难以逆转的操作（例如错误支付授权），引发对模型可靠性的担忧。本文提出SafeGround——一种面向GUI基础模型的不确定性感知框架，通过测试前的校准实现风险感知预测。SafeGround采用分布感知的不确定性量化方法，捕捉任意给定模型输出中随机样本的空间离散性。随后通过校准过程，推导出具有统计保证的误发现率（FDR）控制的测试时决策阈值。我们在挑战性基准ScreenSpot-Pro上对多个GUI基础模型应用SafeGround。实验结果表明：1）我们的不确定性度量在区分正误预测方面持续优于现有基线；2）校准后的阈值能可靠实现严格风险控制，并具备显著提升系统级准确率的潜力。在多个GUI基础模型中，SafeGround较纯Gemini推理将系统级准确率最高提升5.38个百分点。</div>
</details>
<details class="detail"><summary>Summary / 总结</summary>
<div class="mono">This research addresses the reliability concerns in GUI grounding, where incorrect predictions can lead to costly irreversible actions, by proposing SafeGround, an uncertainty-aware framework that enables risk-aware predictions. The method employs a distribution-aware uncertainty quantification technique to capture spatial dispersion from model outputs and calibrates a decision threshold with statistical false discovery rate control. Experiments on the ScreenSpot-Pro benchmark demonstrate that SafeGround&#x27;s uncertainty measure outperforms baselines in distinguishing correct from incorrect predictions, reliably controls risk, and improves system-level accuracy by up to 5.38 percentage points over baseline models.</div>
<div class="mono" style="margin-top:8px">本研究针对图形用户界面（GUI）定位中错误预测可能导致代价高昂的不可逆操作这一可靠性问题，提出了SafeGround框架。该方法通过分析模型随机输出的空间分布来量化预测不确定性，并校准决策阈值以在统计上控制错误发现率。在ScreenSpot-Pro基准测试上的实验表明，SafeGround的不确定性度量在区分正确与错误预测方面优于现有基线，实现了严格的风险控制，并将系统级准确率最高提升了5.38个百分点。</div>
</details>
</div>
<div class="card">
<div class="title">FS-DFM: Fast and Accurate Long Text Generation with Few-Step Diffusion Language Models</div>
<div class="meta-line">Authors: Amin Karimi Monsefi, Nikhil Bhendawade, Manuel Rafael Ciosici, Dominic Culver, Yizhe Zhang, Irina Belousova</div>
<div class="meta-line">Venue: ICLR 2026</div>
<div class="meta-line">First: 2025-09-24T23:59:05+00:00 · Latest: 2026-02-02T18:18:24+00:00</div>
<div class="meta-line">Comments: Accepted to ICLR 2026</div>
<div class="links" style="margin-top:8px"><a href="https://arxiv.org/abs/2509.20624v3">Abs</a> · <a href="https://arxiv.org/pdf/2509.20624v3">PDF</a> · <a href="https://huggingface.co/huggingface">Code1</a> · <a href="https://huggingface.co/docs/hub/spaces">Code2</a></div>
<details class="detail"><summary>Abstract</summary>
<div class="mono">Autoregressive language models (ARMs) deliver strong likelihoods, but are inherently serial: they generate one token per forward pass, which limits throughput and inflates latency for long sequences. Diffusion Language Models (DLMs) parallelize across positions and thus appear promising for language generation, yet standard discrete diffusion typically needs hundreds to thousands of model evaluations to reach high quality, trading serial depth for iterative breadth. We introduce FS-DFM, Few-Step Discrete Flow-Matching. A discrete flow-matching model designed for speed without sacrificing quality. The core idea is simple: make the number of sampling steps an explicit parameter and train the model to be consistent across step budgets, so one big move lands where many small moves would. We pair this with a reliable update rule that moves probability in the right direction without overshooting, and with strong teacher guidance distilled from long-run trajectories. Together, these choices make few-step sampling stable, accurate, and easy to control. On language modeling benchmarks, FS-DFM with 8 sampling steps achieves perplexity parity with a 1,024-step discrete-flow baseline for generating 1,024 tokens using a similar-size model, delivering up to 128 times faster sampling and corresponding latency/throughput gains.</div></details>
<details class="detail"><summary>中文标题/摘要</summary>
<div class="mono"><b>标题：</b>FS-DFM：基于少步扩散语言模型的快速精准长文本生成方法</div>
<div class="mono" style="margin-top:8px">自回归语言模型（ARMs）虽能提供较强的似然估计，但其本质是串行生成：每次前向传播仅产生一个词元，导致长序列生成的吞吐量受限且延迟增加。扩散语言模型（DLMs）通过并行化处理各位置词元，展现出语言生成的潜力，然而标准离散扩散通常需要数百至数千次模型评估才能达到高质量输出，实则是以迭代广度换取串行深度。本文提出FS-DFM（少步离散流匹配模型），这是一种兼顾速度与质量的离散流匹配模型。其核心思想简明：将采样步数设为显式参数，并训练模型在不同步数预算下保持输出一致性，从而实现“大步跨越等效多步微调”的效果。我们结合了可靠的更新规则（确保概率定向移动且避免超调）以及从长程轨迹中提炼的强教师指导，共同使少步采样具备稳定性、精确性和易控性。在语言建模基准测试中，使用8步采样的FS-DFM在生成1,024个词元时，与采用1,024步离散流基线的同规模模型达到同等困惑度水平，采样速度提升高达128倍，并相应获得延迟降低与吞吐量提升。</div>
</details>
<details class="detail"><summary>Summary / 总结</summary>
<div class="mono">To address the serial generation bottleneck of autoregressive language models and the high computational cost of standard discrete diffusion models, this paper proposes FS-DFM, a few-step discrete flow-matching model for fast long text generation. The method explicitly parameterizes the number of sampling steps and trains the model to be consistent across different step budgets, enabling large, accurate updates in few steps, supported by a stable update rule and distilled teacher guidance. Experimental results on language modeling benchmarks show that FS-DFM with only 8 sampling steps matches the perplexity of a 1,024-step discrete-flow baseline for generating 1,024 tokens, achieving up to 128x faster sampling with corresponding latency and throughput improvements.</div>
<div class="mono" style="margin-top:8px">为解决自回归语言模型的串行生成瓶颈和标准离散扩散模型的高计算成本，本文提出了FS-DFM，一种用于快速生成长文本的少步离散流匹配模型。该方法将采样步数显式参数化，并训练模型在不同步数预算下保持一致性，通过稳定的更新规则和蒸馏的教师指导，实现少步内的大幅准确更新。在语言建模基准测试中，FS-DFM仅用8个采样步就达到了1024步离散流基线在生成1024个词元时的困惑度水平，采样速度提升高达128倍，并相应改善了延迟和吞吐量。</div>
</details>
</div>
<div class="card">
<div class="title">Structure Enables Effective Self-Localization of Errors in LLMs</div>
<div class="meta-line">Authors: Ankur Samanta, Akshayaa Magesh, Ayush Jain, Kavosh Asadi, Youliang Yu, Daniel Jiang, Boris Vidolov, Kaveh Hassani, Paul Sajda, Jalaj Bhandari, Yonathan Efroni</div>
<div class="meta-line">First: 2026-02-02T18:15:59+00:00 · Latest: 2026-02-02T18:15:59+00:00</div>
<div class="links" style="margin-top:8px"><a href="https://arxiv.org/abs/2602.02416v1">Abs</a> · <a href="https://arxiv.org/pdf/2602.02416v1">PDF</a> · <a href="https://huggingface.co/huggingface">Code1</a> · <a href="https://huggingface.co/docs/hub/spaces">Code2</a></div>
<details class="detail"><summary>Abstract</summary>
<div class="mono">Self-correction in language models remains elusive. In this work, we explore whether language models can explicitly localize errors in incorrect reasoning, as a path toward building AI systems that can effectively correct themselves. We introduce a prompting method that structures reasoning as discrete, semantically coherent thought steps, and show that models are able to reliably localize errors within this structure, while failing to do so in conventional, unstructured chain-of-thought reasoning. Motivated by how the human brain monitors errors at discrete decision points and resamples alternatives, we introduce Iterative Correction Sampling of Thoughts (Thought-ICS), a self-correction framework. Thought-ICS iteratively prompts the model to generate reasoning one discrete and complete thought at a time--where each thought represents a deliberate decision by the model--creating natural boundaries for precise error localization. Upon verification, the model localizes the first erroneous step, and the system backtracks to generate alternative reasoning from the last correct point. When asked to correct reasoning verified as incorrect by an oracle, Thought-ICS achieves 20-40% self-correction lift. In a completely autonomous setting without external verification, it outperforms contemporary self-correction baselines.</div></details>
<details class="detail"><summary>中文标题/摘要</summary>
<div class="mono"><b>标题：</b>结构化赋能大语言模型有效自我定位错误</div>
<div class="mono" style="margin-top:8px">语言模型的自我纠错能力仍具挑战性。本研究探索语言模型能否显式定位错误推理中的问题，以此构建能有效自我修正的AI系统。我们提出一种提示方法，将推理结构化为离散且语义连贯的思维步骤，证明模型在此结构中能可靠定位错误，而在传统非结构化思维链推理中则无法实现。受人类大脑在离散决策点监控错误并重采替代方案的启发，我们提出迭代校正思维采样框架（Thought-ICS）。该框架通过迭代提示模型每次生成一个离散完整的思维单元（每个单元代表模型的审慎决策），为精准错误定位建立自然边界。经验证后，模型定位首个错误步骤，系统即回溯至最后正确节点生成替代推理。在需要修正经外部验证的错误推理时，Thought-ICS实现了20-40%的自我纠错提升；在完全无需外部验证的自主场景中，其表现优于当前主流自我纠错基线方法。</div>
</details>
<details class="detail"><summary>Summary / 总结</summary>
<div class="mono">This research addresses the challenge of enabling language models to self-correct by investigating whether they can explicitly localize errors within their own reasoning chains. The method introduces a prompting technique that structures reasoning into discrete, semantically coherent thought steps, and develops Thought-ICS, a framework that iteratively generates one complete thought at a time to create natural boundaries for error detection. Experimental results show that models reliably localize errors within this structured format but fail with conventional chain-of-thought, and the autonomous Thought-ICS system achieves a 20-40% improvement in self-correction when provided with oracle verification and outperforms other baselines without external feedback.</div>
<div class="mono" style="margin-top:8px">为了推进语言模型的自我修正能力，本研究探讨模型能否显式定位自身推理中的错误，作为实现有效自我修正的途径。方法上引入了一种提示技术，将推理结构化为离散、语义连贯的思维步骤，从而实现了可靠的错误定位，而这在非结构化的思维链中无法实现。受人类错误监控机制的启发，提出的迭代修正思维采样框架迭代地生成离散的思维步骤，为精确错误定位创造边界；经验证后，系统从最后一个正确点回溯并重新采样替代推理。实验结果表明，在修正经外部验证的错误推理时，该框架将自我修正性能提升了20-40%，并且在完全自主、无需外部验证的设置下，其表现优于当前的自修正基线方法。</div>
</details>
</div>
<div class="card">
<div class="title">ReasonEdit: Editing Vision-Language Models using Human Reasoning</div>
<div class="meta-line">Authors: Jiaxing Qiu, Kaihua Hou, Roxana Daneshjou, Ahmed Alaa, Thomas Hartvigsen</div>
<div class="meta-line">First: 2026-02-02T18:06:14+00:00 · Latest: 2026-02-02T18:06:14+00:00</div>
<div class="links" style="margin-top:8px"><a href="https://arxiv.org/abs/2602.02408v1">Abs</a> · <a href="https://arxiv.org/pdf/2602.02408v1">PDF</a> · <a href="https://huggingface.co/huggingface">Code1</a> · <a href="https://huggingface.co/docs/hub/spaces">Code2</a></div>
<details class="detail"><summary>Abstract</summary>
<div class="mono">Model editing aims to correct errors in large, pretrained models without altering unrelated behaviors. While some recent works have edited vision-language models (VLMs), no existing editors tackle reasoning-heavy tasks, which typically require humans and models to reason about images.We therefore propose ReasonEdit, the first VLM editor to let users explain their reasoning during editing, introducing a new, practical model editing setup. ReasonEdit continuously stores human reasoning in a codebook, and retrieves only relevant facts during inference using a novel topology-balanced multimodal embedding method inspired by network science. Across four VLMs on multiple rationale-based visual question answering datasets, ReasonEdit achieves state-of-the-art editing performance, ultimately showing that using human reasoning during editing greatly improves edit generalization.</div></details>
<details class="detail"><summary>中文标题/摘要</summary>
<div class="mono"><b>标题：</b>ReasonEdit：基于人类推理的视觉语言模型编辑方法</div>
<div class="mono" style="margin-top:8px">模型编辑旨在修正大型预训练模型的错误而不影响无关行为。现有视觉语言模型编辑器尚未涉及需要人类与模型对图像进行推理的复杂任务。为此，我们提出首个支持用户在编辑过程中解释推理逻辑的视觉语言模型编辑器ReasonEdit，构建了新颖实用的模型编辑框架。该方法通过受网络科学启发的拓扑平衡多模态嵌入技术，将人类推理持续存储于编码本，并在推理时仅检索相关事实。在四个视觉语言模型及多个基于推理的视觉问答数据集上的实验表明，ReasonEdit实现了最先进的编辑性能，证明编辑过程中引入人类推理能显著提升编辑泛化能力。</div>
</details>
<details class="detail"><summary>Summary / 总结</summary>
<div class="mono">The research is motivated by the need to correct errors in vision-language models (VLMs) without affecting unrelated capabilities, particularly for reasoning-heavy tasks where existing editors fall short. The method introduces ReasonEdit, a novel editor that allows users to incorporate human reasoning during edits by storing reasoning in a codebook and retrieving relevant facts during inference via a topology-balanced multimodal embedding technique inspired by network science. Experimental results on multiple rationale-based visual question answering datasets across four VLMs demonstrate state-of-the-art editing performance, showing that integrating human reasoning significantly enhances edit generalization.</div>
<div class="mono" style="margin-top:8px">该研究的动机在于需要纠正视觉-语言模型在推理密集型任务中的错误，而现有模型编辑方法未能利用人类推理。提出的方法ReasonEdit引入了一种新颖的编辑设置，允许用户提供推理解释，将人类推理持续存储在码本中，并在推理时使用受网络科学启发的拓扑平衡多模态嵌入技术检索相关事实。在四个视觉-语言模型和多个基于原理的视觉问答数据集上的实验结果表明，ReasonEdit实现了最先进的编辑性能，证明在编辑中融入人类推理能显著提升编辑泛化能力。</div>
</details>
</div>
<div class="card">
<div class="title">Didactic to Constructive: Turning Expert Solutions into Learnable Reasoning</div>
<div class="meta-line">Authors: Ethan Mendes, Jungsoo Park, Alan Ritter</div>
<div class="meta-line">First: 2026-02-02T18:03:43+00:00 · Latest: 2026-02-02T18:03:43+00:00</div>
<div class="links" style="margin-top:8px"><a href="https://arxiv.org/abs/2602.02405v1">Abs</a> · <a href="https://arxiv.org/pdf/2602.02405v1">PDF</a> · <a href="https://huggingface.co/huggingface">Code1</a> · <a href="https://huggingface.co/docs/hub/spaces">Code2</a></div>
<details class="detail"><summary>Abstract</summary>
<div class="mono">Improving the reasoning capabilities of large language models (LLMs) typically relies either on the model&#x27;s ability to sample a correct solution to be reinforced or on the existence of a stronger model able to solve the problem. However, many difficult problems remain intractable for even current frontier models, preventing the extraction of valid training signals. A promising alternative is to leverage high-quality expert human solutions, yet naive imitation of this data fails because it is fundamentally out of distribution: expert solutions are typically didactic, containing implicit reasoning gaps intended for human readers rather than computational models. Furthermore, high-quality expert solutions are expensive, necessitating generalizable sample-efficient training methods. We propose Distribution Aligned Imitation Learning (DAIL), a two-step method that bridges the distributional gap by first transforming expert solutions into detailed, in-distribution reasoning traces and then applying a contrastive objective to focus learning on expert insights and methodologies. We find that DAIL can leverage fewer than 1000 high-quality expert solutions to achieve 10-25% pass@k gains on Qwen2.5-Instruct and Qwen3 models, improve reasoning efficiency by 2x to 4x, and enable out-of-domain generalization.</div></details>
<details class="detail"><summary>中文标题/摘要</summary>
<div class="mono"><b>标题：</b>从说教到建构：将专家解法转化为可学习的推理过程</div>
<div class="mono" style="margin-top:8px">提升大语言模型（LLMs）的推理能力通常依赖模型采样正确解以供强化，或依赖更强模型解决问题。然而，许多难题即使对当前前沿模型仍不可解，导致无法提取有效训练信号。利用高质量人类专家解法是可行替代方案，但直接模仿此类数据往往失效，因其本质分布外移：专家解法通常具有说教性，包含面向人类读者而非计算模型的隐含推理断层。此外，高质量专家解法成本高昂，需开发泛化性强、样本高效的训练方法。我们提出分布对齐模仿学习（DAIL），通过两步法弥合分布差距：先将专家解法转化为分布内的详细推理轨迹，再采用对比目标使学习聚焦于专家洞见与方法论。实验表明，DAIL仅需不足1000个高质量专家样本，即可在Qwen2.5-Instruct和Qwen3模型上实现10-25%的pass@k增益，推理效率提升2至4倍，并具备跨领域泛化能力。</div>
</details>
<details class="detail"><summary>Summary / 总结</summary>
<div class="mono">The research addresses the challenge of improving large language models&#x27; reasoning on difficult problems where neither model self-sampling nor stronger model solutions are available, and where directly imitating scarce, high-quality expert solutions fails due to their didactic, human-oriented nature being out-of-distribution for models. The proposed method, Distribution Aligned Imitation Learning (DAIL), first transforms expert solutions into detailed, model-aligned reasoning traces and then applies a contrastive learning objective to focus on the core expert methodologies. Experimental results show that DAIL, using fewer than 1000 expert solutions, yields 10-25% pass@k gains on Qwen2.5-Instruct and Qwen3 models, improves reasoning efficiency by 2x to 4x, and enables out-of-domain generalization.</div>
<div class="mono" style="margin-top:8px">本研究旨在解决提升大语言模型在困难问题上的推理能力所面临的挑战，即当模型自身采样或更强模型均无法提供解决方案，且直接模仿稀缺、高质量专家方案会因其说教式、面向人类的特性而与模型分布不匹配时，如何有效利用专家知识。所提出的方法——分布对齐模仿学习（DAIL）——首先将专家解决方案转化为详细的、与模型分布对齐的推理轨迹，然后应用对比学习目标以聚焦于核心的专家方法。实验结果表明，DAIL使用少于1000个专家解决方案，便在Qwen2.5-Instruct和Qwen3模型上实现了10-25%的pass@k提升，将推理效率提高了2到4倍，并展现出领域外泛化能力。</div>
</details>
</div>
<div class="card">
<div class="title">Language Family Matters: Evaluating LLM-Based ASR Across Linguistic Boundaries</div>
<div class="meta-line">Authors: Yuchen Zhang, Ravi Shekhar, Haralambos Mouratidis</div>
<div class="meta-line">First: 2026-01-26T19:11:03+00:00 · Latest: 2026-02-02T18:02:52+00:00</div>
<div class="meta-line">Comments: Accepted by EACL&#x27;26 main</div>
<div class="links" style="margin-top:8px"><a href="https://arxiv.org/abs/2601.18899v2">Abs</a> · <a href="https://arxiv.org/pdf/2601.18899v2">PDF</a> · <a href="https://huggingface.co/huggingface">Code1</a> · <a href="https://huggingface.co/docs/hub/spaces">Code2</a></div>
<details class="detail"><summary>Abstract</summary>
<div class="mono">Large Language Model (LLM)-powered Automatic Speech Recognition (ASR) systems achieve strong performance with limited resources by linking a frozen speech encoder to a pretrained LLM via a lightweight connector. Prior work trains a separate connector per language, overlooking linguistic relatedness. We propose an efficient and novel connector-sharing strategy based on linguistic family membership, enabling one connector per family, and empirically validate its effectiveness across two multilingual LLMs and two real-world corpora spanning curated and crowd-sourced speech. Our results show that family-based connectors reduce parameter count while improving generalization across domains, offering a practical and scalable strategy for multilingual ASR deployment.</div></details>
<details class="detail"><summary>中文标题/摘要</summary>
<div class="mono"><b>标题：</b>语言谱系的重要性：跨语言边界评估基于大语言模型的自动语音识别系统</div>
<div class="mono" style="margin-top:8px">基于大语言模型（LLM）的自动语音识别（ASR）系统通过轻量级连接器将冻结的语音编码器与预训练大语言模型相连接，在有限资源下实现了优异性能。先前研究为每种语言单独训练连接器，忽略了语言间的亲缘关系。我们提出一种基于语言谱系归属的高效创新连接器共享策略，实现每个语系仅需一个连接器，并在两种多语言大语言模型和两个涵盖精选与众包语音的真实语料库上实证验证了其有效性。结果表明，基于语系的连接器在减少参数量的同时提升了跨领域泛化能力，为多语言ASR部署提供了实用且可扩展的策略。</div>
</details>
<details class="detail"><summary>Summary / 总结</summary>
<div class="mono">The research addresses the inefficiency of training separate connectors for each language in LLM-based ASR systems, which ignores linguistic relationships. The method introduces a connector-sharing strategy based on language families, allowing a single connector to serve multiple languages within the same family, thereby reducing parameters. Experimental results using two multilingual LLMs and two speech corpora demonstrate that this approach not only decreases the parameter count but also enhances cross-domain generalization, providing a scalable solution for multilingual ASR deployment.</div>
<div class="mono" style="margin-top:8px">本研究针对基于大语言模型的自动语音识别系统中为每种语言单独训练连接器效率低下、忽视语言亲缘关系的问题，提出了一种基于语言谱系成员关系的连接器共享策略，使得同一语系的语言可共享一个连接器以减少参数量。通过在两个多语言大语言模型和两个涵盖精选与众包语音的真实语料库上进行实验验证，结果表明这种基于语系的方法在减少参数的同时，提升了跨领域的泛化能力，为多语言ASR部署提供了更实用且可扩展的解决方案。</div>
</details>
</div>
<div class="card">
<div class="title">SoMA: A Real-to-Sim Neural Simulator for Robotic Soft-body Manipulation</div>
<div class="meta-line">Authors: Mu Huang, Hui Wang, Kerui Ren, Linning Xu, Yunsong Zhou, Mulin Yu, Bo Dai, Jiangmiao Pang</div>
<div class="meta-line">First: 2026-02-02T17:59:31+00:00 · Latest: 2026-02-02T17:59:31+00:00</div>
<div class="meta-line">Comments: Project page: https://city-super.github.io/SoMA/</div>
<div class="links" style="margin-top:8px"><a href="https://arxiv.org/abs/2602.02402v1">Abs</a> · <a href="https://arxiv.org/pdf/2602.02402v1">PDF</a> · <a href="https://huggingface.co/huggingface">Code1</a> · <a href="https://huggingface.co/docs/hub/spaces">Code2</a> · <a href="https://city-super.github.io/SoMA/">Project1</a></div>
<details class="detail"><summary>Abstract</summary>
<div class="mono">Simulating deformable objects under rich interactions remains a fundamental challenge for real-to-sim robot manipulation, with dynamics jointly driven by environmental effects and robot actions. Existing simulators rely on predefined physics or data-driven dynamics without robot-conditioned control, limiting accuracy, stability, and generalization. This paper presents SoMA, a 3D Gaussian Splat simulator for soft-body manipulation. SoMA couples deformable dynamics, environmental forces, and robot joint actions in a unified latent neural space for end-to-end real-to-sim simulation. Modeling interactions over learned Gaussian splats enables controllable, stable long-horizon manipulation and generalization beyond observed trajectories without predefined physical models. SoMA improves resimulation accuracy and generalization on real-world robot manipulation by 20%, enabling stable simulation of complex tasks such as long-horizon cloth folding.</div></details>
<details class="detail"><summary>中文标题/摘要</summary>
<div class="mono"><b>标题：</b>SoMA：面向机器人软体操作的真实到仿真神经模拟器</div>
<div class="mono" style="margin-top:8px">在丰富交互条件下模拟可变形物体仍是真实到仿真机器人操作的核心挑战，其动力学同时受环境效应与机器人动作驱动。现有模拟器依赖预定义物理模型或无机器人条件控制的数据驱动动力学，限制了精度、稳定性和泛化能力。本文提出SoMA——基于三维高斯溅射的软体操作模拟器。SoMA将可变形动力学、环境作用力与机器人关节动作耦合于统一潜在神经空间，实现端到端真实到仿真模拟。通过学习的高斯溅射建模交互，可在无预定义物理模型条件下实现可控、稳定的长时程操作，并泛化至未观测轨迹。SoMA将真实机器人操作的再模拟精度与泛化能力提升20%，支持长时程布料折叠等复杂任务的稳定仿真。</div>
</details>
<details class="detail"><summary>Summary / 总结</summary>
<div class="mono">This research addresses the challenge of accurately simulating deformable objects in robotic manipulation, where dynamics are influenced by both environmental forces and robot actions. The authors propose SoMA, a neural simulator that uses 3D Gaussian Splatting to model soft-body dynamics in a unified latent space, integrating robot joint actions for end-to-end real-to-simulation. Experimental results show that SoMA improves resimulation accuracy and generalization by 20% over existing methods, enabling stable, long-horizon simulation of complex tasks like cloth folding without predefined physical models.</div>
<div class="mono" style="margin-top:8px">本研究针对机器人操作中可变形物体模拟的挑战，其动力学同时受环境力和机器人动作影响。作者提出了SoMA，一种利用3D高斯泼溅在统一潜在空间中建模软体动力学的神经模拟器，集成了机器人关节动作以实现端到端的真实到模拟。实验结果表明，SoMA将重模拟精度和泛化能力提高了20%，无需预定义物理模型即可稳定模拟如布料折叠等复杂的长时程任务。</div>
</details>
</div>
<div class="card">
<div class="title">David vs. Goliath: Verifiable Agent-to-Agent Jailbreaking via Reinforcement Learning</div>
<div class="meta-line">Authors: Samuel Nellessen, Tal Kachman</div>
<div class="meta-line">First: 2026-02-02T17:56:55+00:00 · Latest: 2026-02-02T17:56:55+00:00</div>
<div class="meta-line">Comments: Under review. 8 main pages, 2 figures, 2 tables. Appendix included</div>
<div class="links" style="margin-top:8px"><a href="https://arxiv.org/abs/2602.02395v1">Abs</a> · <a href="https://arxiv.org/pdf/2602.02395v1">PDF</a> · <a href="https://huggingface.co/huggingface">Code1</a> · <a href="https://huggingface.co/docs/hub/spaces">Code2</a></div>
<details class="detail"><summary>Abstract</summary>
<div class="mono">The evolution of large language models into autonomous agents introduces adversarial failures that exploit legitimate tool privileges, transforming safety evaluation in tool-augmented environments from a subjective NLP task into an objective control problem. We formalize this threat model as Tag-Along Attacks: a scenario where a tool-less adversary &quot;tags along&quot; on the trusted privileges of a safety-aligned Operator to induce prohibited tool use through conversation alone. To validate this threat, we present Slingshot, a &#x27;cold-start&#x27; reinforcement learning framework that autonomously discovers emergent attack vectors, revealing a critical insight: in our setting, learned attacks tend to converge to short, instruction-like syntactic patterns rather than multi-turn persuasion. On held-out extreme-difficulty tasks, Slingshot achieves a 67.0% success rate against a Qwen2.5-32B-Instruct-AWQ Operator (vs. 1.7% baseline), reducing the expected attempts to first success (on solved tasks) from 52.3 to 1.3. Crucially, Slingshot transfers zero-shot to several model families, including closed-source models like Gemini 2.5 Flash (56.0% attack success rate) and defensive-fine-tuned open-source models like Meta-SecAlign-8B (39.2% attack success rate). Our work establishes Tag-Along Attacks as a first-class, verifiable threat model and shows that effective agentic attacks can be elicited from off-the-shelf open-weight models through environment interaction alone.</div></details>
<details class="detail"><summary>中文标题/摘要</summary>
<div class="mono"><b>标题：</b>大卫对阵歌利亚：基于强化学习的可验证智能体间越狱攻击</div>
<div class="mono" style="margin-top:8px">大型语言模型向自主智能体的演进引入了利用合法工具权限的对抗性失效，将工具增强环境中的安全评估从主观自然语言处理任务转变为客观控制问题。我们将此威胁模型形式化为&#x27;尾随攻击&#x27;：无工具攻击者通过对话&#x27;尾随&#x27;安全对齐操作者的受信权限，仅凭交流即可诱导被禁止的工具使用。为验证该威胁，我们提出&#x27;弹弓&#x27;框架——一种&#x27;冷启动&#x27;强化学习系统，能自主发现涌现的攻击向量，揭示关键洞见：在我们的设定中，习得攻击倾向于收敛为简短、类指令的句法模式，而非多轮次说服。在保留的极端难度任务上，弹弓对Qwen2.5-32B-Instruct-AWQ操作者的攻击成功率达67.0%（基线为1.7%），将首次成功所需预期尝试次数（在已破解任务中）从52.3次降至1.3次。关键的是，弹弓能零样本迁移至多个模型系列，包括Gemini 2.5 Flash等闭源模型（56.0%攻击成功率）和Meta-SecAlign-8B等防御性微调开源模型（39.2%攻击成功率）。本研究确立了尾随攻击作为一类可验证的一级威胁模型，并证明仅通过环境交互即可从现成的开放权重模型中引发有效的智能体攻击。</div>
</details>
<details class="detail"><summary>Summary / 总结</summary>
<div class="mono">The research addresses a novel adversarial threat in tool-augmented language model agents, where a safety-aligned agent&#x27;s tool privileges can be hijacked through conversation by a less capable adversary, formalized as Tag-Along Attacks. To validate this, the authors introduce Slingshot, a reinforcement learning framework that autonomously discovers attack vectors, finding that effective attacks converge to short, instruction-like patterns rather than complex persuasion. Experimental results show Slingshot achieves a 67.0% success rate against a Qwen2.5-32B-Instruct-AWQ operator, drastically reducing the expected attempts for first success from 52.3 to 1.3, and demonstrates strong zero-shot transferability to other model families including closed-source and defensively fine-tuned models.</div>
<div class="mono" style="margin-top:8px">本研究针对自主语言模型代理利用合法工具权限的安全威胁，将其形式化为“跟随攻击”，即无工具权限的攻击者通过对话操纵安全对齐的操作员进行被禁止的工具使用。作者开发了Slingshot强化学习框架，自主发现攻击向量，发现有效攻击收敛于简短指令式模式而非多轮说服。实验结果表明，Slingshot对Qwen2.5-32B-Instruct-AWQ操作员的攻击成功率达67.0%（基线为1.7%），并能零样本迁移至包括Gemini 2.5 Flash（56.0%成功率）和Meta-SecAlign-8B（39.2%成功率）在内的多种模型系列，证明了仅通过环境交互即可实现代理攻击的可行性。</div>
</details>
</div>
<div class="card">
<div class="title">Outcome-Based RL Provably Leads Transformers to Reason, but Only With the Right Data</div>
<div class="meta-line">Authors: Yuval Ran-Milo, Yotam Alexander, Shahar Mendel, Nadav Cohen</div>
<div class="meta-line">First: 2026-01-21T16:36:19+00:00 · Latest: 2026-02-02T17:56:01+00:00</div>
<div class="meta-line">Comments: 87 pages, 6 figures</div>
<div class="links" style="margin-top:8px"><a href="https://arxiv.org/abs/2601.15158v3">Abs</a> · <a href="https://arxiv.org/pdf/2601.15158v3">PDF</a> · <a href="https://huggingface.co/huggingface">Code1</a> · <a href="https://huggingface.co/docs/hub/spaces">Code2</a></div>
<details class="detail"><summary>Abstract</summary>
<div class="mono">Transformers trained via Reinforcement Learning (RL) with outcome-based supervision can spontaneously develop the ability to generate intermediate reasoning steps (Chain-of-Thought). Yet the mechanism by which sparse rewards drive policy gradient to discover such systematic reasoning remains poorly understood. We address this by analyzing the policy gradient dynamics of single-layer Transformers on a synthetic graph traversal task that cannot be solved without Chain-of-Thought but admits a simple iterative solution. We prove that despite training solely on final-answer correctness, policy gradient drives the Transformer to converge to a structured, interpretable algorithm that iteratively traverses the graph vertex-by-vertex. We characterize the distributional properties required for this emergence, identifying the critical role of &quot;simple examples&quot;: instances requiring fewer reasoning steps. When the training distribution places sufficient mass on these simpler examples, the Transformer learns a generalizable traversal strategy that extrapolates to longer chains; when this mass vanishes, policy gradient learning becomes infeasible. We corroborate our theoretical results through experiments on synthetic data and with real-world language models on mathematical reasoning tasks, validating that our theoretical findings carry over to practical settings.</div></details>
<details class="detail"><summary>中文标题/摘要</summary>
<div class="mono"><b>标题：</b>基于结果的强化学习可证明引导Transformer进行推理，但仅适用于特定数据</div>
<div class="mono" style="margin-top:8px">通过基于结果的监督进行强化学习训练的Transformer能够自发产生中间推理步骤（思维链）。然而，稀疏奖励如何驱动策略梯度发现这种系统性推理的机制仍不明确。我们通过分析单层Transformer在合成图遍历任务上的策略梯度动态来研究此问题——该任务必须通过思维链才能解决，但存在简单的迭代解法。我们证明：尽管仅通过最终答案正确性进行训练，策略梯度仍能驱动Transformer收敛至一种结构化、可解释的逐顶点迭代遍历算法。我们刻画了该现象涌现所需的分布特性，指出“简单样本”（需要较少推理步骤的实例）的关键作用。当训练分布中简单样本具有足够权重时，Transformer能学习可泛化至更长链的遍历策略；若此类样本缺失，策略梯度学习将无法实现。我们通过合成数据实验及真实数学推理任务的语言模型实验验证了理论结论在实际场景中的适用性。</div>
</details>
<details class="detail"><summary>Summary / 总结</summary>
<div class="mono">This research investigates how Transformers trained with outcome-based reinforcement learning (RL) can autonomously develop chain-of-thought reasoning, a mechanism not well understood. The authors analyze policy gradient dynamics on a synthetic graph traversal task that necessitates intermediate reasoning steps, proving that training solely on final-answer correctness leads the model to converge to an interpretable, iterative algorithm for vertex-by-vertex traversal. Key experimental findings highlight that the emergence of this generalizable reasoning strategy critically depends on the training distribution containing sufficient &#x27;simple examples&#x27; (instances requiring fewer steps); without them, learning fails, a result validated on both synthetic data and real-world language models for mathematical reasoning.</div>
<div class="mono" style="margin-top:8px">本研究旨在探究基于结果的强化学习训练的Transformer模型如何自发产生思维链推理，这一机制此前尚未得到充分理解。作者通过分析在必须依赖中间推理步骤的合成图遍历任务上的策略梯度动态，证明仅基于最终答案正确性的训练能使模型收敛到一个可解释的、逐顶点迭代遍历的算法。关键的实验结果表明，这种可泛化推理策略的出现，关键依赖于训练数据分布包含足够多的“简单示例”（即所需推理步骤较少的实例）；若缺乏此类示例，学习将无法进行，这一发现在合成数据以及用于数学推理的真实世界语言模型实验中都得到了验证。</div>
</details>
</div>
<div class="card">
<div class="title">Infinite-World: Scaling Interactive World Models to 1000-Frame Horizons via Pose-Free Hierarchical Memory</div>
<div class="meta-line">Authors: Ruiqi Wu, Xuanhua He, Meng Cheng, Tianyu Yang, Yong Zhang, Zhuoliang Kang, Xunliang Cai, Xiaoming Wei, Chunle Guo, Chongyi Li, Ming-Ming Cheng</div>
<div class="meta-line">First: 2026-02-02T17:52:56+00:00 · Latest: 2026-02-02T17:52:56+00:00</div>
<div class="meta-line">Comments: 14 pages, 8 figures</div>
<div class="links" style="margin-top:8px"><a href="https://arxiv.org/abs/2602.02393v1">Abs</a> · <a href="https://arxiv.org/pdf/2602.02393v1">PDF</a> · <a href="https://huggingface.co/huggingface">Code1</a> · <a href="https://huggingface.co/docs/hub/spaces">Code2</a></div>
<details class="detail"><summary>Abstract</summary>
<div class="mono">We propose Infinite-World, a robust interactive world model capable of maintaining coherent visual memory over 1000+ frames in complex real-world environments. While existing world models can be efficiently optimized on synthetic data with perfect ground-truth, they lack an effective training paradigm for real-world videos due to noisy pose estimations and the scarcity of viewpoint revisits. To bridge this gap, we first introduce a Hierarchical Pose-free Memory Compressor (HPMC) that recursively distills historical latents into a fixed-budget representation. By jointly optimizing the compressor with the generative backbone, HPMC enables the model to autonomously anchor generations in the distant past with bounded computational cost, eliminating the need for explicit geometric priors. Second, we propose an Uncertainty-aware Action Labeling module that discretizes continuous motion into a tri-state logic. This strategy maximizes the utilization of raw video data while shielding the deterministic action space from being corrupted by noisy trajectories, ensuring robust action-response learning. Furthermore, guided by insights from a pilot toy study, we employ a Revisit-Dense Finetuning Strategy using a compact, 30-minute dataset to efficiently activate the model&#x27;s long-range loop-closure capabilities. Extensive experiments, including objective metrics and user studies, demonstrate that Infinite-World achieves superior performance in visual quality, action controllability, and spatial consistency.</div></details>
<details class="detail"><summary>中文标题/摘要</summary>
<div class="mono"><b>标题：</b>Infinite-World：通过无姿态分层记忆将交互式世界模型扩展至千帧级视野</div>
<div class="mono" style="margin-top:8px">我们提出Infinite-World，一种鲁棒的交互式世界模型，能够在复杂现实环境中保持超过1000帧的连贯视觉记忆。现有世界模型虽可在具有完美真值的合成数据上高效优化，但因姿态估计噪声和视角重访稀缺，缺乏针对真实世界视频的有效训练范式。为弥合此差距，我们首先引入分层无姿态记忆压缩器（HPMC），通过递归将历史隐变量蒸馏为固定预算的表征。通过将压缩器与生成主干联合优化，HPMC使模型能够以有限计算成本自主锚定远历史生成，无需显式几何先验。其次，我们提出不确定性感知动作标注模块，将连续运动离散化为三态逻辑。该策略在最大化原始视频数据利用率的同时，保护确定性动作空间免受噪声轨迹干扰，确保鲁棒的动作响应学习。此外，基于初步玩具实验的洞察，我们采用重访密集微调策略，利用紧凑的30分钟数据集高效激活模型的长程闭环能力。大量实验（包括客观指标和用户研究）表明，Infinite-World在视觉质量、动作可控性和空间一致性方面均取得优越性能。</div>
</details>
<details class="detail"><summary>Summary / 总结</summary>
<div class="mono">This research addresses the limitations of existing world models in handling real-world videos, which suffer from noisy pose estimations and infrequent viewpoint revisits. The method introduces a Hierarchical Pose-free Memory Compressor (HPMC) that recursively distills historical latents into a fixed-budget representation, eliminating the need for explicit geometric priors, and an Uncertainty-aware Action Labeling module that discretizes continuous motion to protect the action space from noisy trajectories. Experimental results, including objective metrics and user studies, demonstrate that the proposed Infinite-World model achieves superior performance in visual quality, action controllability, and spatial consistency over long horizons exceeding 1000 frames.</div>
<div class="mono" style="margin-top:8px">该研究旨在解决交互式世界模型在真实世界视频中扩展到长时程的挑战，现有方法因噪声姿态估计和有限视角重访而效果不佳。方法引入了分层无姿态记忆压缩器（HPMC），通过递归将历史潜在变量蒸馏为固定预算的表示，并与生成主干联合优化，从而无需显式几何先验即可锚定远距离生成；同时提出不确定性感知动作标注模块，将连续运动离散化为三态逻辑，以利用原始视频数据同时保护动作空间免受噪声干扰；随后采用重访密集微调策略来激活长程闭环能力。实验结果表明，包括客观指标和用户研究在内，Infinite-World在超过1000帧的视觉质量、动作可控性和空间一致性方面均取得了优越性能。</div>
</details>
</div>
<div class="card">
<div class="title">Trust by Design: Skill Profiles for Transparent, Cost-Aware LLM Routing</div>
<div class="meta-line">Authors: Mika Okamoto, Ansel Kaplan Erol, Glenn Matlin</div>
<div class="meta-line">First: 2026-02-02T17:49:30+00:00 · Latest: 2026-02-02T17:49:30+00:00</div>
<div class="meta-line">Comments: Appeared at MLSys YPS 2025</div>
<div class="links" style="margin-top:8px"><a href="https://arxiv.org/abs/2602.02386v1">Abs</a> · <a href="https://arxiv.org/pdf/2602.02386v1">PDF</a> · <a href="https://huggingface.co/huggingface">Code1</a> · <a href="https://huggingface.co/docs/hub/spaces">Code2</a></div>
<details class="detail"><summary>Abstract</summary>
<div class="mono">How should Large Language Model (LLM) practitioners select the right model for a task without wasting money? We introduce BELLA (Budget-Efficient LLM Selection via Automated skill-profiling), a framework that recommends optimal LLM selection for tasks through interpretable skill-based model selection. Standard benchmarks report aggregate metrics that obscure which specific capabilities a task requires and whether a cheaper model could suffice. BELLA addresses this gap through three stages: (1) decomposing LLM outputs and extract the granular skills required by using critic-based profiling, (2) clustering skills into structured capability matrices, and (3) multi-objective optimization to select the right models to maximize performance while respecting budget constraints. BELLA provides natural-language rationale for recommendations, providing transparency that current black-box routing systems lack. We describe the framework architecture, situate it within the landscape of LLM routing and evaluation, and discuss its application to financial reasoning as a representative domain exhibiting diverse skill requirements and cost-variation across models. Our framework enables practitioners to make principled and cost-performance trade-offs for deploying LLMs.</div></details>
<details class="detail"><summary>中文标题/摘要</summary>
<div class="mono"><b>标题：</b>信任设计：面向透明、成本感知大语言模型路由的技能画像</div>
<div class="mono" style="margin-top:8px">大语言模型从业者应如何为任务选择合适的模型，同时避免资源浪费？本文提出BELLA（基于自动化技能画像的预算高效大语言模型选择框架），该框架通过可解释的基于技能的模型选择机制，为任务推荐最优的大语言模型配置。传统基准测试通常报告聚合指标，这掩盖了任务所需的具体能力以及更经济的模型是否足够的问题。BELLA通过三阶段流程解决这一缺陷：（1）通过基于评判的画像方法分解大语言模型输出并提取细粒度技能；（2）将技能聚类为结构化能力矩阵；（3）通过多目标优化选择最佳模型，在满足预算约束的同时最大化性能。BELLA为推荐结果提供自然语言依据，弥补了当前黑盒路由系统缺乏透明性的不足。本文阐述了框架架构，将其置于大语言模型路由与评估的研究体系中，并以金融推理为代表领域（该领域具有多样化的技能需求及显著的模型成本差异）探讨了其应用场景。该框架使从业者能够在部署大语言模型时实现原则性与成本效益的平衡。</div>
</details>
<details class="detail"><summary>Summary / 总结</summary>
<div class="mono">To help practitioners select appropriate large language models (LLMs) for tasks without overspending, this research introduces BELLA, a framework for budget-efficient and transparent model routing. The method decomposes LLM outputs to identify granular skills via critic-based profiling, clusters these skills into structured capability matrices, and then uses multi-objective optimization to recommend models that balance performance and cost. In application to domains like financial reasoning, BELLA demonstrates the ability to provide interpretable, skill-based rationales for its recommendations, enabling principled cost-performance trade-offs that are obscured by aggregate benchmark metrics.</div>
<div class="mono" style="margin-top:8px">为帮助从业者在不过度支出的情况下为任务选择合适的语言模型，本研究提出了BELLA框架，用于实现预算高效且透明的大语言模型路由。该方法通过基于批评者的分析分解模型输出来识别细粒度技能，将这些技能聚类为结构化能力矩阵，并利用多目标优化推荐平衡性能与成本的模型。在金融推理等具有多样化技能需求的领域实验中，BELLA为其推荐提供了可解释的自然语言理由，实现了优于聚合基准指标的成本与性能权衡。</div>
</details>
</div>
<div class="card">
<div class="title">EUGens: Efficient, Unified, and General Dense Layers</div>
<div class="meta-line">Authors: Sang Min Kim, Byeongchan Kim, Arijit Sehanobish, Somnath Basu Roy Chowdhury, Rahul Kidambi, Dongseok Shim, Avinava Dubey, Snigdha Chaturvedi, Min-hwan Oh, Krzysztof Choromanski</div>
<div class="meta-line">First: 2026-01-30T05:01:03+00:00 · Latest: 2026-02-02T17:47:29+00:00</div>
<div class="meta-line">Comments: We want to update 2410.09771 with this submission</div>
<div class="links" style="margin-top:8px"><a href="https://arxiv.org/abs/2601.22563v2">Abs</a> · <a href="https://arxiv.org/pdf/2601.22563v2">PDF</a> · <a href="https://huggingface.co/huggingface">Code1</a> · <a href="https://huggingface.co/docs/hub/spaces">Code2</a></div>
<details class="detail"><summary>Abstract</summary>
<div class="mono">Efficient neural networks are essential for scaling machine learning models to real-time applications and resource-constrained environments. Fully-connected feedforward layers (FFLs) introduce computation and parameter count bottlenecks within neural network architectures. To address this challenge, in this work, we propose a new class of dense layers that generalize standard fully-connected feedforward layers, \textbf{E}fficient, \textbf{U}nified and \textbf{Gen}eral dense layers (EUGens). EUGens leverage random features to approximate standard FFLs and go beyond them by incorporating a direct dependence on the input norms in their computations. The proposed layers unify existing efficient FFL extensions and improve efficiency by reducing inference complexity from quadratic to linear time. They also lead to \textbf{the first} unbiased algorithms approximating FFLs with arbitrary polynomial activation functions. Furthermore, EuGens reduce the parameter count and computational overhead while preserving the expressive power and adaptability of FFLs. We also present a layer-wise knowledge transfer technique that bypasses backpropagation, enabling efficient adaptation of EUGens to pre-trained models. Empirically, we observe that integrating EUGens into Transformers and MLPs yields substantial improvements in inference speed (up to \textbf{27}\%) and memory efficiency (up to \textbf{30}\%) across a range of tasks, including image classification, language model pre-training, and 3D scene reconstruction. Overall, our results highlight the potential of EUGens for the scalable deployment of large-scale neural networks in real-world scenarios.</div></details>
<details class="detail"><summary>中文标题/摘要</summary>
<div class="mono"><b>标题：</b>EUGens：高效、统一、通用的密集层</div>
<div class="mono" style="margin-top:8px">高效神经网络对于将机器学习模型扩展至实时应用与资源受限环境至关重要。全连接前馈层在神经网络架构中引入了计算量与参数量的瓶颈。为应对这一挑战，本研究提出了一类新型密集层，其推广了标准全连接前馈层，即高效、统一、通用密集层。EUGens利用随机特征逼近标准前馈层，并通过在计算中引入对输入范数的直接依赖实现超越。该层统一了现有高效前馈层扩展方案，将推理复杂度从二次降至线性，显著提升效率。同时首次实现了以任意多项式激活函数逼近前馈层的无偏算法。EUGens在保持前馈层表达力与适应性的前提下，有效减少了参数量与计算开销。我们还提出了一种无需反向传播的层级知识迁移技术，支持将EUGens高效适配至预训练模型。实验表明，在图像分类、语言模型预训练及三维场景重建等任务中，将EUGens集成至Transformer与MLP架构可显著提升推理速度（最高达27%）与内存效率（最高达30%）。总体而言，本研究结果凸显了EUGens在大规模神经网络实际场景可扩展部署中的应用潜力。</div>
</details>
<details class="detail"><summary>Summary / 总结</summary>
<div class="mono">To address the computational and parameter inefficiency of standard fully-connected feedforward layers (FFLs) in neural networks, this work introduces EUGens, a new class of dense layers that generalize FFLs. The method leverages random features to approximate standard FFLs and incorporates input norm dependence, unifying existing efficient extensions and reducing inference complexity from quadratic to linear time while enabling unbiased approximation of FFLs with arbitrary polynomial activations. Experimental results show that integrating EUGens into Transformers and MLPs improves inference speed by up to 27% and memory efficiency by up to 30% across tasks like image classification, language model pre-training, and 3D scene reconstruction.</div>
<div class="mono" style="margin-top:8px">为解决标准全连接前馈层在神经网络中存在的计算和参数量瓶颈，本研究提出了EUGens，一种新的、可泛化标准全连接层的高效密集层类别。该方法利用随机特征来近似标准全连接层，并引入输入范数依赖性，从而统一了现有的高效扩展方法，将推理复杂度从二次降低到线性，并能无偏地近似具有任意多项式激活函数的全连接层。实验结果表明，将EUGens集成到Transformer和MLP中，在图像分类、语言模型预训练和3D场景重建等任务上，推理速度最高提升27%，内存效率最高提升30%。</div>
</details>
</div></div>
    <details style="margin-top:16px" class="detail"><summary>History</summary>
      <div class="history-list"><a href="archive/20260202_0623.html">20260202_0623</a>
<a href="archive/20260202_0525.html">20260202_0525</a>
<a href="archive/20260202_0441.html">20260202_0441</a>
<a href="archive/20260202_0331.html">20260202_0331</a>
<a href="archive/20260201_0625.html">20260201_0625</a>
<a href="archive/20260201_0527.html">20260201_0527</a>
<a href="archive/20260201_0443.html">20260201_0443</a>
<a href="archive/20260201_0331.html">20260201_0331</a>
<a href="archive/20260131_0628.html">20260131_0628</a>
<a href="archive/20260131_0535.html">20260131_0535</a>
<a href="archive/20260131_0449.html">20260131_0449</a>
<a href="archive/20260131_0342.html">20260131_0342</a>
<a href="archive/20260130_0631.html">20260130_0631</a>
<a href="archive/20260130_0533.html">20260130_0533</a>
<a href="archive/20260130_0449.html">20260130_0449</a>
<a href="archive/20260130_0341.html">20260130_0341</a>
<a href="archive/20260129_0630.html">20260129_0630</a>
<a href="archive/20260129_0536.html">20260129_0536</a>
<a href="archive/20260129_0450.html">20260129_0450</a>
<a href="archive/20260129_0336.html">20260129_0336</a>
<a href="archive/20260128_0625.html">20260128_0625</a>
<a href="archive/20260128_0439.html">20260128_0439</a>
<a href="archive/20260128_0334.html">20260128_0334</a>
<a href="archive/20260127_0627.html">20260127_0627</a>
<a href="archive/20260127_0529.html">20260127_0529</a>
<a href="archive/20260127_0439.html">20260127_0439</a>
<a href="archive/20260127_0333.html">20260127_0333</a>
<a href="archive/20260126_0626.html">20260126_0626</a>
<a href="archive/20260126_0526.html">20260126_0526</a>
<a href="archive/20260126_0327.html">20260126_0327</a>
<a href="archive/20260125_0624.html">20260125_0624</a>
<a href="archive/20260125_0524.html">20260125_0524</a>
<a href="archive/20260125_0440.html">20260125_0440</a>
<a href="archive/20260125_0325.html">20260125_0325</a>
<a href="archive/20260124_0627.html">20260124_0627</a>
<a href="archive/20260124_0526.html">20260124_0526</a>
<a href="archive/20260124_0444.html">20260124_0444</a>
<a href="archive/20260124_0334.html">20260124_0334</a>
<a href="archive/20260123_0627.html">20260123_0627</a>
<a href="archive/20260123_0529.html">20260123_0529</a>
<a href="archive/20260123_0446.html">20260123_0446</a>
<a href="archive/20260123_0334.html">20260123_0334</a>
<a href="archive/20260122_2019.html">20260122_2019</a>
<a href="archive/20260122_2013.html">20260122_2013</a>
<a href="archive/20260122_2008.html">20260122_2008</a>
<a href="archive/20260122_2001.html">20260122_2001</a>
<a href="archive/20260122_0629.html">20260122_0629</a>
<a href="archive/20260122_0535.html">20260122_0535</a>
<a href="archive/20260122_0449.html">20260122_0449</a>
<a href="archive/20260122_0336.html">20260122_0336</a>
<a href="archive/20260121_0625.html">20260121_0625</a>
<a href="archive/20260121_0529.html">20260121_0529</a>
<a href="archive/20260121_0450.html">20260121_0450</a>
<a href="archive/20260121_0423.html">20260121_0423</a>
<a href="archive/20260120_0626.html">20260120_0626</a>
<a href="archive/20260120_0528.html">20260120_0528</a>
<a href="archive/20260120_0443.html">20260120_0443</a>
<a href="archive/20260120_0330.html">20260120_0330</a>
<a href="archive/20260119_0624.html">20260119_0624</a>
<a href="archive/20260119_0525.html">20260119_0525</a>
<a href="archive/20260119_0440.html">20260119_0440</a>
<a href="archive/20260119_0325.html">20260119_0325</a>
<a href="archive/20260118_2225.html">20260118_2225</a>
<a href="archive/20260118_2159.html">20260118_2159</a>
<a href="archive/20260118_2135.html">20260118_2135</a>
<a href="archive/20260118_2040.html">20260118_2040</a>
<a href="archive/20260118_1953.html">20260118_1953</a>
<a href="archive/20260118_1907.html">20260118_1907</a>
<a href="archive/20260118_0327.html">20260118_0327</a>
<a href="archive/20260117_0332.html">20260117_0332</a>
<a href="archive/20260116_0339.html">20260116_0339</a>
<a href="archive/20260115_0334.html">20260115_0334</a>
<a href="archive/20260114_0333.html">20260114_0333</a>
<a href="archive/20260113_0334.html">20260113_0334</a>
<a href="archive/20260112_0331.html">20260112_0331</a>
<a href="archive/20260111_0329.html">20260111_0329</a>
<a href="archive/20260110_0333.html">20260110_0333</a>
<a href="archive/20260109_0334.html">20260109_0334</a>
<a href="archive/20260108_0335.html">20260108_0335</a>
<a href="archive/20260107_0330.html">20260107_0330</a>
<a href="archive/20260106_0336.html">20260106_0336</a>
<a href="archive/20260105_0328.html">20260105_0328</a>
<a href="archive/20260104_0328.html">20260104_0328</a>
<a href="archive/20260103_0325.html">20260103_0325</a>
<a href="archive/20260102_0339.html">20260102_0339</a>
<a href="archive/20260101_0329.html">20260101_0329</a>
<a href="archive/20251231_0333.html">20251231_0333</a>
<a href="archive/20251230_0332.html">20251230_0332</a>
<a href="archive/20251229_0329.html">20251229_0329</a>
<a href="archive/20251228_0332.html">20251228_0332</a>
<a href="archive/20251227_0329.html">20251227_0329</a>
<a href="archive/20251226_0330.html">20251226_0330</a>
<a href="archive/20251225_0329.html">20251225_0329</a>
<a href="archive/20251224_0331.html">20251224_0331</a>
<a href="archive/20251223_0332.html">20251223_0332</a>
<a href="archive/20251222_0328.html">20251222_0328</a>
<a href="archive/20251221_0329.html">20251221_0329</a>
<a href="archive/20251220_0330.html">20251220_0330</a>
<a href="archive/20251219_0330.html">20251219_0330</a>
<a href="archive/20251218_0345.html">20251218_0345</a></div>
    </details>
    <div class="footer">Generated by arxiv-tracker</div>
  </div>
</body></html>
