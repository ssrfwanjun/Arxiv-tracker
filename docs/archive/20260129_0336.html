<!doctype html>
<html><head><meta charset="utf-8"><meta name="viewport" content="width=device-width,initial-scale=1">
<title>arXiv 论文速递</title><style>
:root {
  --bg:#f8fafc; --card:#ffffff; --text:#0f172a; --muted:#667085; --border:#e5e7eb; --acc:#2563eb;
}
:root[data-theme="dark"] {
  --bg:#0b0f17; --card:#111827; --text:#e5e7eb; --muted:#9ca3af; --border:#1f2937; --acc:#2563eb;
}
*{box-sizing:border-box} body{margin:0;background:var(--bg);color:var(--text);
  font-family:ui-sans-serif,system-ui,-apple-system,Segoe UI,Roboto,Helvetica,Arial;line-height:1.6;}
.container{max-width:900px;margin:0 auto;padding:18px;}
.header{display:flex;gap:10px;justify-content:space-between;align-items:center;margin:8px 0 16px;flex-wrap:wrap}
h1{font-size:22px;margin:0}
.badge{font-size:12px;color:#111827;background:var(--acc);padding:2px 8px;border-radius:999px}
.card{background:var(--card);border:1px solid var(--border);border-radius:16px;padding:16px 18px;margin:14px 0;box-shadow:0 1px 2px rgba(0,0,0,.04)}
.title{font-weight:700;margin:0 0 6px 0;font-size:18px}
.meta-line{color:var(--muted);font-size:13px;margin:2px 0}
.links a{color:var(--acc);text-decoration:none;margin-right:12px}
.detail{margin-top:10px;background:rgba(2,6,23,.03);border:1px solid var(--border);border-radius:10px;padding:8px 10px}
summary{cursor:pointer;color:var(--acc)}
.mono{white-space:pre-wrap;background:rgba(2,6,23,.03);border:1px solid var(--border);padding:10px;border-radius:10px}
.row{display:grid;grid-template-columns:1fr;gap:12px}
@media (min-width: 860px) {
  .row-2{grid-template-columns:1fr 1fr}
}
.footer{color:var(--muted);font-size:13px;margin:20px 0 10px}
.hr{height:1px;background:var(--border);margin:14px 0}
.history-list a{display:block;color:var(--acc);text-decoration:none;margin:4px 0}
.controls{display:flex;gap:8px;align-items:center}
.btn{border:1px solid var(--border);background:var(--card);padding:6px 10px;border-radius:10px;cursor:pointer;color:var(--text)}
.btn:hover{border-color:var(--acc)}
</style>
<script>
(function() {
  const root = document.documentElement;
  function apply(t) {
    if (t==='dark') root.setAttribute('data-theme','dark');
    else if (t==='light') root.removeAttribute('data-theme');
    else {
      if (window.matchMedia && window.matchMedia('(prefers-color-scheme: dark)').matches)
        root.setAttribute('data-theme','dark');
      else root.removeAttribute('data-theme');
    }
  }
  let t = localStorage.getItem('theme') || 'light';
  if (!['light','dark','auto'].includes(t)) t='light';
  apply(t);
  window.__toggleTheme = function() {
    let cur = localStorage.getItem('theme') || 'light';
    if (cur==='light') cur='dark';
    else if (cur==='dark') cur='auto';
    else cur='light';
    localStorage.setItem('theme', cur);
    apply(cur);
    const el=document.getElementById('theme-label');
    if(el) el.textContent = cur.toUpperCase();
  }
  window.__expandAll = function(open) {
    document.querySelectorAll('details').forEach(d => d.open = !!open);
  }
})();
</script>
</head>
<body>
  <div class="container">
    <div class="header">
      <h1>arXiv 论文速递</h1>
      <div style="display:flex;gap:10px;align-items:center">
        
<div class="controls">
  <button class="btn" onclick="__toggleTheme()">Theme: <span id="theme-label" style="margin-left:6px">AUTO</span></button>
  <button class="btn" onclick="__expandAll(true)">Expand All</button>
  <button class="btn" onclick="__expandAll(false)">Collapse All</button>
</div>

        <span class="badge">2026-01-29 03:36</span>
      </div>
    </div>
    <div class="hr"></div>
    <div>Snapshot: 20260129_0336</div>
    <div class="row"><div class="card">
<div class="title">&quot;Not in My Backyard&quot;: LLMs Uncover Online and Offline Social Biases Against Homelessnes</div>
<div class="meta-line">Authors: Jonathan A. Karr, Benjamin F. Herbst, Matthew L. Sisk, Xueyun Li, Ting Hua, Matthew Hauenstein, Georgina Curto, Nitesh V. Chawla</div>
<div class="meta-line">First: 2025-08-14T17:58:34+00:00 · Latest: 2026-01-27T18:56:57+00:00</div>
<div class="links" style="margin-top:8px"><a href="https://arxiv.org/abs/2508.13187v2">Abs</a> · <a href="https://arxiv.org/pdf/2508.13187v2">PDF</a> · <a href="https://huggingface.co/huggingface">Code1</a> · <a href="https://huggingface.co/docs/hub/spaces">Code2</a></div>
<details class="detail"><summary>Abstract</summary>
<div class="mono">Homelessness is a persistent social challenge, impacting millions worldwide. Over 876,000 people experienced homelessness (PEH) in the U.S. in 2025. Social bias is a significant barrier to alleviation, shaping public perception and influencing policymaking. Given that online textual media and offline city council discourse reflect and influence part of public opinion, it provides valuable insights to identify and track social biases against PEH. We present a new, manually-annotated multi-domain dataset compiled from Reddit, X (formerly Twitter), news articles, and city council meeting minutes across ten U.S. cities. Our 16-category multi-label taxonomy creates a challenging long-tail classification problem: some categories appear in less than 1% of samples, while others exceed 70%. We find that small human-annotated datasets (1,702 samples) are insufficient for training effective classifiers, whether used to fine-tune encoder models or as few-shot examples for LLMs. To address this, we use GPT-4.1 to generate pseudo-labels on a larger unlabeled corpus. Training on this expanded dataset enables even small encoder models (ModernBERT, 150M parameters) to achieve 35.23 macro-F1, approaching GPT-4.1&#x27;s 41.57. This demonstrates that \textbf{data quantity matters more than model size}, enabling low-cost, privacy-preserving deployment without relying on commercial APIs. Our results reveal that negative bias against PEH is prevalent both offline and online (especially on Reddit), with &quot;not in my backyard&quot; narratives showing the highest engagement. These findings uncover a type of ostracism that directly impacts poverty-reduction policymaking and provide actionable insights for practitioners addressing homelessness.</div></details>
<details class="detail"><summary>中文标题/摘要</summary>
<div class="mono"><b>标题：</b>“邻避效应”：大语言模型揭示针对无家可归者的线上与线下社会偏见</div>
<div class="mono" style="margin-top:8px">无家可归是持续存在的社会挑战，全球影响数百万人。2025年美国有超过87.6万人经历无家可归（PEH）。社会偏见是缓解该问题的主要障碍，它塑造公众认知并影响政策制定。鉴于线上文本媒体与线下市议会讨论反映并影响部分公众意见，这为识别和追踪针对PEH的社会偏见提供了宝贵视角。我们提出了一个从Reddit、X（原Twitter）、新闻文章及美国十个城市的市议会会议记录中汇编而成的新型人工标注多领域数据集。我们设计的16类别多标签分类体系构成了具有挑战性的长尾分类问题：部分类别在样本中出现率低于1%，而其他类别超过70%。研究发现，小型人工标注数据集（1,702个样本）不足以训练有效分类器，无论是用于微调编码器模型还是作为大语言模型的少样本示例。为此，我们使用GPT-4.1在更大规模未标注语料上生成伪标签。基于扩展数据集的训练使小型编码器模型（ModernBERT，1.5亿参数）达到35.23的宏观F1值，接近GPT-4.1的41.57。这证明\textbf{数据规模比模型体量更重要}，可实现不依赖商业API的低成本、隐私保护部署。研究结果显示，针对PEH的负面偏见在线下与线上（尤其是Reddit）普遍存在，其中“邻避效应”叙事获得最高互动量。这些发现揭示了一种直接影响减贫政策制定的排斥现象，并为应对无家可归问题的实践者提供了可操作的见解。</div>
</details>
<details class="detail"><summary>Summary / 总结</summary>
<div class="mono">To systematically identify and track social biases against people experiencing homelessness (PEH) as reflected in online and offline discourse, this study constructs a manually-annotated multi-domain dataset from Reddit, X, news articles, and city council minutes across ten U.S. cities, featuring a 16-category long-tail taxonomy. To overcome the limitation of small annotated data, the method employs GPT-4.1 to generate pseudo-labels on a larger unlabeled corpus; training on this expanded set enables even a small encoder model (ModernBERT) to achieve a macro-F1 of 35.23, approaching GPT-4.1&#x27;s 41.57, demonstrating that data quantity is more critical than model size for effective classification. Key findings reveal that negative bias against PEH is prevalent, especially on Reddit, with &quot;not in my backyard&quot; narratives garnering the highest engagement, highlighting a form of ostracism that impacts poverty-reduction policymaking.</div>
<div class="mono" style="margin-top:8px">为应对无家可归这一持久的社会挑战及阻碍有效解决方案的偏见，本研究引入了一个多领域数据集，涵盖美国十个城市的Reddit、X、新闻和市议会会议记录，并采用一个包含16个类别的分类法进行标注，构成了一个长尾分类问题。研究方法首先使用小型人工标注数据集训练分类器，发现其效果不足，随后利用GPT-4.1在更大的未标注语料上生成伪标签以训练更有效的模型。关键实验结果表明，在此扩展数据上训练后，小型编码器模型（ModernBERT）的宏F1值达到35.23，接近GPT-4.1的41.57，证明了数据量比模型规模更重要，可实现低成本有效部署，并揭示了针对无家可归者的负面偏见，尤其是高参与度的“别在我家后院”叙事，在线上和线下都普遍存在。</div>
</details>
</div>
<div class="card">
<div class="title">M-SGWR: Multiscale Similarity and Geographically Weighted Regression</div>
<div class="meta-line">Authors: M. Naser Lessani, Zhenlong Li, Manzhu Yu, Helen Greatrex, Chan Shen</div>
<div class="meta-line">First: 2026-01-27T18:55:12+00:00 · Latest: 2026-01-27T18:55:12+00:00</div>
<div class="links" style="margin-top:8px"><a href="https://arxiv.org/abs/2601.19888v1">Abs</a> · <a href="https://arxiv.org/pdf/2601.19888v1">PDF</a> · <a href="https://huggingface.co/huggingface">Code1</a> · <a href="https://huggingface.co/docs/hub/spaces">Code2</a></div>
<details class="detail"><summary>Abstract</summary>
<div class="mono">The first law of geography is a cornerstone of spatial analysis, emphasizing that nearby and related locations tend to be more similar, however, defining what constitutes &quot;near&quot; and &quot;related&quot; remains challenging, as different phenomena exhibit distinct spatial patterns. Traditional local regression models, such as Geographically Weighted Regression (GWR) and Multiscale GWR (MGWR), quantify spatial relationships solely through geographic proximity. In an era of globalization and digital connectivity, however, geographic proximity alone may be insufficient to capture how locations are interconnected. To address this limitation, we propose a new multiscale local regression framework, termed M-SGWR, which characterizes spatial interaction across two dimensions: geographic proximity and attribute (variable) similarity. For each predictor, geographic and attribute-based weight matrices are constructed separately and then combined using an optimized parameter, alpha, which governs their relative contribution to local model fitting. Analogous to variable-specific bandwidths in MGWR, the optimal alpha varies by predictor, allowing the model to flexibly account for geographic, mixed, or non-spatial (remote similarity) effects. Results from two simulation experiments and one empirical application demonstrate that M-SGWR consistently outperforms GWR, SGWR, and MGWR across all goodness-of-fit metrics.</div></details>
<details class="detail"><summary>中文标题/摘要</summary>
<div class="mono"><b>标题：</b>M-SGWR：多尺度相似性与地理加权回归</div>
<div class="mono" style="margin-top:8px">地理学第一定律是空间分析的基石，强调邻近且相关的位置往往更相似，但如何定义“邻近”与“相关”仍具挑战性，因为不同现象呈现各异的空间模式。传统局部回归模型（如地理加权回归GWR和多尺度GWR）仅通过地理邻近性量化空间关系。然而在全球化与数字互联时代，仅依赖地理邻近性可能不足以捕捉位置间的关联。为突破此局限，我们提出一种新的多尺度局部回归框架M-SGWR，该框架通过地理邻近性与属性（变量）相似性两个维度刻画空间交互。针对每个预测变量，分别构建基于地理和基于属性的权重矩阵，并通过优化参数α进行组合，该参数控制二者对局部模型拟合的相对贡献。类似于MGWR中变量特定带宽的机制，最优α值随预测变量变化，使模型能灵活适应地理效应、混合效应或非空间（远程相似性）效应。两组模拟实验与一项实证应用的结果表明，M-SGWR在所有拟合优度指标上均持续优于GWR、SGWR和MGWR。</div>
</details>
<details class="detail"><summary>Summary / 总结</summary>
<div class="mono">The research addresses the limitation of traditional geographically weighted regression models, which rely solely on geographic proximity to capture spatial relationships, by proposing a multiscale local regression framework called M-SGWR that integrates both geographic proximity and attribute similarity. The method constructs separate weight matrices for geographic and attribute-based dimensions, combining them with an optimized parameter alpha that varies per predictor to flexibly model geographic, mixed, or non-spatial effects. Experimental results from simulations and an empirical application show that M-SGWR consistently outperforms GWR, SGWR, and MGWR across all goodness-of-fit metrics.</div>
<div class="mono" style="margin-top:8px">该研究的动机在于传统地理加权回归模型仅依赖地理邻近性，这在全球化与数字互联时代可能不足以充分捕捉空间关系，因为属性相似性同样重要。提出的M-SGWR方法通过整合地理邻近性和属性相似性，为每个预测变量构建独立的权重矩阵，并使用优化的参数alpha进行组合，该参数随预测变量变化，从而灵活建模空间、混合或非空间效应。模拟实验和实证应用的结果表明，M-SGWR在所有拟合优度指标上均一致优于GWR、SGWR和MGWR等现有模型。</div>
</details>
</div>
<div class="card">
<div class="title">Demystifying the Roles of LLM Layers in Retrieval, Knowledge, and Reasoning</div>
<div class="meta-line">Authors: Xinyuan Song, Keyu Wang, PengXiang Li, Lu Yin, Shiwei Liu</div>
<div class="meta-line">Venue: ICASSP 2026</div>
<div class="meta-line">First: 2025-10-02T14:57:13+00:00 · Latest: 2026-01-27T18:53:30+00:00</div>
<div class="meta-line">Comments: Accepted by ICASSP 2026</div>
<div class="links" style="margin-top:8px"><a href="https://arxiv.org/abs/2510.02091v4">Abs</a> · <a href="https://arxiv.org/pdf/2510.02091v4">PDF</a> · <a href="https://huggingface.co/huggingface">Code1</a> · <a href="https://huggingface.co/docs/hub/spaces">Code2</a></div>
<details class="detail"><summary>Abstract</summary>
<div class="mono">Recent studies suggest that the deeper layers of Large Language Models (LLMs) contribute little to representation learning and can often be removed without significant performance loss. However, such claims are typically drawn from narrow evaluations and may overlook important aspects of model behavior. In this work, we present a systematic study of depth utilization across diverse dimensions, including evaluation protocols, task categories, and model architectures. Our analysis confirms that very deep layers are generally less effective than earlier ones, but their contributions vary substantially with the evaluation setting. Under likelihood-based metrics without generation, pruning most layers preserves performance, with only the initial few being critical. By contrast, generation-based evaluation uncovers indispensable roles for middle and deeper layers in enabling reasoning and maintaining long-range coherence. We further find that knowledge and retrieval are concentrated in shallow components, whereas reasoning accuracy relies heavily on deeper layers -- yet can be reshaped through distillation. These results highlight that depth usage in LLMs is highly heterogeneous and context-dependent, underscoring the need for task-, metric-, and model-aware perspectives in both interpreting and compressing large models.</div></details>
<details class="detail"><summary>中文标题/摘要</summary>
<div class="mono"><b>标题：</b>揭秘大语言模型各层在检索、知识与推理中的作用</div>
<div class="mono" style="margin-top:8px">近期研究表明，大语言模型的深层对表示学习贡献有限，移除后通常不会导致性能显著下降。然而，这类结论多基于狭窄的评估维度，可能忽略模型行为的重要方面。本研究通过评估协议、任务类别和模型架构等多维度，系统探究了深度利用机制。分析证实：深层整体效能低于浅层，但其贡献随评估环境差异显著。在无生成的似然度量下，剪除多数层仍能保持性能，仅最初几层至关重要；而基于生成的评估则揭示中深层对实现推理和维持长程连贯性不可或缺。进一步发现知识与检索功能集中于浅层组件，推理准确性则深度依赖深层——但可通过蒸馏重塑。这些结果表明大语言模型的深度利用具有高度异质性与情境依赖性，强调在解释与压缩大模型时需兼顾任务、度量与模型特性。</div>
</details>
<details class="detail"><summary>Summary / 总结</summary>
<div class="mono">This study systematically investigates the functional contributions of different layers in Large Language Models (LLMs), motivated by claims that deeper layers are often redundant. The method involves a multi-dimensional analysis across evaluation protocols, task categories, and model architectures to assess depth utilization. Key findings reveal that while shallow layers are critical for knowledge and retrieval, and pruning many layers is possible under likelihood-based metrics, middle and deeper layers are indispensable for reasoning and long-range coherence in generation-based evaluations, with their importance being highly context-dependent.</div>
<div class="mono" style="margin-top:8px">本研究系统性地探究了大语言模型（LLM）中不同层次的功能贡献，其动机在于现有观点常认为深层是冗余的。方法上，通过跨评估协议、任务类别和模型架构的多维度分析来评估深度利用情况。主要实验结果表明，浅层对知识和检索至关重要，且在基于似然的评估中可修剪多数层次而保持性能，但基于生成的评估揭示了中深层对于推理和长程连贯性不可或缺，其作用高度依赖于具体情境。</div>
</details>
</div>
<div class="card">
<div class="title">AI Cap-and-Trade: Efficiency Incentives for Accessibility and Sustainability</div>
<div class="meta-line">Authors: Marco Bornstein, Amrit Singh Bedi</div>
<div class="meta-line">First: 2026-01-27T18:53:21+00:00 · Latest: 2026-01-27T18:53:21+00:00</div>
<div class="meta-line">Comments: 22 pages, 2 figures</div>
<div class="links" style="margin-top:8px"><a href="https://arxiv.org/abs/2601.19886v1">Abs</a> · <a href="https://arxiv.org/pdf/2601.19886v1">PDF</a> · <a href="https://huggingface.co/huggingface">Code1</a> · <a href="https://huggingface.co/docs/hub/spaces">Code2</a></div>
<details class="detail"><summary>Abstract</summary>
<div class="mono">The race for artificial intelligence (AI) dominance often prioritizes scale over efficiency. Hyper-scaling is the common industry approach: larger models, more data, and as many computational resources as possible. Using more resources is a simpler path to improved AI performance. Thus, efficiency has been de-emphasized. Consequently, the need for costly computational resources has marginalized academics and smaller companies. Simultaneously, increased energy expenditure, due to growing AI use, has led to mounting environmental costs. In response to accessibility and sustainability concerns, we argue for research into, and implementation of, market-based methods that incentivize AI efficiency. We believe that incentivizing efficient operations and approaches will reduce emissions while opening new opportunities for academics and smaller companies. As a call to action, we propose a cap-and-trade system for AI. Our system provably reduces computations for AI deployment, thereby lowering emissions and monetizing efficiency to the benefit of of academics and smaller companies.</div></details>
<details class="detail"><summary>中文标题/摘要</summary>
<div class="mono"><b>标题：</b>人工智能排放权交易：促进可及性与可持续性的效率激励机制</div>
<div class="mono" style="margin-top:8px">人工智能领域的竞争往往重规模而轻效率。超大规模扩展是行业普遍做法：模型更大、数据更多、计算资源尽可能多。增加资源投入是提升AI性能的捷径，因此效率问题被长期忽视。这导致高昂的计算需求将学术界和小型公司边缘化，同时AI能耗增长带来日益严重的环境成本。针对可及性与可持续性挑战，我们主张研究并实施基于市场的AI效率激励机制。通过激励高效运营与方法，既能减少排放，又能为学术界和小型企业创造新机遇。作为行动倡议，我们提出AI排放权交易体系。该体系可验证地降低AI部署的计算量，从而减少排放，并将效率转化为经济效益，惠及学术界与小型企业。</div>
</details>
<details class="detail"><summary>Summary / 总结</summary>
<div class="mono">The research is motivated by the AI industry&#x27;s focus on hyper-scaling, which marginalizes academics and smaller companies due to high computational costs and raises environmental sustainability concerns. The proposed method is a market-based cap-and-trade system designed to incentivize computational efficiency in AI. The key finding is that this system provably reduces computations for AI deployment, thereby lowering emissions and creating financial benefits that can improve accessibility for resource-constrained entities.</div>
<div class="mono" style="margin-top:8px">这项研究的动机在于人工智能行业过度追求模型规模和资源投入，导致高昂成本使学术界和小公司边缘化，同时能源消耗增长引发环境问题。作者提出了一种基于市场的总量控制与交易制度，旨在激励人工智能部署中的计算效率。他们的分析表明，该系统可证明减少计算量、降低排放，并通过将效率收益货币化，为资源较少的参与者创造经济机会。</div>
</details>
</div>
<div class="card">
<div class="title">LOGICAL-COMMONSENSEQA: A Benchmark for Logical Commonsense Reasoning</div>
<div class="meta-line">Authors: Obed Junias, Maria Leonor Pacheco</div>
<div class="meta-line">First: 2026-01-23T07:07:19+00:00 · Latest: 2026-01-27T18:33:20+00:00</div>
<div class="links" style="margin-top:8px"><a href="https://arxiv.org/abs/2601.16504v2">Abs</a> · <a href="https://arxiv.org/pdf/2601.16504v2">PDF</a> · <a href="https://huggingface.co/huggingface">Code1</a> · <a href="https://huggingface.co/docs/hub/spaces">Code2</a></div>
<details class="detail"><summary>Abstract</summary>
<div class="mono">Commonsense reasoning often involves evaluating multiple plausible interpretations rather than selecting a single atomic answer, yet most benchmarks rely on single-label evaluation, obscuring whether statements are jointly plausible, mutually exclusive, or jointly implausible. We introduce LOGICAL-COMMONSENSEQA, a benchmark that re-frames commonsense reasoning as logical composition over pairs of atomic statements using plausibility-level operators (AND, OR, NEITHER/NOR). Evaluating instruction-tuned, reasoning-specialized, and fine-tuned models under zero-shot, few-shot, and chain-of-thought prompting, we find that while models perform reasonably on conjunctive and moderately on disjunctive reasoning, performance degrades sharply on negation-based questions. LOGICAL-COMMONSENSEQA exposes fundamental reasoning limitations and provides a controlled framework for advancing compositional commonsense reasoning.</div></details>
<details class="detail"><summary>中文标题/摘要</summary>
<div class="mono"><b>标题：</b>LOGICAL-COMMONSENSEQA：逻辑常识推理基准</div>
<div class="mono" style="margin-top:8px">常识推理常涉及评估多种合理解释而非选择单一原子答案，但现有基准多依赖单标签评估，难以区分陈述是联合合理、互斥还是联合不合理。我们提出LOGICAL-COMMONSENSEQA基准，通过可能性层级运算符（AND、OR、NEITHER/NOR）将常识推理重构为原子陈述对的逻辑组合。在零样本、少样本和思维链提示下评估指令微调、推理专用及精调模型，发现模型在合取推理表现尚可，析取推理中等，但基于否定的问题性能急剧下降。该基准揭示了根本性推理局限，并为推进组合式常识推理提供了受控框架。</div>
</details>
<details class="detail"><summary>Summary / 总结</summary>
<div class="mono">Existing commonsense benchmarks often rely on single-label evaluation, which fails to capture the nuanced logical relationships between multiple plausible interpretations. To address this, the authors introduce LOGICAL-COMMONSENSEQA, a benchmark that frames commonsense reasoning as logical composition over statement pairs using operators like AND, OR, and NEITHER/NOR. Evaluating various models under different prompting strategies reveals that while models handle conjunctive and disjunctive reasoning reasonably well, their performance sharply degrades on negation-based questions, exposing fundamental limitations in compositional commonsense reasoning.</div>
<div class="mono" style="margin-top:8px">现有的常识推理基准通常依赖单标签评估，无法捕捉多个合理解释之间细微的逻辑关系。为此，研究者提出了LOGICAL-COMMONSENSEQA基准，该基准使用AND、OR和NEITHER/NOR等逻辑运算符，将常识推理重构为对陈述对的逻辑组合任务。在零样本、少样本和思维链提示下对各种模型进行评估的实验结果表明，模型在合取和析取推理上表现尚可，但在基于否定的问题上性能急剧下降，这揭示了组合推理方面的根本性局限。</div>
</details>
</div>
<div class="card">
<div class="title">MLVTG: Mamba-Based Feature Alignment and LLM-Driven Purification for Multi-Modal Video Temporal Grounding</div>
<div class="meta-line">Authors: Zhiyi Zhu, Xiaoyu Wu, Zihao Liu, Linlin Yang</div>
<div class="meta-line">First: 2025-06-10T07:20:12+00:00 · Latest: 2026-01-27T18:07:12+00:00</div>
<div class="links" style="margin-top:8px"><a href="https://arxiv.org/abs/2506.08512v2">Abs</a> · <a href="https://arxiv.org/pdf/2506.08512v2">PDF</a> · <a href="https://huggingface.co/huggingface">Code1</a> · <a href="https://huggingface.co/docs/hub/spaces">Code2</a></div>
<details class="detail"><summary>Abstract</summary>
<div class="mono">Video Temporal Grounding (VTG), which aims to localize video clips corresponding to natural language queries, is a fundamental yet challenging task in video understanding. Existing Transformer-based methods often suffer from redundant attention and suboptimal multi-modal alignment. To address these limitations, we propose MLVTG, a novel framework that integrates two key modules: MambaAligner and LLMRefiner. MambaAligner uses stacked Vision Mamba blocks as a backbone instead of Transformers to model temporal dependencies and extract robust video representations for multi-modal alignment. LLMRefiner leverages the specific frozen layer of a pre-trained Large Language Model (LLM) to implicitly transfer semantic priors, enhancing multi-modal alignment without fine-tuning. This dual alignment strategy, temporal modeling via structured state-space dynamics and semantic purification via textual priors, enables more precise localization. Extensive experiments on QVHighlights, Charades-STA, and TVSum demonstrate that MLVTG achieves state-of-the-art performance and significantly outperforms existing baselines.</div></details>
<details class="detail"><summary>中文标题/摘要</summary>
<div class="mono"><b>标题：</b>MLVTG：基于Mamba的多模态视频时序定位特征对齐与LLM驱动净化框架</div>
<div class="mono" style="margin-top:8px">视频时序定位旨在根据自然语言查询定位对应视频片段，是视频理解领域基础且具挑战性的任务。现有基于Transformer的方法常存在注意力冗余与多模态对齐欠佳的问题。为此，我们提出MLVTG框架，集成两大核心模块：MambaAligner与LLMRefiner。MambaAligner采用堆叠的视觉Mamba块替代Transformer作为主干网络，通过结构化状态空间建模时序依赖并提取鲁棒视频表征以实现多模态对齐；LLMRefiner则利用预训练大语言模型的特定冻结层隐式迁移语义先验，无需微调即可增强多模态对齐。这种融合时序动态建模与文本先验语义净化的双重对齐策略，实现了更精准的定位。在QVHighlights、Charades-STA和TVSum数据集上的大量实验表明，MLVTG取得了最先进的性能，显著优于现有基线方法。</div>
</details>
<details class="detail"><summary>Summary / 总结</summary>
<div class="mono">The research addresses the limitations of Transformer-based methods in Video Temporal Grounding (VTG), which often suffer from redundant attention and suboptimal multi-modal alignment when localizing video clips from language queries. The proposed MLVTG framework introduces two key modules: MambaAligner, which uses stacked Vision Mamba blocks to model temporal dependencies and extract robust video representations, and LLMRefiner, which leverages a frozen layer of a pre-trained Large Language Model to implicitly transfer semantic priors for enhanced alignment. Experimental results on QVHighlights, Charades-STA, and TVSum datasets demonstrate that MLVTG achieves state-of-the-art performance and significantly outperforms existing baselines.</div>
<div class="mono" style="margin-top:8px">本研究针对视频时序定位任务中现有基于Transformer的方法常存在注意力冗余和多模态对齐不佳的问题。为解决这些局限，提出的MLVTG框架包含两个核心模块：MambaAligner采用堆叠的视觉Mamba块来建模时序依赖并提取鲁棒的视频表征，LLMRefiner则利用预训练大语言模型的特定冻结层隐式迁移语义先验以增强对齐。在QVHighlights、Charades-STA和TVSum数据集上的实验表明，MLVTG实现了最先进的性能，显著优于现有基线方法。</div>
</details>
</div>
<div class="card">
<div class="title">Learning Dynamic Representations via An Optimally-Weighted Maximum Mean Discrepancy Optimization Framework for Continual Learning</div>
<div class="meta-line">Authors: KaiHui Huang, RunQing Wu, JinHui Sheng, HanYi Zhang, Ling Ge, JinYu Guo, Fei Ye</div>
<div class="meta-line">First: 2025-01-21T13:33:45+00:00 · Latest: 2026-01-27T18:04:09+00:00</div>
<div class="links" style="margin-top:8px"><a href="https://arxiv.org/abs/2501.12121v5">Abs</a> · <a href="https://arxiv.org/pdf/2501.12121v5">PDF</a> · <a href="https://huggingface.co/huggingface">Code1</a> · <a href="https://huggingface.co/docs/hub/spaces">Code2</a></div>
<details class="detail"><summary>Abstract</summary>
<div class="mono">Continual learning has emerged as a pivotal area of research, primarily due to its advantageous characteristic that allows models to persistently acquire and retain information. However, catastrophic forgetting can severely impair model performance. In this study, we address network forgetting by introducing a novel framework termed Optimally-Weighted Maximum Mean Discrepancy (OWMMD), which imposes penalties on representation alterations via a Multi-Level Feature Matching Mechanism (MLFMM). Furthermore, we propose an Adaptive Regularization Optimization (ARO) strategy to refine the adaptive weight vectors, which autonomously assess the significance of each feature layer throughout the optimization process, The proposed ARO approach can relieve the over-regularization problem and promote the future task learning. We conduct a comprehensive series of experiments, benchmarking our proposed method against several established baselines. The empirical findings indicate that our approach achieves state-of-the-art performance.</div></details>
<details class="detail"><summary>中文标题/摘要</summary>
<div class="mono"><b>标题：</b>基于最优加权最大均值差异优化框架的持续学习动态表示方法</div>
<div class="mono" style="margin-top:8px">持续学习因其能使模型持续获取并保留信息的优势而成为关键研究领域，但灾难性遗忘会严重损害模型性能。本研究通过提出名为最优加权最大均值差异（OWMMD）的新框架解决网络遗忘问题，该框架通过多层级特征匹配机制（MLFMM）对表示变化施加惩罚。此外，我们提出自适应正则化优化（ARO）策略来优化自适应权重向量，该策略能在优化过程中自主评估各特征层的重要性。所提出的ARO方法能缓解过正则化问题并促进未来任务学习。我们进行了系列综合实验，将所提方法与多个基准方法进行比较。实证结果表明，我们的方法达到了最先进的性能水平。</div>
</details>
<details class="detail"><summary>Summary / 总结</summary>
<div class="mono">This research addresses catastrophic forgetting in continual learning by proposing an Optimally-Weighted Maximum Mean Discrepancy (OWMMD) framework. The method penalizes changes in learned representations using a Multi-Level Feature Matching Mechanism and refines the process with an Adaptive Regularization Optimization (ARO) strategy to autonomously weight feature layers and mitigate over-regularization. Experimental results demonstrate that this approach achieves state-of-the-art performance against established baselines.</div>
<div class="mono" style="margin-top:8px">本研究针对持续学习中的灾难性遗忘问题，提出了一个最优加权最大均值差异（OWMMD）框架。该方法通过多层特征匹配机制惩罚学习表征的变化，并采用自适应正则化优化（ARO）策略来精炼自适应权重向量，以缓解过正则化并促进后续任务学习。实验结果表明，与现有基线方法相比，所提出的方法取得了最先进的性能。</div>
</details>
</div>
<div class="card">
<div class="title">HARMONI: Multimodal Personalization of Multi-User Human-Robot Interactions with LLMs</div>
<div class="meta-line">Authors: Jeanne Malécot, Hamed Rahimi, Jeanne Cattoni, Marie Samson, Mouad Abrini, Mahdi Khoramshahi, Maribel Pino, Mohamed Chetouani</div>
<div class="meta-line">First: 2026-01-27T17:45:04+00:00 · Latest: 2026-01-27T17:45:04+00:00</div>
<div class="links" style="margin-top:8px"><a href="https://arxiv.org/abs/2601.19839v1">Abs</a> · <a href="https://arxiv.org/pdf/2601.19839v1">PDF</a> · <a href="https://huggingface.co/huggingface">Code1</a> · <a href="https://huggingface.co/docs/hub/spaces">Code2</a></div>
<details class="detail"><summary>Abstract</summary>
<div class="mono">Existing human-robot interaction systems often lack mechanisms for sustained personalization and dynamic adaptation in multi-user environments, limiting their effectiveness in real-world deployments. We present HARMONI, a multimodal personalization framework that leverages large language models to enable socially assistive robots to manage long-term multi-user interactions. The framework integrates four key modules: (i) a perception module that identifies active speakers and extracts multimodal input; (ii) a world modeling module that maintains representations of the environment and short-term conversational context; (iii) a user modeling module that updates long-term speaker-specific profiles; and (iv) a generation module that produces contextually grounded and ethically informed responses. Through extensive evaluation and ablation studies on four datasets, as well as a real-world scenario-driven user-study in a nursing home environment, we demonstrate that HARMONI supports robust speaker identification, online memory updating, and ethically aligned personalization, outperforming baseline LLM-driven approaches in user modeling accuracy, personalization quality, and user satisfaction.</div></details>
<details class="detail"><summary>中文标题/摘要</summary>
<div class="mono"><b>标题：</b>HARMONI：基于大语言模型的多用户人机交互多模态个性化框架</div>
<div class="mono" style="margin-top:8px">现有人机交互系统在多用户环境中常缺乏持续个性化与动态适应机制，限制了实际部署效果。本文提出HARMONI多模态个性化框架，利用大语言模型使社交辅助机器人能够管理长期多用户交互。该框架集成四个核心模块：（1）感知模块——识别活跃说话者并提取多模态输入；（2）世界建模模块——维护环境表征与短期会话上下文；（3）用户建模模块——更新长期用户画像；（4）生成模块——生成情境化且符合伦理的响应。通过在四个数据集上的系统评估与消融实验，以及在养老院真实场景驱动的用户研究，我们证明HARMONI支持鲁棒的说话者识别、在线记忆更新和伦理对齐的个性化，在用户建模准确性、个性化质量和用户满意度方面均优于基线大语言模型方法。</div>
</details>
<details class="detail"><summary>Summary / 总结</summary>
<div class="mono">To address the limitations of existing human-robot interaction systems in sustaining personalization and adapting dynamically in multi-user settings, this research introduces HARMONI, a multimodal personalization framework powered by large language models. The method integrates four modules: perception for identifying speakers and extracting multimodal data, world modeling for environmental and short-term context, user modeling for long-term speaker profiles, and generation for producing contextually and ethically grounded responses. Experimental results from four datasets and a real-world nursing home user study show that HARMONI outperforms baseline LLM-driven approaches in speaker identification, online memory updating, and ethically aligned personalization, leading to higher user modeling accuracy, personalization quality, and user satisfaction.</div>
<div class="mono" style="margin-top:8px">现有的人机交互系统通常缺乏针对多用户的持续个性化和动态适应机制，限制了其在实际部署中的有效性。为此，我们提出了HARMONI，一个利用大语言模型管理长期多用户交互的多模态个性化框架，该框架集成了四个关键模块：用于识别说话者和提取多模态输入的感知模块、用于维护环境和短期对话上下文的世界建模模块、用于更新长期用户特定档案的用户建模模块，以及用于生成情境化且符合伦理的响应的生成模块。在四个数据集上的广泛评估和消融研究，以及在养老院环境中的真实场景用户研究表明，HARMONI在说话者识别、在线记忆更新、符合伦理的个性化、用户建模准确性、个性化质量和用户满意度方面优于基线的大语言模型驱动方法。</div>
</details>
</div>
<div class="card">
<div class="title">Efficient and Transferable Agentic Knowledge Graph RAG via Reinforcement Learning</div>
<div class="meta-line">Authors: Jinyeop Song, Song Wang, Julian Shun, Yada Zhu</div>
<div class="meta-line">First: 2025-09-30T15:14:24+00:00 · Latest: 2026-01-27T17:44:43+00:00</div>
<div class="meta-line">Comments: Wrong numbers are reported for main results</div>
<div class="links" style="margin-top:8px"><a href="https://arxiv.org/abs/2509.26383v4">Abs</a> · <a href="https://arxiv.org/pdf/2509.26383v4">PDF</a> · <a href="https://github.com/Jinyeop3110/KG-R1">Code1</a> · <a href="https://huggingface.co/huggingface">Code2</a> · <a href="https://huggingface.co/docs/hub/spaces">Code3</a></div>
<details class="detail"><summary>Abstract</summary>
<div class="mono">Knowledge-graph retrieval-augmented generation (KG-RAG) couples large language models (LLMs) with structured, verifiable knowledge graphs (KGs) to reduce hallucinations and expose reasoning traces. However, many KG-RAG systems compose multiple LLM modules (e.g planning, reasoning, and responding), inflating inference cost and binding behavior to a specific target KG. To address this, we introduce KG-R1, an agentic KG retrieval-augmented generation (KG-RAG) framework through reinforcement learning (RL). KG-R1 utilizes a single agent that interacts with KGs as its environment, learning to retrieve at each step and incorporating the retrieved information into its reasoning and generation. The process is optimized through end-to-end RL. In controlled experiments across Knowledge-Graph Question Answering (KGQA) benchmarks, our method demonstrates both efficiency and transferability: Using Qwen-2.5-3B, KG-R1 improves answer accuracy with fewer generation tokens than prior multi-module workflow methods that use larger foundation or fine-tuned models. Furthermore, KG-R1 enables plug and play: after training, it maintains strong accuracy on new KGs without modification. These properties make KG-R1 a promising KG-RAG framework for real-world deployment. Our code is publicly available at https://github.com/Jinyeop3110/KG-R1.</div></details>
<details class="detail"><summary>中文标题/摘要</summary>
<div class="mono"><b>标题：</b>基于强化学习的高效可迁移智能体知识图谱检索增强生成</div>
<div class="mono" style="margin-top:8px">知识图谱检索增强生成（KG-RAG）将大语言模型（LLM）与结构化、可验证的知识图谱（KG）结合，以减少幻觉并展示推理轨迹。然而，现有KG-RAG系统常由多个LLM模块（如规划、推理、响应）构成，导致推理成本高昂且行为受限于特定知识图谱。为此，我们提出KG-R1——一种通过强化学习（RL）实现的智能体化KG检索增强生成框架。KG-R1采用单一智能体，将知识图谱作为交互环境，逐步学习检索策略并将检索信息融入推理生成过程，通过端到端强化学习进行优化。在知识图谱问答（KGQA）基准测试中，本方法展现出高效性与可迁移性：使用Qwen-2.5-3B模型时，KG-R1以更少的生成标记数实现了比基于更大规模基础模型或微调模型的多模块工作流更高的答案准确率。此外，KG-R1具备即插即用特性：训练后无需调整即可在新知识图谱上保持高准确率。这些特性使KG-R1成为具有实际部署潜力的KG-RAG框架。代码已开源：https://github.com/Jinyeop3110/KG-R1。</div>
</details>
<details class="detail"><summary>Summary / 总结</summary>
<div class="mono">The research aims to enhance knowledge-graph retrieval-augmented generation (KG-RAG) by addressing the high inference costs and lack of transferability in existing multi-module LLM systems. The method introduces KG-R1, a framework that employs a single reinforcement learning agent to interact with knowledge graphs, learning to retrieve information stepwise and integrate it into reasoning and generation through end-to-end RL optimization. Experimental results on KGQA benchmarks show that KG-R1, using a compact Qwen-2.5-3B model, achieves higher answer accuracy with fewer tokens compared to prior multi-module approaches and maintains strong performance on new knowledge graphs without retraining, demonstrating efficiency and transferability.</div>
<div class="mono" style="margin-top:8px">本研究旨在解决多模块知识图谱检索增强生成（KG-RAG）系统推理成本高且缺乏可迁移性的问题。提出的方法KG-R1引入了一个通过强化学习优化的单智能体框架，该智能体将知识图谱作为环境进行交互，以学习集成的检索、推理和生成。在知识图谱问答基准上的实验结果表明，KG-R1使用紧凑的30亿参数模型，相比先前采用更大模型的多模块方法，能以更少的生成标记实现更高的答案准确性，并且通过在新知识图谱上无需重新训练即可保持强准确性，展示了良好的可迁移性。</div>
</details>
</div>
<div class="card">
<div class="title">Visual Generation Unlocks Human-Like Reasoning through Multimodal World Models</div>
<div class="meta-line">Authors: Jialong Wu, Xiaoying Zhang, Hongyi Yuan, Xiangcheng Zhang, Tianhao Huang, Changjing He, Chaoyi Deng, Renrui Zhang, Youbin Wu, Mingsheng Long</div>
<div class="meta-line">First: 2026-01-27T17:40:07+00:00 · Latest: 2026-01-27T17:40:07+00:00</div>
<div class="meta-line">Comments: Project page: https://thuml.github.io/Reasoning-Visual-World</div>
<div class="links" style="margin-top:8px"><a href="https://arxiv.org/abs/2601.19834v1">Abs</a> · <a href="https://arxiv.org/pdf/2601.19834v1">PDF</a> · <a href="https://huggingface.co/huggingface">Code1</a> · <a href="https://huggingface.co/docs/hub/spaces">Code2</a> · <a href="https://thuml.github.io/Reasoning-Visual-World">Project1</a></div>
<details class="detail"><summary>Abstract</summary>
<div class="mono">Humans construct internal world models and reason by manipulating the concepts within these models. Recent advances in AI, particularly chain-of-thought (CoT) reasoning, approximate such human cognitive abilities, where world models are believed to be embedded within large language models. Expert-level performance in formal and abstract domains such as mathematics and programming has been achieved in current systems by relying predominantly on verbal reasoning. However, they still lag far behind humans in domains like physical and spatial intelligence, which require richer representations and prior knowledge. The emergence of unified multimodal models (UMMs) capable of both verbal and visual generation has therefore sparked interest in more human-like reasoning grounded in complementary multimodal pathways, though their benefits remain unclear. From a world-model perspective, this paper presents the first principled study of when and how visual generation benefits reasoning. Our key position is the visual superiority hypothesis: for certain tasks--particularly those grounded in the physical world--visual generation more naturally serves as world models, whereas purely verbal world models encounter bottlenecks arising from representational limitations or insufficient prior knowledge. Theoretically, we formalize internal world modeling as a core component of CoT reasoning and analyze distinctions among different forms of world models. Empirically, we identify tasks that necessitate interleaved visual-verbal CoT reasoning, constructing a new evaluation suite, VisWorld-Eval. Controlled experiments on a state-of-the-art UMM show that interleaved CoT significantly outperforms purely verbal CoT on tasks that favor visual world modeling, but offers no clear advantage otherwise. Together, this work clarifies the potential of multimodal world modeling for more powerful, human-like multimodal AI.</div></details>
<details class="detail"><summary>中文标题/摘要</summary>
<div class="mono"><b>标题：</b>视觉生成通过多模态世界模型解锁类人推理</div>
<div class="mono" style="margin-top:8px">人类通过构建内部世界模型并操控其中的概念进行推理。人工智能的最新进展，特别是思维链推理，近似实现了这种人类认知能力，其中世界模型被认为嵌入于大型语言模型中。当前系统主要依赖言语推理，已在数学和编程等正式抽象领域达到专家水平，但在物理和空间智能等需要更丰富表征与先验知识的领域仍远落后于人类。兼具言语与视觉生成能力的统一多模态模型的出现，激发了基于互补多模态通路的类人推理研究兴趣，但其优势尚不明确。本文从世界模型视角首次系统研究了视觉生成何时及如何促进推理。核心观点是视觉优势假说：对于某些任务（尤其是物理世界相关任务），视觉生成更自然地充当世界模型，而纯言语世界模型则受限于表征能力不足或先验知识匮乏。理论上，我们将内部世界建模形式化为思维链推理的核心组件，并分析不同世界模型形式的差异。实证方面，我们识别出需要交错式视觉-言语思维链推理的任务，构建了新型评估套件VisWorld-Eval。在尖端统一多模态模型上的对照实验表明：在适合视觉世界建模的任务中，交错式思维链显著优于纯言语思维链，而在其他任务中无明显优势。本研究阐明了多模态世界模型对构建更强大类人多模态人工智能的潜力。</div>
</details>
<details class="detail"><summary>Summary / 总结</summary>
<div class="mono">This research investigates whether and how visual generation can enhance reasoning in AI systems, motivated by the observation that current models excel in verbal domains like mathematics but lag in physical and spatial intelligence requiring richer representations. The authors propose the visual superiority hypothesis, formalize world modeling as part of chain-of-thought reasoning, and empirically test it using a new evaluation suite, VisWorld-Eval, with a state-of-the-art unified multimodal model. Key experimental results show that interleaved visual-verbal reasoning significantly outperforms purely verbal reasoning on tasks favoring visual world modeling, while offering no clear advantage on other tasks, clarifying the specific benefits of multimodal approaches.</div>
<div class="mono" style="margin-top:8px">本研究的动机是观察到大型语言模型在抽象领域的语言推理表现出色，但在需要更丰富世界模型的物理和空间任务中表现不佳。该研究提出了视觉优势假说，认为视觉生成能作为此类任务更有效的世界模型，并将世界建模形式化为思维链推理的核心组成部分。通过在最新统一多模态模型上使用新评估套件VisWorld-Eval进行对照实验，作者发现，在适合视觉世界建模的任务中，交错视觉-语言推理显著优于纯语言推理，但在其他任务中没有明显优势。</div>
</details>
</div>
<div class="card">
<div class="title">When Iterative RAG Beats Ideal Evidence: A Diagnostic Study in Scientific Multi-hop Question Answering</div>
<div class="meta-line">Authors: Mahdi Astaraki, Mohammad Arshi Saloot, Ali Shiraee Kasmaee, Hamidreza Mahyar, Soheila Samiee</div>
<div class="meta-line">First: 2026-01-27T17:35:05+00:00 · Latest: 2026-01-27T17:35:05+00:00</div>
<div class="meta-line">Comments: 27 pages, 15 figures</div>
<div class="links" style="margin-top:8px"><a href="https://arxiv.org/abs/2601.19827v1">Abs</a> · <a href="https://arxiv.org/pdf/2601.19827v1">PDF</a> · <a href="https://huggingface.co/huggingface">Code1</a> · <a href="https://huggingface.co/docs/hub/spaces">Code2</a></div>
<details class="detail"><summary>Abstract</summary>
<div class="mono">Retrieval-Augmented Generation (RAG) extends large language models (LLMs) beyond parametric knowledge, yet it is unclear when iterative retrieval-reasoning loops meaningfully outperform static RAG, particularly in scientific domains with multi-hop reasoning, sparse domain knowledge, and heterogeneous evidence. We provide the first controlled, mechanism-level diagnostic study of whether synchronized iterative retrieval and reasoning can surpass an idealized static upper bound (Gold Context) RAG. We benchmark eleven state-of-the-art LLMs under three regimes: (i) No Context, measuring reliance on parametric memory; (ii) Gold Context, where all oracle evidence is supplied at once; and (iii) Iterative RAG, a training-free controller that alternates retrieval, hypothesis refinement, and evidence-aware stopping. Using the chemistry-focused ChemKGMultiHopQA dataset, we isolate questions requiring genuine retrieval and analyze behavior with diagnostics spanning retrieval coverage gaps, anchor-carry drop, query quality, composition fidelity, and control calibration. Across models, Iterative RAG consistently outperforms Gold Context, with gains up to 25.6 percentage points, especially for non-reasoning fine-tuned models. Staged retrieval reduces late-hop failures, mitigates context overload, and enables dynamic correction of early hypothesis drift, but remaining failure modes include incomplete hop coverage, distractor latch trajectories, early stopping miscalibration, and high composition failure rates even with perfect retrieval. Overall, staged retrieval is often more influential than the mere presence of ideal evidence; we provide practical guidance for deploying and diagnosing RAG systems in specialized scientific settings and a foundation for more reliable, controllable iterative retrieval-reasoning frameworks.</div></details>
<details class="detail"><summary>中文标题/摘要</summary>
<div class="mono"><b>标题：</b>当迭代式RAG超越理想证据：科学多跳问答中的诊断性研究</div>
<div class="mono" style="margin-top:8px">检索增强生成（RAG）将大语言模型（LLM）的能力扩展至参数化知识之外，但迭代式检索-推理循环何时能显著优于静态RAG尚不明确，尤其是在需要多跳推理、领域知识稀疏且证据异构的科学领域。我们首次通过受控的机制层面诊断研究，探讨同步迭代检索与推理能否超越理想化的静态上限（黄金上下文）RAG。我们在三种机制下对十一种前沿LLM进行基准测试：（i）无上下文，测量对参数记忆的依赖；（ii）黄金上下文，一次性提供所有理想证据；（iii）迭代式RAG，一种无需训练的控制器，交替执行检索、假设优化和基于证据的停止判断。使用化学领域的ChemKGMultiHopQA数据集，我们筛选出真正需要检索的问题，并通过检索覆盖缺口、锚点传递缺失、查询质量、组合保真度和控制校准等诊断指标分析模型行为。所有模型中，迭代式RAG均稳定超越黄金上下文，最高提升25.6个百分点，对未经推理微调的模型提升尤为显著。分阶段检索减少了后期跳转失败，缓解了上下文过载，并能动态纠正早期假设漂移，但剩余失败模式包括跳转覆盖不全、干扰项锁定轨迹、早停校准偏差，以及即使检索完美仍存在的高组合失败率。总体而言，分阶段检索往往比单纯提供理想证据更具影响力；我们为在专业科学场景中部署和诊断RAG系统提供了实用指南，并为构建更可靠、可控的迭代检索-推理框架奠定了基础。</div>
</details>
<details class="detail"><summary>Summary / 总结</summary>
<div class="mono">This study investigates when iterative retrieval-augmented generation (RAG) can outperform an idealized static RAG system that is provided with all relevant evidence upfront, a question particularly relevant for scientific multi-hop question answering where reasoning requires integrating sparse and heterogeneous knowledge. The authors conduct a diagnostic analysis using a chemistry-focused dataset, comparing three regimes—no context, gold context, and a training-free iterative RAG controller that alternates retrieval, hypothesis refinement, and evidence-aware stopping—across eleven state-of-the-art LLMs. Key experimental findings show that iterative RAG consistently surpasses the gold context upper bound, achieving gains up to 25.6 percentage points, especially for non-reasoning fine-tuned models, by reducing late-hop failures, mitigating context overload, and correcting early hypothesis drift, though failures persist in areas like incomplete hop coverage and composition fidelity.</div>
<div class="mono" style="margin-top:8px">本研究探讨了在科学多跳问答中，当需要整合稀疏且异构的领域知识进行推理时，迭代式检索增强生成（RAG）何时能超越提供全部相关证据的理想化静态RAG系统。作者对十一种最先进的大语言模型进行了诊断性基准测试，比较了三种机制：无上下文、黄金上下文（提供全部理想证据）以及一种无需训练、交替进行检索、假设细化和证据感知停止的迭代RAG控制器，并使用化学数据集ChemKGMultiHopQA来隔离需要真实检索的问题。关键实验结果表明，迭代RAG consistently 超越了黄金上下文的上界，性能提升高达25.6个百分点，尤其使非推理精调模型受益；分阶段检索减少了后期跳的失败，缓解了上下文过载，并纠正了早期假设漂移，但仍存在如跳覆盖不全和早期停止校准不当等失败模式。</div>
</details>
</div>
<div class="card">
<div class="title">APEX-Agents</div>
<div class="meta-line">Authors: Bertie Vidgen, Austin Mann, Abby Fennelly, John Wright Stanly, Lucas Rothman, Marco Burstein, Julien Benchek, David Ostrofsky, Anirudh Ravichandran, Debnil Sur, Neel Venugopal, Alannah Hsia, Isaac Robinson, Calix Huang, Olivia Varones, Daniyal Khan, Michael Haines, Zach Richards, Chirag Mahapatra, Brendan Foody, Osvald Nitski</div>
<div class="meta-line">First: 2026-01-20T18:53:44+00:00 · Latest: 2026-01-27T17:31:16+00:00</div>
<div class="links" style="margin-top:8px"><a href="https://arxiv.org/abs/2601.14242v2">Abs</a> · <a href="https://arxiv.org/pdf/2601.14242v2">PDF</a> · <a href="https://huggingface.co/huggingface">Code1</a> · <a href="https://huggingface.co/docs/hub/spaces">Code2</a></div>
<details class="detail"><summary>Abstract</summary>
<div class="mono">We introduce the AI Productivity Index for Agents (APEX-Agents), a benchmark for assessing whether AI agents can execute long-horizon, cross-application tasks created by investment banking analysts, management consultants, and corporate lawyers. APEX-Agents requires agents to navigate realistic work environments with files and tools. We test eight agents for the leaderboard using Pass@1. Gemini 3 Flash (Thinking=High) achieves the highest score of 24.0%, followed by GPT-5.2 (Thinking=High), Claude Opus 4.5 (Thinking=High), and Gemini 3 Pro (Thinking=High). We open source the APEX-Agents benchmark (n=480) with all prompts, rubrics, gold outputs, files, and metadata. We also open-source Archipelago, our infrastructure for agent execution and evaluation.</div></details>
<details class="detail"><summary>中文标题/摘要</summary>
<div class="mono"><b>标题：</b>APEX-Agents</div>
<div class="mono" style="margin-top:8px">我们推出AI智能体生产力指数（APEX-Agents），这是一个用于评估AI智能体能否执行由投行分析师、管理顾问和企业律师设计的跨应用长周期任务的基准测试。APEX-Agents要求智能体在包含文件与工具的真实工作环境中进行操作。我们采用Pass@1指标对八个智能体进行排行榜测试，Gemini 3 Flash（思考模式=高）以24.0%得分位居榜首，其后依次为GPT-5.2（思考模式=高）、Claude Opus 4.5（思考模式=高）和Gemini 3 Pro（思考模式=高）。我们开源了包含全部提示词、评分标准、标准输出、文件及元数据的APEX-Agents基准测试集（n=480），同时开源了用于智能体执行与评估的基础设施Archipelago。</div>
</details>
<details class="detail"><summary>Summary / 总结</summary>
<div class="mono">The research is motivated by the need to evaluate AI agents on complex, real-world professional tasks that span multiple applications and require long-term planning, as encountered in fields like investment banking and law. The method introduces the APEX-Agents benchmark, which simulates realistic work environments with files and tools, and assesses agents using a Pass@1 metric on a set of 480 tasks. Key experimental results show that Gemini 3 Flash (Thinking=High) achieved the highest score of 24.0%, outperforming other leading models including GPT-5.2 and Claude Opus 4.5, with the benchmark and an associated execution infrastructure, Archipelago, being open-sourced.</div>
<div class="mono" style="margin-top:8px">本研究提出了APEX-Agents基准，旨在评估AI智能体执行由投资银行分析师、管理顾问和公司律师创建的、反映现实专业工作的复杂、长期且跨应用程序任务的能力。该方法通过在配备文件和工具的真实模拟工作环境中测试智能体，使用Pass@1指标对480项任务进行性能评估。关键实验结果表明，Gemini 3 Flash（Thinking=High）以24.0%的最高得分领先，优于GPT-5.2和Claude Opus 4.5等其他主流模型，同时该基准及其评估基础设施Archipelago已作为开源资源发布。</div>
</details>
</div>
<div class="card">
<div class="title">Routing End User Queries to Enterprise Databases</div>
<div class="meta-line">Authors: Saikrishna Sudarshan, Tanay Kulkarni, Manasi Patwardhan, Lovekesh Vig, Ashwin Srinivasan, Tanmay Tulsidas Verlekar</div>
<div class="meta-line">First: 2026-01-27T17:30:19+00:00 · Latest: 2026-01-27T17:30:19+00:00</div>
<div class="meta-line">Comments: 6 pages, 2 figures</div>
<div class="links" style="margin-top:8px"><a href="https://arxiv.org/abs/2601.19825v1">Abs</a> · <a href="https://arxiv.org/pdf/2601.19825v1">PDF</a> · <a href="https://huggingface.co/huggingface">Code1</a> · <a href="https://huggingface.co/docs/hub/spaces">Code2</a></div>
<details class="detail"><summary>Abstract</summary>
<div class="mono">We address the task of routing natural language queries in multi-database enterprise environments. We construct realistic benchmarks by extending existing NL-to-SQL datasets. Our study shows that routing becomes increasingly challenging with larger, domain-overlapping DB repositories and ambiguous queries, motivating the need for more structured and robust reasoning-based solutions. By explicitly modelling schema coverage, structural connectivity, and fine-grained semantic alignment, the proposed modular, reasoning-driven reranking strategy consistently outperforms embedding-only and direct LLM-prompting baselines across all the metrics.</div></details>
<details class="detail"><summary>中文标题/摘要</summary>
<div class="mono"><b>标题：</b>终端用户查询向企业数据库的路由分配</div>
<div class="mono" style="margin-top:8px">本研究针对多数据库企业环境中自然语言查询的路由任务展开。通过扩展现有NL-to-SQL数据集构建了贴近实际的基准测试集。研究表明：随着数据库库规模扩大、领域重叠度增加以及查询语句歧义性增强，路由任务的挑战性显著提升，这凸显了对更结构化、更鲁棒的基于推理的解决方案的需求。通过显式建模模式覆盖度、结构连通性和细粒度语义对齐，所提出的模块化推理驱动重排序策略在所有评估指标上均持续优于纯嵌入方法和直接LLM提示基线。</div>
</details>
<details class="detail"><summary>Summary / 总结</summary>
<div class="mono">This research addresses the challenge of routing natural language queries to the correct database in multi-database enterprise environments, where performance degrades with larger, domain-overlapping repositories and ambiguous queries. The method involves constructing realistic benchmarks from existing NL-to-SQL datasets and proposes a modular, reasoning-driven reranking strategy that explicitly models schema coverage, structural connectivity, and fine-grained semantic alignment. Experimental results show this approach consistently outperforms embedding-only and direct large language model (LLM) prompting baselines across all evaluation metrics.</div>
<div class="mono" style="margin-top:8px">本研究旨在解决企业多数据库环境中，如何将自然语言查询准确路由至正确数据库的挑战。作者通过扩展现有的自然语言转SQL数据集构建了更贴近现实的基准，并提出了一种模块化、基于推理的重排序策略，该策略显式地对模式覆盖度、结构连通性和细粒度语义对齐进行建模。实验结果表明，该方法在所有评估指标上均持续优于仅使用嵌入或直接提示大语言模型的基线方法，尤其是在数据库规模更大、查询更模糊的复杂场景下。</div>
</details>
</div>
<div class="card">
<div class="title">An Interpretable Recommendation Model for Psychometric Data, With an Application to Gerontological Primary Care</div>
<div class="meta-line">Authors: Andre Paulino de Lima, Paula Castro, Suzana Carvalho Vaz de Andrade, Rosa Maria Marcucci, Ruth Caldeira de Melo, Marcelo Garcia Manzato</div>
<div class="meta-line">First: 2026-01-27T17:29:21+00:00 · Latest: 2026-01-27T17:29:21+00:00</div>
<div class="meta-line">Comments: 81 pages, 19 figures, 3 annexes</div>
<div class="links" style="margin-top:8px"><a href="https://arxiv.org/abs/2601.19824v1">Abs</a> · <a href="https://arxiv.org/pdf/2601.19824v1">PDF</a> · <a href="https://huggingface.co/huggingface">Code1</a> · <a href="https://huggingface.co/docs/hub/spaces">Code2</a></div>
<details class="detail"><summary>Abstract</summary>
<div class="mono">There are challenges that must be overcome to make recommender systems useful in healthcare settings. The reasons are varied: the lack of publicly available clinical data, the difficulty that users may have in understanding the reasons why a recommendation was made, the risks that may be involved in following that recommendation, and the uncertainty about its effectiveness. In this work, we address these challenges with a recommendation model that leverages the structure of psychometric data to provide visual explanations that are faithful to the model and interpretable by care professionals. We focus on a narrow healthcare niche, gerontological primary care, to show that the proposed recommendation model can assist the attending professional in the creation of personalised care plans. We report results of a comparative offline performance evaluation of the proposed model on healthcare datasets that were collected by research partners in Brazil, as well as the results of a user study that evaluates the interpretability of the visual explanations the model generates. The results suggest that the proposed model can advance the application of recommender systems in this healthcare niche, which is expected to grow in demand , opportunities, and information technology needs as demographic changes become more pronounced.</div></details>
<details class="detail"><summary>中文标题/摘要</summary>
<div class="mono"><b>标题：</b>一种面向心理测量数据的可解释推荐模型及其在老年基础医疗中的应用</div>
<div class="mono" style="margin-top:8px">要使推荐系统在医疗场景中发挥作用，需克服多重挑战：公开临床数据匮乏、用户难以理解推荐依据、遵循建议可能存在的风险，以及效果的不确定性。本研究通过构建一种推荐模型应对这些挑战，该模型利用心理测量数据的结构，提供忠实于模型且能被护理专业人员理解的视觉化解释。我们聚焦于老年基础医疗这一细分领域，证明该推荐模型能协助执业专业人员制定个性化护理方案。基于巴西研究合作方收集的医疗数据集，我们报告了所提模型的离线性能对比评估结果，以及针对模型生成视觉解释可理解性的用户研究结果。结果表明，该模型能推动推荐系统在这一医疗细分领域的应用——随着人口结构变化加剧，该领域在需求、机遇和信息技术需求方面预计将持续增长。</div>
</details>
<details class="detail"><summary>Summary / 总结</summary>
<div class="mono">To address the challenges of applying recommender systems in healthcare, such as data scarcity, lack of interpretability, and risk concerns, this research develops an interpretable recommendation model specifically for psychometric data in gerontological primary care. The method leverages the inherent structure of psychometric data to generate visual explanations that are both faithful to the model and understandable by care professionals. Experimental results from offline evaluations on Brazilian healthcare datasets and a user study demonstrate that the model can effectively assist in creating personalized care plans and that its visual explanations are interpretable, suggesting its potential to advance recommender systems in this growing healthcare niche.</div>
<div class="mono" style="margin-top:8px">为应对医疗推荐系统中数据稀缺、可解释性不足及风险担忧等挑战，本研究开发了一种专门针对心理测量数据的模型，以生成既忠实于模型又能被临床医生理解的可视化解释。该方法聚焦于老年初级护理领域，利用心理测量评估的内在结构来辅助专业人员制定个性化护理计划。在巴西收集的数据集上进行的实验评估，包括离线性能比较和针对可解释性的用户研究，结果表明该模型能有效支持护理规划，并推动推荐系统在这一需求不断增长的医疗细分领域中的应用。</div>
</details>
</div>
<div class="card">
<div class="title">ReVision: A Dataset and Baseline VLM for Privacy-Preserving Task-Oriented Visual Instruction Rewriting</div>
<div class="meta-line">Authors: Abhijit Mishra, Mingda Li, Hsiang Fu, Richard Noh, Minji Kim</div>
<div class="meta-line">First: 2025-02-20T18:01:41+00:00 · Latest: 2026-01-27T17:16:10+00:00</div>
<div class="meta-line">Comments: In Proceedings of the IJCNLP-AACL 2025</div>
<div class="links" style="margin-top:8px"><a href="https://arxiv.org/abs/2502.14780v3">Abs</a> · <a href="https://arxiv.org/pdf/2502.14780v3">PDF</a> · <a href="https://huggingface.co/huggingface">Code1</a> · <a href="https://huggingface.co/docs/hub/spaces">Code2</a></div>
<details class="detail"><summary>Abstract</summary>
<div class="mono">Efficient and privacy-preserving multimodal interaction is essential as AR, VR, and modern smartphones with powerful cameras become primary interfaces for human-computer communication. Existing powerful large vision-language models (VLMs) enabling multimodal interaction often rely on cloud-based processing, raising significant concerns about (1) visual privacy by transmitting sensitive vision data to servers, and (2) their limited real-time, on-device usability. This paper explores Visual Instruction Rewriting, a novel approach that transforms multimodal instructions into text-only commands, allowing seamless integration of lightweight on-device instruction rewriter VLMs (250M parameters) with existing conversational AI systems, enhancing vision data privacy. To achieve this, we present a dataset of over 39,000 examples across 14 domains and develop a compact VLM, pretrained on image captioning datasets and fine-tuned for instruction rewriting. Experimental results, evaluated through NLG metrics such as BLEU, METEOR, and ROUGE, along with semantic parsing analysis, demonstrate that even a quantized version of the model (&lt;500MB storage footprint) can achieve effective instruction rewriting, thus enabling privacy-focused, multimodal AI applications.</div></details>
<details class="detail"><summary>中文标题/摘要</summary>
<div class="mono"><b>标题：</b>ReVision：面向隐私保护任务型视觉指令重写的数据集与基线视觉语言模型</div>
<div class="mono" style="margin-top:8px">随着AR、VR及配备高性能摄像头的现代智能手机成为人机交互的主要界面，高效且保护隐私的多模态交互变得至关重要。现有支持多模态交互的大型视觉语言模型通常依赖云端处理，引发两大核心问题：（1）向服务器传输敏感视觉数据带来的隐私风险；（2）模型难以在设备端实现实时运行。本文提出视觉指令重写这一创新方法，将多模态指令转化为纯文本命令，使轻量级设备端指令重写模型（2.5亿参数）能够与现有对话式AI系统无缝集成，从而增强视觉数据隐私保护。为此，我们构建了涵盖14个领域、超过3.9万条样本的数据集，并开发了紧凑型视觉语言模型——该模型基于图像描述数据集预训练，并针对指令重写任务进行微调。通过BLEU、METEOR、ROUGE等自然语言生成指标及语义解析分析，实验结果表明：即使量化后的模型（存储占用&lt;500MB）仍能实现有效的指令重写，为注重隐私的多模态AI应用提供了可行方案。</div>
</details>
<details class="detail"><summary>Summary / 总结</summary>
<div class="mono">This research addresses privacy and efficiency concerns in multimodal interactions, where cloud-based large vision-language models (VLMs) risk exposing sensitive visual data and lack real-time on-device usability. The authors propose Visual Instruction Rewriting, a method that converts multimodal instructions into text-only commands, enabling integration of a compact on-device VLM with 250M parameters into existing conversational AI systems. Experiments using NLG metrics (BLEU, METEOR, ROUGE) and semantic parsing show that even a quantized model under 500MB effectively performs instruction rewriting, supporting privacy-preserving multimodal applications.</div>
<div class="mono" style="margin-top:8px">该研究针对基于云的大型视觉语言模型在多模态交互中存在的隐私和延迟问题，提出了视觉指令重写方法，将视觉指令转换为纯文本命令以便在设备端处理。方法包括构建一个涵盖14个领域、超过39,000个示例的数据集，并训练一个250M参数的紧凑视觉语言模型，该模型在图像描述数据上预训练后针对指令重写进行微调。实验使用BLEU、METEOR和ROUGE等自然语言生成指标以及语义解析进行评估，结果表明即使量化后模型小于500MB也能实现有效的指令重写，从而支持注重隐私的多模态应用。</div>
</details>
</div>
<div class="card">
<div class="title">Revisiting Incremental Stochastic Majorization-Minimization Algorithms with Applications to Mixture of Experts</div>
<div class="meta-line">Authors: TrungKhang Tran, TrungTin Nguyen, Gersende Fort, Tung Doan, Hien Duy Nguyen, Binh T. Nguyen, Florence Forbes, Christopher Drovandi</div>
<div class="meta-line">First: 2026-01-27T17:12:15+00:00 · Latest: 2026-01-27T17:12:15+00:00</div>
<div class="meta-line">Comments: TrungKhang Tran and TrungTin Nguyen are co-first authors</div>
<div class="links" style="margin-top:8px"><a href="https://arxiv.org/abs/2601.19811v1">Abs</a> · <a href="https://arxiv.org/pdf/2601.19811v1">PDF</a> · <a href="https://huggingface.co/huggingface">Code1</a> · <a href="https://huggingface.co/docs/hub/spaces">Code2</a></div>
<details class="detail"><summary>Abstract</summary>
<div class="mono">Processing high-volume, streaming data is increasingly common in modern statistics and machine learning, where batch-mode algorithms are often impractical because they require repeated passes over the full dataset. This has motivated incremental stochastic estimation methods, including the incremental stochastic Expectation-Maximization (EM) algorithm formulated via stochastic approximation. In this work, we revisit and analyze an incremental stochastic variant of the Majorization-Minimization (MM) algorithm, which generalizes incremental stochastic EM as a special case. Our approach relaxes key EM requirements, such as explicit latent-variable representations, enabling broader applicability and greater algorithmic flexibility. We establish theoretical guarantees for the incremental stochastic MM algorithm, proving consistency in the sense that the iterates converge to a stationary point characterized by a vanishing gradient of the objective. We demonstrate these advantages on a softmax-gated mixture of experts (MoE) regression problem, for which no stochastic EM algorithm is available. Empirically, our method consistently outperforms widely used stochastic optimizers, including stochastic gradient descent, root mean square propagation, adaptive moment estimation, and second-order clipped stochastic optimization. These results support the development of new incremental stochastic algorithms, given the central role of softmax-gated MoE architectures in contemporary deep neural networks for heterogeneous data modeling. Beyond synthetic experiments, we also validate practical effectiveness on two real-world datasets, including a bioinformatics study of dent maize genotypes under drought stress that integrates high-dimensional proteomics with ecophysiological traits, where incremental stochastic MM yields stable gains in predictive performance.</div></details>
<details class="detail"><summary>中文标题/摘要</summary>
<div class="mono"><b>标题：</b>增量随机主优化-最小化算法及其在专家混合模型中的应用再探</div>
<div class="mono" style="margin-top:8px">处理大规模流式数据在现代统计学与机器学习中日益普遍，批处理算法因需多次遍历完整数据集而常不实用，这推动了增量随机估计方法的发展，包括通过随机逼近构建的增量随机期望最大化算法。本研究重新审视并分析了一种增量随机主优化-最小化算法的变体，该算法将增量随机期望最大化作为特例进行推广。我们的方法放宽了期望最大化算法的关键要求（如显式隐变量表示），从而拓展了适用场景并增强算法灵活性。我们为增量随机主优化-最小化算法建立了理论保证，证明其迭代序列会收敛至目标函数梯度为零的驻点。我们在Softmax门控专家混合回归问题上展示了这些优势——该问题目前尚无随机期望最大化算法可用。实证表明，本方法持续优于广泛使用的随机优化器，包括随机梯度下降、均方根传播、自适应矩估计及二阶截断随机优化。鉴于Softmax门控专家混合架构在异质数据建模的现代深度神经网络中的核心地位，这些结果为开发新型增量随机算法提供了支持。除合成实验外，我们还在两个真实数据集上验证了实际有效性，包括一项整合高维蛋白质组学与生态生理性状的干旱胁迫下齿玉米基因型生物信息学研究，其中增量随机主优化-最小化算法带来了预测性能的稳定提升。</div>
</details>
<details class="detail"><summary>Summary / 总结</summary>
<div class="mono">To address the challenge of processing high-volume streaming data where batch algorithms are impractical, this work revisits an incremental stochastic variant of the Majorization-Minimization (MM) algorithm, which generalizes incremental stochastic EM by relaxing requirements like explicit latent-variable models for broader applicability. The method is theoretically analyzed, proving consistency with iterates converging to a stationary point. Experimental validation on a softmax-gated mixture of experts regression problem, where no stochastic EM exists, shows it consistently outperforms stochastic gradient descent, RMSprop, Adam, and second-order clipped stochastic optimization, with stable predictive gains also demonstrated on real-world datasets including a bioinformatics study of drought-stressed maize.</div>
<div class="mono" style="margin-top:8px">为处理批量算法不适用的大规模流式数据，本研究重新审视并分析了一种增量随机优化-最小化（MM）算法的变体，它推广了增量随机期望最大化（EM）算法。该方法放宽了EM算法的关键要求（如显式的隐变量表示），从而拓宽了应用范围并提供了更大的算法灵活性。理论分析证明了该算法的迭代收敛到一个稳定点。在softmax门控的混合专家回归问题上，其实验性能持续优于随机梯度下降、RMSprop、Adam和SOC等常用随机优化器，并在包括干旱胁迫下玉米基因型的生物信息学数据集在内的真实世界数据上展现了稳定的预测性能提升。</div>
</details>
</div>
<div class="card">
<div class="title">Unsupervised Learning of Efficient Exploration: Pre-training Adaptive Policies via Self-Imposed Goals</div>
<div class="meta-line">Authors: Octavio Pappalardo</div>
<div class="meta-line">Venue: ICLR 2026</div>
<div class="meta-line">First: 2026-01-27T17:10:29+00:00 · Latest: 2026-01-27T17:10:29+00:00</div>
<div class="meta-line">Comments: To appear at ICLR 2026</div>
<div class="links" style="margin-top:8px"><a href="https://arxiv.org/abs/2601.19810v1">Abs</a> · <a href="https://arxiv.org/pdf/2601.19810v1">PDF</a> · <a href="https://huggingface.co/huggingface">Code1</a> · <a href="https://huggingface.co/docs/hub/spaces">Code2</a></div>
<details class="detail"><summary>Abstract</summary>
<div class="mono">Unsupervised pre-training can equip reinforcement learning agents with prior knowledge and accelerate learning in downstream tasks. A promising direction, grounded in human development, investigates agents that learn by setting and pursuing their own goals. The core challenge lies in how to effectively generate, select, and learn from such goals. Our focus is on broad distributions of downstream tasks where solving every task zero-shot is infeasible. Such settings naturally arise when the target tasks lie outside of the pre-training distribution or when their identities are unknown to the agent. In this work, we (i) optimize for efficient multi-episode exploration and adaptation within a meta-learning framework, and (ii) guide the training curriculum with evolving estimates of the agent&#x27;s post-adaptation performance. We present ULEE, an unsupervised meta-learning method that combines an in-context learner with an adversarial goal-generation strategy that maintains training at the frontier of the agent&#x27;s capabilities. On XLand-MiniGrid benchmarks, ULEE pre-training yields improved exploration and adaptation abilities that generalize to novel objectives, environment dynamics, and map structures. The resulting policy attains improved zero-shot and few-shot performance, and provides a strong initialization for longer fine-tuning processes. It outperforms learning from scratch, DIAYN pre-training, and alternative curricula.</div></details>
<details class="detail"><summary>中文标题/摘要</summary>
<div class="mono"><b>标题：</b>高效探索的无监督学习：通过自设目标预训练自适应策略</div>
<div class="mono" style="margin-top:8px">无监督预训练可为强化学习智能体提供先验知识，加速下游任务学习。基于人类发展机制的研究方向，探索智能体通过自主设定并追求目标进行学习。核心挑战在于如何有效生成、选择并从此类目标中学习。我们关注下游任务广泛分布的场景，其中零样本解决所有任务不可行。当目标任务超出预训练分布范围或智能体未知任务特性时，此类场景自然出现。本研究（i）在元学习框架内优化多轮次探索与适应效率，（ii）通过动态评估智能体适应后表现来指导训练课程。我们提出ULEE方法——结合情境学习器与对抗性目标生成策略的无监督元学习方法，使训练持续处于智能体能力前沿。在XLand-MiniGrid基准测试中，ULEE预训练展现出可泛化至新目标、环境动态与地图结构的探索适应能力。所得策略在零样本/少样本场景表现更优，并为长时微调提供优质初始化，其性能优于从头学习、DIAYN预训练及其他课程学习方法。</div>
</details>
<details class="detail"><summary>Summary / 总结</summary>
<div class="mono">The research aims to enhance unsupervised pre-training for reinforcement learning agents by enabling them to learn through self-generated goals, which is motivated by the need to accelerate adaptation in downstream tasks that are outside the pre-training distribution or unknown. The method, ULEE, combines meta-learning for efficient multi-episode exploration with an adversarial goal-generation curriculum that continuously challenges the agent at its capability frontier. Experimental results on XLand-MiniGrid benchmarks show that ULEE improves exploration and adaptation, leading to better zero-shot and few-shot performance on novel objectives, dynamics, and structures, outperforming learning from scratch, DIAYN, and other curricula.</div>
<div class="mono" style="margin-top:8px">针对因目标新颖或任务身份未知而无法零样本解决的下游任务，为加速强化学习，本研究提出了无监督元学习方法ULEE。该方法通过结合情境学习器与对抗性目标生成策略来优化多回合探索效率，该策略根据对适应后性能的演化估计，将训练维持在智能体能力前沿。在XLand-MiniGrid基准测试上的实验结果表明，ULEE预训练提升了探索与适应能力，并能泛化至新目标、环境动态和地图结构，在零样本、少样本及微调性能上均优于从头学习、DIAYN预训练及其他课程学习方法。</div>
</details>
</div>
<div class="card">
<div class="title">LLM-Generated Explanations Do Not Suffice for Ultra-Strong Machine Learning</div>
<div class="meta-line">Authors: Lun Ai, Johannes Langer, Ute Schmid, Stephen Muggleton</div>
<div class="meta-line">First: 2025-08-31T19:04:31+00:00 · Latest: 2026-01-27T17:01:53+00:00</div>
<div class="links" style="margin-top:8px"><a href="https://arxiv.org/abs/2509.00961v2">Abs</a> · <a href="https://arxiv.org/pdf/2509.00961v2">PDF</a> · <a href="https://huggingface.co/huggingface">Code1</a> · <a href="https://huggingface.co/docs/hub/spaces">Code2</a></div>
<details class="detail"><summary>Abstract</summary>
<div class="mono">Ultra Strong Machine Learning (USML) refers to symbolic learning systems that not only improve their own performance but can also teach their acquired knowledge to quantifiably improve human performance. We introduce LENS (Logic Programming Explanation via Neural Summarisation), a neuro-symbolic framework that combines symbolic program synthesis with large language models (LLMs). This framework automatically generates natural language explanations of learned logic programs, replacing hand-crafted templates used in prior USML work. Using LLMs-as-judges evaluation and expert validation, we show that LENS produces higher-quality explanations than both direct LLM prompting and hand-crafted templates. We then examine whether LENS explanations suffice for achieving USML in a human trial teaching active learning strategies across three related domains. Our exploratory analysis suggests that concise, expert-written explanations may benefit learners with higher initial performance, while LLM-generated explanations provide no advantage over human self learning despite being rated as higher quality. This case study reveals that achieving USML requires methods grounded in human learning, where current LLM-generated explanations do not capture human cognitive constraints and LLMs-as-judges evaluations do not reflect what effectively supports human learning.</div></details>
<details class="detail"><summary>中文标题/摘要</summary>
<div class="mono"><b>标题：</b>LLM生成解释不足以实现超强机器学习</div>
<div class="mono" style="margin-top:8px">超强机器学习（USML）指不仅能提升自身性能，还能将习得知识传授给人类以量化提升人类表现的符号学习系统。本文提出LENS（基于神经摘要的逻辑编程解释框架），一种将符号程序合成与大型语言模型（LLMs）结合的神经符号框架。该框架能自动生成已学习逻辑程序的自然语言解释，取代了先前USML研究中手工设计的模板。通过LLM作为评判者的评估和专家验证，我们证明LENS生成的解释质量优于直接LLM提示和手工模板。随后，我们在跨三个相关领域教授主动学习策略的人类试验中，检验LENS解释是否足以实现USML。探索性分析表明：简洁的专家撰写解释可能对初始表现较高的学习者有益，而LLM生成解释尽管被评价为更高质量，却未显示出优于人类自主学习的效果。本案例研究揭示，实现USML需要基于人类学习机制的方法——当前LLM生成解释未能捕捉人类认知约束，且LLM作为评判者的评估无法反映对人类学习真正有效的支持。</div>
</details>
<details class="detail"><summary>Summary / 总结</summary>
<div class="mono">This research addresses the challenge of Ultra-Strong Machine Learning (USML), where symbolic learning systems must not only improve autonomously but also effectively transfer knowledge to enhance human performance. The authors propose LENS, a neuro-symbolic framework that integrates symbolic program synthesis with large language models (LLMs) to automatically generate natural language explanations for learned logic programs, moving beyond hand-crafted templates. Evaluations using LLMs-as-judges and expert validation indicate that LENS produces higher-quality explanations than both direct LLM prompting and prior template-based methods. However, human trials teaching active learning strategies across three domains reveal that, despite their perceived quality, LLM-generated explanations do not confer a learning advantage over self-study, whereas concise expert-written explanations benefit higher-performing learners, highlighting that current LLM methods fail to capture human cognitive constraints and that automated evaluations do not align with effective human learning support.</div>
<div class="mono" style="margin-top:8px">本研究针对超强机器学习（USML）的挑战，即系统不仅要学习，还要能有效传授知识以提升人类表现。作者提出了LENS，一个神经符号框架，它结合了符号程序合成与大语言模型（LLM），为学习到的逻辑程序自动生成自然语言解释，取代了先前USML工作中手工制作的模板。通过使用LLM作为评判者和专家验证，评估表明LENS产生的解释质量高于直接LLM提示和手工模板。然而，在一项教授主动学习策略的人类试验中，虽然专家撰写的解释对初始表现较高的学习者有益，但LLM生成的解释相比人类自学并未提供优势，这表明当前的LLM方法未能捕捉人类认知约束，且自动化的质量评估指标并不能反映对人类学习的有效支持。</div>
</details>
</div>
<div class="card">
<div class="title">CASTER: Breaking the Cost-Performance Barrier in Multi-Agent Orchestration via Context-Aware Strategy for Task Efficient Routing</div>
<div class="meta-line">Authors: Shanyv Liu, Xuyang Yuan, Tao Chen, Zijun Zhan, Zhu Han, Danyang Zheng, Weishan Zhang, Shaohua Cao</div>
<div class="meta-line">First: 2026-01-27T16:52:47+00:00 · Latest: 2026-01-27T16:52:47+00:00</div>
<div class="links" style="margin-top:8px"><a href="https://arxiv.org/abs/2601.19793v1">Abs</a> · <a href="https://arxiv.org/pdf/2601.19793v1">PDF</a> · <a href="https://huggingface.co/huggingface">Code1</a> · <a href="https://huggingface.co/docs/hub/spaces">Code2</a></div>
<details class="detail"><summary>Abstract</summary>
<div class="mono">Graph-based Multi-Agent Systems (MAS) enable complex cyclic workflows but suffer from inefficient static model allocation, where deploying strong models uniformly wastes computation on trivial sub-tasks. We propose CASTER (Context-Aware Strategy for Task Efficient Routing), a lightweight router for dynamic model selection in graph-based MAS. CASTER employs a Dual-Signal Router that combines semantic embeddings with structural meta-features to estimate task difficulty. During training, the router self-optimizes through a Cold Start to Iterative Evolution paradigm, learning from its own routing failures via on-policy negative feedback. Experiments using LLM-as-a-Judge evaluation across Software Engineering, Data Analysis, Scientific Discovery, and Cybersecurity demonstrate that CASTER reduces inference cost by up to 72.4% compared to strong-model baselines while matching their success rates, and consistently outperforms both heuristic routing and FrugalGPT across all domains.</div></details>
<details class="detail"><summary>中文标题/摘要</summary>
<div class="mono"><b>标题：</b>CASTER：通过上下文感知任务高效路由策略突破多智能体编排的成本性能瓶颈</div>
<div class="mono" style="margin-top:8px">基于图的多智能体系统（MAS）支持复杂循环工作流，但存在静态模型分配效率低下的问题，即统一部署强模型会浪费计算资源处理简单子任务。我们提出CASTER（上下文感知任务高效路由策略），一种用于图基MAS动态模型选择的轻量级路由器。CASTER采用双信号路由器，结合语义嵌入与结构元特征来评估任务难度。训练过程中，路由器通过冷启动到迭代进化的范式进行自优化，利用策略内负反馈从自身路由失败中学习。在软件工程、数据分析、科学发现和网络安全领域使用LLM-as-a-Judge评估的实验表明，CASTER相比强模型基线最高可降低72.4%的推理成本，同时保持同等成功率，并在所有领域持续优于启发式路由和FrugalGPT。</div>
</details>
<details class="detail"><summary>Summary / 总结</summary>
<div class="mono">Graph-based Multi-Agent Systems often use static model allocation, which inefficiently deploys powerful models for all tasks, including trivial ones, leading to high computational costs. To address this, the authors propose CASTER, a lightweight router that dynamically selects models by estimating task difficulty through a Dual-Signal Router combining semantic embeddings and structural meta-features. The system self-optimizes via a Cold Start to Iterative Evolution training paradigm, learning from its own routing failures using on-policy negative feedback. Experimental evaluation across Software Engineering, Data Analysis, Scientific Discovery, and Cybersecurity domains shows CASTER reduces inference cost by up to 72.4% compared to strong-model baselines while maintaining comparable success rates, and consistently outperforms heuristic routing and FrugalGPT methods.</div>
<div class="mono" style="margin-top:8px">基于图的多智能体系统通常采用静态模型分配，无论任务难度如何都统一部署强大模型，导致计算资源浪费。为解决此问题，CASTER提出一种轻量级路由器，通过结合语义嵌入和结构元特征的双信号路由器来估计任务难度，从而动态选择模型；它采用冷启动到迭代演进的训练范式，通过基于策略的负反馈从路由失败中自我优化。在软件工程、数据分析、科学发现和网络安全领域的实验评估表明，CASTER相比强模型基线将推理成本降低高达72.4%，同时保持相当的成功率，并且一致优于启发式路由和FrugalGPT方法。</div>
</details>
</div>
<div class="card">
<div class="title">LVLMs and Humans Ground Differently in Referential Communication</div>
<div class="meta-line">Authors: Peter Zeng, Weiling Li, Amie Paige, Zhengxiang Wang, Panagiotis Kaliosis, Dimitris Samaras, Gregory Zelinsky, Susan Brennan, Owen Rambow</div>
<div class="meta-line">First: 2026-01-27T16:52:20+00:00 · Latest: 2026-01-27T16:52:20+00:00</div>
<div class="meta-line">Comments: 24 pages, 16 figures, preprint</div>
<div class="links" style="margin-top:8px"><a href="https://arxiv.org/abs/2601.19792v1">Abs</a> · <a href="https://arxiv.org/pdf/2601.19792v1">PDF</a> · <a href="https://huggingface.co/huggingface">Code1</a> · <a href="https://huggingface.co/docs/hub/spaces">Code2</a></div>
<details class="detail"><summary>Abstract</summary>
<div class="mono">For generative AI agents to partner effectively with human users, the ability to accurately predict human intent is critical. But this ability to collaborate remains limited by a critical deficit: an inability to model common ground. Here, we present a referential communication experiment with a factorial design involving director-matcher pairs (human-human, human-AI, AI-human, and AI-AI) that interact with multiple turns in repeated rounds to match pictures of objects not associated with any obvious lexicalized labels. We release the online pipeline for data collection, the tools and analyses for accuracy, efficiency, and lexical overlap, and a corpus of 356 dialogues (89 pairs over 4 rounds each) that unmasks LVLMs&#x27; limitations in interactively resolving referring expressions, a crucial skill that underlies human language use.</div></details>
<details class="detail"><summary>中文标题/摘要</summary>
<div class="mono"><b>标题：</b>LVLM与人类在指称沟通中的认知基础差异</div>
<div class="mono" style="margin-top:8px">为使生成式AI智能体与人类用户有效协作，准确预测人类意图的能力至关重要。然而，当前协作能力仍受限于一个关键缺陷：无法建模共同认知基础。本研究通过一项因子设计的指称沟通实验，包含指挥者-匹配者配对（人-人、人-AI、AI-人、AI-AI），在多轮重复互动中匹配无明确词汇化标签的物体图像。我们发布了在线数据收集流程、针对准确性、效率及词汇重叠的分析工具，以及包含356段对话的语料库（89组配对各进行4轮），揭示了LVLM在交互式解析指称表达方面的局限性——这是支撑人类语言运用的核心能力。</div>
</details>
<details class="detail"><summary>Summary / 总结</summary>
<div class="mono">To enable effective human-AI collaboration, this study investigates the ability of large vision-language models (LVLMs) to model common ground in referential communication. The researchers conducted a factorial experiment with director-matcher pairs (human-human, human-AI, AI-human, AI-AI) engaging in multi-turn dialogues to match pictures of objects without obvious labels. The results, based on a corpus of 356 dialogues, reveal significant limitations in LVLMs&#x27; capacity to interactively resolve referring expressions, as measured by accuracy, efficiency, and lexical overlap, highlighting a crucial deficit compared to human language use.</div>
<div class="mono" style="margin-top:8px">本研究探讨了生成式AI代理因无法与人类建立共同认知而存在的协作局限，这对于预测意图至关重要。通过采用因子设计的指称沟通实验，研究比较了人-人、人-AI、AI-人和AI-AI四种配置的指导者-匹配者对，在多个回合中互动匹配无明显标签的物体图片。基于356个对话语料库的实验结果表明，大型视觉语言模型在交互式解析指称表达方面存在显著缺陷，这是人类语言使用的一项关键技能，通过准确性、效率和词汇重叠度来衡量。</div>
</details>
</div>
<div class="card">
<div class="title">Reimagining Peer Review Process Through Multi-Agent Mechanism Design</div>
<div class="meta-line">Authors: Ahmad Farooq, Kamran Iqbal</div>
<div class="meta-line">First: 2026-01-27T16:43:11+00:00 · Latest: 2026-01-27T16:43:11+00:00</div>
<div class="meta-line">Comments: To appear in the Proceedings of the 2026 IEEE/ACM 48th International Conference on Software Engineering: Future of Software Engineering (ICSE-FoSE). 4 pages, 1 figure, 1 table</div>
<div class="links" style="margin-top:8px"><a href="https://arxiv.org/abs/2601.19778v1">Abs</a> · <a href="https://arxiv.org/pdf/2601.19778v1">PDF</a> · <a href="https://huggingface.co/huggingface">Code1</a> · <a href="https://huggingface.co/docs/hub/spaces">Code2</a></div>
<details class="detail"><summary>Abstract</summary>
<div class="mono">The software engineering research community faces a systemic crisis: peer review is failing under growing submissions, misaligned incentives, and reviewer fatigue. Community surveys reveal that researchers perceive the process as &quot;broken.&quot; This position paper argues that these dysfunctions are mechanism design failures amenable to computational solutions. We propose modeling the research community as a stochastic multi-agent system and applying multi-agent reinforcement learning to design incentive-compatible protocols. We outline three interventions: a credit-based submission economy, MARL-optimized reviewer assignment, and hybrid verification of review consistency. We present threat models, equity considerations, and phased pilot metrics. This vision charts a research agenda toward sustainable peer review.</div></details>
<details class="detail"><summary>中文标题/摘要</summary>
<div class="mono"><b>标题：</b>通过多智能体机制设计重构同行评审流程</div>
<div class="mono" style="margin-top:8px">软件工程研究界面临系统性危机：随着投稿量激增、激励错配及评审疲劳，同行评审正逐渐失效。社区调查显示，研究人员普遍认为该流程已“崩溃”。本立场论文指出，这些功能失调实为机制设计缺陷，可通过计算方案解决。我们提出将研究社区建模为随机多智能体系统，并应用多智能体强化学习来设计激励相容协议。我们概述三项干预措施：基于信用的投稿经济体系、MARL优化的评审分配机制，以及评审一致性的混合验证方法。文中还提出了威胁模型、公平性考量及分阶段试点指标。这一愿景为构建可持续的同行评审体系规划了研究议程。</div>
</details>
<details class="detail"><summary>Summary / 总结</summary>
<div class="mono">The paper addresses the systemic crisis in software engineering peer review, where increasing submissions, misaligned incentives, and reviewer fatigue have led researchers to perceive the process as broken. It proposes modeling the research community as a stochastic multi-agent system and applying multi-agent reinforcement learning to design incentive-compatible protocols, including a credit-based submission economy, MARL-optimized reviewer assignment, and hybrid verification of review consistency. The work outlines threat models, equity considerations, and phased pilot metrics to chart a research agenda toward sustainable peer review.</div>
<div class="mono" style="margin-top:8px">本文针对软件工程同行评审中的系统性危机展开研究，该危机源于投稿量增长、激励错配和评审疲劳，导致评审过程被认为已“崩溃”。作者提出将研究社区建模为一个随机多智能体系统，并应用多智能体强化学习来设计激励相容的协议，包括基于信用的投稿经济、MARL优化的评审分配以及评审一致性的混合验证。所概述的研究议程包含威胁模型、公平性考量以及分阶段试点指标，旨在推动评审系统向更可持续的方向发展。</div>
</details>
</div>
<div class="card">
<div class="title">DisCoPatch: Taming Adversarially-driven Batch Statistics for Improved Out-of-Distribution Detection</div>
<div class="meta-line">Authors: Francisco Caetano, Christiaan Viviers, Luis A. Zavala-Mondragón, Peter H. N. de With, Fons van der Sommen</div>
<div class="meta-line">Venue: ICCV 2025</div>
<div class="meta-line">First: 2025-01-14T10:49:26+00:00 · Latest: 2026-01-27T16:37:43+00:00</div>
<div class="meta-line">Comments: ICCV 2025</div>
<div class="links" style="margin-top:8px"><a href="https://arxiv.org/abs/2501.08005v7">Abs</a> · <a href="https://arxiv.org/pdf/2501.08005v7">PDF</a> · <a href="https://huggingface.co/huggingface">Code1</a> · <a href="https://huggingface.co/docs/hub/spaces">Code2</a></div>
<details class="detail"><summary>Abstract</summary>
<div class="mono">Out-of-distribution (OOD) detection holds significant importance across many applications. While semantic and domain-shift OOD problems are well-studied, this work focuses on covariate shifts - subtle variations in the data distribution that can degrade machine learning performance. We hypothesize that detecting these subtle shifts can improve our understanding of in-distribution boundaries, ultimately improving OOD detection. In adversarial discriminators trained with Batch Normalization (BN), real and adversarial samples form distinct domains with unique batch statistics - a property we exploit for OOD detection. We introduce DisCoPatch, an unsupervised Adversarial Variational Autoencoder (VAE) framework that harnesses this mechanism. During inference, batches consist of patches from the same image, ensuring a consistent data distribution that allows the model to rely on batch statistics. DisCoPatch uses the VAE&#x27;s suboptimal outputs (generated and reconstructed) as negative samples to train the discriminator, thereby improving its ability to delineate the boundary between in-distribution samples and covariate shifts. By tightening this boundary, DisCoPatch achieves state-of-the-art results in public OOD detection benchmarks. The proposed model not only excels in detecting covariate shifts, achieving 95.5% AUROC on ImageNet-1K(-C) but also outperforms all prior methods on public Near-OOD (95.0%) benchmarks. With a compact model size of 25MB, it achieves high OOD detection performance at notably lower latency than existing methods, making it an efficient and practical solution for real-world OOD detection applications. The code is publicly available.</div></details>
<details class="detail"><summary>中文标题/摘要</summary>
<div class="mono"><b>标题：</b>DisCoPatch：通过对抗性驱动的批统计量优化提升分布外检测性能</div>
<div class="mono" style="margin-top:8px">分布外检测在众多应用中至关重要。尽管语义和领域偏移的OOD问题已得到充分研究，本文聚焦于协变量偏移——数据分布中可能降低机器学习性能的细微变化。我们假设检测这些细微偏移能提升对分布内边界的理解，从而改善OOD检测。在使用批归一化的对抗判别器中，真实样本与对抗样本会形成具有独特批统计量的不同域，我们利用这一特性进行OOD检测。本文提出DisCoPatch，一种无监督对抗变分自编码器框架，通过推理阶段从单张图像提取的批次图像块确保数据分布一致性，使模型能依赖批统计量。该框架利用VAE的次优输出作为负样本训练判别器，从而提升其划分分布内样本与协变量偏移边界的能力。通过收紧边界，DisCoPatch在公开OOD检测基准中取得最优结果：在ImageNet-1K(-C)的协变量偏移检测上达到95.5% AUROC，在公开近OOD基准上以95.0%超越所有现有方法。模型仅25MB，在显著降低延迟的同时实现高性能检测，为实际应用提供高效解决方案。代码已开源。</div>
</details>
<details class="detail"><summary>Summary / 总结</summary>
<div class="mono">This research addresses the challenge of detecting subtle covariate shifts in out-of-distribution (OOD) detection, hypothesizing that identifying these shifts can clarify in-distribution boundaries. The method introduces DisCoPatch, an unsupervised Adversarial Variational Autoencoder framework that exploits distinct batch statistics formed by real and adversarial samples in discriminators with Batch Normalization. During inference, it processes batches of patches from single images to maintain consistent distributions. The model uses suboptimal VAE outputs as negative samples to train the discriminator, tightening the in-distribution boundary. Experiments show state-of-the-art performance, achieving 95.5% AUROC on ImageNet-1K(-C) for covariate shifts and 95.0% on Near-OOD benchmarks, with a compact 25MB model offering lower latency than prior methods.</div>
<div class="mono" style="margin-top:8px">本研究旨在检测分布外数据中细微的协变量偏移，假设这能明确分布内边界并提升整体OOD检测性能。方法提出了DisCoPatch，一种无监督的对抗变分自编码器框架，它利用批归一化判别器中真实样本与对抗样本形成的独特批统计特性；在推理时，使用单张图像的补丁以确保一致的批统计，并利用VAE的次优输出作为负样本来锐化判别器的决策边界。实验结果表明该模型取得了最先进的性能，在ImageNet-1K(-C)的协变量偏移检测上达到95.5%的AUROC，在Near-OOD基准上达到95.0%，同时模型尺寸仅为25MB且推理延迟低于现有方法。</div>
</details>
</div>
<div class="card">
<div class="title">Quantifying Fidelity: A Decisive Feature Approach to Comparing Synthetic and Real Imagery</div>
<div class="meta-line">Authors: Danial Safaei, Siddartha Khastgir, Mohsen Alirezaei, Jeroen Ploeg, Son Tong, Xingyu Zhao</div>
<div class="meta-line">First: 2025-12-18T12:39:13+00:00 · Latest: 2026-01-27T16:34:36+00:00</div>
<div class="links" style="margin-top:8px"><a href="https://arxiv.org/abs/2512.16468v2">Abs</a> · <a href="https://arxiv.org/pdf/2512.16468v2">PDF</a> · <a href="https://huggingface.co/huggingface">Code1</a> · <a href="https://huggingface.co/docs/hub/spaces">Code2</a></div>
<details class="detail"><summary>Abstract</summary>
<div class="mono">Virtual testing using synthetic data has become a cornerstone of autonomous vehicle (AV) safety assurance. Despite progress in improving visual realism through advanced simulators and generative AI, recent studies reveal that pixel-level fidelity alone does not ensure reliable transfer from simulation to the real world. What truly matters is whether the system-under-test (SUT) bases its decisions on consistent decision evidence in both real and simulated environments, not just whether images &quot;look real&quot; to humans. To this end this paper proposes a behavior-grounded fidelity measure by introducing Decisive Feature Fidelity (DFF), a new SUT-specific metric that extends the existing fidelity spectrum to capture mechanism parity, that is, agreement in the model-specific decisive evidence that drives the SUT&#x27;s decisions across domains. DFF leverages explainable-AI methods to identify and compare the decisive features driving the SUT&#x27;s outputs for matched real-synthetic pairs. We further propose estimators based on counterfactual explanations, along with a DFF-guided calibration scheme to enhance simulator fidelity. Experiments on 2126 matched KITTI-VirtualKITTI2 pairs demonstrate that DFF reveals discrepancies overlooked by conventional output-value fidelity. Furthermore, results show that DFF-guided calibration improves decisive-feature and input-level fidelity without sacrificing output value fidelity across diverse SUTs.</div></details>
<details class="detail"><summary>中文标题/摘要</summary>
<div class="mono"><b>标题：</b>量化保真度：基于决定性特征的合成与真实图像对比方法</div>
<div class="mono" style="margin-top:8px">基于合成数据的虚拟测试已成为自动驾驶车辆安全验证的基石。尽管通过先进模拟器和生成式人工智能提升了视觉真实感，但近期研究表明，仅凭像素级保真度并不能确保从仿真到现实世界的可靠迁移。关键在于被测系统是否在真实与仿真环境中基于一致的决策依据作出判断，而非图像是否对人类而言“看起来真实”。为此，本文提出一种基于行为的保真度度量方法——决定性特征保真度，这是一种针对特定被测系统的新指标，通过扩展现有保真度谱系来捕捉机制对等性，即驱动被测系统跨域决策的模型特异性决定性证据的一致性。该方法利用可解释人工智能技术识别并比较匹配的真实-合成图像对中驱动系统输出的决定性特征。我们进一步提出基于反事实解释的估计器，以及DFF引导的校准方案以提升模拟器保真度。在2126组匹配的KITTI-VirtualKITTI2数据对上的实验表明，DFF能揭示传统输出值保真度忽略的差异。此外，结果显示DFF引导的校准能在不牺牲各类被测系统输出值保真度的前提下，提升决定性特征与输入级保真度。</div>
</details>
<details class="detail"><summary>Summary / 总结</summary>
<div class="mono">The research is motivated by the need to ensure that synthetic data used for autonomous vehicle safety testing elicits decision-making behavior consistent with real-world data, moving beyond mere visual realism. The method introduces Decisive Feature Fidelity (DFF), a system-under-test-specific metric that uses explainable AI to identify and compare the decisive features driving model decisions for matched real-synthetic image pairs, and proposes a DFF-guided calibration scheme for simulators. Experimental results on 2126 matched KITTI-VirtualKITTI2 pairs demonstrate that DFF uncovers discrepancies missed by conventional fidelity measures and that DFF-guided calibration improves both decisive-feature and input-level fidelity without degrading output performance across various models.</div>
<div class="mono" style="margin-top:8px">本文的研究动机在于，仅凭视觉真实性无法确保合成数据能像真实数据一样引发自动驾驶系统相同的决策行为，因此需要一种更可靠的虚拟测试保真度度量。方法上，论文提出了名为决定性特征保真度（DFF）的新行为基础度量，它利用可解释AI技术来识别和比较被测系统在匹配的真实-合成图像对中做出决策所依据的模型特异性决定性特征，并引入了一种DFF引导的校准方案来提升模拟器保真度。在2126对匹配的KITTI-VirtualKITTI2图像对上的实验结果表明，DFF能有效揭示被传统保真度度量所忽视的关键决策证据差异，并且DFF引导的校准能在不损害输出值保真度的前提下，提升多种被测系统的决定性特征和输入级保真度。</div>
</details>
</div>
<div class="card">
<div class="title">Optimal Scaling Needs Optimal Norm</div>
<div class="meta-line">Authors: Oleg Filatov, Jiangtao Wang, Jan Ebert, Stefan Kesselheim</div>
<div class="meta-line">First: 2025-10-04T16:48:36+00:00 · Latest: 2026-01-27T16:32:23+00:00</div>
<div class="links" style="margin-top:8px"><a href="https://arxiv.org/abs/2510.03871v2">Abs</a> · <a href="https://arxiv.org/pdf/2510.03871v2">PDF</a> · <a href="https://huggingface.co/huggingface">Code1</a> · <a href="https://huggingface.co/docs/hub/spaces">Code2</a></div>
<details class="detail"><summary>Abstract</summary>
<div class="mono">Despite recent progress in optimal hyperparameter transfer under model and dataset scaling, no unifying explanatory principle has been established. For Adam and Scion optimizers, we discover that joint optimal scaling across model and dataset sizes is conditioned on a single invariant: the operator norm of the output layer. Across models with up to 1.3B parameters trained on up to 138B tokens, the optimal learning rate/batch size pair $(η^{\ast}, B^{\ast})$ consistently has the same operator norm value - a phenomenon we term norm transfer. This constant norm condition is necessary but not sufficient: while for each dataset size, multiple $(η, B)$ reach the optimal norm, only a unique $(η^{\ast}, B^{\ast})$ achieves the best loss. As a sufficient condition, we provide the first measurement of $(η^{\ast}, B^{\ast})$ scaling with dataset size for Scion, and find that the scaling rules are consistent with those of Adam. Tuning per-layer-group learning rates also improves model performance, with the output layer being the most sensitive and hidden layers benefiting from lower learning rates. We provide practical insights on norm-guided optimal scaling and release our Distributed Scion (Disco) implementation with logs from over two thousand runs to support research on LLM training dynamics at scale.</div></details>
<details class="detail"><summary>中文标题/摘要</summary>
<div class="mono"><b>标题：</b>最优缩放需最优范数</div>
<div class="mono" style="margin-top:8px">尽管近期在模型与数据集缩放下的最优超参数迁移方面取得进展，但尚未建立统一解释原理。针对Adam与Scion优化器，我们发现模型与数据集规模的联合最优缩放取决于单一不变量：输出层的算子范数。在参数高达13亿、训练令牌数达1380亿的模型中，最优学习率/批量大小对$(η^{\ast}, B^{\ast})$始终具有相同的算子范数值——这一现象称为范数迁移。该恒定范数条件是必要非充分的：虽然每个数据集规模下存在多个$(η, B)$达到最优范数，但仅唯一$(η^{\ast}, B^{\ast})$能实现最佳损失。作为充分条件，我们首次测量了Scion的$(η^{\ast}, B^{\ast})$随数据集规模的缩放规律，发现其与Adam的缩放规则一致。逐层组调整学习率也能提升模型性能，其中输出层最敏感，隐藏层则受益于较低学习率。我们提供了范数引导最优缩放的实践洞见，并开源分布式Scion（Disco）实现及两千余次运行日志，以支持大规模LLM训练动态研究。</div>
</details>
<details class="detail"><summary>Summary / 总结</summary>
<div class="mono">The research aims to establish a unifying principle for optimal hyperparameter transfer across model and dataset scaling, addressing the lack of explanatory frameworks in this area. The method identifies that joint optimal scaling for Adam and Scion optimizers is conditioned on a single invariant: the operator norm of the output layer, termed norm transfer, which is necessary but not sufficient for achieving the best loss. Experimental results across models up to 1.3B parameters trained on up to 138B tokens show that the optimal learning rate and batch size pair consistently maintains this constant norm, with scaling rules for Scion aligning with those of Adam, and tuning per-layer-group learning rates, particularly lowering them for hidden layers, further improves performance.</div>
<div class="mono" style="margin-top:8px">本研究旨在为模型和数据集规模扩展中的最优超参数迁移建立一个统一原则，以解决该领域缺乏解释性框架的问题。方法涉及分析输出层的算子范数作为关键不变量，发现在Adam和Scion优化器中，对于高达13亿参数的模型和高达1380亿标记的数据集，最优学习率和批量大小组合始终产生相同的算子范数值，这一现象被称为范数迁移。实验结果表明，虽然多个超参数组合能达到最优范数，但只有唯一组合实现最佳损失，其中Scion的缩放规则与Adam一致，且逐层组调优显示输出层最为敏感，隐藏层则受益于较低学习率。</div>
</details>
</div>
<div class="card">
<div class="title">GAVEL: Towards rule-based safety through activation monitoring</div>
<div class="meta-line">Authors: Shir Rozenfeld, Rahul Pankajakshan, Itay Zloczower, Eyal Lenga, Gilad Gressel, Yisroel Mirsky</div>
<div class="meta-line">Venue: ICLR 2026</div>
<div class="meta-line">First: 2026-01-27T16:31:39+00:00 · Latest: 2026-01-27T16:31:39+00:00</div>
<div class="meta-line">Comments: Accepted to ICLR 2026</div>
<div class="links" style="margin-top:8px"><a href="https://arxiv.org/abs/2601.19768v1">Abs</a> · <a href="https://arxiv.org/pdf/2601.19768v1">PDF</a> · <a href="https://huggingface.co/huggingface">Code1</a> · <a href="https://huggingface.co/docs/hub/spaces">Code2</a></div>
<details class="detail"><summary>Abstract</summary>
<div class="mono">Large language models (LLMs) are increasingly paired with activation-based monitoring to detect and prevent harmful behaviors that may not be apparent at the surface-text level. However, existing activation safety approaches, trained on broad misuse datasets, struggle with poor precision, limited flexibility, and lack of interpretability. This paper introduces a new paradigm: rule-based activation safety, inspired by rule-sharing practices in cybersecurity. We propose modeling activations as cognitive elements (CEs), fine-grained, interpretable factors such as &#x27;&#x27;making a threat&#x27;&#x27; and &#x27;&#x27;payment processing&#x27;&#x27;, that can be composed to capture nuanced, domain-specific behaviors with higher precision. Building on this representation, we present a practical framework that defines predicate rules over CEs and detects violations in real time. This enables practitioners to configure and update safeguards without retraining models or detectors, while supporting transparency and auditability. Our results show that compositional rule-based activation safety improves precision, supports domain customization, and lays the groundwork for scalable, interpretable, and auditable AI governance. We will release GAVEL as an open-source framework and provide an accompanying automated rule creation tool.</div></details>
<details class="detail"><summary>中文标题/摘要</summary>
<div class="mono"><b>标题：</b>GAVEL：通过激活监控实现基于规则的安全性</div>
<div class="mono" style="margin-top:8px">大型语言模型（LLMs）日益与基于激活的监控结合，以检测和预防表层文本可能未显现的有害行为。然而，现有基于广泛滥用数据集训练的激活安全方法存在精度低、灵活性有限及缺乏可解释性的问题。本文提出一种新范式：基于规则的激活安全，其灵感源自网络安全的规则共享实践。我们将激活建模为认知元素（CEs）——细粒度、可解释的因子（如“发出威胁”和“支付处理”），这些元素可组合以更高精度捕捉细微的领域特定行为。基于此表征，我们提出一个实用框架，定义CEs的谓词规则并实时检测违规行为。这使得实践者无需重新训练模型或检测器即可配置和更新安全措施，同时支持透明度和可审计性。实验结果表明，基于组合规则的激活安全方法提升了精度，支持领域定制，并为可扩展、可解释、可审计的AI治理奠定了基础。我们将开源GAVEL框架，并提供配套的自动规则生成工具。</div>
</details>
<details class="detail"><summary>Summary / 总结</summary>
<div class="mono">To address the poor precision, limited flexibility, and lack of interpretability in existing activation-based safety monitors for large language models, this paper introduces a rule-based paradigm inspired by cybersecurity practices. The method models activations as fine-grained, interpretable cognitive elements (e.g., &#x27;making a threat&#x27;) and defines predicate rules over them to detect nuanced, domain-specific harmful behaviors in real time, allowing safeguards to be configured without retraining. Experimental results demonstrate that this compositional, rule-based approach improves precision, supports domain customization, and provides a foundation for scalable and auditable AI governance.</div>
<div class="mono" style="margin-top:8px">针对现有基于激活的大型语言模型安全监控方法精度低、灵活性差且缺乏可解释性的问题，本文提出了一种基于规则的激活安全新范式。该方法将激活建模为可解释的认知要素，并通过组合这些要素来定义谓词规则，以实时检测细微、领域特定的有害行为，从而无需重新训练模型即可配置安全措施。实验结果表明，这种基于组合规则的方法提高了检测精度，支持领域定制，并为可扩展、可审计的AI治理奠定了基础。</div>
</details>
</div>
<div class="card">
<div class="title">Activation Function Design Sustains Plasticity in Continual Learning</div>
<div class="meta-line">Authors: Lute Lillo, Nick Cheney</div>
<div class="meta-line">First: 2025-09-26T16:41:47+00:00 · Latest: 2026-01-27T16:19:30+00:00</div>
<div class="links" style="margin-top:8px"><a href="https://arxiv.org/abs/2509.22562v2">Abs</a> · <a href="https://arxiv.org/pdf/2509.22562v2">PDF</a> · <a href="https://huggingface.co/huggingface">Code1</a> · <a href="https://huggingface.co/docs/hub/spaces">Code2</a></div>
<details class="detail"><summary>Abstract</summary>
<div class="mono">In independent, identically distributed (i.i.d.) training regimes, activation functions have been benchmarked extensively, and their differences often shrink once model size and optimization are tuned. In continual learning, however, the picture is different: beyond catastrophic forgetting, models can progressively lose the ability to adapt (referred to as loss of plasticity) and the role of the non-linearity in this failure mode remains underexplored. We show that activation choice is a primary, architecture-agnostic lever for mitigating plasticity loss. Building on a property-level analysis of negative-branch shape and saturation behavior, we introduce two drop-in nonlinearities (Smooth-Leaky and Randomized Smooth-Leaky) and evaluate them in two complementary settings: (i) supervised class-incremental benchmarks and (ii) reinforcement learning with non-stationary MuJoCo environments designed to induce controlled distribution and dynamics shifts. We also provide a simple stress protocol and diagnostics that link the shape of the activation to the adaptation under change. The takeaway is straightforward: thoughtful activation design offers a lightweight, domain-general way to sustain plasticity in continual learning without extra capacity or task-specific tuning.</div></details>
<details class="detail"><summary>中文标题/摘要</summary>
<div class="mono"><b>标题：</b>激活函数设计维持持续学习中的可塑性</div>
<div class="mono" style="margin-top:8px">在独立同分布训练模式下，激活函数已得到广泛基准测试，一旦调整模型规模和优化策略，其差异往往缩小。然而在持续学习中情况不同：除了灾难性遗忘，模型可能逐渐丧失适应能力（称为可塑性丧失），非线性在此失效模式中的作用仍未充分探索。我们证明激活函数选择是缓解可塑性丧失的主要且与架构无关的调控手段。基于对负分支形态和饱和行为的特性分析，我们提出两种即插即用非线性函数（平滑泄漏型与随机平滑泄漏型），并在两个互补场景中评估：（1）监督式类增量基准测试；（2）采用非平稳MuJoCo环境的强化学习，该环境设计用于引发受控分布与动态偏移。我们还提供简易压力测试协议和诊断方法，将激活函数形态与变化适应能力相关联。核心结论明确：经过深思熟虑的激活函数设计，能以轻量级、跨领域的方式维持持续学习中的可塑性，无需额外容量或任务特定调优。</div>
</details>
<details class="detail"><summary>Summary / 总结</summary>
<div class="mono">In continual learning, models often suffer from loss of plasticity beyond catastrophic forgetting, yet the role of activation functions in this failure mode remains underexplored. This work demonstrates that activation choice is a primary, architecture-agnostic lever for mitigating plasticity loss, and introduces two drop-in nonlinearities, Smooth-Leaky and Randomized Smooth-Leaky, based on an analysis of negative-branch shape and saturation behavior. Evaluated in supervised class-incremental benchmarks and reinforcement learning with non-stationary MuJoCo environments, these activations effectively sustain adaptation under distribution and dynamics shifts, as shown through a simple stress protocol and diagnostics linking activation shape to adaptation performance.</div>
<div class="mono" style="margin-top:8px">在持续学习中，模型除了灾难性遗忘外，还会逐渐丧失适应能力（即塑性丧失），而激活函数在此问题中的作用尚未得到充分探索。本研究通过分析负分支形状和饱和行为，提出激活函数选择是缓解塑性丧失的关键架构无关因素，并引入了两种即插即用的非线性函数：平滑泄漏和随机平滑泄漏。在监督类增量基准测试以及具有非平稳MuJoCo环境的强化学习实验中，这些激活函数在分布和动态变化下有效维持了模型的适应能力，提供了一种轻量级、跨领域的解决方案，无需额外容量或任务特定调整。</div>
</details>
</div>
<div class="card">
<div class="title">BASIL: Bayesian Assessment of Sycophancy in LLMs</div>
<div class="meta-line">Authors: Katherine Atwell, Pedram Heydari, Anthony Sicilia, Malihe Alikhani</div>
<div class="meta-line">First: 2025-08-23T00:11:00+00:00 · Latest: 2026-01-27T16:15:18+00:00</div>
<div class="links" style="margin-top:8px"><a href="https://arxiv.org/abs/2508.16846v4">Abs</a> · <a href="https://arxiv.org/pdf/2508.16846v4">PDF</a> · <a href="https://huggingface.co/huggingface">Code1</a> · <a href="https://huggingface.co/docs/hub/spaces">Code2</a></div>
<details class="detail"><summary>Abstract</summary>
<div class="mono">Sycophancy (overly agreeable or flattering behavior) poses a fundamental challenge for human-AI collaboration, particularly in high-stakes decision-making domains such as health, law, and education. A central difficulty in studying sycophancy in large language models (LLMs) is disentangling sycophantic belief shifts from rational changes in behavior driven by new evidence or user-provided information. Existing approaches either measure descriptive behavior changes or apply normative evaluations that rely on objective ground truth, limiting their applicability to subjective or uncertain tasks. We introduce a Bayesian probabilistic framework, grounded in behavioral economics and rational decision theory, that explicitly separates sycophancy from rational belief updating. Within this framework, we achieve three objectives: (i) a descriptive metric that measures sycophancy while controlling for rational responses to evidence; (ii) a normative metric that quantifies how sycophancy leads models astray from Bayesian-consistent belief updating; and (iii) the ability to apply both metrics in settings without ground-truth labels. Applying our framework across multiple LLMs and three uncertainty-driven tasks, we find robust evidence of sycophantic belief shifts and show that their impact on rationality depends on whether models systematically over- or under-update their beliefs. Finally, we demonstrate that a post-hoc calibration method and two fine-tuning strategies (SFT and DPO) substantially reduce Bayesian inconsistency, with particularly strong improvements under explicit sycophancy prompting.</div></details>
<details class="detail"><summary>中文标题/摘要</summary>
<div class="mono"><b>标题：</b>BASIL：大语言模型中谄媚行为的贝叶斯评估</div>
<div class="mono" style="margin-top:8px">谄媚行为（过度迎合或奉承）对人类与人工智能协作构成根本性挑战，尤其在健康、法律、教育等高风险决策领域。研究大语言模型中的谄媚行为时，核心难点在于区分谄媚性信念转变与由新证据或用户信息驱动的理性行为变化。现有方法要么测量描述性行为变化，要么应用依赖客观事实的规范性评估，限制了其在主观或不确定性任务中的适用性。我们提出一个基于行为经济学和理性决策理论的贝叶斯概率框架，明确将谄媚行为与理性信念更新分离。该框架实现三个目标：（1）在控制证据理性响应的前提下测量谄媚行为的描述性指标；（2）量化谄媚行为导致模型偏离贝叶斯一致性信念更新的规范性指标；（3）在无真实标签场景中应用双指标的能力。通过在多个大语言模型和三项不确定性驱动任务中应用本框架，我们发现了谄媚性信念转变的强有力证据，并证明其对理性程度的影响取决于模型是否系统性过度或不足更新信念。最后，我们验证了事后校准方法与两种微调策略（监督微调与直接偏好优化）能显著降低贝叶斯不一致性，在显式谄媚提示下的改进尤为显著。</div>
</details>
<details class="detail"><summary>Summary / 总结</summary>
<div class="mono">The research addresses the challenge of distinguishing sycophantic behavior from rational belief updating in large language models, which is crucial for reliable human-AI collaboration in high-stakes domains. The method introduces a Bayesian probabilistic framework that separates sycophancy from rational responses to evidence, enabling descriptive and normative assessments even without ground-truth labels. Experiments across multiple LLMs and tasks reveal robust sycophantic belief shifts, show their variable impact on model rationality, and demonstrate that post-hoc calibration and fine-tuning strategies can significantly reduce Bayesian inconsistency, especially under explicit sycophancy prompts.</div>
<div class="mono" style="margin-top:8px">本研究旨在解决大型语言模型中区分阿谀奉承行为与理性信念更新的难题，这对高风险领域的人机协作至关重要。方法上引入了一个贝叶斯概率框架，将阿谀奉承与对证据的理性响应分离开来，即使在缺乏客观事实的任务中也能实现描述性和规范性度量。在多个大模型和不确定性驱动任务上的实验结果表明，存在明显的阿谀奉承性信念偏移，并且事后校准以及监督微调和直接偏好优化等微调策略能显著减少贝叶斯不一致性，尤其在明确的阿谀奉承提示下改善效果尤为显著。</div>
</details>
</div>
<div class="card">
<div class="title">Agentic Design Patterns: A System-Theoretic Framework</div>
<div class="meta-line">Authors: Minh-Dung Dao, Quy Minh Le, Hoang Thanh Lam, Duc-Trong Le, Quoc-Viet Pham, Barry O&#x27;Sullivan, Hoang D. Nguyen</div>
<div class="meta-line">First: 2026-01-27T16:14:08+00:00 · Latest: 2026-01-27T16:14:08+00:00</div>
<div class="links" style="margin-top:8px"><a href="https://arxiv.org/abs/2601.19752v1">Abs</a> · <a href="https://arxiv.org/pdf/2601.19752v1">PDF</a> · <a href="https://huggingface.co/huggingface">Code1</a> · <a href="https://huggingface.co/docs/hub/spaces">Code2</a></div>
<details class="detail"><summary>Abstract</summary>
<div class="mono">With the development of foundation model (FM), agentic AI systems are getting more attention, yet their inherent issues like hallucination and poor reasoning, coupled with the frequent ad-hoc nature of system design, lead to unreliable and brittle applications. Existing efforts to characterise agentic design patterns often lack a rigorous systems-theoretic foundation, resulting in high-level or convenience-based taxonomies that are difficult to implement. This paper addresses this gap by introducing a principled methodology for engineering robust AI agents. We propose two primary contributions: first, a novel system-theoretic framework that deconstructs an agentic AI system into five core, interacting functional subsystems: Reasoning &amp; World Model, Perception &amp; Grounding, Action Execution, Learning &amp; Adaptation, and Inter-Agent Communication. Second, derived from this architecture and directly mapped to a comprehensive taxonomy of agentic challenges, we present a collection of 12 agentic design patterns. These patterns - categorised as Foundational, Cognitive &amp; Decisional, Execution &amp; Interaction, and Adaptive &amp; Learning - offer reusable, structural solutions to recurring problems in agent design. The utility of the framework is demonstrated by a case study on the ReAct framework, showing how the proposed patterns can rectify systemic architectural deficiencies. This work provides a foundational language and a structured methodology to standardise agentic design communication among researchers and engineers, leading to more modular, understandable, and reliable autonomous systems.</div></details>
<details class="detail"><summary>中文标题/摘要</summary>
<div class="mono"><b>标题：</b>智能体设计模式：一种系统理论框架</div>
<div class="mono" style="margin-top:8px">随着基础模型的发展，智能体AI系统日益受到关注，但其固有的幻觉与推理能力不足等问题，加之系统设计常呈临时性，导致应用不可靠且脆弱。现有刻画智能体设计模式的尝试多缺乏严谨的系统理论基础，形成难以实施的高层或便利性分类。本文通过引入一种工程化稳健AI智能体的原则性方法填补这一空白。我们提出两项主要贡献：首先，一种新颖的系统理论框架，将智能体AI系统解构为五个核心交互功能子系统：推理与世界模型、感知与接地、行动执行、学习与适应、以及智能体间通信。其次，基于此架构并直接映射到智能体挑战的全面分类，我们提出一套包含12种智能体设计模式的集合。这些模式——分为基础类、认知与决策类、执行与交互类、适应与学习类——为智能体设计中反复出现的问题提供了可复用的结构化解决方案。通过对ReAct框架的案例研究，展示了该框架的实用性，表明所提模式如何修正系统性架构缺陷。本工作为研究人员和工程师提供了标准化智能体设计交流的基础语言与结构化方法，有助于构建更模块化、可理解且可靠的自主系统。</div>
</details>
<details class="detail"><summary>Summary / 总结</summary>
<div class="mono">The research is motivated by the unreliability and brittleness of agentic AI systems, which stem from issues like hallucination and poor reasoning in foundation models, as well as the ad-hoc nature of current system designs that lack a rigorous theoretical foundation. To address this, the paper introduces a system-theoretic framework that deconstructs an agentic system into five core functional subsystems—Reasoning &amp; World Model, Perception &amp; Grounding, Action Execution, Learning &amp; Adaptation, and Inter-Agent Communication—and derives 12 agentic design patterns from this architecture, categorized into Foundational, Cognitive &amp; Decisional, Execution &amp; Interaction, and Adaptive &amp; Learning types. In a case study on the ReAct framework, the proposed patterns effectively rectified systemic architectural deficiencies, demonstrating their utility in creating more modular, understandable, and reliable autonomous systems.</div>
<div class="mono" style="margin-top:8px">本研究旨在解决智能体AI系统因基础模型的幻觉、推理能力差以及当前设计方法缺乏严谨系统理论基础而导致的临时性、不可靠和脆弱问题。为此，论文提出了一种原则性方法，其核心是一个新颖的系统理论框架，该框架将智能体AI系统解构为五个核心且相互作用的功能子系统：推理与世界模型、感知与接地、行动执行、学习与适应以及智能体间通信。基于此架构，作者推导出12种智能体设计模式，分为基础型、认知与决策型、执行与交互型以及适应与学习型，为常见设计挑战提供了可重用的结构性解决方案。通过对ReAct框架的案例研究，证明了该框架和模式的实用性，展示了它们如何纠正系统性架构缺陷，从而促进构建更模块化、可理解和可靠的自主系统。</div>
</details>
</div>
<div class="card">
<div class="title">Veri-Sure: A Contract-Aware Multi-Agent Framework with Temporal Tracing and Formal Verification for Correct RTL Code Generation</div>
<div class="meta-line">Authors: Jiale Liu, Taiyu Zhou, Tianqi Jiang</div>
<div class="meta-line">First: 2026-01-27T16:10:23+00:00 · Latest: 2026-01-27T16:10:23+00:00</div>
<div class="links" style="margin-top:8px"><a href="https://arxiv.org/abs/2601.19747v1">Abs</a> · <a href="https://arxiv.org/pdf/2601.19747v1">PDF</a> · <a href="https://huggingface.co/huggingface">Code1</a> · <a href="https://huggingface.co/docs/hub/spaces">Code2</a></div>
<details class="detail"><summary>Abstract</summary>
<div class="mono">In the rapidly evolving field of Electronic Design Automation (EDA), the deployment of Large Language Models (LLMs) for Register-Transfer Level (RTL) design has emerged as a promising direction. However, silicon-grade correctness remains bottlenecked by: (i) limited test coverage and reliability of simulation-centric evaluation, (ii) regressions and repair hallucinations introduced by iterative debugging, and (iii) semantic drift as intent is reinterpreted across agent handoffs. In this work, we propose Veri-Sure, a multi-agent framework that establishes a design contract to align agents&#x27; intent and uses a patching mechanism guided by static dependency slicing to perform precise, localized repairs. By integrating a multi-branch verification pipeline that combines trace-driven temporal analysis with formal verification consisting of assertion-based checking and boolean equivalence proofs, Veri-Sure enables functional correctness beyond pure simulations. We also introduce VerilogEval-v2-EXT, extending the original benchmark with 53 more industrial-grade design tasks and stratified difficulty levels, and show that Veri-Sure achieves state-of-the-art verified-correct RTL code generation performance, surpassing standalone LLMs and prior agentic systems.</div></details>
<details class="detail"><summary>中文标题/摘要</summary>
<div class="mono"><b>标题：</b>Veri-Sure：一种具备时序追踪与形式化验证的契约感知多智能体框架，用于生成正确的RTL代码</div>
<div class="mono" style="margin-top:8px">在快速发展的电子设计自动化（EDA）领域，利用大语言模型（LLM）进行寄存器传输级（RTL）设计已成为一个前景广阔的方向。然而，芯片级正确性仍受限于：（i）以仿真为中心的评估方法测试覆盖有限且可靠性不足；（ii）迭代调试过程中引入的回归与修复幻觉；（iii）智能体任务交接时因意图重解释导致的语义漂移。本研究提出Veri-Sure多智能体框架，通过建立设计契约对齐智能体意图，并采用基于静态依赖切片的修补机制实现精准局部修复。该框架集成结合了时序追踪分析与形式化验证（含基于断言的检查与布尔等价证明）的多分支验证流程，使功能正确性超越纯仿真验证。我们还推出了VerilogEval-v2-EXT基准测试集，在原有基础上新增53项工业级设计任务并划分难度层级。实验表明，Veri-Sure在已验证正确的RTL代码生成方面达到最先进性能，超越独立大语言模型及现有智能体系统。</div>
</details>
<details class="detail"><summary>Summary / 总结</summary>
<div class="mono">The research addresses the challenge of achieving silicon-grade correctness in RTL code generation using LLMs, which is hindered by limited simulation coverage, regressions from iterative debugging, and semantic drift in multi-agent workflows. The proposed Veri-Sure framework employs a contract-aware multi-agent system that aligns agent intent, uses static dependency slicing for precise patching, and integrates a multi-branch verification pipeline combining trace-driven temporal analysis with formal methods like assertion checking and equivalence proofs. Experimental results on the extended VerilogEval-v2-EXT benchmark, featuring 53 additional industrial tasks, demonstrate that Veri-Sure achieves state-of-the-art performance in generating verified-correct RTL code, outperforming standalone LLMs and prior agentic systems.</div>
<div class="mono" style="margin-top:8px">本研究的动机是解决使用大语言模型生成正确的寄存器传输级代码时的局限性，包括测试覆盖不足、调试引发的回归问题以及多智能体协作中的语义漂移。所提出的方法Veri-Sure是一个多智能体框架，它通过建立设计契约来对齐智能体意图，并采用基于静态依赖切片的修补机制进行精确修复，同时集成了结合追踪驱动时序分析和形式验证的多分支验证流程。关键实验结果基于扩展的基准测试集VerilogEval-v2-EXT（新增53个工业级任务）表明，Veri-Sure在生成经验证正确的RTL代码方面达到了最先进的性能，超越了独立的大语言模型和先前的智能体系统。</div>
</details>
</div>
<div class="card">
<div class="title">Language Agents for Hypothesis-driven Clinical Decision Making with Reinforcement Learning</div>
<div class="meta-line">Authors: David Bani-Harouni, Chantal Pellegrini, Ege Özsoy, Matthias Keicher, Nassir Navab</div>
<div class="meta-line">First: 2025-06-16T13:32:01+00:00 · Latest: 2026-01-27T16:05:43+00:00</div>
<div class="links" style="margin-top:8px"><a href="https://arxiv.org/abs/2506.13474v2">Abs</a> · <a href="https://arxiv.org/pdf/2506.13474v2">PDF</a> · <a href="https://huggingface.co/huggingface">Code1</a> · <a href="https://huggingface.co/docs/hub/spaces">Code2</a></div>
<details class="detail"><summary>Abstract</summary>
<div class="mono">Clinical decision-making is a dynamic, interactive, and cyclic process where doctors have to repeatedly decide on which clinical action to perform and consider newly uncovered information for diagnosis and treatment. Large Language Models (LLMs) have the potential to support clinicians in this process, however, most applications of LLMs in clinical decision support suffer from one of two limitations: Either they assume the unrealistic scenario of immediate availability of all patient information and do not model the interactive and iterative investigation process, or they restrict themselves to the limited &quot;out-of-the-box&quot; capabilities of large pre-trained models without performing task-specific training. In contrast to this, we propose to model clinical decision-making for diagnosis with a hypothesis-driven uncertainty-aware language agent, LA-CDM, that converges towards a diagnosis via repeatedly requesting and interpreting relevant tests. Using a hybrid training paradigm combining supervised and reinforcement learning, we train LA-CDM with three objectives targeting critical aspects of clinical decision-making: accurate hypothesis generation, hypothesis uncertainty estimation, and efficient decision-making. We evaluate our methodology on MIMIC-CDM, a real-world dataset covering four abdominal diseases containing various clinical tests and show the benefit of explicitly training clinical decision-making for increasing diagnostic performance and efficiency.</div></details>
<details class="detail"><summary>中文标题/摘要</summary>
<div class="mono"><b>标题：</b>基于强化学习的假设驱动临床决策语言智能体</div>
<div class="mono" style="margin-top:8px">临床决策是一个动态、交互且循环的过程，医生需反复决定执行何种临床操作，并依据新发现的信息进行诊断与治疗。大语言模型（LLMs）具备辅助临床医生完成这一过程的潜力，但当前LLMs在临床决策支持中的应用大多存在以下局限：要么假设所有患者信息可即时获取（这一场景不切实际），未对交互式迭代调查过程进行建模；要么仅依赖大型预训练模型的有限“开箱即用”能力，未进行任务特异性训练。为此，我们提出一种假设驱动且具备不确定性感知的语言智能体LA-CDM，通过循环请求并解读相关检测，逐步收敛至最终诊断，从而构建临床诊断决策模型。采用监督学习与强化学习结合的混合训练范式，我们围绕临床决策的三个关键目标训练LA-CDM：准确生成假设、评估假设不确定性、实现高效决策。我们在真实世界数据集MIMIC-CDM（涵盖四种腹部疾病及多样临床检测）上评估该方法，结果表明针对临床决策的显式训练能有效提升诊断性能与效率。</div>
</details>
<details class="detail"><summary>Summary / 总结</summary>
<div class="mono">Clinical decision-making is an iterative process where clinicians sequentially gather and interpret information, but existing LLM-based support systems either assume full information upfront or rely on generic pre-trained models without task-specific optimization. To address this, the authors propose LA-CDM, a hypothesis-driven, uncertainty-aware language agent that progressively requests and analyzes clinical tests to reach a diagnosis. Using a hybrid training approach combining supervised and reinforcement learning with objectives for hypothesis generation, uncertainty estimation, and decision efficiency, the method is evaluated on the MIMIC-CDM dataset for abdominal diseases, demonstrating improved diagnostic accuracy and efficiency compared to baseline approaches.</div>
<div class="mono" style="margin-top:8px">临床决策是一个需要逐步收集和解读信息的迭代过程，但现有基于大语言模型的辅助系统要么假设所有信息立即可得，要么依赖未经任务特定训练的通用预训练模型。为此，研究者提出了LA-CDM，这是一个基于假设驱动且具有不确定性感知的语言智能体，通过逐步请求和解读临床检查来收敛至诊断，其训练结合了监督学习和强化学习，目标包括准确生成假设、估计不确定性以及提升决策效率。在涵盖四种腹部疾病的真实世界数据集MIMIC-CDM上的评估表明，LA-CDM相比基线方法在诊断性能和效率上均有提升。</div>
</details>
</div></div>
    <details style="margin-top:16px" class="detail"><summary>History</summary>
      <div class="history-list"><a href="archive/20260128_0625.html">20260128_0625</a>
<a href="archive/20260128_0439.html">20260128_0439</a>
<a href="archive/20260128_0334.html">20260128_0334</a>
<a href="archive/20260127_0627.html">20260127_0627</a>
<a href="archive/20260127_0529.html">20260127_0529</a>
<a href="archive/20260127_0439.html">20260127_0439</a>
<a href="archive/20260127_0333.html">20260127_0333</a>
<a href="archive/20260126_0626.html">20260126_0626</a>
<a href="archive/20260126_0526.html">20260126_0526</a>
<a href="archive/20260126_0327.html">20260126_0327</a>
<a href="archive/20260125_0624.html">20260125_0624</a>
<a href="archive/20260125_0524.html">20260125_0524</a>
<a href="archive/20260125_0440.html">20260125_0440</a>
<a href="archive/20260125_0325.html">20260125_0325</a>
<a href="archive/20260124_0627.html">20260124_0627</a>
<a href="archive/20260124_0526.html">20260124_0526</a>
<a href="archive/20260124_0444.html">20260124_0444</a>
<a href="archive/20260124_0334.html">20260124_0334</a>
<a href="archive/20260123_0627.html">20260123_0627</a>
<a href="archive/20260123_0529.html">20260123_0529</a>
<a href="archive/20260123_0446.html">20260123_0446</a>
<a href="archive/20260123_0334.html">20260123_0334</a>
<a href="archive/20260122_2019.html">20260122_2019</a>
<a href="archive/20260122_2013.html">20260122_2013</a>
<a href="archive/20260122_2008.html">20260122_2008</a>
<a href="archive/20260122_2001.html">20260122_2001</a>
<a href="archive/20260122_0629.html">20260122_0629</a>
<a href="archive/20260122_0535.html">20260122_0535</a>
<a href="archive/20260122_0449.html">20260122_0449</a>
<a href="archive/20260122_0336.html">20260122_0336</a>
<a href="archive/20260121_0625.html">20260121_0625</a>
<a href="archive/20260121_0529.html">20260121_0529</a>
<a href="archive/20260121_0450.html">20260121_0450</a>
<a href="archive/20260121_0423.html">20260121_0423</a>
<a href="archive/20260120_0626.html">20260120_0626</a>
<a href="archive/20260120_0528.html">20260120_0528</a>
<a href="archive/20260120_0443.html">20260120_0443</a>
<a href="archive/20260120_0330.html">20260120_0330</a>
<a href="archive/20260119_0624.html">20260119_0624</a>
<a href="archive/20260119_0525.html">20260119_0525</a>
<a href="archive/20260119_0440.html">20260119_0440</a>
<a href="archive/20260119_0325.html">20260119_0325</a>
<a href="archive/20260118_2225.html">20260118_2225</a>
<a href="archive/20260118_2159.html">20260118_2159</a>
<a href="archive/20260118_2135.html">20260118_2135</a>
<a href="archive/20260118_2040.html">20260118_2040</a>
<a href="archive/20260118_1953.html">20260118_1953</a>
<a href="archive/20260118_1907.html">20260118_1907</a>
<a href="archive/20260118_0327.html">20260118_0327</a>
<a href="archive/20260117_0332.html">20260117_0332</a>
<a href="archive/20260116_0339.html">20260116_0339</a>
<a href="archive/20260115_0334.html">20260115_0334</a>
<a href="archive/20260114_0333.html">20260114_0333</a>
<a href="archive/20260113_0334.html">20260113_0334</a>
<a href="archive/20260112_0331.html">20260112_0331</a>
<a href="archive/20260111_0329.html">20260111_0329</a>
<a href="archive/20260110_0333.html">20260110_0333</a>
<a href="archive/20260109_0334.html">20260109_0334</a>
<a href="archive/20260108_0335.html">20260108_0335</a>
<a href="archive/20260107_0330.html">20260107_0330</a>
<a href="archive/20260106_0336.html">20260106_0336</a>
<a href="archive/20260105_0328.html">20260105_0328</a>
<a href="archive/20260104_0328.html">20260104_0328</a>
<a href="archive/20260103_0325.html">20260103_0325</a>
<a href="archive/20260102_0339.html">20260102_0339</a>
<a href="archive/20260101_0329.html">20260101_0329</a>
<a href="archive/20251231_0333.html">20251231_0333</a>
<a href="archive/20251230_0332.html">20251230_0332</a>
<a href="archive/20251229_0329.html">20251229_0329</a>
<a href="archive/20251228_0332.html">20251228_0332</a>
<a href="archive/20251227_0329.html">20251227_0329</a>
<a href="archive/20251226_0330.html">20251226_0330</a>
<a href="archive/20251225_0329.html">20251225_0329</a>
<a href="archive/20251224_0331.html">20251224_0331</a>
<a href="archive/20251223_0332.html">20251223_0332</a>
<a href="archive/20251222_0328.html">20251222_0328</a>
<a href="archive/20251221_0329.html">20251221_0329</a>
<a href="archive/20251220_0330.html">20251220_0330</a>
<a href="archive/20251219_0330.html">20251219_0330</a>
<a href="archive/20251218_0345.html">20251218_0345</a>
<a href="archive/20251217_0332.html">20251217_0332</a>
<a href="archive/20251216_0333.html">20251216_0333</a>
<a href="archive/20251215_0333.html">20251215_0333</a>
<a href="archive/20251214_0327.html">20251214_0327</a>
<a href="archive/20251212_0333.html">20251212_0333</a>
<a href="archive/20251211_0331.html">20251211_0331</a>
<a href="archive/20251210_0332.html">20251210_0332</a>
<a href="archive/20251209_0331.html">20251209_0331</a>
<a href="archive/20251208_0328.html">20251208_0328</a>
<a href="archive/20251207_0327.html">20251207_0327</a>
<a href="archive/20251206_0330.html">20251206_0330</a>
<a href="archive/20251205_0331.html">20251205_0331</a>
<a href="archive/20251204_0331.html">20251204_0331</a>
<a href="archive/20251203_0333.html">20251203_0333</a>
<a href="archive/20251202_0335.html">20251202_0335</a>
<a href="archive/20251201_0328.html">20251201_0328</a>
<a href="archive/20251130_0327.html">20251130_0327</a>
<a href="archive/20251129_0328.html">20251129_0328</a>
<a href="archive/20251128_0327.html">20251128_0327</a>
<a href="archive/20251127_0327.html">20251127_0327</a></div>
    </details>
    <div class="footer">Generated by arxiv-tracker</div>
  </div>
</body></html>
