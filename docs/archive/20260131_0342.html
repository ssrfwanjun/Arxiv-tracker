<!doctype html>
<html><head><meta charset="utf-8"><meta name="viewport" content="width=device-width,initial-scale=1">
<title>arXiv 论文速递</title><style>
:root {
  --bg:#f8fafc; --card:#ffffff; --text:#0f172a; --muted:#667085; --border:#e5e7eb; --acc:#2563eb;
}
:root[data-theme="dark"] {
  --bg:#0b0f17; --card:#111827; --text:#e5e7eb; --muted:#9ca3af; --border:#1f2937; --acc:#2563eb;
}
*{box-sizing:border-box} body{margin:0;background:var(--bg);color:var(--text);
  font-family:ui-sans-serif,system-ui,-apple-system,Segoe UI,Roboto,Helvetica,Arial;line-height:1.6;}
.container{max-width:900px;margin:0 auto;padding:18px;}
.header{display:flex;gap:10px;justify-content:space-between;align-items:center;margin:8px 0 16px;flex-wrap:wrap}
h1{font-size:22px;margin:0}
.badge{font-size:12px;color:#111827;background:var(--acc);padding:2px 8px;border-radius:999px}
.card{background:var(--card);border:1px solid var(--border);border-radius:16px;padding:16px 18px;margin:14px 0;box-shadow:0 1px 2px rgba(0,0,0,.04)}
.title{font-weight:700;margin:0 0 6px 0;font-size:18px}
.meta-line{color:var(--muted);font-size:13px;margin:2px 0}
.links a{color:var(--acc);text-decoration:none;margin-right:12px}
.detail{margin-top:10px;background:rgba(2,6,23,.03);border:1px solid var(--border);border-radius:10px;padding:8px 10px}
summary{cursor:pointer;color:var(--acc)}
.mono{white-space:pre-wrap;background:rgba(2,6,23,.03);border:1px solid var(--border);padding:10px;border-radius:10px}
.row{display:grid;grid-template-columns:1fr;gap:12px}
@media (min-width: 860px) {
  .row-2{grid-template-columns:1fr 1fr}
}
.footer{color:var(--muted);font-size:13px;margin:20px 0 10px}
.hr{height:1px;background:var(--border);margin:14px 0}
.history-list a{display:block;color:var(--acc);text-decoration:none;margin:4px 0}
.controls{display:flex;gap:8px;align-items:center}
.btn{border:1px solid var(--border);background:var(--card);padding:6px 10px;border-radius:10px;cursor:pointer;color:var(--text)}
.btn:hover{border-color:var(--acc)}
</style>
<script>
(function() {
  const root = document.documentElement;
  function apply(t) {
    if (t==='dark') root.setAttribute('data-theme','dark');
    else if (t==='light') root.removeAttribute('data-theme');
    else {
      if (window.matchMedia && window.matchMedia('(prefers-color-scheme: dark)').matches)
        root.setAttribute('data-theme','dark');
      else root.removeAttribute('data-theme');
    }
  }
  let t = localStorage.getItem('theme') || 'light';
  if (!['light','dark','auto'].includes(t)) t='light';
  apply(t);
  window.__toggleTheme = function() {
    let cur = localStorage.getItem('theme') || 'light';
    if (cur==='light') cur='dark';
    else if (cur==='dark') cur='auto';
    else cur='light';
    localStorage.setItem('theme', cur);
    apply(cur);
    const el=document.getElementById('theme-label');
    if(el) el.textContent = cur.toUpperCase();
  }
  window.__expandAll = function(open) {
    document.querySelectorAll('details').forEach(d => d.open = !!open);
  }
})();
</script>
</head>
<body>
  <div class="container">
    <div class="header">
      <h1>arXiv 论文速递</h1>
      <div style="display:flex;gap:10px;align-items:center">
        
<div class="controls">
  <button class="btn" onclick="__toggleTheme()">Theme: <span id="theme-label" style="margin-left:6px">AUTO</span></button>
  <button class="btn" onclick="__expandAll(true)">Expand All</button>
  <button class="btn" onclick="__expandAll(false)">Collapse All</button>
</div>

        <span class="badge">2026-01-31 03:42</span>
      </div>
    </div>
    <div class="hr"></div>
    <div>Snapshot: 20260131_0342</div>
    <div class="row"><div class="card">
<div class="title">RedSage: A Cybersecurity Generalist LLM</div>
<div class="meta-line">Authors: Naufal Suryanto, Muzammal Naseer, Pengfei Li, Syed Talal Wasim, Jinhui Yi, Juergen Gall, Paolo Ceravolo, Ernesto Damiani</div>
<div class="meta-line">Venue: ICLR 2026</div>
<div class="meta-line">First: 2026-01-29T18:59:57+00:00 · Latest: 2026-01-29T18:59:57+00:00</div>
<div class="meta-line">Comments: Accepted on ICLR 2026; Project page: https://risys-lab.github.io/RedSage/</div>
<div class="links" style="margin-top:8px"><a href="https://arxiv.org/abs/2601.22159v1">Abs</a> · <a href="https://arxiv.org/pdf/2601.22159v1">PDF</a> · <a href="https://huggingface.co/huggingface">Code1</a> · <a href="https://huggingface.co/docs/hub/spaces">Code2</a> · <a href="https://risys-lab.github.io/RedSage/">Project1</a></div>
<details class="detail"><summary>Abstract</summary>
<div class="mono">Cybersecurity operations demand assistant LLMs that support diverse workflows without exposing sensitive data. Existing solutions either rely on proprietary APIs with privacy risks or on open models lacking domain adaptation. To bridge this gap, we curate 11.8B tokens of cybersecurity-focused continual pretraining data via large-scale web filtering and manual collection of high-quality resources, spanning 28.6K documents across frameworks, offensive techniques, and security tools. Building on this, we design an agentic augmentation pipeline that simulates expert workflows to generate 266K multi-turn cybersecurity samples for supervised fine-tuning. Combined with general open-source LLM data, these resources enable the training of RedSage, an open-source, locally deployable cybersecurity assistant with domain-aware pretraining and post-training. To rigorously evaluate the models, we introduce RedSage-Bench, a benchmark with 30K multiple-choice and 240 open-ended Q&amp;A items covering cybersecurity knowledge, skills, and tool expertise. RedSage is further evaluated on established cybersecurity benchmarks (e.g., CTI-Bench, CyberMetric, SECURE) and general LLM benchmarks to assess broader generalization. At the 8B scale, RedSage achieves consistently better results, surpassing the baseline models by up to +5.59 points on cybersecurity benchmarks and +5.05 points on Open LLM Leaderboard tasks. These findings demonstrate that domain-aware agentic augmentation and pre/post-training can not only enhance cybersecurity-specific expertise but also help to improve general reasoning and instruction-following. All models, datasets, and code are publicly available.</div></details>
<details class="detail"><summary>中文标题/摘要</summary>
<div class="mono"><b>标题：</b>RedSage：网络安全通用大语言模型</div>
<div class="mono" style="margin-top:8px">网络安全运营需要能够支持多样化工作流程且不暴露敏感数据的辅助大语言模型。现有解决方案要么依赖存在隐私风险的专有API，要么采用缺乏领域适配的开源模型。为弥补这一缺口，我们通过大规模网络过滤和高质量资源人工收集，整理了118亿个以网络安全为重点的持续预训练数据标记，涵盖框架、攻击技术和安全工具等2.86万份文档。在此基础上，我们设计了模拟专家工作流程的智能增强流水线，生成26.6万个用于监督微调的多轮网络安全样本。结合通用开源大语言模型数据，这些资源训练出RedSage——一个具备领域感知预训练与后训练、可本地部署的开源网络安全助手。为严格评估模型，我们推出RedSage-Bench基准测试，包含3万个选择题和240个开放式问答项目，覆盖网络安全知识、技能和工具专长。RedSage还在既有网络安全基准（如CTI-Bench、CyberMetric、SECURE）和通用大语言模型基准上接受评估以检验泛化能力。在80亿参数规模下，RedSage持续取得更优结果：网络安全基准超越基线模型最高达+5.59分，Open LLM排行榜任务提升+5.05分。这些发现表明，领域感知的智能增强与预/后训练不仅能提升网络安全专项能力，也有助于改进通用推理与指令遵循。所有模型、数据集和代码均已公开。</div>
</details>
<details class="detail"><summary>Summary / 总结</summary>
<div class="mono">The research addresses the need for cybersecurity assistant LLMs that can support diverse workflows while preserving data privacy, as existing solutions either pose privacy risks through proprietary APIs or lack domain-specific adaptation. The method involves curating 11.8B tokens of cybersecurity-focused data for continual pretraining and generating 266K multi-turn samples via an agentic augmentation pipeline that simulates expert workflows, which are used to train RedSage, an open-source, locally deployable model. Experimental results on the introduced RedSage-Bench and established benchmarks show that RedSage at the 8B scale outperforms baseline models by up to +5.59 points in cybersecurity tasks and +5.05 points on general LLM benchmarks, demonstrating enhanced domain expertise and improved general reasoning.</div>
<div class="mono" style="margin-top:8px">为满足网络安全操作对可本地部署、支持多样化工作流程且无需依赖有隐私风险的专有API的大型语言模型（LLM）的需求，本研究通过大规模网络过滤和手动收集高质量资源，整理了118亿标记的领域特定数据进行持续预训练，并通过模拟专家工作流程的智能体增强管道生成了26.6万轮多轮对话样本用于监督微调。基于此训练的RedSage模型在新构建的RedSage-Bench基准以及现有网络安全测试上进行了评估。实验结果表明，80亿参数的RedSage模型在网络安全基准上比基线模型提升高达5.59分，在通用LLM排行榜任务上提升高达5.05分，证明了其增强的领域专业知识和改进的通用推理能力。</div>
</details>
</div>
<div class="card">
<div class="title">Hybrid Linear Attention Done Right: Efficient Distillation and Effective Architectures for Extremely Long Contexts</div>
<div class="meta-line">Authors: Yingfa Chen, Zhen Leng Thai, Zihan Zhou, Zhu Zhang, Xingyu Shen, Shuo Wang, Chaojun Xiao, Xu Han, Zhiyuan Liu</div>
<div class="meta-line">First: 2026-01-29T18:59:53+00:00 · Latest: 2026-01-29T18:59:53+00:00</div>
<div class="meta-line">Comments: 20 pages, 8 figures</div>
<div class="links" style="margin-top:8px"><a href="https://arxiv.org/abs/2601.22156v1">Abs</a> · <a href="https://arxiv.org/pdf/2601.22156v1">PDF</a> · <a href="https://huggingface.co/huggingface">Code1</a> · <a href="https://huggingface.co/docs/hub/spaces">Code2</a></div>
<details class="detail"><summary>Abstract</summary>
<div class="mono">Hybrid Transformer architectures, which combine softmax attention blocks and recurrent neural networks (RNNs), have shown a desirable performance-throughput tradeoff for long-context modeling, but their adoption and studies are hindered by the prohibitive cost of large-scale pre-training from scratch. Some recent studies have shown that pre-trained softmax attention blocks can be converted into RNN blocks through parameter transfer and knowledge distillation. However, these transfer methods require substantial amounts of training data (more than 10B tokens), and the resulting hybrid models also exhibit poor long-context performance, which is the scenario where hybrid models enjoy significant inference speedups over Transformer-based models. In this paper, we present HALO (Hybrid Attention via Layer Optimization), a pipeline for distilling Transformer models into RNN-attention hybrid models. We then present HypeNet, a hybrid architecture with superior length generalization enabled by a novel position encoding scheme (named HyPE) and various architectural modifications. We convert the Qwen3 series into HypeNet using HALO, achieving performance comparable to the original Transformer models while enjoying superior long-context performance and efficiency. The conversion requires just 2.3B tokens, less than 0.01% of their pre-training data</div></details>
<details class="detail"><summary>中文标题/摘要</summary>
<div class="mono"><b>标题：</b>混合线性注意力机制的正确实现：面向超长上下文的高效蒸馏与有效架构</div>
<div class="mono" style="margin-top:8px">混合Transformer架构通过结合softmax注意力模块与循环神经网络（RNN），在长上下文建模中展现出理想的性能-吞吐量权衡，但其大规模从头预训练的高昂成本阻碍了实际应用与研究。近期研究表明，预训练的softmax注意力模块可通过参数迁移与知识蒸馏转化为RNN模块，但现有迁移方法需消耗大量训练数据（超过100亿词元），且所得混合模型在长上下文场景下表现欠佳——而这正是混合模型相比纯Transformer模型具备显著推理加速优势的场景。本文提出HALO（基于层优化的混合注意力），一种将Transformer模型蒸馏为RNN-注意力混合模型的流程；继而提出HypeNet混合架构，该架构通过新型位置编码方案（命名为HyPE）及多项结构改进，实现了卓越的长度泛化能力。我们使用HALO将Qwen3系列模型转换为HypeNet架构，在保持与原Transformer模型相当性能的同时，获得了更优的长上下文处理性能与效率，整个转换过程仅需23亿词元，不足其预训练数据量的0.01%。</div>
</details>
<details class="detail"><summary>Summary / 总结</summary>
<div class="mono">To address the high computational cost of pre-training hybrid Transformer-RNN models from scratch and the inefficiency of existing conversion methods, this work introduces HALO, a pipeline for distilling pre-trained softmax attention Transformers into hybrid models, and HypeNet, a novel hybrid architecture featuring a new position encoding scheme (HyPE) and architectural modifications for better length generalization. The method successfully converts the Qwen3 model series using only 2.3B tokens of training data, achieving performance comparable to the original Transformer while demonstrating superior efficiency and long-context modeling capabilities.</div>
<div class="mono" style="margin-top:8px">针对从头预训练混合Transformer-RNN模型的高计算成本以及现有转换方法的低效问题，本文提出了HALO蒸馏流程和HypeNet混合架构，后者采用了新颖的HyPE位置编码。该方法仅使用23亿token（远少于原始预训练数据）即可高效完成知识迁移。实验结果表明，基于Qwen3系列转换的模型在性能上与原始Transformer相当，同时在长上下文建模能力和推理效率方面表现更优。</div>
</details>
</div>
<div class="card">
<div class="title">Exploring Reasoning Reward Model for Agents</div>
<div class="meta-line">Authors: Kaixuan Fan, Kaituo Feng, Manyuan Zhang, Tianshuo Peng, Zhixun Li, Yilei Jiang, Shuang Chen, Peng Pei, Xunliang Cai, Xiangyu Yue</div>
<div class="meta-line">First: 2026-01-29T18:59:52+00:00 · Latest: 2026-01-29T18:59:52+00:00</div>
<div class="meta-line">Comments: Project page: https://github.com/kxfan2002/Reagent</div>
<div class="links" style="margin-top:8px"><a href="https://arxiv.org/abs/2601.22154v1">Abs</a> · <a href="https://arxiv.org/pdf/2601.22154v1">PDF</a> · <a href="https://github.com/kxfan2002/Reagent">Code1</a> · <a href="https://huggingface.co/huggingface">Code2</a> · <a href="https://huggingface.co/docs/hub/spaces">Code3</a></div>
<details class="detail"><summary>Abstract</summary>
<div class="mono">Agentic Reinforcement Learning (Agentic RL) has achieved notable success in enabling agents to perform complex reasoning and tool use. However, most methods still relies on sparse outcome-based reward for training. Such feedback fails to differentiate intermediate reasoning quality, leading to suboptimal training results. In this paper, we introduce Agent Reasoning Reward Model (Agent-RRM), a multi-faceted reward model that produces structured feedback for agentic trajectories, including (1) an explicit reasoning trace , (2) a focused critique that provides refinement guidance by highlighting reasoning flaws, and (3) an overall score that evaluates process performance. Leveraging these signals, we systematically investigate three integration strategies: Reagent-C (text-augmented refinement), Reagent-R (reward-augmented guidance), and Reagent-U (unified feedback integration). Extensive evaluations across 12 diverse benchmarks demonstrate that Reagent-U yields substantial performance leaps, achieving 43.7% on GAIA and 46.2% on WebWalkerQA, validating the effectiveness of our reasoning reward model and training schemes. Code, models, and datasets are all released to facilitate future research.</div></details>
<details class="detail"><summary>中文标题/摘要</summary>
<div class="mono"><b>标题：</b>探索智能体推理奖励模型</div>
<div class="mono" style="margin-top:8px">智能体强化学习在实现复杂推理与工具使用方面取得显著成功，但现有方法仍主要依赖稀疏的结果奖励进行训练。此类反馈无法区分中间推理质量，导致训练效果欠佳。本文提出智能体推理奖励模型——一种为智能体轨迹提供结构化反馈的多维度奖励模型，包含：(1)显式推理轨迹，(2)聚焦式批判（通过突出推理缺陷提供改进指导），(3)评估过程性能的综合评分。基于这些信号，我们系统研究三种集成策略：Reagent-C（文本增强优化）、Reagent-R（奖励增强引导）和Reagent-U（统一反馈集成）。在12个多样化基准测试中的广泛评估表明，Reagent-U实现显著性能跃升，在GAIA和WebWalkerQA上分别达到43.7%和46.2%，验证了推理奖励模型与训练方案的有效性。代码、模型及数据集均已开源以促进后续研究。</div>
</details>
<details class="detail"><summary>Summary / 总结</summary>
<div class="mono">To address the limitation of sparse outcome-based rewards in Agentic Reinforcement Learning, which fails to capture intermediate reasoning quality, this paper introduces the Agent Reasoning Reward Model (Agent-RRM) that provides structured feedback including explicit reasoning traces, focused critiques, and overall scores. The method systematically integrates these signals through three strategies—Reagent-C, Reagent-R, and Reagent-U—with extensive evaluations across 12 benchmarks showing that Reagent-U achieves significant performance improvements, such as 43.7% on GAIA and 46.2% on WebWalkerQA, validating the effectiveness of the proposed reward model and training schemes.</div>
<div class="mono" style="margin-top:8px">针对智能体强化学习中稀疏结果奖励无法评估中间推理质量的局限性，本文提出了智能体推理奖励模型（Agent-RRM），该模型提供结构化反馈，包括显式推理轨迹、突出推理缺陷的针对性批评以及整体过程评分。方法系统探索了三种集成策略：用于文本增强优化的Reagent-C、用于奖励增强指导的Reagent-R以及用于统一反馈集成的Reagent-U。在12个多样化基准上的广泛实验表明，Reagent-U实现了显著的性能提升，如在GAIA上达到43.7%，在WebWalkerQA上达到46.2%，验证了所提奖励模型和训练方案的有效性。</div>
</details>
</div>
<div class="card">
<div class="title">DynaWeb: Model-Based Reinforcement Learning of Web Agents</div>
<div class="meta-line">Authors: Hang Ding, Peidong Liu, Junqiao Wang, Ziwei Ji, Meng Cao, Rongzhao Zhang, Lynn Ai, Eric Yang, Tianyu Shi, Lei Yu</div>
<div class="meta-line">First: 2026-01-29T18:59:07+00:00 · Latest: 2026-01-29T18:59:07+00:00</div>
<div class="links" style="margin-top:8px"><a href="https://arxiv.org/abs/2601.22149v1">Abs</a> · <a href="https://arxiv.org/pdf/2601.22149v1">PDF</a> · <a href="https://huggingface.co/huggingface">Code1</a> · <a href="https://huggingface.co/docs/hub/spaces">Code2</a></div>
<details class="detail"><summary>Abstract</summary>
<div class="mono">The development of autonomous web agents, powered by Large Language Models (LLMs) and reinforcement learning (RL), represents a significant step towards general-purpose AI assistants. However, training these agents is severely hampered by the challenges of interacting with the live internet, which is inefficient, costly, and fraught with risks. Model-based reinforcement learning (MBRL) offers a promising solution by learning a world model of the environment to enable simulated interaction. This paper introduces DynaWeb, a novel MBRL framework that trains web agents through interacting with a web world model trained to predict naturalistic web page representations given agent actions. This model serves as a synthetic web environment where an agent policy can dream by generating vast quantities of rollout action trajectories for efficient online reinforcement learning. Beyond free policy rollouts, DynaWeb incorporates real expert trajectories from training data, which are randomly interleaved with on-policy rollouts during training to improve stability and sample efficiency. Experiments conducted on the challenging WebArena and WebVoyager benchmarks demonstrate that DynaWeb consistently and significantly improves the performance of state-of-the-art open-source web agent models. Our findings establish the viability of training web agents through imagination, offering a scalable and efficient way to scale up online agentic RL.</div></details>
<details class="detail"><summary>中文标题/摘要</summary>
<div class="mono"><b>标题：</b>DynaWeb：基于模型的网页智能体强化学习</div>
<div class="mono" style="margin-top:8px">基于大语言模型与强化学习的自主网页智能体开发，是迈向通用人工智能助手的重要进展。然而，与实时互联网交互的低效性、高成本与高风险严重阻碍了此类智能体的训练。基于模型的强化学习通过构建环境的世界模型实现模拟交互，为此提供了可行方案。本文提出DynaWeb——一种创新的MBRL框架，通过训练网页世界模型来预测智能体动作对应的拟真网页表征，进而在此合成网页环境中训练智能体策略。该模型支持智能体通过生成海量推演动作轨迹进行“想象式”高效在线强化学习。除自由策略推演外，DynaWeb还融合训练数据中的真实专家轨迹，在训练过程中与策略推演随机交织，以提升稳定性与样本效率。在WebArena和WebVoyager基准测试中的实验表明，DynaWeb能持续显著提升前沿开源网页智能体模型的性能。本研究证实了通过“想象”训练网页智能体的可行性，为规模化在线智能体强化学习提供了高效可扩展的路径。</div>
</details>
<details class="detail"><summary>Summary / 总结</summary>
<div class="mono">Training autonomous web agents via direct interaction with the live internet is inefficient, costly, and risky. To address this, the authors propose DynaWeb, a model-based reinforcement learning framework where a world model is trained to predict realistic web page representations from agent actions, creating a synthetic environment for policy rollouts. This approach is augmented by interleaving real expert trajectories with on-policy rollouts during training. Experimental results on the WebArena and WebVoyager benchmarks show that DynaWeb consistently and significantly boosts the performance of state-of-the-art open-source web agent models.</div>
<div class="mono" style="margin-top:8px">通过直接与实时互联网交互来训练自主网络智能体效率低下、成本高昂且存在风险。为此，研究者提出了DynaWeb，这是一个基于模型的强化学习框架，它训练一个世界模型来预测智能体动作后产生的逼真网页表示，从而创建一个用于策略模拟的合成环境。该方法在训练过程中还将真实的专家轨迹与模拟轨迹随机交织以提高稳定性，实验表明，在WebArena和WebVoyager基准测试中，该框架显著提升了先进开源网络智能体的性能，验证了基于想象的、可扩展的高效训练路径的可行性。</div>
</details>
</div>
<div class="card">
<div class="title">MORPH: PDE Foundation Models with Arbitrary Data Modality</div>
<div class="meta-line">Authors: Mahindra Singh Rautela, Alexander Most, Siddharth Mansingh, Bradley C. Love, Alexander Scheinker, Diane Oyen, Nathan Debardeleben, Earl Lawrence, Ayan Biswas</div>
<div class="meta-line">First: 2025-09-25T22:38:36+00:00 · Latest: 2026-01-29T18:57:23+00:00</div>
<div class="links" style="margin-top:8px"><a href="https://arxiv.org/abs/2509.21670v4">Abs</a> · <a href="https://arxiv.org/pdf/2509.21670v4">PDF</a> · <a href="https://github.com/lanl/MORPH">Code1</a> · <a href="https://huggingface.co/huggingface">Code2</a> · <a href="https://huggingface.co/docs/hub/spaces">Code3</a></div>
<details class="detail"><summary>Abstract</summary>
<div class="mono">We introduce MORPH, a modality-agnostic, autoregressive foundation model for partial differential equations (PDEs). MORPH is built on a convolutional vision transformer backbone that seamlessly handles heterogeneous spatiotemporal datasets of varying data modality (1D--3D) at different resolutions, and multiple fields with mixed scalar and vector components. The architecture combines (i) component-wise convolution, which jointly processes scalar and vector channels to capture local interactions, (ii) inter-field cross-attention, which models and selectively propagates information between different physical fields, (iii) axial attentions, which factorize full spatiotemporal self-attention along individual spatial and temporal axes to reduce computational burden while retaining expressivity. We pretrain multiple model variants on a diverse collection of heterogeneous PDE datasets and evaluate transfer to a range of downstream prediction tasks. Using both full-model fine-tuning and parameter-efficient low-rank adapters, MORPH outperforms models trained from scratch. Across extensive evaluations, MORPH matches or surpasses strong baselines and recent state-of-the-art models. Collectively, these capabilities present a flexible and powerful backbone for learning from the heterogeneous and multimodal nature of scientific observations, charting a path toward scalable and data-efficient scientific machine learning. The source code, datasets, and models are publicly available at https://github.com/lanl/MORPH.</div></details>
<details class="detail"><summary>中文标题/摘要</summary>
<div class="mono"><b>标题：</b>MORPH：支持任意数据模态的偏微分方程基础模型</div>
<div class="mono" style="margin-top:8px">我们提出了MORPH，一种与模态无关、自回归的偏微分方程基础模型。MORPH基于卷积视觉Transformer架构构建，能够无缝处理不同分辨率（1D至3D）的异构时空数据集，以及包含标量与矢量分量的多物理场。其架构融合了：（i）分量级卷积，联合处理标量与矢量通道以捕捉局部相互作用；（ii）场间交叉注意力，建模并选择性传递不同物理场间的信息；（iii）轴向注意力，将完整时空自注意力分解至独立的空间与时间轴，在保持表达力的同时降低计算负担。我们在多样化的异构PDE数据集上预训练了多个模型变体，并评估其在下游预测任务中的迁移性能。通过全模型微调与参数高效的低秩适配器，MORPH的表现均优于从头训练的模型。在广泛评估中，MORPH达到或超越了强基线及近期前沿模型。这些能力共同构成了一个灵活而强大的学习框架，能够从科学观测数据的异构与多模态特性中学习，为可扩展且数据高效的科学机器学习开辟了路径。源代码、数据集与模型已公开于https://github.com/lanl/MORPH。</div>
</details>
<details class="detail"><summary>Summary / 总结</summary>
<div class="mono">The research addresses the challenge of learning from heterogeneous spatiotemporal datasets in scientific machine learning by introducing MORPH, a modality-agnostic, autoregressive foundation model for partial differential equations (PDEs). The method employs a convolutional vision transformer backbone with component-wise convolution to process mixed scalar and vector fields, inter-field cross-attention to propagate information between different physical fields, and axial attentions to factorize spatiotemporal self-attention for computational efficiency. Experimental results from pretraining on diverse PDE datasets and fine-tuning on downstream tasks show that MORPH outperforms models trained from scratch and matches or surpasses strong baselines and state-of-the-art models, demonstrating its effectiveness as a flexible backbone for data-efficient scientific learning.</div>
<div class="mono" style="margin-top:8px">为应对从异构多模态科学数据中学习的挑战，本文提出了MORPH，一种适用于偏微分方程（PDE）的模态无关基础模型。该方法采用卷积视觉Transformer主干网络，结合分量卷积处理局部交互，场间交叉注意力在不同物理场间传播信息，以及轴向注意力实现高效时空建模。实验结果表明，在多样化PDE数据集上预训练、并通过微调或适配器应用于下游任务时，MORPH的性能优于从头训练的模型，并达到或超越了强基线及当前最先进模型。</div>
</details>
</div>
<div class="card">
<div class="title">Routing the Lottery: Adaptive Subnetworks for Heterogeneous Data</div>
<div class="meta-line">Authors: Grzegorz Stefanski, Alberto Presta, Michal Byra</div>
<div class="meta-line">First: 2026-01-29T18:56:41+00:00 · Latest: 2026-01-29T18:56:41+00:00</div>
<div class="links" style="margin-top:8px"><a href="https://arxiv.org/abs/2601.22141v1">Abs</a> · <a href="https://arxiv.org/pdf/2601.22141v1">PDF</a> · <a href="https://huggingface.co/huggingface">Code1</a> · <a href="https://huggingface.co/docs/hub/spaces">Code2</a></div>
<details class="detail"><summary>Abstract</summary>
<div class="mono">In pruning, the Lottery Ticket Hypothesis posits that large networks contain sparse subnetworks, or winning tickets, that can be trained in isolation to match the performance of their dense counterparts. However, most existing approaches assume a single universal winning ticket shared across all inputs, ignoring the inherent heterogeneity of real-world data. In this work, we propose Routing the Lottery (RTL), an adaptive pruning framework that discovers multiple specialized subnetworks, called adaptive tickets, each tailored to a class, semantic cluster, or environmental condition. Across diverse datasets and tasks, RTL consistently outperforms single- and multi-model baselines in balanced accuracy and recall, while using up to 10 times fewer parameters than independent models and exhibiting semantically aligned. Furthermore, we identify subnetwork collapse, a performance drop under aggressive pruning, and introduce a subnetwork similarity score that enables label-free diagnosis of oversparsification. Overall, our results recast pruning as a mechanism for aligning model structure with data heterogeneity, paving the way toward more modular and context-aware deep learning.</div></details>
<details class="detail"><summary>中文标题/摘要</summary>
<div class="mono"><b>标题：</b>路由彩票：面向异构数据的自适应子网络</div>
<div class="mono" style="margin-top:8px">在剪枝领域，彩票假说认为大型网络包含稀疏子网络（即中奖彩票），这些子网络可独立训练以达到与稠密网络相当的性能。然而现有方法多假设存在适用于所有输入的单一通用中奖彩票，忽视了现实数据的固有异构性。本研究提出&#x27;路由彩票&#x27;自适应剪枝框架，该框架能发现多个专用子网络（称为自适应彩票），每个子网络分别适配特定类别、语义簇或环境条件。在多样化数据集和任务中，RTL在平衡准确率与召回率上持续优于单模型及多模型基线，同时参数使用量比独立模型减少高达10倍，且呈现语义对齐特性。此外，我们发现了激进剪枝下的子网络坍缩现象，并提出可通过子网络相似度评分实现无标签的过稀疏化诊断。总体而言，本研究将剪枝重构为模型结构与数据异构性对齐的机制，为构建更具模块化和情境感知能力的深度学习模型开辟了新路径。</div>
</details>
<details class="detail"><summary>Summary / 总结</summary>
<div class="mono">The research is motivated by the observation that the Lottery Ticket Hypothesis typically assumes a single universal winning subnetwork, which overlooks the heterogeneity of real-world data. The method introduces Routing the Lottery (RTL), an adaptive pruning framework that discovers multiple specialized subnetworks, termed adaptive tickets, each tailored to specific data classes, clusters, or conditions. Key experimental findings show that RTL consistently outperforms single- and multi-model baselines in balanced accuracy and recall across diverse datasets, using up to 10 times fewer parameters than independent models, while also identifying and diagnosing subnetwork collapse through a novel similarity score.</div>
<div class="mono" style="margin-top:8px">本研究动机源于彩票假设的局限性，该假设认为所有输入共享一个通用获胜子网络，忽略了现实数据的异质性。为此，我们提出了“路由彩票”（RTL）自适应剪枝框架，该方法通过剪枝密集网络来发现多个针对不同数据类别或条件定制的专用子网络（自适应彩票），并根据输入进行路由。实验结果表明，在多种数据集上，RTL在平衡准确率和召回率上优于单模型和多模型基线，参数使用量比独立模型少达10倍，且表现出语义对齐；研究还识别了激进剪枝下的子网络崩溃现象，并引入了一种相似性评分来诊断过度稀疏化问题。</div>
</details>
</div>
<div class="card">
<div class="title">Reasoning While Asking: Transforming Reasoning Large Language Models from Passive Solvers to Proactive Inquirers</div>
<div class="meta-line">Authors: Xin Chen, Feng Jiang, Yiqian Zhang, Hardy Chen, Shuo Yan, Wenya Xie, Min Yang, Shujian Huang</div>
<div class="meta-line">First: 2026-01-29T18:56:12+00:00 · Latest: 2026-01-29T18:56:12+00:00</div>
<div class="meta-line">Comments: The manuscript is under review</div>
<div class="links" style="margin-top:8px"><a href="https://arxiv.org/abs/2601.22139v1">Abs</a> · <a href="https://arxiv.org/pdf/2601.22139v1">PDF</a> · <a href="https://github.com/SUAT-AIRI/Proactive-Interactive-R1">Code1</a> · <a href="https://huggingface.co/huggingface">Code2</a> · <a href="https://huggingface.co/docs/hub/spaces">Code3</a></div>
<details class="detail"><summary>Abstract</summary>
<div class="mono">Reasoning-oriented Large Language Models (LLMs) have achieved remarkable progress with Chain-of-Thought (CoT) prompting, yet they remain fundamentally limited by a \emph{blind self-thinking} paradigm: performing extensive internal reasoning even when critical information is missing or ambiguous. We propose Proactive Interactive Reasoning (PIR), a new reasoning paradigm that transforms LLMs from passive solvers into proactive inquirers that interleave reasoning with clarification. Unlike existing search- or tool-based frameworks that primarily address knowledge uncertainty by querying external environments, PIR targets premise- and intent-level uncertainty through direct interaction with the user. PIR is implemented via two core components: (1) an uncertainty-aware supervised fine-tuning procedure that equips models with interactive reasoning capability, and (2) a user-simulator-based policy optimization framework driven by a composite reward that aligns model behavior with user intent. Extensive experiments on mathematical reasoning, code generation, and document editing demonstrate that PIR consistently outperforms strong baselines, achieving up to 32.70\% higher accuracy, 22.90\% higher pass rate, and 41.36 BLEU improvement, while reducing nearly half of the reasoning computation and unnecessary interaction turns. Further reliability evaluations on factual knowledge, question answering, and missing-premise scenarios confirm the strong generalization and robustness of PIR. Model and code are publicly available at: \href{https://github.com/SUAT-AIRI/Proactive-Interactive-R1}</div></details>
<details class="detail"><summary>中文标题/摘要</summary>
<div class="mono"><b>标题：</b>推理中提问：将推理大语言模型从被动求解器转变为主动询问者</div>
<div class="mono" style="margin-top:8px">面向推理的大语言模型（LLMs）通过思维链提示取得了显著进展，但其根本上仍受限于一种“盲目的自我思考”范式：即使在关键信息缺失或模糊时仍进行大量内部推理。我们提出主动交互式推理（PIR），这是一种新的推理范式，将LLMs从被动求解器转变为主动询问者，实现推理与澄清的交替进行。与现有主要通过查询外部环境处理知识不确定性的搜索或工具框架不同，PIR通过与用户直接交互，针对前提和意图层面的不确定性。PIR通过两个核心组件实现：（1）不确定性感知的监督微调程序，使模型具备交互推理能力；（2）基于用户模拟器的策略优化框架，由复合奖励驱动，使模型行为与用户意图对齐。在数学推理、代码生成和文档编辑上的大量实验表明，PIR始终优于强基线，准确率最高提升32.70%，通过率最高提升22.90%，BLEU分数提升41.36，同时减少近半推理计算和不必要的交互轮次。在事实知识、问答和缺失前提场景下的可靠性评估进一步证实了PIR的强大泛化能力和鲁棒性。模型和代码已公开于：https://github.com/SUAT-AIRI/Proactive-Interactive-R1</div>
</details>
<details class="detail"><summary>Summary / 总结</summary>
<div class="mono">Current reasoning-oriented Large Language Models (LLMs) are limited by a passive, &#x27;blind self-thinking&#x27; paradigm that persists even when faced with missing or ambiguous information. To address this, the authors propose Proactive Interactive Reasoning (PIR), a new paradigm that transforms LLMs into proactive inquirers capable of interleaving reasoning with clarification questions directed at the user, targeting premise- and intent-level uncertainty rather than just knowledge gaps. The method is implemented through an uncertainty-aware supervised fine-tuning procedure and a user-simulator-based policy optimization framework guided by a composite reward. Experimental results on mathematical reasoning, code generation, and document editing tasks show that PIR consistently outperforms strong baselines, achieving significant gains in accuracy, pass rates, and BLEU scores while reducing reasoning computation and unnecessary interactions by nearly half, with further evaluations confirming its generalization and robustness.</div>
<div class="mono" style="margin-top:8px">当前面向推理的大语言模型（LLMs）在关键信息缺失或模糊时，受限于被动的自我思考范式。为此，本研究提出了主动交互式推理（PIR）新范式，将LLMs从被动求解器转变为主动询问者，使其能够在推理过程中穿插向用户请求澄清。该方法通过不确定性感知的监督微调和基于用户模拟器的复合奖励策略优化框架实现。在数学推理、代码生成和文档编辑任务上的实验表明，PIR显著优于基线模型，准确率最高提升32.70%，通过率最高提升22.90%，同时将推理计算和不必要的交互轮次减少近一半，并在可靠性评估中展现出强大的泛化能力。</div>
</details>
</div>
<div class="card">
<div class="title">&quot;Not in My Backyard&quot;: LLMs Uncover Online and Offline Social Biases Against Homelessness</div>
<div class="meta-line">Authors: Jonathan A. Karr, Benjamin F. Herbst, Matthew L. Sisk, Xueyun Li, Ting Hua, Matthew Hauenstein, Georgina Curto, Nitesh V. Chawla</div>
<div class="meta-line">First: 2025-08-14T17:58:34+00:00 · Latest: 2026-01-29T18:55:57+00:00</div>
<div class="links" style="margin-top:8px"><a href="https://arxiv.org/abs/2508.13187v3">Abs</a> · <a href="https://arxiv.org/pdf/2508.13187v3">PDF</a> · <a href="https://huggingface.co/huggingface">Code1</a> · <a href="https://huggingface.co/docs/hub/spaces">Code2</a></div>
<details class="detail"><summary>Abstract</summary>
<div class="mono">Homelessness is a persistent social challenge, impacting millions worldwide. Over 876,000 people experienced homelessness (PEH) in the U.S. in 2025. Social bias is a significant barrier to alleviation, shaping public perception and influencing policymaking. Given that online textual media and offline city council discourse reflect and influence part of public opinion, it provides valuable insights to identify and track social biases against PEH. We present a new, manually-annotated multi-domain dataset compiled from Reddit, X (formerly Twitter), news articles, and city council meeting minutes across ten U.S. cities. Our 16-category multi-label taxonomy creates a challenging long-tail classification problem: some categories appear in less than 1% of samples, while others exceed 70%. We find that small human-annotated datasets (1,702 samples) are insufficient for training effective classifiers, whether used to fine-tune encoder models or as few-shot examples for LLMs. To address this, we use GPT-4.1 to generate pseudo-labels on a larger unlabeled corpus. Training on this expanded dataset enables even small encoder models (ModernBERT, 150M parameters) to achieve 35.23 macro-F1, approaching GPT-4.1&#x27;s 41.57. This demonstrates that \textbf{data quantity matters more than model size}, enabling low-cost, privacy-preserving deployment without relying on commercial APIs. Our results reveal that negative bias against PEH is prevalent both offline and online (especially on Reddit), with &quot;not in my backyard&quot; narratives showing the highest engagement. These findings uncover a type of ostracism that directly impacts poverty-reduction policymaking and provide actionable insights for practitioners addressing homelessness.</div></details>
<details class="detail"><summary>中文标题/摘要</summary>
<div class="mono"><b>标题：</b>“邻避效应”：大语言模型揭示针对无家可归者的线上与线下社会偏见</div>
<div class="mono" style="margin-top:8px">无家可归问题是全球范围内影响数百万人的持续性社会挑战，2025年美国有超过87.6万人经历无家可归。社会偏见是缓解该问题的主要障碍，它塑造公众认知并影响政策制定。鉴于线上文本媒体与线下市议会讨论能反映并影响部分舆论，这为识别和追踪针对无家可归者的社会偏见提供了宝贵视角。我们构建了一个全新的人工标注多领域数据集，涵盖美国十个城市的Reddit、X（原Twitter）、新闻报道及市议会会议记录。基于16个类别的多标签分类体系形成了具有挑战性的长尾分类问题：部分类别在样本中占比不足1%，而其他类别超过70%。研究发现，小型人工标注数据集（1,702条样本）不足以训练有效分类器，无论是用于微调编码器模型还是作为大语言模型的少样本示例。为此，我们使用GPT-4.1对更大规模未标注语料生成伪标签。基于扩展数据集训练后，即使小型编码器模型（ModernBERT，1.5亿参数）也能达到35.23的宏观F1值，接近GPT-4.1的41.57。这表明数据规模比模型体量更为关键，能够实现不依赖商业API的低成本、隐私保护型部署。研究结果显示，针对无家可归者的负面偏见在线下与线上（尤其是Reddit）普遍存在，其中“邻避效应”叙事获得最高关注度。这些发现揭示了一种直接影响减贫政策制定的社会排斥机制，并为无家可归问题实践者提供了可操作的见解。</div>
</details>
<details class="detail"><summary>Summary / 总结</summary>
<div class="mono">To address the persistent social challenge of homelessness and the significant barrier posed by social bias, this study introduces a new multi-domain dataset compiled from Reddit, X, news articles, and city council minutes across ten U.S. cities, annotated with a 16-category taxonomy that creates a long-tail classification problem. The method involves using a small human-annotated dataset to train classifiers, finding it insufficient, and then employing GPT-4.1 to generate pseudo-labels on a larger unlabeled corpus to expand the training data. Key experimental results show that training on this expanded dataset enables small encoder models like ModernBERT to achieve a macro-F1 of 35.23, approaching GPT-4.1&#x27;s 41.57, demonstrating that data quantity matters more than model size for effective, low-cost deployment. The findings reveal that negative bias against people experiencing homelessness is prevalent both offline and online, with &#x27;not in my backyard&#x27; narratives showing the highest engagement, providing insights that impact poverty-reduction policymaking.</div>
<div class="mono" style="margin-top:8px">本研究针对无家可归这一持续的社会挑战，调查了线上和线下话语中对无家可归者（PEH）的偏见，这些偏见塑造了公众认知并影响政策制定。作者从美国十个城市的Reddit、X、新闻和市议会会议记录中汇编了一个手动标注的多领域数据集，包含16个类别的长尾分类体系，并发现小型标注数据集不足以训练有效的分类器。为解决此问题，他们使用GPT-4.1在更大的未标注语料上生成伪标签，使得即使是像ModernBERT（1.5亿参数）这样的小型编码器模型也能达到35.23的宏观F1分数，接近GPT-4.1的41.57，这表明数据量比模型规模更重要，有利于低成本、保护隐私的部署。实验结果揭示，对PEH的负面偏见在线上和线下普遍存在，尤其在Reddit上，其中“别在我家后院”的叙事参与度最高，这揭示了一种直接影响减贫政策制定的排斥现象。</div>
</details>
</div>
<div class="card">
<div class="title">PRISM: Distribution-free Adaptive Computation of Matrix Functions for Accelerating Neural Network Training</div>
<div class="meta-line">Authors: Shenghao Yang, Zhichao Wang, Oleg Balabanov, N. Benjamin Erichson, Michael W. Mahoney</div>
<div class="meta-line">First: 2026-01-29T18:55:46+00:00 · Latest: 2026-01-29T18:55:46+00:00</div>
<div class="links" style="margin-top:8px"><a href="https://arxiv.org/abs/2601.22137v1">Abs</a> · <a href="https://arxiv.org/pdf/2601.22137v1">PDF</a> · <a href="https://huggingface.co/huggingface">Code1</a> · <a href="https://huggingface.co/docs/hub/spaces">Code2</a></div>
<details class="detail"><summary>Abstract</summary>
<div class="mono">Matrix functions such as square root, inverse roots, and orthogonalization play a central role in preconditioned gradient methods for neural network training. This has motivated the development of iterative algorithms that avoid explicit eigendecompositions and rely primarily on matrix multiplications, making them well suited for modern GPU accelerators. We present PRISM (Polynomial-fitting and Randomized Iterative Sketching for Matrix functions computation), a general framework for accelerating iterative algorithms for computing matrix functions. PRISM combines adaptive polynomial approximation with randomized sketching: at each iteration, it fits a polynomial surrogate to the current spectrum via a sketched least-squares problem, adapting to the instance at hand with minimal overhead. We apply PRISM to accelerate Newton-Schulz-like iterations for matrix square roots and orthogonalization, which are core primitives in machine learning. Unlike prior methods, PRISM requires no explicit spectral bounds or singular value estimates; and it adapts automatically to the evolving spectrum. Empirically, PRISM accelerates training when integrated into Shampoo and Muon optimizers.</div></details>
<details class="detail"><summary>中文标题/摘要</summary>
<div class="mono"><b>标题：</b>PRISM：用于加速神经网络训练的无分布自适应矩阵函数计算</div>
<div class="mono" style="margin-top:8px">矩阵函数（如平方根、逆根和正交化）在神经网络训练的预处理梯度方法中起着核心作用。这推动了迭代算法的发展，这些算法避免显式特征分解，主要依赖矩阵乘法，使其非常适合现代GPU加速器。我们提出PRISM（用于矩阵函数计算的多项式拟合与随机迭代草图），这是一个加速计算矩阵函数的迭代算法的通用框架。PRISM将自适应多项式逼近与随机草图技术相结合：在每次迭代中，通过草图最小二乘问题拟合当前谱的多项式代理，以最小开销自适应处理当前实例。我们将PRISM应用于加速类牛顿-舒尔茨迭代的矩阵平方根和正交化计算，这些是机器学习中的核心原语。与现有方法不同，PRISM无需显式谱界或奇异值估计，并能自动适应演化中的谱。实证表明，将PRISM集成到Shampoo和Muon优化器中可加速训练。</div>
</details>
<details class="detail"><summary>Summary / 总结</summary>
<div class="mono">Matrix functions like square roots and orthogonalization are crucial for preconditioned gradient methods in neural network training, but existing iterative algorithms often require explicit spectral bounds and lack adaptability. To address this, the authors propose PRISM, a framework that accelerates iterative matrix function computation by combining adaptive polynomial approximation with randomized sketching; at each iteration, it fits a polynomial surrogate to the current spectrum via a sketched least-squares problem, eliminating the need for prior spectral bounds and automatically adapting to the evolving spectrum. Experimental results show that PRISM effectively accelerates training when integrated into optimizers such as Shampoo and Muon.</div>
<div class="mono" style="margin-top:8px">该研究的动机在于需要高效计算矩阵函数（如平方根和正交化）以支持神经网络训练中的预处理梯度方法，这些方法传统上依赖于适合GPU加速器的迭代算法。提出的PRISM方法通过结合自适应多项式逼近和随机化草图技术来加速这些迭代计算，它在每次迭代中通过草图最小二乘问题拟合当前谱的多项式代理，自动适应而不需要显式谱边界。实验结果表明，当集成到Shampoo和Muon等优化器中时，PRISM能有效加速训练，通过以最小开销适应演化谱，优于先前方法。</div>
</details>
</div>
<div class="card">
<div class="title">StepShield: When, Not Whether to Intervene on Rogue Agents</div>
<div class="meta-line">Authors: Gloria Felicia, Michael Eniolade, Jinfeng He, Zitha Sasindran, Hemant Kumar, Milan Hussain Angati, Sandeep Bandarupalli</div>
<div class="meta-line">First: 2026-01-29T18:55:46+00:00 · Latest: 2026-01-29T18:55:46+00:00</div>
<div class="meta-line">Comments: 16 pages, 2 figures, 14 tables</div>
<div class="links" style="margin-top:8px"><a href="https://arxiv.org/abs/2601.22136v1">Abs</a> · <a href="https://arxiv.org/pdf/2601.22136v1">PDF</a> · <a href="https://huggingface.co/huggingface">Code1</a> · <a href="https://huggingface.co/docs/hub/spaces">Code2</a></div>
<details class="detail"><summary>Abstract</summary>
<div class="mono">Existing agent safety benchmarks report binary accuracy, conflating early intervention with post-mortem analysis. A detector that flags a violation at step 8 enables intervention; one that reports it at step 48 provides only forensic value. This distinction is critical, yet current benchmarks cannot measure it. We introduce StepShield, the first benchmark to evaluate when violations are detected, not just whether. StepShield contains 9,213 code agent trajectories, including 1,278 meticulously annotated training pairs and a 7,935-trajectory test set with a realistic 8.1% rogue rate. Rogue behaviors are grounded in real-world security incidents across six categories. We propose three novel temporal metrics: Early Intervention Rate (EIR), Intervention Gap, and Tokens Saved. Surprisingly, our evaluation reveals that an LLM-based judge achieves 59% EIR while a static analyzer achieves only 26%, a 2.3x performance gap that is entirely invisible to standard accuracy metrics. We further show that early detection has direct economic benefits: our cascaded HybridGuard detector reduces monitoring costs by 75% and projects to $108M in cumulative savings over five years at enterprise scale. By shifting the focus of evaluation from whether to when, StepShield provides a new foundation for building safer and more economically viable AI agents. The code and data are released under an Apache 2.0 license.</div></details>
<details class="detail"><summary>中文标题/摘要</summary>
<div class="mono"><b>标题：</b>StepShield：何时而非是否干预恶意智能体</div>
<div class="mono" style="margin-top:8px">现有智能体安全基准仅报告二元准确率，将早期干预与事后分析混为一谈。在第8步标记违规的检测器可实现干预，而在第48步报告的检测器仅具取证价值。这一区分至关重要，但现有基准无法衡量。我们推出首个评估违规检测时机的基准StepShield，其包含9,213条代码智能体轨迹，含1,278条精细标注的训练对和7,935条轨迹的测试集（真实恶意率8.1%）。恶意行为基于六类现实安全事件构建。我们提出三项时序指标：早期干预率（EIR）、干预间隔和节省令牌数。评估显示，基于LLM的评判器达到59% EIR，而静态分析器仅26%，这2.3倍的性能差距在标准准确率指标中完全不可见。研究进一步表明早期检测具有直接经济效益：级联式HybridGuard检测器将监控成本降低75%，在企业级规模下五年累计节省预计达1.08亿美元。通过将评估重点从‘是否’转向‘何时’，StepShield为构建更安全、更经济可行的AI智能体奠定新基础。代码与数据基于Apache 2.0协议开源。</div>
</details>
<details class="detail"><summary>Summary / 总结</summary>
<div class="mono">Current agent safety benchmarks only measure binary detection accuracy, failing to distinguish between early intervention and post-mortem analysis, which is critical for practical safety. To address this, we introduce StepShield, a benchmark that evaluates when violations are detected, not just whether, using 9,213 code agent trajectories with realistic rogue behaviors grounded in real-world security incidents. We propose three temporal metrics—Early Intervention Rate, Intervention Gap, and Tokens Saved—and find that an LLM-based judge achieves a 59% Early Intervention Rate, outperforming a static analyzer&#x27;s 26% by 2.3x, a gap invisible to standard accuracy metrics, while a cascaded HybridGuard detector reduces monitoring costs by 75% and projects $108M in savings over five years at scale.</div>
<div class="mono" style="margin-top:8px">现有智能体安全基准仅衡量二元检测准确率，无法区分早期干预与事后分析，而这对实际安全至关重要。为此，研究者提出了StepShield基准，通过9,213条代码智能体轨迹（包含基于真实安全事件的恶意行为）来评估违规行为被检测到的时机，而不仅仅是是否被检测。他们提出了早期干预率、干预间隔和节省令牌数三项时序指标，实验发现基于大语言模型的判断器早期干预率达到59%，显著优于静态分析器的26%，这一差距在标准指标中无法体现；此外，级联检测器能将监控成本降低75%，预计带来可观的经济效益。</div>
</details>
</div>
<div class="card">
<div class="title">World of Workflows: a Benchmark for Bringing World Models to Enterprise Systems</div>
<div class="meta-line">Authors: Lakshya Gupta, Litao Li, Yizhe Liu, Sriram Ganapathi Subramanian, Kaheer Suleman, Zichen Zhang, Haoye Lu, Sumit Pasupalak</div>
<div class="meta-line">First: 2026-01-29T18:51:54+00:00 · Latest: 2026-01-29T18:51:54+00:00</div>
<div class="links" style="margin-top:8px"><a href="https://arxiv.org/abs/2601.22130v1">Abs</a> · <a href="https://arxiv.org/pdf/2601.22130v1">PDF</a> · <a href="https://huggingface.co/huggingface">Code1</a> · <a href="https://huggingface.co/docs/hub/spaces">Code2</a></div>
<details class="detail"><summary>Abstract</summary>
<div class="mono">Frontier large language models (LLMs) excel as autonomous agents in many domains, yet they remain untested in complex enterprise systems where hidden workflows create cascading effects across interconnected databases. Existing enterprise benchmarks evaluate surface-level agentic task completion similar to general consumer benchmarks, ignoring true challenges in enterprises, such as limited observability, large database state, and hidden workflows with cascading side effects. We introduce World of Workflows (WoW), a realistic ServiceNow-based environment incorporating 4,000+ business rules and 55 active workflows embedded in the system, alongside WoW-bench, a benchmark of 234 tasks evaluating constrained agentic task completion and enterprise dynamics modeling capabilities. We reveal two major takeaways: (1) Frontier LLMs suffer from dynamics blindness, consistently failing to predict the invisible, cascading side effects of their actions, which leads to silent constraint violations, and (2) reliability in opaque systems requires grounded world modeling, where agents must mentally simulate hidden state transitions to bridge the observability gap when high-fidelity feedback is unavailable. For reliable and useful enterprise agents, WoW motivates a new paradigm to explicitly learn system dynamics. We release our GitHub for setting up and evaluating WoW.</div></details>
<details class="detail"><summary>中文标题/摘要</summary>
<div class="mono"><b>标题：</b>工作流世界：将世界模型引入企业系统的基准测试</div>
<div class="mono" style="margin-top:8px">前沿大语言模型（LLMs）作为自主智能体在许多领域表现出色，但在复杂的企业系统中尚未经过充分测试——这些系统中隐藏的工作流会在互连数据库间产生级联效应。现有企业基准测试仅评估类似通用消费级基准的表面任务完成度，忽视了企业环境中的真实挑战，如有限可观测性、大规模数据库状态以及具有级联副作用的隐藏工作流。我们提出了“工作流世界”（WoW），这是一个基于ServiceNow的真实环境，包含系统内嵌的4000余条业务规则和55个活跃工作流；同时推出WoW-bench基准测试，包含234项任务，用于评估受限智能体任务完成度与企业动态建模能力。研究揭示两大关键发现：（1）前沿LLMs存在动态盲区，始终无法预测其行为引发的不可见级联副作用，导致隐性约束违反；（2）在不透明系统中实现可靠性需要基于现实的世界建模，智能体必须在缺乏高保真反馈时通过心智模拟隐藏状态转换来弥合可观测性鸿沟。为实现可靠实用的企业智能体，WoW推动了一种显式学习系统动态的新范式。我们已开源GitHub仓库供部署和评估WoW。</div>
</details>
<details class="detail"><summary>Summary / 总结</summary>
<div class="mono">The research is motivated by the need to test frontier large language models (LLMs) as autonomous agents in complex enterprise systems, where hidden workflows and cascading side effects across databases pose unique challenges not captured by existing benchmarks. The method introduces World of Workflows (WoW), a realistic ServiceNow-based environment with over 4,000 business rules and 55 active workflows, and WoW-bench, a benchmark of 234 tasks designed to evaluate both constrained agentic task completion and enterprise dynamics modeling. Key experimental findings reveal that frontier LLMs suffer from dynamics blindness, consistently failing to predict invisible cascading side effects, which leads to silent constraint violations, and demonstrate that reliability in such opaque systems requires grounded world modeling where agents mentally simulate hidden state transitions to bridge the observability gap.</div>
<div class="mono" style="margin-top:8px">本研究的动机在于需要测试前沿大语言模型作为自主智能体在复杂企业系统中的表现，这些系统中隐藏的工作流和跨数据库的连锁效应带来了现有基准测试未能捕捉的独特挑战。方法上引入了World of Workflows（WoW），这是一个基于ServiceNow的真实环境，包含4000多条业务规则和55个活跃工作流，以及WoW-bench基准测试，包含234个任务，用于评估受限的智能体任务完成度和企业动态建模能力。主要实验结果表明，前沿大语言模型存在动态盲区，持续无法预测其行为引发的不可见连锁效应，导致隐性约束违规，并证明在不透明系统中实现可靠性需要基于现实的世界建模，即智能体必须通过心智模拟隐藏的状态转换来弥补可观测性差距。</div>
</details>
</div>
<div class="card">
<div class="title">SWE-Replay: Efficient Test-Time Scaling for Software Engineering Agents</div>
<div class="meta-line">Authors: Yifeng Ding, Lingming Zhang</div>
<div class="meta-line">First: 2026-01-29T18:50:29+00:00 · Latest: 2026-01-29T18:50:29+00:00</div>
<div class="links" style="margin-top:8px"><a href="https://arxiv.org/abs/2601.22129v1">Abs</a> · <a href="https://arxiv.org/pdf/2601.22129v1">PDF</a> · <a href="https://huggingface.co/huggingface">Code1</a> · <a href="https://huggingface.co/docs/hub/spaces">Code2</a></div>
<details class="detail"><summary>Abstract</summary>
<div class="mono">Test-time scaling has been widely adopted to enhance the capabilities of Large Language Model (LLM) agents in software engineering (SWE) tasks. However, the standard approach of repeatedly sampling trajectories from scratch is computationally expensive. While recent methods have attempted to mitigate costs using specialized value agents, they can suffer from model miscalibration and fail to generalize to modern agents that synthesize custom bash scripts as tools. In this paper, we introduce SWE-Replay, the first efficient and generalizable test-time scaling technique for modern agents without reliance on potentially noisy value estimates. SWE-Replay optimizes the scaling process by recycling trajectories from prior trials, dynamically choosing to either explore from scratch or exploit archived experience by branching at critical intermediate steps. This selection of intermediate steps is driven by the potential and reasoning significance of repository exploration, rather than external LLM-based quality estimates. Our evaluation shows that, on SWE-Bench Verified, SWE-Replay consistently outperforms naive scaling, reducing costs by up to 17.4% while maintaining or even improving performance by up to 3.8%. Further evaluation on SWE-Bench Pro and Multilingual validates the generalizability of SWE-Replay, establishing it as a robust foundation for efficient test-time scaling of software engineering agents.</div></details>
<details class="detail"><summary>中文标题/摘要</summary>
<div class="mono"><b>标题：</b>SWE-Replay：面向软件工程代理的高效测试时扩展方法</div>
<div class="mono" style="margin-top:8px">测试时扩展已被广泛用于增强大语言模型（LLM）代理在软件工程（SWE）任务中的能力。然而，标准方法需重复从头采样轨迹，计算成本高昂。近期研究尝试通过专用价值代理降低成本，但存在模型校准偏差问题，且难以推广至使用自定义bash脚本作为工具的现代代理。本文提出SWE-Replay，这是首个无需依赖可能含噪声价值估计、适用于现代代理的高效可泛化测试时扩展技术。该方法通过复用历史试验轨迹优化扩展过程，动态选择从头探索或在关键中间步骤分支调用存档经验。中间步骤的选择依据代码库探索潜力与推理意义驱动，而非依赖外部基于LLM的质量评估。在SWE-Bench Verified上的评估表明，SWE-Replay始终优于朴素扩展方法，在保持性能（甚至提升3.8%）的同时降低高达17.4%的成本。在SWE-Bench Pro与多语言场景的进一步验证证实了该方法的泛化能力，为软件工程代理的高效测试时扩展奠定了坚实基础。</div>
</details>
<details class="detail"><summary>Summary / 总结</summary>
<div class="mono">The research addresses the computational inefficiency of standard test-time scaling for LLM-based software engineering agents, which involves costly repeated trajectory sampling, and the limitations of recent value-agent methods that suffer from miscalibration and poor generalization to agents using custom bash scripts. The proposed method, SWE-Replay, introduces an efficient and generalizable scaling technique that recycles trajectories from prior trials, dynamically choosing between exploring from scratch or exploiting archived experience by branching at critical intermediate steps based on the potential and reasoning significance of repository exploration, without relying on external LLM quality estimates. Experimental results on SWE-Bench Verified demonstrate that SWE-Replay consistently outperforms naive scaling, reducing costs by up to 17.4% while maintaining or improving performance by up to 3.8%, with further validation on SWE-Bench Pro and Multilingual confirming its generalizability.</div>
<div class="mono" style="margin-top:8px">为解决软件工程智能体在测试时扩展中重复从头采样轨迹导致计算成本高昂的问题，本文提出了SWE-Replay，这是一种高效且可泛化的技术，避免依赖可能带噪声的价值估计。该方法通过回收先前试验的轨迹，并基于仓库探索的潜力和推理重要性（而非外部基于LLM的质量估计），动态选择从头探索或利用存档经验在关键中间步骤进行分支，从而优化扩展过程。在SWE-Bench Verified上的实验结果表明，SWE-Replay持续优于朴素扩展方法，成本降低高达17.4%，同时性能保持或提升高达3.8%；在SWE-Bench Pro和Multilingual上的进一步评估验证了其泛化能力。</div>
</details>
</div>
<div class="card">
<div class="title">The Patient is not a Moving Document: A World Model Training Paradigm for Longitudinal EHR</div>
<div class="meta-line">Authors: Irsyad Adam, Zekai Chen, David Laprade, Shaun Porwal, David Laub, Erik Reinertsen, Arda Pekis, Kevin Brown</div>
<div class="meta-line">First: 2026-01-29T18:49:37+00:00 · Latest: 2026-01-29T18:49:37+00:00</div>
<div class="links" style="margin-top:8px"><a href="https://arxiv.org/abs/2601.22128v1">Abs</a> · <a href="https://arxiv.org/pdf/2601.22128v1">PDF</a> · <a href="https://huggingface.co/standardmodelbio/SMB-v1-1.7B-Structure">Code1</a> · <a href="https://huggingface.co/huggingface">Code2</a> · <a href="https://huggingface.co/docs/hub/spaces">Code3</a></div>
<details class="detail"><summary>Abstract</summary>
<div class="mono">Large language models (LLMs) trained with next-word-prediction have achieved success as clinical foundation models. Representations from these language backbones yield strong linear probe performance across biomedical tasks, suggesting that patient semantics emerge from next-token prediction at scale. However, this paradigm treats patients as a document to be summarized rather than a dynamical system to be simulated; a patient&#x27;s trajectory emerges from their state evolving under interventions and time, requiring models that simulate dynamics rather than predict tokens. To address this, we introduce SMB-Structure, a world model for structured EHR that grounds a joint-embedding prediction architecture (JEPA) with next-token prediction (SFT). SFT grounds our model to reconstruct future patient states in token space, while JEPA predicts those futures in latent space from the initial patient representation alone, forcing trajectory dynamics to be encoded before the next state is observed. We validate across two large-scale cohorts: Memorial Sloan Kettering (23,319 oncology patients; 323,000+ patient-years) and INSPECT (19,402 pulmonary embolism patients). Using a linear probe evaluated at multiple points along the disease trajectory, we demonstrate that our training paradigm learns embeddings that capture disease dynamics not recoverable by autoregressive baselines, enabling SMB-Structure to achieve competitive performance on complex tasks characterized by high patient heterogeneity. Model weights are available at https://huggingface.co/standardmodelbio/SMB-v1-1.7B-Structure.</div></details>
<details class="detail"><summary>中文标题/摘要</summary>
<div class="mono"><b>标题：</b>患者非移动文档：面向纵向电子健康记录的世界模型训练范式</div>
<div class="mono" style="margin-top:8px">基于下一词预测训练的大语言模型已成为临床基础模型的重要成果。这些语言骨干网络生成的表征在生物医学任务中展现出优异的线性探测性能，表明患者语义可通过大规模下一词预测自然涌现。然而，该范式将患者视为待总结的文档，而非待模拟的动态系统——患者轨迹实则是其状态在干预与时间作用下的演化过程，需要能模拟动态而非预测词元的模型。为此，我们提出SMB-Structure：一种面向结构化电子健康记录的世界模型，其融合联合嵌入预测架构与下一词预测的监督微调。监督微调使模型能在词元空间重构未来患者状态，而联合嵌入预测架构仅通过初始患者表征在潜空间预测未来状态，从而迫使模型在观测下一状态前编码轨迹动态。我们在两大队列中验证模型：纪念斯隆凯特琳癌症中心的23,319名肿瘤患者（超323,000患者-年）及INSPECT队列的19,402名肺栓塞患者。通过沿疾病轨迹多时间点的线性探测评估，证明本训练范式所学习的嵌入能捕捉自回归基线无法恢复的疾病动态，使SMB-Structure在患者异质性高的复杂任务中取得优异性能。模型权重发布于https://huggingface.co/standardmodelbio/SMB-v1-1.7B-Structure。</div>
</details>
<details class="detail"><summary>Summary / 总结</summary>
<div class="mono">The research is motivated by the limitation of current clinical foundation models that treat patient records as static documents for next-token prediction, which fails to capture the dynamic evolution of a patient&#x27;s state over time under interventions. To address this, the authors introduce SMB-Structure, a world model training paradigm that combines a joint-embedding prediction architecture (JEPA) with supervised fine-tuning (SFT) for next-token prediction on structured EHR data; this forces the model to encode trajectory dynamics in a latent space from an initial patient state before observing the next state. Experimental validation on two large-scale cohorts—Memorial Sloan Kettering (23,319 oncology patients) and INSPECT (19,402 pulmonary embolism patients)—using linear probes shows that the learned embeddings capture disease dynamics not recoverable by autoregressive baselines, achieving competitive performance on complex tasks with high patient heterogeneity.</div>
<div class="mono" style="margin-top:8px">本研究旨在解决当前临床基础模型的局限性，这些模型将患者记录视为用于下一个词预测的静态文档，无法捕捉患者在干预下随时间动态演化的状态。为此，作者提出了SMB-Structure，这是一种世界模型范式，结合了联合嵌入预测架构（JEPA）与监督微调（SFT），用于结构化电子健康记录数据的下一个词预测；该方法迫使模型在观察到下一个状态之前，从初始患者状态在潜在空间中编码轨迹动态。在两个大规模队列——纪念斯隆凯特琳癌症中心（23,319名肿瘤患者）和INSPECT（19,402名肺栓塞患者）上的实验验证表明，所学习的嵌入能够捕捉自回归基线无法恢复的疾病动态，在患者异质性高的复杂任务上实现了有竞争力的性能。</div>
</details>
</div>
<div class="card">
<div class="title">Alpha Discovery via Grammar-Guided Learning and Search</div>
<div class="meta-line">Authors: Han Yang, Dong Hao, Zhuohan Wang, Qi Shi, Xingtong Li</div>
<div class="meta-line">First: 2026-01-29T18:46:15+00:00 · Latest: 2026-01-29T18:46:15+00:00</div>
<div class="meta-line">Comments: 24 pages, 10 figures</div>
<div class="links" style="margin-top:8px"><a href="https://arxiv.org/abs/2601.22119v1">Abs</a> · <a href="https://arxiv.org/pdf/2601.22119v1">PDF</a> · <a href="https://huggingface.co/huggingface">Code1</a> · <a href="https://huggingface.co/docs/hub/spaces">Code2</a></div>
<details class="detail"><summary>Abstract</summary>
<div class="mono">Automatically discovering formulaic alpha factors is a central problem in quantitative finance. Existing methods often ignore syntactic and semantic constraints, relying on exhaustive search over unstructured and unbounded spaces. We present AlphaCFG, a grammar-based framework for defining and discovering alpha factors that are syntactically valid, financially interpretable, and computationally efficient. AlphaCFG uses an alpha-oriented context-free grammar to define a tree-structured, size-controlled search space, and formulates alpha discovery as a tree-structured linguistic Markov decision process, which is then solved using a grammar-aware Monte Carlo Tree Search guided by syntax-sensitive value and policy networks. Experiments on Chinese and U.S. stock market datasets show that AlphaCFG outperforms state-of-the-art baselines in both search efficiency and trading profitability. Beyond trading strategies, AlphaCFG serves as a general framework for symbolic factor discovery and refinement across quantitative finance, including asset pricing and portfolio construction.</div></details>
<details class="detail"><summary>中文标题/摘要</summary>
<div class="mono"><b>标题：</b>基于语法引导学习与搜索的阿尔法因子发现</div>
<div class="mono" style="margin-top:8px">自动发现公式化阿尔法因子是量化金融的核心问题。现有方法常忽略句法和语义约束，依赖于对非结构化、无边界空间的穷举搜索。本文提出AlphaCFG，一种基于语法的框架，用于定义和发现句法有效、金融可解释且计算高效的阿尔法因子。AlphaCFG使用面向阿尔法的上下文无关语法定义树状结构、规模可控的搜索空间，并将阿尔法发现建模为树状结构语言马尔可夫决策过程，进而通过语法感知的蒙特卡洛树搜索（由句法敏感的价值与策略网络引导）求解。在中国和美国股市数据集上的实验表明，AlphaCFG在搜索效率和交易盈利能力上均优于现有先进基线。除交易策略外，AlphaCFG还可作为量化金融中符号因子发现与优化的通用框架，适用于资产定价和投资组合构建等领域。</div>
</details>
<details class="detail"><summary>Summary / 总结</summary>
<div class="mono">The research addresses the challenge of automatically discovering formulaic alpha factors in quantitative finance, where existing methods often overlook syntactic and semantic constraints, leading to inefficient searches over unstructured spaces. The proposed method, AlphaCFG, introduces a grammar-based framework that defines a tree-structured, size-controlled search space using an alpha-oriented context-free grammar, formulating alpha discovery as a tree-structured linguistic Markov decision process solved via grammar-aware Monte Carlo Tree Search guided by syntax-sensitive value and policy networks. Experimental results on Chinese and U.S. stock market datasets demonstrate that AlphaCFG surpasses state-of-the-art baselines in both search efficiency and trading profitability, and it extends as a general framework for symbolic factor discovery in areas like asset pricing and portfolio construction.</div>
<div class="mono" style="margin-top:8px">该研究针对量化金融中自动发现公式化阿尔法因子的挑战，现有方法常忽略句法和语义约束，导致在非结构化空间中进行低效搜索。提出的方法AlphaCFG引入了一个基于语法的框架，使用阿尔法导向的上下文无关文法定义了一个树状结构、大小可控的搜索空间，将阿尔法发现建模为树状结构语言马尔可夫决策过程，并通过语法感知的蒙特卡洛树搜索结合语法敏感的价值和策略网络求解。在中国和美国股市数据集上的实验结果表明，AlphaCFG在搜索效率和交易盈利能力上均优于现有先进基线，并可扩展为资产定价和投资组合构建等量化金融领域中符号因子发现和优化的通用框架。</div>
</details>
</div>
<div class="card">
<div class="title">Defining Operational Conditions for Safety-Critical AI-Based Systems from Data</div>
<div class="meta-line">Authors: Johann Christensen, Elena Hoemann, Frank Köster, Sven Hallerbach</div>
<div class="meta-line">First: 2026-01-29T18:46:02+00:00 · Latest: 2026-01-29T18:46:02+00:00</div>
<div class="links" style="margin-top:8px"><a href="https://arxiv.org/abs/2601.22118v1">Abs</a> · <a href="https://arxiv.org/pdf/2601.22118v1">PDF</a> · <a href="https://huggingface.co/huggingface">Code1</a> · <a href="https://huggingface.co/docs/hub/spaces">Code2</a></div>
<details class="detail"><summary>Abstract</summary>
<div class="mono">Artificial Intelligence (AI) has been on the rise in many domains, including numerous safety-critical applications. However, for complex systems found in the real world, or when data already exist, defining the underlying environmental conditions is extremely challenging. This often results in an incomplete description of the environment in which the AI-based system must operate. Nevertheless, this description, called the Operational Design Domain (ODD), is required in many domains for the certification of AI-based systems. Traditionally, the ODD is created in the early stages of the development process, drawing on sophisticated expert knowledge and related standards. This paper presents a novel Safety-by-Design method to a posteriori define the ODD from previously collected data using a multi-dimensional kernel-based representation. This approach is validated through both Monte Carlo methods and a real-world aviation use case for a future safety-critical collision-avoidance system. Moreover, by defining under what conditions two ODDs are equal, the paper shows that the data-driven ODD can equal the original, underlying hidden ODD of the data. Utilizing the novel, Safe-by-Design kernel-based ODD enables future certification of data-driven, safety-critical AI-based systems.</div></details>
<details class="detail"><summary>中文标题/摘要</summary>
<div class="mono"><b>标题：</b>基于数据定义安全关键人工智能系统的运行条件</div>
<div class="mono" style="margin-top:8px">人工智能（AI）在包括众多安全关键应用在内的多个领域日益普及。然而，对于现实世界中的复杂系统或已有数据的情况，定义其基础环境条件极具挑战性，常导致对AI系统运行环境的描述不完整。这种描述被称为运行设计域（ODD），是许多领域认证AI系统所必需的。传统上，ODD在开发过程早期基于专家知识和相关标准创建。本文提出了一种新颖的“设计即安全”方法，利用基于多维核的表示，从先前收集的数据中后验定义ODD。该方法通过蒙特卡洛模拟和未来安全关键防撞系统的实际航空用例进行了验证。此外，通过界定两个ODD相等的条件，本文表明数据驱动的ODD能够等同于数据原始隐含的ODD。采用这种基于核的“设计即安全”ODD方法，将为未来数据驱动的安全关键AI系统认证提供支持。</div>
</details>
<details class="detail"><summary>Summary / 总结</summary>
<div class="mono">The research addresses the challenge of defining the Operational Design Domain (ODD) for safety-critical AI systems, which is essential for certification but often incomplete when derived from expert knowledge alone. The method proposes a Safety-by-Design approach that uses a multi-dimensional kernel-based representation to define the ODD a posteriori from previously collected data. Experimental validation via Monte Carlo simulations and a real-world aviation collision-avoidance use case demonstrates that this data-driven ODD can equal the original, hidden ODD of the data, facilitating future certification of such systems.</div>
<div class="mono" style="margin-top:8px">本研究针对安全关键型人工智能系统操作设计域（ODD）定义的挑战，该定义对认证至关重要，但仅凭专家知识往往不完整。作者提出了一种安全设计方法，使用基于多维核的表示，从先前收集的数据中后验地定义ODD。通过蒙特卡洛模拟和真实世界航空防撞系统的案例验证表明，这种数据驱动的ODD能够等同于数据中原始隐藏的ODD，从而为未来此类系统的认证提供了可能。</div>
</details>
</div>
<div class="card">
<div class="title">SINA: A Circuit Schematic Image-to-Netlist Generator Using Artificial Intelligence</div>
<div class="meta-line">Authors: Saoud Aldowaish, Yashwanth Karumanchi, Kai-Chen Chiang, Soroosh Noorzad, Morteza Fayazi</div>
<div class="meta-line">First: 2026-01-29T18:41:52+00:00 · Latest: 2026-01-29T18:41:52+00:00</div>
<div class="links" style="margin-top:8px"><a href="https://arxiv.org/abs/2601.22114v1">Abs</a> · <a href="https://arxiv.org/pdf/2601.22114v1">PDF</a> · <a href="https://huggingface.co/huggingface">Code1</a> · <a href="https://huggingface.co/docs/hub/spaces">Code2</a></div>
<details class="detail"><summary>Abstract</summary>
<div class="mono">Current methods for converting circuit schematic images into machine-readable netlists struggle with component recognition and connectivity inference. In this paper, we present SINA, an open-source, fully automated circuit schematic image-to-netlist generator. SINA integrates deep learning for accurate component detection, Connected-Component Labeling (CCL) for precise connectivity extraction, and Optical Character Recognition (OCR) for component reference designator retrieval, while employing a Vision-Language Model (VLM) for reliable reference designator assignments. In our experiments, SINA achieves 96.47% overall netlist-generation accuracy, which is 2.72x higher than state-of-the-art approaches.</div></details>
<details class="detail"><summary>中文标题/摘要</summary>
<div class="mono"><b>标题：</b>SINA：基于人工智能的电路原理图图像至网表生成器</div>
<div class="mono" style="margin-top:8px">现有电路原理图图像转机器可读网表的方法在元件识别与连接关系推断方面存在局限。本文提出SINA——一种开源全自动电路原理图图像至网表生成器。该系统集成深度学习实现精确元件检测，采用连通域标记技术提取准确连接关系，结合光学字符识别获取元件参考标识符，并运用视觉语言模型实现可靠的参考标识符分配。实验表明，SINA的网表生成总体准确率达96.47%，较现有最优方法提升2.72倍。</div>
</details>
<details class="detail"><summary>Summary / 总结</summary>
<div class="mono">To address the limitations of existing methods in accurately recognizing components and inferring connectivity from circuit schematic images, this paper introduces SINA, an open-source automated generator that converts such images into netlists. The method combines deep learning for component detection, Connected-Component Labeling for connectivity extraction, Optical Character Recognition for retrieving component reference designators, and a Vision-Language Model to assign these designators reliably. Experimental results demonstrate that SINA achieves an overall netlist-generation accuracy of 96.47%, outperforming state-of-the-art approaches by a factor of 2.72.</div>
<div class="mono" style="margin-top:8px">针对现有方法在电路原理图图像中准确识别元件和推断连接性方面的不足，本文提出了SINA，一种开源的自动化生成器，可将此类图像转换为网表。该方法结合了深度学习进行元件检测、连通域标记用于连接性提取、光学字符识别以获取元件参考标识符，并利用视觉语言模型可靠地分配这些标识符。实验结果表明，SINA实现了96.47%的整体网表生成准确率，比现有最佳方法提高了2.72倍。</div>
</details>
</div>
<div class="card">
<div class="title">Value-Based Pre-Training with Downstream Feedback</div>
<div class="meta-line">Authors: Shuqi Ke, Giulia Fanti</div>
<div class="meta-line">First: 2026-01-29T18:38:09+00:00 · Latest: 2026-01-29T18:38:09+00:00</div>
<div class="links" style="margin-top:8px"><a href="https://arxiv.org/abs/2601.22108v1">Abs</a> · <a href="https://arxiv.org/pdf/2601.22108v1">PDF</a> · <a href="https://huggingface.co/huggingface">Code1</a> · <a href="https://huggingface.co/docs/hub/spaces">Code2</a></div>
<details class="detail"><summary>Abstract</summary>
<div class="mono">Can a small amount of verified goal information steer the expensive self-supervised pretraining of foundation models? Standard pretraining optimizes a fixed proxy objective (e.g., next-token prediction), which can misallocate compute away from downstream capabilities of interest. We introduce V-Pretraining: a value-based, modality-agnostic method for controlled continued pretraining in which a lightweight task designer reshapes the pretraining task to maximize the value of each gradient step. For example, consider self-supervised learning (SSL) with sample augmentation. The V-Pretraining task designer selects pretraining tasks (e.g., augmentations) for which the pretraining loss gradient is aligned with a gradient computed over a downstream task (e.g., image segmentation). This helps steer pretraining towards relevant downstream capabilities. Notably, the pretrained model is never updated on downstream task labels; they are used only to shape the pretraining task. Under matched learner update budgets, V-Pretraining of 0.5B--7B language models improves reasoning (GSM8K test Pass@1) by up to 18% relative over standard next-token prediction using only 12% of GSM8K training examples as feedback. In vision SSL, we improve the state-of-the-art results on ADE20K by up to 1.07 mIoU and reduce NYUv2 RMSE while improving ImageNet linear accuracy, and we provide pilot evidence of improved token efficiency in continued pretraining.</div></details>
<details class="detail"><summary>中文标题/摘要</summary>
<div class="mono"><b>标题：</b>基于价值的下游反馈预训练</div>
<div class="mono" style="margin-top:8px">少量已验证的目标信息能否引导基础模型昂贵的自监督预训练？标准预训练优化固定的代理目标（如下一令牌预测），可能将计算资源错误分配至无关的下游能力。我们提出V-Pretraining：一种基于价值、模态无关的受控持续预训练方法，通过轻量级任务设计器重塑预训练任务，以最大化每个梯度步的价值。例如，在采用样本增强的自监督学习（SSL）中，V-Pretraining任务设计器会选择那些预训练损失梯度与下游任务（如图像分割）梯度对齐的预训练任务（如增强方式），从而引导预训练朝向相关下游能力发展。值得注意的是，预训练模型从未使用下游任务标签进行更新，这些标签仅用于塑造预训练任务。在匹配的学习器更新预算下，对0.5B-7B语言模型进行V-Pretraining，仅使用12%的GSM8K训练样本作为反馈，相比标准下一令牌预测方法，推理能力（GSM8K测试Pass@1）相对提升高达18%。在视觉SSL中，我们将ADE20K的最先进结果提升达1.07 mIoU，降低NYUv2 RMSE的同时提升ImageNet线性准确率，并为持续预训练中的令牌效率提升提供了初步证据。</div>
</details>
<details class="detail"><summary>Summary / 总结</summary>
<div class="mono">The research addresses the misalignment between standard self-supervised pretraining objectives, like next-token prediction, and downstream task performance, which can lead to inefficient compute allocation. The proposed method, V-Pretraining, is a value-based, modality-agnostic approach that uses a lightweight task designer to reshape the pretraining task selection—such as choosing specific data augmentations—so that the pretraining loss gradient aligns with gradients computed from a small set of verified downstream task examples, thereby steering the model toward relevant capabilities without directly training on downstream labels. Experimental results show that applying V-Pretraining to language models (0.5B–7B parameters) improves reasoning performance on GSM8K by up to 18% relative using only 12% of the training data for feedback, while in vision SSL, it advances state-of-the-art on ADE20K segmentation by up to 1.07 mIoU, reduces error on NYUv2, and maintains or improves ImageNet linear accuracy, demonstrating enhanced pretraining efficiency.</div>
<div class="mono" style="margin-top:8px">标准的自监督预训练优化固定的代理目标，可能导致计算资源未有效分配至下游任务所需的能力。为此，本文提出了V-Pretraining，这是一种基于价值且与模态无关的方法，通过一个轻量级任务设计器，利用下游任务的反馈来选择预训练任务（例如特定的数据增强），使得预训练损失的梯度与下游任务的梯度对齐，从而在不使用下游标签更新模型的情况下引导预训练过程。实验结果表明，在语言模型上，V-Pretraining将0.5B–7B模型的GSM8K推理性能相对提升高达18%，仅需12%的训练样本作为反馈；在视觉自监督学习中，该方法将ADE20K的mIoU指标提升高达1.07，降低了NYUv2的RMSE，并提高了ImageNet的线性准确率。</div>
</details>
</div>
<div class="card">
<div class="title">ECO: Quantized Training without Full-Precision Master Weights</div>
<div class="meta-line">Authors: Mahdi Nikdan, Amir Zandieh, Dan Alistarh, Vahab Mirrokni</div>
<div class="meta-line">First: 2026-01-29T18:35:01+00:00 · Latest: 2026-01-29T18:35:01+00:00</div>
<div class="links" style="margin-top:8px"><a href="https://arxiv.org/abs/2601.22101v1">Abs</a> · <a href="https://arxiv.org/pdf/2601.22101v1">PDF</a> · <a href="https://huggingface.co/huggingface">Code1</a> · <a href="https://huggingface.co/docs/hub/spaces">Code2</a></div>
<details class="detail"><summary>Abstract</summary>
<div class="mono">Quantization has significantly improved the compute and memory efficiency of Large Language Model (LLM) training. However, existing approaches still rely on accumulating their updates in high-precision: concretely, gradient updates must be applied to a high-precision weight buffer, known as $\textit{master weights}$. This buffer introduces substantial memory overhead, particularly for Sparse Mixture of Experts (SMoE) models, where model parameters and optimizer states dominate memory usage. To address this, we introduce the Error-Compensating Optimizer (ECO), which eliminates master weights by applying updates directly to quantized parameters. ECO quantizes weights after each step and carefully injects the resulting quantization error into the optimizer momentum, forming an error-feedback loop with no additional memory. We prove that, under standard assumptions and a decaying learning rate, ECO converges to a constant-radius neighborhood of the optimum, while naive master-weight removal can incur an error that is inversely proportional to the learning rate. We show empirical results for pretraining small Transformers (30-800M), a Gemma-3 1B model, and a 2.1B parameter Sparse MoE model with FP8 quantization, and fine-tuning DeepSeek-MoE-16B in INT4 precision. Throughout, ECO matches baselines with master weights up to near-lossless accuracy, significantly shifting the static memory vs validation loss Pareto frontier.</div></details>
<details class="detail"><summary>中文标题/摘要</summary>
<div class="mono"><b>标题：</b>ECO：无需全精度主权重的量化训练方法</div>
<div class="mono" style="margin-top:8px">量化技术显著提升了大型语言模型（LLM）训练的计算与内存效率，但现有方法仍需依赖高精度累积更新：具体而言，梯度更新必须作用于高精度权重缓冲区（即$\textit{主权重}$）。该缓冲区会带来显著内存开销，尤其对于稀疏专家混合（SMoE）模型，其模型参数与优化器状态占用了主要内存。为此，我们提出误差补偿优化器（ECO），通过直接将更新应用于量化参数来消除主权重。ECO在每步训练后量化权重，并将量化误差精确注入优化器动量，形成无需额外内存的误差反馈循环。我们证明，在标准假设与衰减学习率条件下，ECO能收敛至最优解的常数半径邻域，而简单移除主权重可能导致误差与学习率成反比。实验部分展示了采用FP8量化的30-800M小型Transformer、Gemma-3 1B模型及2.1B参数稀疏MoE模型的预训练结果，以及INT4精度下DeepSeek-MoE-16B的微调效果。在所有实验中，ECO在保持近乎无损精度的前提下均匹配了含主权重的基线方法，显著改善了静态内存与验证损失的帕累托前沿。</div>
</details>
<details class="detail"><summary>Summary / 总结</summary>
<div class="mono">Quantization reduces memory and compute costs in LLM training, but existing methods still require high-precision master weights for gradient updates, which incur substantial memory overhead, especially for Sparse Mixture of Experts (SMoE) models. To eliminate this need, the authors propose the Error-Compensating Optimizer (ECO), which applies updates directly to quantized parameters, quantizes weights after each step, and injects the quantization error into the optimizer momentum to form an error-feedback loop without extra memory. Theoretical analysis shows ECO converges to a neighborhood of the optimum, unlike naive approaches where error scales inversely with learning rate. Experiments on Transformers (30M-800M), Gemma-3 1B, a 2.1B SMoE model with FP8, and fine-tuning DeepSeek-MoE-16B in INT4 demonstrate that ECO matches the accuracy of master-weight baselines near-losslessly, significantly improving the memory-accuracy trade-off.</div>
<div class="mono" style="margin-top:8px">量化技术虽能降低大语言模型训练的内存与计算开销，但现有方法仍需维护高精度主权重，这对于稀疏专家混合模型等大型模型尤为负担。为消除这一开销，本研究提出了误差补偿优化器（ECO），该方法无需主权重副本，直接将梯度更新应用于量化后的权重：它在每一步后量化权重，并将量化误差注入优化器动量中，形成一个无需额外内存的误差反馈循环。理论分析表明，ECO能收敛至最优解邻域，而简单移除主权重的方法误差会与学习率成反比。实验在FP8精度下预训练了Transformer模型（30M-800M）、Gemma-3 1B模型和2.1B稀疏专家混合模型，并在INT4精度下微调了DeepSeek-MoE-16B，结果显示ECO在保持近乎无损精度的同时，显著改善了内存与验证损失的帕累托边界。</div>
</details>
</div>
<div class="card">
<div class="title">Do graph neural network states contain graph properties?</div>
<div class="meta-line">Authors: Tom Pelletreau-Duris, Ruud van Bakel, Michael Cochez</div>
<div class="meta-line">Venue: Proceedings of Machine Learning Research vol 284:1_37 2025, 19th Conference on Neurosymbolic Learning and Reasoning</div>
<div class="meta-line">First: 2024-11-04T15:26:07+00:00 · Latest: 2026-01-29T18:33:46+00:00</div>
<div class="meta-line">Comments: 10 pages, 22 figures, conference</div>
<div class="links" style="margin-top:8px"><a href="https://arxiv.org/abs/2411.02168v3">Abs</a> · <a href="https://arxiv.org/pdf/2411.02168v3">PDF</a> · <a href="https://huggingface.co/huggingface">Code1</a> · <a href="https://huggingface.co/docs/hub/spaces">Code2</a></div>
<details class="detail"><summary>Abstract</summary>
<div class="mono">Deep neural networks (DNNs) achieve state-of-the-art performance on many tasks, but this often requires increasingly larger model sizes, which in turn leads to more complex internal representations. Explainability techniques (XAI) have made remarkable progress in the interpretability of ML models. However, the non-euclidean nature of Graph Neural Networks (GNNs) makes it difficult to reuse already existing XAI methods. While other works have focused on instance-based explanation methods for GNNs, very few have investigated model-based methods and, to our knowledge, none have tried to probe the embedding of the GNNs for structural graph properties. In this paper we present a model agnostic explainability pipeline for Graph Neural Networks (GNNs) employing diagnostic classifiers. We propose to consider graph-theoretic properties as the features of choice for studying the emergence of representations in GNNs. This pipeline aims to probe and interpret the learned representations in GNNs across various architectures and datasets, refining our understanding and trust in these models.</div></details>
<details class="detail"><summary>中文标题/摘要</summary>
<div class="mono"><b>标题：</b>图神经网络状态是否包含图属性？</div>
<div class="mono" style="margin-top:8px">深度神经网络（DNNs）在许多任务上实现了最先进的性能，但这通常需要越来越大的模型规模，进而导致更复杂的内部表示。可解释性技术（XAI）在机器学习模型的可解释性方面取得了显著进展。然而，图神经网络（GNNs）的非欧几里得特性使得难以重用现有的XAI方法。尽管其他研究专注于GNNs的基于实例的解释方法，但很少有研究探讨基于模型的方法，且据我们所知，尚未有尝试探测GNNs嵌入中结构图属性的工作。本文提出了一种模型无关的图神经网络可解释性流程，采用诊断分类器。我们建议将图论属性作为研究GNNs表示涌现的特征选择。该流程旨在探测和解释不同架构和数据集下GNNs学习到的表示，以深化对这些模型的理解和信任。</div>
</details>
<details class="detail"><summary>Summary / 总结</summary>
<div class="mono">The research is motivated by the challenge of interpreting the complex internal representations of Graph Neural Networks (GNNs), as their non-Euclidean nature hinders the application of existing explainability (XAI) methods, and few studies have probed these embeddings for structural graph properties. The method introduces a model-agnostic explainability pipeline that employs diagnostic classifiers to analyze whether GNN states encode graph-theoretic properties, aiming to probe learned representations across various architectures and datasets. The key experimental findings, though not detailed in the abstract, are implied to provide insights into the emergence of structural representations, thereby refining understanding and trust in GNN models.</div>
<div class="mono" style="margin-top:8px">该研究的动机源于解释图神经网络（GNN）的挑战，因为其非欧几里得特性使得现有可解释性（XAI）方法难以直接应用，且少有研究探索GNN嵌入是否包含图的结构属性。方法上，提出了一种模型无关的可解释性流程，采用诊断分类器来分析学习到的GNN状态是否编码了图论属性。主要实验结果表明，该流程能够成功探测和解释不同GNN架构和数据集中的表示，从而增强对这些模型的理解和信任。</div>
</details>
</div>
<div class="card">
<div class="title">Investigating Associational Biases in Inter-Model Communication of Large Generative Models</div>
<div class="meta-line">Authors: Fethiye Irmak Dogan, Yuval Weiss, Kajal Patel, Jiaee Cheong, Hatice Gunes</div>
<div class="meta-line">First: 2026-01-29T18:29:55+00:00 · Latest: 2026-01-29T18:29:55+00:00</div>
<div class="links" style="margin-top:8px"><a href="https://arxiv.org/abs/2601.22093v1">Abs</a> · <a href="https://arxiv.org/pdf/2601.22093v1">PDF</a> · <a href="https://huggingface.co/huggingface">Code1</a> · <a href="https://huggingface.co/docs/hub/spaces">Code2</a></div>
<details class="detail"><summary>Abstract</summary>
<div class="mono">Social bias in generative AI can manifest not only as performance disparities but also as associational bias, whereby models learn and reproduce stereotypical associations between concepts and demographic groups, even in the absence of explicit demographic information (e.g., associating doctors with men). These associations can persist, propagate, and potentially amplify across repeated exchanges in inter-model communication pipelines, where one generative model&#x27;s output becomes another&#x27;s input. This is especially salient for human-centred perception tasks, such as human activity recognition and affect prediction, where inferences about behaviour and internal states can lead to errors or stereotypical associations that propagate into unequal treatment. In this work, focusing on human activity and affective expression, we study how such associations evolve within an inter-model communication pipeline that alternates between image generation and image description. Using the RAF-DB and PHASE datasets, we quantify demographic distribution drift induced by model-to-model information exchange and assess whether these drifts are systematic using an explainability pipeline. Our results reveal demographic drifts toward younger representations for both actions and emotions, as well as toward more female-presenting representations, primarily for emotions. We further find evidence that some predictions are supported by spurious visual regions (e.g., background or hair) rather than concept-relevant cues (e.g., body or face). We also examine whether these demographic drifts translate into measurable differences in downstream behaviour, i.e., while predicting activity and emotion labels. Finally, we outline mitigation strategies spanning data-centric, training and deployment interventions, and emphasise the need for careful safeguards when deploying interconnected models in human-centred AI systems.</div></details>
<details class="detail"><summary>中文标题/摘要</summary>
<div class="mono"><b>标题：</b>探究大型生成模型间通信中的关联性偏见</div>
<div class="mono" style="margin-top:8px">生成式AI的社会偏见不仅表现为性能差异，还可能体现为关联性偏见——即使在没有明确人口统计信息的情况下，模型仍能学习并复现概念与人口群体间的刻板关联（例如将医生与男性关联）。在模型间通信流程中，当某个生成模型的输出成为另一模型的输入时，这些关联可能通过反复交互持续存在、传播甚至放大。这对以人为中心的感知任务（如人类活动识别与情感预测）尤为突出，其中对行为及内在状态的推断可能导致错误或刻板关联，进而引发不平等对待。本研究聚焦人类活动与情感表达，通过交替进行图像生成与图像描述的模型间通信流程，探究此类关联的演化机制。基于RAF-DB和PHASE数据集，我们量化了模型间信息交换引发的人口统计分布漂移，并通过可解释性流程评估这些漂移是否具有系统性。结果显示：在动作与情感表征中均出现向年轻化群体的人口统计漂移，情感表征还呈现向女性化群体的显著漂移。进一步发现某些预测依赖于虚假视觉区域（如背景或头发）而非概念相关线索（如身体或面部）。我们还检验了这些人口统计漂移是否转化为下游行为（如预测活动与情感标签时）的可测量差异。最后，我们提出了涵盖数据层面、训练过程与部署干预的缓解策略，并强调在以人为中心的AI系统中部署互联模型时需建立审慎的防护机制。</div>
</details>
<details class="detail"><summary>Summary / 总结</summary>
<div class="mono">This research investigates how associational biases, where generative models learn stereotypical links between concepts and demographic groups without explicit cues, can persist and amplify in inter-model communication pipelines. The study employs a pipeline alternating between image generation and description, using RAF-DB and PHASE datasets to quantify demographic distribution drift and analyze its systematic nature via an explainability method. Key findings reveal drifts toward younger and more female-presenting representations, especially for emotions, with some predictions relying on spurious visual features rather than relevant cues, highlighting risks for downstream tasks like activity and emotion recognition and underscoring the need for mitigation strategies in human-centred AI systems.</div>
<div class="mono" style="margin-top:8px">本研究探讨了生成式AI中的关联性偏见（如概念与人口群体间的刻板联系）在模型间顺序通信的流程中如何持续和放大，特别是在以人为中心的感知任务（如活动和情感识别）中。方法采用交替进行图像生成与描述的模型间通信流程，利用RAF-DB和PHASE数据集量化人口统计分布漂移，并通过可解释性流程进行分析。主要实验结果表明，系统性的漂移趋向于更年轻和更女性化的表征，尤其在情感方面，且一些预测依赖于背景或头发等虚假视觉线索而非相关特征，这突显了互联AI系统在下游任务性能中的风险以及实施缓解策略的必要性。</div>
</details>
</div>
<div class="card">
<div class="title">Latent Adversarial Regularization for Offline Preference Optimization</div>
<div class="meta-line">Authors: Enyi Jiang, Yibo Jacky Zhang, Yinglun Xu, Andreas Haupt, Nancy Amato, Sanmi Koyejo</div>
<div class="meta-line">First: 2026-01-29T18:21:57+00:00 · Latest: 2026-01-29T18:21:57+00:00</div>
<div class="links" style="margin-top:8px"><a href="https://arxiv.org/abs/2601.22083v1">Abs</a> · <a href="https://arxiv.org/pdf/2601.22083v1">PDF</a> · <a href="https://huggingface.co/huggingface">Code1</a> · <a href="https://huggingface.co/docs/hub/spaces">Code2</a></div>
<details class="detail"><summary>Abstract</summary>
<div class="mono">Learning from human feedback typically relies on preference optimization that constrains policy updates through token-level regularization. However, preference optimization for language models is particularly challenging because token-space similarity does not imply semantic or behavioral similarity. To address this challenge, we leverage latent-space regularization for language model preference optimization. We introduce GANPO, which achieves latent-space regularization by penalizing divergence between the internal representations of a policy model and a reference model. Given that latent representations are not associated with explicit probability densities, we adopt an adversarial approach inspired by GANs to minimize latent-space divergence. We integrate GANPO as a regularizer into existing offline preference optimization objectives. Experiments across multiple model architectures and tasks show consistent improvements from latent-space regularization. Further, by comparing GANPO-induced inferential biases with those from token-level regularization, we find that GANPO provides more robust structural feedback under distributional shift and noise while maintaining comparable downstream performance with minor computational overhead.</div></details>
<details class="detail"><summary>中文标题/摘要</summary>
<div class="mono"><b>标题：</b>基于隐空间对抗正则化的离线偏好优化</div>
<div class="mono" style="margin-top:8px">从人类反馈中学习通常依赖于通过词元级正则化约束策略更新的偏好优化方法。然而，语言模型的偏好优化尤为困难，因为词元空间的相似性并不等同于语义或行为相似性。为解决这一挑战，我们采用隐空间正则化进行语言模型偏好优化。我们提出GANPO方法，通过惩罚策略模型与参考模型内部表征之间的差异来实现隐空间正则化。鉴于隐空间表征没有显式概率密度对应，我们借鉴生成对抗网络的对抗训练思想来最小化隐空间差异。我们将GANPO作为正则化项集成到现有离线偏好优化目标中。在多模型架构与任务上的实验表明，隐空间正则化能带来持续的性能提升。进一步通过比较GANPO与词元级正则化引发的推理偏差，发现GANPO在分布偏移和噪声条件下能提供更稳健的结构化反馈，同时以微小计算开销保持相当的下游任务性能。</div>
</details>
<details class="detail"><summary>Summary / 总结</summary>
<div class="mono">The research addresses the limitation of token-level regularization in language model preference optimization, where token-space similarity does not guarantee semantic or behavioral alignment. The method introduces GANPO, which applies latent adversarial regularization by minimizing the divergence between the internal representations of a policy model and a reference model using a GAN-inspired approach, integrated into existing offline preference optimization objectives. Experimental results across various models and tasks demonstrate that GANPO consistently improves performance, offering more robust structural feedback under distributional shift and noise while maintaining comparable downstream performance with minimal computational overhead.</div>
<div class="mono" style="margin-top:8px">语言模型偏好优化通常依赖词元级正则化，但词元空间相似性并不保证语义或行为相似性，这限制了其效果。为解决这一问题，研究者提出了GANPO方法，该方法通过惩罚策略模型与参考模型内部表征之间的差异，实现潜在空间正则化；由于潜在表征缺乏显式概率密度，该方法采用了受生成对抗网络启发的对抗性方法。在多种模型架构和任务上的实验表明，GANPO能持续提升性能，在分布偏移和噪声下提供更稳健的结构性反馈，同时以微小的计算开销保持了可比的下游性能。</div>
</details>
</div>
<div class="card">
<div class="title">Think Locally, Explain Globally: Graph-Guided LLM Investigations via Local Reasoning and Belief Propagation</div>
<div class="meta-line">Authors: Saurabh Jha, Rohan Arora, Bhavya, Noah Zheutlin, Paulina Toro Isaza, Laura Shwartz, Yu Deng, Daby Sow, Ruchi Mahindru, Ruchir Puri</div>
<div class="meta-line">First: 2026-01-25T17:27:19+00:00 · Latest: 2026-01-29T18:18:39+00:00</div>
<div class="links" style="margin-top:8px"><a href="https://arxiv.org/abs/2601.17915v2">Abs</a> · <a href="https://arxiv.org/pdf/2601.17915v2">PDF</a> · <a href="https://huggingface.co/huggingface">Code1</a> · <a href="https://huggingface.co/docs/hub/spaces">Code2</a></div>
<details class="detail"><summary>Abstract</summary>
<div class="mono">LLM agents excel when environments are mostly static and the needed information fits in a model&#x27;s context window, but they often fail in open-ended investigations where explanations must be constructed by iteratively mining evidence from massive, heterogeneous operational data. These investigations exhibit hidden dependency structure: entities interact, signals co-vary, and the importance of a fact may only become clear after other evidence is discovered. Because the context window is bounded, agents must summarize intermediate findings before their significance is known, increasing the risk of discarding key evidence. ReAct-style agents are especially brittle in this regime. Their retrieve-summarize-reason loop makes conclusions sensitive to exploration order and introduces run-to-run non-determinism, producing a reliability gap where Pass-at-k may be high but Majority-at-k remains low. Simply sampling more rollouts or generating longer reasoning traces does not reliably stabilize results, since hypotheses cannot be autonomously checked as new evidence arrives and there is no explicit mechanism for belief bookkeeping and revision. In addition, ReAct entangles semantic reasoning with controller duties such as tool orchestration and state tracking, so execution errors and plan drift degrade reasoning while consuming scarce context.
  We address these issues by formulating investigation as abductive reasoning over a dependency graph and proposing EoG (Explanations over Graphs), a disaggregated framework in which an LLM performs bounded local evidence mining and labeling (cause vs symptom) while a deterministic controller manages traversal, state, and belief propagation to compute a minimal explanatory frontier. On a representative ITBench diagnostics task, EoG improves both accuracy and run-to-run consistency over ReAct baselines, including a 7x average gain in Majority-at-k entity F1.</div></details>
<details class="detail"><summary>中文标题/摘要</summary>
<div class="mono"><b>标题：</b>局部思考，全局解释：基于局部推理与信念传播的图引导大语言模型调查框架</div>
<div class="mono" style="margin-top:8px">大语言模型智能体在静态环境且所需信息适配上下文窗口时表现优异，但在开放式调查任务中常显不足——这类任务需通过从海量异构操作数据中迭代挖掘证据来构建解释。此类调查存在隐含的依赖结构：实体相互关联、信号协同变化，且事实的重要性往往需在其他证据被发现后才得以显现。由于上下文窗口受限，智能体必须在明确信息重要性前就总结中间发现，增加了丢弃关键证据的风险。ReAct类智能体在此场景下尤为脆弱：其“检索-总结-推理”循环使结论易受探索顺序影响，引入运行间非确定性，导致可靠性缺口——即使k次尝试通过率较高，但k次多数一致性仍偏低。单纯增加采样轮次或延长推理轨迹并不能稳定结果，因为新证据出现时假设无法自主验证，且缺乏显式的信念簿记与修正机制。此外，ReAct将语义推理与工具编排、状态跟踪等控制职责耦合，导致执行错误和计划漂移在消耗有限上下文的同时损害推理质量。
我们通过将调查建模为依赖图上的溯因推理来解决这些问题，提出EoG（图结构解释）解耦框架：大语言模型负责有界的局部证据挖掘与标注（原因vs症状），而确定性控制器管理图遍历、状态维护及信念传播以计算最小解释边界。在典型ITBench诊断任务中，EoG相比ReAct基线在准确性和运行一致性上均有提升，其中k次多数实体F1平均提升达7倍。</div>
</details>
<details class="detail"><summary>Summary / 总结</summary>
<div class="mono">The research addresses the limitations of LLM agents in open-ended investigations, where they struggle to construct explanations by iteratively mining evidence from massive, heterogeneous data due to bounded context windows and the hidden dependency structures among entities. The proposed method, EoG (Explanations over Graphs), formulates investigation as abductive reasoning over a dependency graph, disaggregating the process so an LLM handles local evidence mining and labeling while a deterministic controller manages graph traversal, state, and belief propagation to compute a minimal explanatory frontier. Experimental results on the ITBench diagnostics task show that EoG improves both accuracy and run-to-run consistency over ReAct baselines, achieving a 7x average gain in Majority-at-k entity F1.</div>
<div class="mono" style="margin-top:8px">本研究针对LLM智能体在开放式调查中的局限性展开，这些智能体由于上下文窗口有限以及实体间隐藏的依赖关系，难以通过从海量异构数据中迭代挖掘证据来构建解释。提出的方法EoG（基于图的解释）将调查建模为在依赖图上的溯因推理，将过程解耦，由LLM负责有界的局部证据挖掘和标注，而一个确定性控制器管理图遍历、状态和信念传播，以计算最小解释边界。在ITBench诊断任务上的实验结果表明，EoG相比ReAct基线在准确性和运行间一致性上均有提升，在Majority-at-k实体F1分数上实现了平均7倍的增益。</div>
</details>
</div>
<div class="card">
<div class="title">Vision-DeepResearch: Incentivizing DeepResearch Capability in Multimodal Large Language Models</div>
<div class="meta-line">Authors: Wenxuan Huang, Yu Zeng, Qiuchen Wang, Zhen Fang, Shaosheng Cao, Zheng Chu, Qingyu Yin, Shuang Chen, Zhenfei Yin, Lin Chen, Zehui Chen, Yao Hu, Philip Torr, Feng Zhao, Wanli Ouyang</div>
<div class="meta-line">First: 2026-01-29T17:58:40+00:00 · Latest: 2026-01-29T17:58:40+00:00</div>
<div class="links" style="margin-top:8px"><a href="https://arxiv.org/abs/2601.22060v1">Abs</a> · <a href="https://arxiv.org/pdf/2601.22060v1">PDF</a> · <a href="https://github.com/Osilly/Vision-DeepResearch">Code1</a> · <a href="https://huggingface.co/huggingface">Code2</a> · <a href="https://huggingface.co/docs/hub/spaces">Code3</a></div>
<details class="detail"><summary>Abstract</summary>
<div class="mono">Multimodal large language models (MLLMs) have achieved remarkable success across a broad range of vision tasks. However, constrained by the capacity of their internal world knowledge, prior work has proposed augmenting MLLMs by ``reasoning-then-tool-call&#x27;&#x27; for visual and textual search engines to obtain substantial gains on tasks requiring extensive factual information. However, these approaches typically define multimodal search in a naive setting, assuming that a single full-level or entity-level image query and few text query suffices to retrieve the key evidence needed to answer the question, which is unrealistic in real-world scenarios with substantial visual noise. Moreover, they are often limited in the reasoning depth and search breadth, making it difficult to solve complex questions that require aggregating evidence from diverse visual and textual sources. Building on this, we propose Vision-DeepResearch, which proposes one new multimodal deep-research paradigm, i.e., performs multi-turn, multi-entity and multi-scale visual and textual search to robustly hit real-world search engines under heavy noise. Our Vision-DeepResearch supports dozens of reasoning steps and hundreds of engine interactions, while internalizing deep-research capabilities into the MLLM via cold-start supervision and RL training, resulting in a strong end-to-end multimodal deep-research MLLM. It substantially outperforming existing multimodal deep-research MLLMs, and workflows built on strong closed-source foundation model such as GPT-5, Gemini-2.5-pro and Claude-4-Sonnet. The code will be released in https://github.com/Osilly/Vision-DeepResearch.</div></details>
<details class="detail"><summary>中文标题/摘要</summary>
<div class="mono"><b>标题：</b>Vision-DeepResearch：激励多模态大语言模型的深度研究能力</div>
<div class="mono" style="margin-top:8px">多模态大语言模型（MLLMs）在广泛的视觉任务中取得了显著成功。然而，受限于其内部世界知识容量，先前研究提出通过“先推理后工具调用”的方式增强MLLMs，借助视觉与文本搜索引擎在需要大量事实信息的任务上获得显著提升。但这些方法通常将多模态搜索定义在理想化场景中，假设单一完整层级或实体层级的图像查询配合少量文本查询即足以检索回答问题的关键证据，这在现实存在大量视觉噪声的场景中并不实际。此外，它们往往在推理深度和搜索广度上受限，难以解决需要聚合多元视觉与文本证据的复杂问题。基于此，我们提出Vision-DeepResearch，引入一种新的多模态深度研究范式，即通过多轮次、多实体、多尺度的视觉与文本搜索，在强噪声环境下稳健地调用现实搜索引擎。该系统支持数十步推理与数百次引擎交互，并通过冷启动监督与强化学习训练将深度研究能力内化至MLLM，最终形成强大的端到端多模态深度研究模型。其性能显著超越现有同类模型，以及基于GPT-5、Gemini-2.5-pro和Claude-4-Sonnet等强闭源基础模型构建的工作流程。代码将在https://github.com/Osilly/Vision-DeepResearch发布。</div>
</details>
<details class="detail"><summary>Summary / 总结</summary>
<div class="mono">Existing multimodal large language models (MLLMs) often rely on simplistic, single-query search strategies that struggle with visual noise and complex questions requiring evidence aggregation from diverse sources. To address this, the authors propose Vision-DeepResearch, a new paradigm that enables multi-turn, multi-entity, and multi-scale visual and textual searches, integrating deep-research capabilities into the MLLM through cold-start supervision and reinforcement learning training. Experimental results show that this approach significantly outperforms existing multimodal deep-research MLLMs and workflows based on powerful closed-source models like GPT-5, Gemini-2.5-pro, and Claude-4-Sonnet.</div>
<div class="mono" style="margin-top:8px">针对现有多模态大语言模型在处理需要深度信息聚合的复杂、含噪声真实世界查询时的局限性，本研究提出了Vision-DeepResearch，这是一种新的多模态深度研究范式，通过执行多轮、多实体和多尺度的视觉与文本搜索，以在重度噪声下稳健地命中搜索引擎。该方法通过冷启动监督和强化学习训练，将深度研究能力内化到模型中，支持数十个推理步骤和数百次引擎交互。实验结果表明，该模型显著优于现有的多模态深度研究模型，以及基于GPT-5、Gemini-2.5-pro和Claude-4-Sonnet等强大闭源基础模型构建的工作流程。</div>
</details>
</div>
<div class="card">
<div class="title">Unsupervised Decomposition and Recombination with Discriminator-Driven Diffusion Models</div>
<div class="meta-line">Authors: Archer Wang, Emile Anand, Yilun Du, Marin Soljačić</div>
<div class="meta-line">First: 2026-01-29T17:57:06+00:00 · Latest: 2026-01-29T17:57:06+00:00</div>
<div class="meta-line">Comments: 28 pages, 16 figures, 4 tables</div>
<div class="links" style="margin-top:8px"><a href="https://arxiv.org/abs/2601.22057v1">Abs</a> · <a href="https://arxiv.org/pdf/2601.22057v1">PDF</a> · <a href="https://huggingface.co/huggingface">Code1</a> · <a href="https://huggingface.co/docs/hub/spaces">Code2</a></div>
<details class="detail"><summary>Abstract</summary>
<div class="mono">Decomposing complex data into factorized representations can reveal reusable components and enable synthesizing new samples via component recombination. We investigate this in the context of diffusion-based models that learn factorized latent spaces without factor-level supervision. In images, factors can capture background, illumination, and object attributes; in robotic videos, they can capture reusable motion components. To improve both latent factor discovery and quality of compositional generation, we introduce an adversarial training signal via a discriminator trained to distinguish between single-source samples and those generated by recombining factors across sources. By optimizing the generator to fool this discriminator, we encourage physical and semantic consistency in the resulting recombinations. Our method outperforms implementations of prior baselines on CelebA-HQ, Virtual KITTI, CLEVR, and Falcor3D, achieving lower FID scores and better disentanglement as measured by MIG and MCC. Furthermore, we demonstrate a novel application to robotic video trajectories: by recombining learned action components, we generate diverse sequences that significantly increase state-space coverage for exploration on the LIBERO benchmark.</div></details>
<details class="detail"><summary>中文标题/摘要</summary>
<div class="mono"><b>标题：</b>基于判别器驱动扩散模型的无监督分解与重组</div>
<div class="mono" style="margin-top:8px">将复杂数据分解为因子化表示可揭示可复用组件，并通过组件重组实现新样本的合成。本研究在基于扩散的模型框架下探索了无需因子级监督的因子化潜在空间学习。在图像中，因子可捕捉背景、光照与物体属性；在机器人视频中，则可捕捉可复用的运动组件。为提升潜在因子发现与组合生成的质量，我们引入了一种对抗训练信号：通过训练判别器区分单一来源样本与跨来源因子重组生成的样本，并优化生成器以欺骗该判别器，从而促进重组结果在物理与语义层面的一致性。在CelebA-HQ、Virtual KITTI、CLEVR和Falcor3D数据集上，本方法在FID分数、MIG和MCC度量衡量的解耦性能方面均优于现有基线模型。此外，我们展示了在机器人视频轨迹中的创新应用：通过重组学习到的动作组件，生成多样化序列，显著提升了LIBERO基准测试中探索任务的状态空间覆盖范围。</div>
</details>
<details class="detail"><summary>Summary / 总结</summary>
<div class="mono">This research aims to learn factorized latent representations from complex data without supervision, enabling the decomposition of samples into reusable components and the synthesis of new samples via recombination. The method introduces an adversarial training signal using a discriminator that distinguishes between original samples and those generated by recombining latent factors from different sources; the generator is optimized to fool this discriminator, thereby promoting physically and semantically consistent recombinations. Experiments on image datasets (CelebA-HQ, Virtual KITTI, CLEVR, Falcor3D) show the method outperforms prior baselines in generation quality (lower FID) and disentanglement (higher MIG and MCC), and an application to robotic video trajectories demonstrates that recombining learned action components can generate diverse sequences that increase state-space coverage for exploration on the LIBERO benchmark.</div>
<div class="mono" style="margin-top:8px">本研究旨在改进对复杂数据的无监督分解，将其分解为可重用组件，并通过重组生成新样本，这对于揭示图像中的背景、光照和物体属性等潜在因素或机器人视频中的运动组件至关重要。该方法引入了一种对抗性训练信号，使用一个判别器来区分原始样本与通过重组不同来源的潜在因子生成的样本；生成器则被优化以欺骗该判别器，从而鼓励物理和语义上一致的重组。在CelebA-HQ、Virtual KITTI、CLEVR和Falcor3D等数据集上的实验结果表明，该方法优于现有基线，实现了更低的FID分数和更好的解缠结度量（MIG和MCC），并且还展示了在机器人视频轨迹中的新颖应用，通过重组学习到的动作组件生成多样化序列，显著提高了LIBERO基准测试中的状态空间覆盖率。</div>
</details>
</div>
<div class="card">
<div class="title">MetricAnything: Scaling Metric Depth Pretraining with Noisy Heterogeneous Sources</div>
<div class="meta-line">Authors: Baorui Ma, Jiahui Yang, Donglin Di, Xuancheng Zhang, Jianxun Cui, Hao Li, Yan Xie, Wei Chen</div>
<div class="meta-line">First: 2026-01-29T17:52:41+00:00 · Latest: 2026-01-29T17:52:41+00:00</div>
<div class="meta-line">Comments: Project Page: https://metric-anything.github.io/metric-anything-io/</div>
<div class="links" style="margin-top:8px"><a href="https://arxiv.org/abs/2601.22054v1">Abs</a> · <a href="https://arxiv.org/pdf/2601.22054v1">PDF</a> · <a href="https://huggingface.co/huggingface">Code1</a> · <a href="https://huggingface.co/docs/hub/spaces">Code2</a> · <a href="https://metric-anything.github.io/metric-anything-io/">Project1</a> · <a href="http://metric-anything.github.io/metric-anything-io/">Project2</a></div>
<details class="detail"><summary>Abstract</summary>
<div class="mono">Scaling has powered recent advances in vision foundation models, yet extending this paradigm to metric depth estimation remains challenging due to heterogeneous sensor noise, camera-dependent biases, and metric ambiguity in noisy cross-source 3D data. We introduce Metric Anything, a simple and scalable pretraining framework that learns metric depth from noisy, diverse 3D sources without manually engineered prompts, camera-specific modeling, or task-specific architectures. Central to our approach is the Sparse Metric Prompt, created by randomly masking depth maps, which serves as a universal interface that decouples spatial reasoning from sensor and camera biases. Using about 20M image-depth pairs spanning reconstructed, captured, and rendered 3D data across 10000 camera models, we demonstrate-for the first time-a clear scaling trend in the metric depth track. The pretrained model excels at prompt-driven tasks such as depth completion, super-resolution and Radar-camera fusion, while its distilled prompt-free student achieves state-of-the-art results on monocular depth estimation, camera intrinsics recovery, single/multi-view metric 3D reconstruction, and VLA planning. We also show that using pretrained ViT of Metric Anything as a visual encoder significantly boosts Multimodal Large Language Model capabilities in spatial intelligence. These results show that metric depth estimation can benefit from the same scaling laws that drive modern foundation models, establishing a new path toward scalable and efficient real-world metric perception. We open-source MetricAnything at http://metric-anything.github.io/metric-anything-io/ to support community research.</div></details>
<details class="detail"><summary>中文标题/摘要</summary>
<div class="mono"><b>标题：</b>MetricAnything：基于异构噪声源的可扩展度量深度预训练框架</div>
<div class="mono" style="margin-top:8px">规模化推动了视觉基础模型的近期进展，但将这一范式扩展到度量深度估计仍面临挑战，原因包括异构传感器噪声、相机相关偏差以及跨源噪声三维数据中的度量模糊性。我们提出Metric Anything——一种简单可扩展的预训练框架，能够从噪声多样化的三维数据源中学习度量深度，无需人工设计提示、相机特定建模或任务专用架构。该方法的核心是稀疏度量提示：通过对深度图随机掩码生成，作为通用接口将空间推理与传感器及相机偏差解耦。利用约2000万张图像-深度对（涵盖重建、采集与渲染三维数据，涉及10000种相机模型），我们首次在度量深度领域证明了清晰的规模化趋势。预训练模型在深度补全、超分辨率及雷达-相机融合等提示驱动任务中表现优异；其蒸馏后的无提示学生模型在单目深度估计、相机内参恢复、单/多视角度量三维重建及VLA规划任务中达到最先进水平。我们还发现，将Metric Anything的预训练ViT作为视觉编码器可显著提升多模态大语言模型的空间推理能力。这些结果表明，度量深度估计同样受益于驱动现代基础模型的缩放定律，为可扩展、高效的真实世界度量感知开辟了新路径。我们在http://metric-anything.github.io/metric-anything-io/开源MetricAnything以支持社区研究。</div>
</details>
<details class="detail"><summary>Summary / 总结</summary>
<div class="mono">The research is motivated by the challenge of scaling vision foundation models to metric depth estimation, which is hindered by heterogeneous sensor noise, camera biases, and metric ambiguity in cross-source 3D data. The method introduces Metric Anything, a pretraining framework that learns from noisy, diverse 3D sources using a Sparse Metric Prompt created by randomly masking depth maps, which decouples spatial reasoning from sensor and camera biases without manual prompts or task-specific architectures. Experimental results on about 20M image-depth pairs show a clear scaling trend, with the model excelling at prompt-driven tasks like depth completion and super-resolution, while its distilled student achieves state-of-the-art performance in monocular depth estimation, camera intrinsics recovery, 3D reconstruction, and VLA planning, and boosts Multimodal Large Language Model spatial intelligence.</div>
<div class="mono" style="margin-top:8px">本研究旨在解决度量深度估计难以规模化的问题，该任务因异构传感器噪声、相机相关偏差以及跨来源3D数据中的度量模糊性而落后于其他视觉任务。提出的方法Metric Anything是一个可扩展的预训练框架，它通过一种新颖的稀疏度量提示（通过随机掩码深度图创建）来从噪声多样的3D数据中学习，无需人工设计的提示或相机特定建模，从而将空间推理与传感器偏差解耦。在约2000万图像-深度对、涵盖10000种相机模型的实验表明，该方法首次在度量深度领域展现出清晰的缩放趋势，模型在深度补全等提示驱动任务上表现优异，其蒸馏后的无提示学生模型在单目深度估计、相机内参恢复和3D重建上达到最先进水平，同时还能提升多模态大语言模型的空间智能。</div>
</details>
</div>
<div class="card">
<div class="title">SIA: Symbolic Interpretability for Anticipatory Deep Reinforcement Learning in Network Control</div>
<div class="meta-line">Authors: MohammadErfan Jabbari, Abhishek Duttagupta, Claudio Fiandrino, Leonardo Bonati, Salvatore D&#x27;Oro, Michele Polese, Marco Fiore, Tommaso Melodia</div>
<div class="meta-line">First: 2026-01-29T17:46:46+00:00 · Latest: 2026-01-29T17:46:46+00:00</div>
<div class="meta-line">Comments: 10 pages, 12 figures, accepted at IEEE INFOCOM 2026</div>
<div class="links" style="margin-top:8px"><a href="https://arxiv.org/abs/2601.22044v1">Abs</a> · <a href="https://arxiv.org/pdf/2601.22044v1">PDF</a> · <a href="https://huggingface.co/huggingface">Code1</a> · <a href="https://huggingface.co/docs/hub/spaces">Code2</a></div>
<details class="detail"><summary>Abstract</summary>
<div class="mono">Deep reinforcement learning (DRL) promises adaptive control for future mobile networks but conventional agents remain reactive: they act on past and current measurements and cannot leverage short-term forecasts of exogenous KPIs such as bandwidth. Augmenting agents with predictions can overcome this temporal myopia, yet uptake in networking is scarce because forecast-aware agents act as closed-boxes; operators cannot tell whether predictions guide decisions or justify the added complexity. We propose SIA, the first interpreter that exposes in real time how forecast-augmented DRL agents operate. SIA fuses Symbolic AI abstractions with per-KPI Knowledge Graphs to produce explanations, and includes a new Influence Score metric. SIA achieves sub-millisecond speed, over 200x faster than existing XAI methods. We evaluate SIA on three diverse networking use cases, uncovering hidden issues, including temporal misalignment in forecast integration and reward-design biases that trigger counter-productive policies. These insights enable targeted fixes: a redesigned agent achieves a 9% higher average bitrate in video streaming, and SIA&#x27;s online Action-Refinement module improves RAN-slicing reward by 25% without retraining. By making anticipatory DRL transparent and tunable, SIA lowers the barrier to proactive control in next-generation mobile networks.</div></details>
<details class="detail"><summary>中文标题/摘要</summary>
<div class="mono"><b>标题：</b>SIA：面向网络控制中前瞻性深度强化学习的符号可解释性框架</div>
<div class="mono" style="margin-top:8px">深度强化学习（DRL）为未来移动网络提供了自适应控制的潜力，但传统智能体仍停留在反应式模式：它们基于过去和当前的测量数据行动，无法利用带宽等外生关键绩效指标的短期预测。通过预测增强智能体可克服这种时序短视，但网络领域应用甚少，因为具备预测感知能力的智能体如同黑箱；运营商无法判断预测是否真正指导决策或证明其额外复杂性是合理的。我们提出SIA——首个实时揭示预测增强型DRL智能体运作机制的解析器。SIA融合符号人工智能抽象与逐KPI知识图谱以生成解释，并引入新型影响力评分指标。SIA实现亚毫秒级解析速度，比现有可解释人工智能方法快200倍以上。我们在三个异构网络用例中评估SIA，揭示了包括预测集成时序错位和奖励设计偏差引发低效策略在内的潜在问题。这些洞察启发了针对性改进：重新设计的智能体在视频流传输中实现平均比特率提升9%，SIA的在线动作优化模块无需重新训练即可将无线接入网切片奖励提升25%。通过使前瞻性DRL具备透明性与可调性，SIA降低了下一代移动网络中主动控制的应用门槛。</div>
</details>
<details class="detail"><summary>Summary / 总结</summary>
<div class="mono">This research addresses the opacity of forecast-augmented deep reinforcement learning (DRL) agents in network control, which hinders operator trust and adoption despite their potential for proactive decision-making. The proposed method, SIA (Symbolic Interpretability for Anticipatory Deep Reinforcement Learning), fuses symbolic AI abstractions with per-KPI knowledge graphs to generate real-time explanations and introduces an Influence Score metric. Experimental results show SIA operates with sub-millisecond latency, over 200 times faster than existing explainable AI methods, and its application to three networking use cases revealed hidden issues like temporal misalignment and reward biases; these insights enabled targeted fixes that improved video streaming bitrate by 9% and RAN-slicing reward by 25%.</div>
<div class="mono" style="margin-top:8px">本研究针对网络控制中预测增强深度强化学习（DRL）智能体的不透明性问题展开，该问题阻碍了运营商对其的信任和采用，尽管这类智能体具有主动决策的潜力。提出的SIA（面向预见性深度强化学习的符号可解释性）方法融合了符号人工智能抽象与每KPI知识图谱以生成实时解释，并引入了影响力评分指标。在三个网络用例上的实验评估表明，SIA具有亚毫秒级的运行速度，比现有可解释人工智能方法快200倍以上，并揭示了诸如时间错位和奖励设计偏差等隐藏问题。这些洞察促成了针对性改进，包括一个重新设计的智能体在视频流中实现了平均比特率提升9%，以及一个在线动作优化模块在不重新训练的情况下将无线接入网切片奖励提升了25%。</div>
</details>
</div>
<div class="card">
<div class="title">Learning to Communicate Across Modalities: Perceptual Heterogeneity in Multi-Agent Systems</div>
<div class="meta-line">Authors: Naomi Pitzer, Daniela Mihai</div>
<div class="meta-line">First: 2026-01-29T17:45:41+00:00 · Latest: 2026-01-29T17:45:41+00:00</div>
<div class="meta-line">Comments: To be published in EvoLang XVI proceedings. 15 pages, 17 figures</div>
<div class="links" style="margin-top:8px"><a href="https://arxiv.org/abs/2601.22041v1">Abs</a> · <a href="https://arxiv.org/pdf/2601.22041v1">PDF</a> · <a href="https://huggingface.co/huggingface">Code1</a> · <a href="https://huggingface.co/docs/hub/spaces">Code2</a></div>
<details class="detail"><summary>Abstract</summary>
<div class="mono">Emergent communication offers insight into how agents develop shared structured representations, yet most research assumes homogeneous modalities or aligned representational spaces, overlooking the perceptual heterogeneity of real-world settings. We study a heterogeneous multi-step binary communication game where agents differ in modality and lack perceptual grounding. Despite perceptual misalignment, multimodal systems converge to class-consistent messages grounded in perceptual input. Unimodal systems communicate more efficiently, using fewer bits and achieving lower classification entropy, while multimodal agents require greater information exchange and exhibit higher uncertainty. Bit perturbation experiments provide strong evidence that meaning is encoded in a distributional rather than compositional manner, as each bit&#x27;s contribution depends on its surrounding pattern. Finally, interoperability analyses show that systems trained in different perceptual worlds fail to directly communicate, but limited fine-tuning enables successful cross-system communication. This work positions emergent communication as a framework for studying how agents adapt and transfer representations across heterogeneous modalities, opening new directions for both theory and experimentation.</div></details>
<details class="detail"><summary>中文标题/摘要</summary>
<div class="mono"><b>标题：</b>跨模态通信学习：多智能体系统中的感知异质性</div>
<div class="mono" style="margin-top:8px">涌现通信揭示了智能体如何形成共享结构化表征，但现有研究多假设同质模态或对齐的表征空间，忽视了真实场景中的感知异质性。本研究通过异构多步二元通信博弈展开实验，其中智能体模态各异且缺乏感知基础。尽管存在感知错位，多模态系统仍能基于感知输入收敛至类别一致的消息。单模态系统通信效率更高，使用更少比特且分类熵更低；而多模态智能体需要更多信息交换并表现出更高不确定性。比特扰动实验有力证明意义以分布式（而非组合式）方式编码——每个比特的贡献取决于其周边模式。互操作性分析表明，在不同感知世界训练的系统无法直接通信，但有限微调可实现成功的跨系统通信。本研究将涌现通信确立为探索智能体如何适应并迁移异构模态间表征的框架，为理论与实验开辟了新方向。</div>
</details>
<details class="detail"><summary>Summary / 总结</summary>
<div class="mono">This research addresses the gap in emergent communication studies by examining how agents with heterogeneous perceptual modalities develop shared representations without aligned perceptual grounding. The authors design a multi-step binary communication game where agents differ in modality and lack perceptual alignment, analyzing message convergence, efficiency, and encoding patterns. Experimental results show that multimodal systems achieve class-consistent messages grounded in perceptual input but require more bits and exhibit higher uncertainty compared to unimodal systems, which communicate more efficiently with lower classification entropy. Bit perturbation reveals meaning is encoded distributionally rather than compositionally, and interoperability tests indicate that systems trained in different perceptual worlds cannot directly communicate but can achieve cross-system communication with limited fine-tuning.</div>
<div class="mono" style="margin-top:8px">本研究针对涌现通信研究中通常假设智能体模态同质化的局限，探讨了具有不同感知模态的智能体如何在缺乏先验对齐的情况下发展共享通信。作者设计了一个多步二进制通信游戏，其中单模态或多模态智能体缺乏感知基础，必须学习就感知输入进行通信。实验结果表明，单模态系统通信效率更高，使用更少的比特和更低的分类熵，而多模态系统需要更多信息交换且表现出更高的不确定性；比特扰动实验揭示意义是以分布方式而非组合方式编码的。此外，互操作性测试表明，在不同感知世界中训练的系统无法直接通信，但通过有限微调可实现跨系统通信，从而将涌现通信定位为研究跨异质模态表示迁移的框架。</div>
</details>
</div>
<div class="card">
<div class="title">A Separable Architecture for Continuous Token Representation in Language Models</div>
<div class="meta-line">Authors: Reza T. Batley, Sourav Saha</div>
<div class="meta-line">First: 2026-01-29T17:44:25+00:00 · Latest: 2026-01-29T17:44:25+00:00</div>
<div class="links" style="margin-top:8px"><a href="https://arxiv.org/abs/2601.22040v1">Abs</a> · <a href="https://arxiv.org/pdf/2601.22040v1">PDF</a> · <a href="https://huggingface.co/huggingface">Code1</a> · <a href="https://huggingface.co/docs/hub/spaces">Code2</a></div>
<details class="detail"><summary>Abstract</summary>
<div class="mono">Transformer scaling law analyses typically treat parameters as interchangeable; an abstraction that accurately predicts loss-compute relationships. Yet, in sub-billion-parameter small language models (SLMs), embedding matrices dominate the parameter budget. This work argues that this allocation is as suboptimal as it is counterintuitive. Leviathan is an architecture with a continuous embedding generator to replace the discrete lookup tables of canonical models. Evaluating on the Pile dataset under isoparametric settings, Leviathan consistently outperforms a standard, LLaMA-style architecture. By means of an empirical power-law fit, Leviathan exhibits a markedly superior effective parameter capacity. Across the regime studied, Leviathan behaves as a dense model with $1.47$ to $2.11 \times$ more parameters.</div></details>
<details class="detail"><summary>中文标题/摘要</summary>
<div class="mono"><b>标题：</b>语言模型中连续词元表示的可分离架构</div>
<div class="mono" style="margin-top:8px">Transformer缩放定律分析通常将参数视为可互换的，这一抽象能准确预测损失-计算关系。然而，在十亿参数以下的小型语言模型中，嵌入矩阵占据了参数预算的主导地位。本研究指出这种分配既低效又反直觉。Leviathan是一种采用连续嵌入生成器替代经典模型离散查找表的架构。在等参数设置下基于Pile数据集评估，Leviathan始终优于标准的LLaMA风格架构。通过经验幂律拟合，Leviathan展现出显著更优的有效参数容量。在研究范围内，Leviathan表现出相当于密集模型增加1.47至2.11倍参数的行为。</div>
</details>
<details class="detail"><summary>Summary / 总结</summary>
<div class="mono">This work challenges the standard parameter allocation in sub-billion parameter small language models (SLMs), where embedding matrices dominate the budget, arguing this is suboptimal. It introduces Leviathan, an architecture that replaces discrete token embedding lookup tables with a continuous embedding generator. Evaluated on the Pile dataset under isoparametric conditions, Leviathan consistently outperforms a standard LLaMA-style baseline; empirical power-law fitting shows it behaves as if it had 1.47 to 2.11 times more parameters, demonstrating superior effective parameter capacity.</div>
<div class="mono" style="margin-top:8px">本研究针对参数规模在十亿以下的小型语言模型中，嵌入矩阵占据主要参数量这一低效且反直觉的参数分配问题。作者提出了Leviathan架构，用连续的嵌入生成器取代了传统模型中的离散查找表以提高效率。在等参数量设置下于Pile数据集上进行评估，Leviathan持续优于标准的LLaMA风格架构，其有效参数容量在所研究的范围内相当于稠密模型的1.47至2.11倍。</div>
</details>
</div>
<div class="card">
<div class="title">Optimizing Agentic Workflows using Meta-tools</div>
<div class="meta-line">Authors: Sami Abuzakuk, Anne-Marie Kermarrec, Rishi Sharma, Rasmus Moorits Veski, Martijn de Vos</div>
<div class="meta-line">First: 2026-01-29T17:43:08+00:00 · Latest: 2026-01-29T17:43:08+00:00</div>
<div class="links" style="margin-top:8px"><a href="https://arxiv.org/abs/2601.22037v1">Abs</a> · <a href="https://arxiv.org/pdf/2601.22037v1">PDF</a> · <a href="https://huggingface.co/huggingface">Code1</a> · <a href="https://huggingface.co/docs/hub/spaces">Code2</a></div>
<details class="detail"><summary>Abstract</summary>
<div class="mono">Agentic AI enables LLM to dynamically reason, plan, and interact with tools to solve complex tasks. However, agentic workflows often require many iterative reasoning steps and tool invocations, leading to significant operational expense, end-to-end latency and failures due to hallucinations. This work introduces Agent Workflow Optimization (AWO), a framework that identifies and optimizes redundant tool execution patterns to improve the efficiency and robustness of agentic workflows. AWO analyzes existing workflow traces to discover recurring sequences of tool calls and transforms them into meta-tools, which are deterministic, composite tools that bundle multiple agent actions into a single invocation. Meta-tools bypass unnecessary intermediate LLM reasoning steps and reduce operational cost while also shortening execution paths, leading to fewer failures. Experiments on two agentic AI benchmarks show that AWO reduces the number of LLM calls up to 11.9% while also increasing the task success rate by up to 4.2 percent points.</div></details>
<details class="detail"><summary>中文标题/摘要</summary>
<div class="mono"><b>标题：</b>利用元工具优化智能体工作流</div>
<div class="mono" style="margin-top:8px">智能体AI使大语言模型能够动态推理、规划并与工具交互以解决复杂任务。然而，智能体工作流通常需要大量迭代推理步骤和工具调用，导致显著的操作开销、端到端延迟以及因幻觉而产生的故障。本研究提出智能体工作流优化框架，通过识别并优化冗余工具执行模式来提升智能体工作流的效率与鲁棒性。该框架分析现有工作流轨迹以发现重复出现的工具调用序列，并将其转化为元工具——一种将多个智能体动作捆绑为单次调用的确定性复合工具。元工具绕过了不必要的中间大语言模型推理步骤，在降低操作成本的同时缩短执行路径，从而减少故障。在两个智能体AI基准测试上的实验表明，该框架将大语言模型调用次数降低达11.9%，同时将任务成功率提升达4.2个百分点。</div>
</details>
<details class="detail"><summary>Summary / 总结</summary>
<div class="mono">This research addresses the inefficiency and unreliability of agentic AI workflows, which often involve numerous iterative reasoning steps and tool calls that increase operational costs, latency, and failure rates due to hallucinations. The proposed Agent Workflow Optimization (AWO) framework analyzes historical workflow traces to identify redundant patterns of tool execution and replaces them with deterministic, composite meta-tools that bundle multiple actions into a single invocation. Experimental evaluation on two agentic AI benchmarks demonstrates that AWO reduces the number of required LLM calls by up to 11.9% and simultaneously improves task success rates by up to 4.2 percentage points.</div>
<div class="mono" style="margin-top:8px">智能体AI工作流常因重复的推理步骤和工具调用导致效率低下和不可靠，增加了成本、延迟和错误率。为解决此问题，本研究提出了智能体工作流优化（AWO）框架，该框架通过分析工作流执行轨迹来识别冗余的工具调用序列，并将其替换为确定性的复合元工具。在两个智能体AI基准测试上的实验表明，AWO能将大语言模型调用减少高达11.9%，并将任务成功率提升高达4.2个百分点。</div>
</details>
</div>
<div class="card">
<div class="title">Thinking Out of Order: When Output Order Stops Reflecting Reasoning Order in Diffusion Language Models</div>
<div class="meta-line">Authors: Longxuan Yu, Yu Fu, Shaorong Zhang, Hui Liu, Mukund Varma T, Greg Ver Steeg, Yue Dong</div>
<div class="meta-line">First: 2026-01-29T17:40:58+00:00 · Latest: 2026-01-29T17:40:58+00:00</div>
<div class="meta-line">Comments: 18 pages, 13 figures, 5 tables</div>
<div class="links" style="margin-top:8px"><a href="https://arxiv.org/abs/2601.22035v1">Abs</a> · <a href="https://arxiv.org/pdf/2601.22035v1">PDF</a> · <a href="https://huggingface.co/huggingface">Code1</a> · <a href="https://huggingface.co/docs/hub/spaces">Code2</a></div>
<details class="detail"><summary>Abstract</summary>
<div class="mono">Autoregressive (AR) language models enforce a fixed left-to-right generation order, creating a fundamental limitation when the required output structure conflicts with natural reasoning (e.g., producing answers before explanations due to presentation or schema constraints). In such cases, AR models must commit to answers before generating intermediate reasoning, and this rigid constraint forces premature commitment. Masked diffusion language models (MDLMs), which iteratively refine all tokens in parallel, offer a way to decouple computation order from output structure. We validate this capability on GSM8K, Math500, and ReasonOrderQA, a benchmark we introduce with controlled difficulty and order-level evaluation. When prompts request answers before reasoning, AR models exhibit large accuracy gaps compared to standard chain-of-thought ordering (up to 67% relative drop), while MDLMs remain stable ($\leq$14% relative drop), a property we term &quot;order robustness&quot;. Using ReasonOrderQA, we present evidence that MDLMs achieve order robustness by stabilizing simpler tokens (e.g., reasoning steps) earlier in the diffusion process than complex ones (e.g., final answers), enabling reasoning tokens to stabilize before answer commitment. Finally, we identify failure conditions where this advantage weakens, outlining the limits required for order robustness.</div></details>
<details class="detail"><summary>中文标题/摘要</summary>
<div class="mono"><b>标题：</b>突破顺序思维：当扩散语言模型的输出顺序不再反映推理顺序</div>
<div class="mono" style="margin-top:8px">自回归语言模型强制采用固定的从左到右生成顺序，当所需输出结构与自然推理过程冲突时（例如因呈现方式或模式约束需先输出答案后生成解释），这一根本性限制会导致模型必须在生成中间推理步骤前就确定答案，这种刚性约束迫使模型过早做出决策。掩码扩散语言模型通过并行迭代优化所有词元，实现了计算顺序与输出结构的解耦。我们在GSM8K、Math500及新构建的难度可控且支持顺序层级评估的基准数据集ReasonOrderQA上验证了该能力。当提示要求先输出答案后生成推理时，自回归模型相比标准思维链顺序出现显著准确率下降（相对降幅最高达67%），而掩码扩散语言模型保持稳定（相对降幅≤14%），我们将此特性称为“顺序鲁棒性”。通过ReasonOrderQA的实验证据表明，掩码扩散语言模型通过在扩散过程中更早稳定简单词元（如推理步骤）而非复杂词元（如最终答案）来实现顺序鲁棒性，使得推理词元能在答案确定前趋于稳定。最后，我们识别了该优势减弱的失效条件，明确了顺序鲁棒性所需的边界限制。</div>
</details>
<details class="detail"><summary>Summary / 总结</summary>
<div class="mono">The research addresses the limitation of autoregressive language models, which enforce a fixed left-to-right generation order that can conflict with natural reasoning when output schemas require answers before explanations, forcing premature commitment. The method employs masked diffusion language models, which iteratively refine all tokens in parallel, to decouple computation order from output structure, evaluated on GSM8K, Math500, and a new benchmark, ReasonOrderQA. Key experimental findings show that while autoregressive models suffer large accuracy drops (up to 67% relative) when prompts request answers before reasoning, masked diffusion models remain stable (≤14% relative drop), demonstrating order robustness, with evidence that simpler reasoning tokens stabilize earlier in the diffusion process than complex answer tokens, though failure conditions where this advantage weakens are also identified.</div>
<div class="mono" style="margin-top:8px">本研究针对自回归语言模型的局限性，即其固定的从左到右生成顺序可能与自然推理相冲突，当输出模式要求答案先于解释时，会迫使模型过早做出承诺。研究提出使用掩码扩散语言模型，通过并行迭代优化所有词元，以解耦计算顺序与输出结构。在GSM8K、Math500和新基准ReasonOrderQA上的实验表明，当要求答案先于推理时，自回归模型准确率大幅下降（相对下降高达67%），而掩码扩散模型保持稳定（相对下降≤14%），实现了顺序鲁棒性，其机制是在扩散过程中更早地稳定较简单的推理词元而非复杂的答案词元。</div>
</details>
</div></div>
    <details style="margin-top:16px" class="detail"><summary>History</summary>
      <div class="history-list"><a href="archive/20260130_0631.html">20260130_0631</a>
<a href="archive/20260130_0533.html">20260130_0533</a>
<a href="archive/20260130_0449.html">20260130_0449</a>
<a href="archive/20260130_0341.html">20260130_0341</a>
<a href="archive/20260129_0630.html">20260129_0630</a>
<a href="archive/20260129_0536.html">20260129_0536</a>
<a href="archive/20260129_0450.html">20260129_0450</a>
<a href="archive/20260129_0336.html">20260129_0336</a>
<a href="archive/20260128_0625.html">20260128_0625</a>
<a href="archive/20260128_0439.html">20260128_0439</a>
<a href="archive/20260128_0334.html">20260128_0334</a>
<a href="archive/20260127_0627.html">20260127_0627</a>
<a href="archive/20260127_0529.html">20260127_0529</a>
<a href="archive/20260127_0439.html">20260127_0439</a>
<a href="archive/20260127_0333.html">20260127_0333</a>
<a href="archive/20260126_0626.html">20260126_0626</a>
<a href="archive/20260126_0526.html">20260126_0526</a>
<a href="archive/20260126_0327.html">20260126_0327</a>
<a href="archive/20260125_0624.html">20260125_0624</a>
<a href="archive/20260125_0524.html">20260125_0524</a>
<a href="archive/20260125_0440.html">20260125_0440</a>
<a href="archive/20260125_0325.html">20260125_0325</a>
<a href="archive/20260124_0627.html">20260124_0627</a>
<a href="archive/20260124_0526.html">20260124_0526</a>
<a href="archive/20260124_0444.html">20260124_0444</a>
<a href="archive/20260124_0334.html">20260124_0334</a>
<a href="archive/20260123_0627.html">20260123_0627</a>
<a href="archive/20260123_0529.html">20260123_0529</a>
<a href="archive/20260123_0446.html">20260123_0446</a>
<a href="archive/20260123_0334.html">20260123_0334</a>
<a href="archive/20260122_2019.html">20260122_2019</a>
<a href="archive/20260122_2013.html">20260122_2013</a>
<a href="archive/20260122_2008.html">20260122_2008</a>
<a href="archive/20260122_2001.html">20260122_2001</a>
<a href="archive/20260122_0629.html">20260122_0629</a>
<a href="archive/20260122_0535.html">20260122_0535</a>
<a href="archive/20260122_0449.html">20260122_0449</a>
<a href="archive/20260122_0336.html">20260122_0336</a>
<a href="archive/20260121_0625.html">20260121_0625</a>
<a href="archive/20260121_0529.html">20260121_0529</a>
<a href="archive/20260121_0450.html">20260121_0450</a>
<a href="archive/20260121_0423.html">20260121_0423</a>
<a href="archive/20260120_0626.html">20260120_0626</a>
<a href="archive/20260120_0528.html">20260120_0528</a>
<a href="archive/20260120_0443.html">20260120_0443</a>
<a href="archive/20260120_0330.html">20260120_0330</a>
<a href="archive/20260119_0624.html">20260119_0624</a>
<a href="archive/20260119_0525.html">20260119_0525</a>
<a href="archive/20260119_0440.html">20260119_0440</a>
<a href="archive/20260119_0325.html">20260119_0325</a>
<a href="archive/20260118_2225.html">20260118_2225</a>
<a href="archive/20260118_2159.html">20260118_2159</a>
<a href="archive/20260118_2135.html">20260118_2135</a>
<a href="archive/20260118_2040.html">20260118_2040</a>
<a href="archive/20260118_1953.html">20260118_1953</a>
<a href="archive/20260118_1907.html">20260118_1907</a>
<a href="archive/20260118_0327.html">20260118_0327</a>
<a href="archive/20260117_0332.html">20260117_0332</a>
<a href="archive/20260116_0339.html">20260116_0339</a>
<a href="archive/20260115_0334.html">20260115_0334</a>
<a href="archive/20260114_0333.html">20260114_0333</a>
<a href="archive/20260113_0334.html">20260113_0334</a>
<a href="archive/20260112_0331.html">20260112_0331</a>
<a href="archive/20260111_0329.html">20260111_0329</a>
<a href="archive/20260110_0333.html">20260110_0333</a>
<a href="archive/20260109_0334.html">20260109_0334</a>
<a href="archive/20260108_0335.html">20260108_0335</a>
<a href="archive/20260107_0330.html">20260107_0330</a>
<a href="archive/20260106_0336.html">20260106_0336</a>
<a href="archive/20260105_0328.html">20260105_0328</a>
<a href="archive/20260104_0328.html">20260104_0328</a>
<a href="archive/20260103_0325.html">20260103_0325</a>
<a href="archive/20260102_0339.html">20260102_0339</a>
<a href="archive/20260101_0329.html">20260101_0329</a>
<a href="archive/20251231_0333.html">20251231_0333</a>
<a href="archive/20251230_0332.html">20251230_0332</a>
<a href="archive/20251229_0329.html">20251229_0329</a>
<a href="archive/20251228_0332.html">20251228_0332</a>
<a href="archive/20251227_0329.html">20251227_0329</a>
<a href="archive/20251226_0330.html">20251226_0330</a>
<a href="archive/20251225_0329.html">20251225_0329</a>
<a href="archive/20251224_0331.html">20251224_0331</a>
<a href="archive/20251223_0332.html">20251223_0332</a>
<a href="archive/20251222_0328.html">20251222_0328</a>
<a href="archive/20251221_0329.html">20251221_0329</a>
<a href="archive/20251220_0330.html">20251220_0330</a>
<a href="archive/20251219_0330.html">20251219_0330</a>
<a href="archive/20251218_0345.html">20251218_0345</a>
<a href="archive/20251217_0332.html">20251217_0332</a>
<a href="archive/20251216_0333.html">20251216_0333</a>
<a href="archive/20251215_0333.html">20251215_0333</a>
<a href="archive/20251214_0327.html">20251214_0327</a>
<a href="archive/20251212_0333.html">20251212_0333</a>
<a href="archive/20251211_0331.html">20251211_0331</a>
<a href="archive/20251210_0332.html">20251210_0332</a>
<a href="archive/20251209_0331.html">20251209_0331</a>
<a href="archive/20251208_0328.html">20251208_0328</a>
<a href="archive/20251207_0327.html">20251207_0327</a>
<a href="archive/20251206_0330.html">20251206_0330</a>
<a href="archive/20251205_0331.html">20251205_0331</a></div>
    </details>
    <div class="footer">Generated by arxiv-tracker</div>
  </div>
</body></html>
