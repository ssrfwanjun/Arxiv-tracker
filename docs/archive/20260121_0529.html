<!doctype html>
<html><head><meta charset="utf-8"><meta name="viewport" content="width=device-width,initial-scale=1">
<title>arXiv 论文速递</title><style>
:root {
  --bg:#f8fafc; --card:#ffffff; --text:#0f172a; --muted:#667085; --border:#e5e7eb; --acc:#2563eb;
}
:root[data-theme="dark"] {
  --bg:#0b0f17; --card:#111827; --text:#e5e7eb; --muted:#9ca3af; --border:#1f2937; --acc:#2563eb;
}
*{box-sizing:border-box} body{margin:0;background:var(--bg);color:var(--text);
  font-family:ui-sans-serif,system-ui,-apple-system,Segoe UI,Roboto,Helvetica,Arial;line-height:1.6;}
.container{max-width:900px;margin:0 auto;padding:18px;}
.header{display:flex;gap:10px;justify-content:space-between;align-items:center;margin:8px 0 16px;flex-wrap:wrap}
h1{font-size:22px;margin:0}
.badge{font-size:12px;color:#111827;background:var(--acc);padding:2px 8px;border-radius:999px}
.card{background:var(--card);border:1px solid var(--border);border-radius:16px;padding:16px 18px;margin:14px 0;box-shadow:0 1px 2px rgba(0,0,0,.04)}
.title{font-weight:700;margin:0 0 6px 0;font-size:18px}
.meta-line{color:var(--muted);font-size:13px;margin:2px 0}
.links a{color:var(--acc);text-decoration:none;margin-right:12px}
.detail{margin-top:10px;background:rgba(2,6,23,.03);border:1px solid var(--border);border-radius:10px;padding:8px 10px}
summary{cursor:pointer;color:var(--acc)}
.mono{white-space:pre-wrap;background:rgba(2,6,23,.03);border:1px solid var(--border);padding:10px;border-radius:10px}
.row{display:grid;grid-template-columns:1fr;gap:12px}
@media (min-width: 860px) {
  .row-2{grid-template-columns:1fr 1fr}
}
.footer{color:var(--muted);font-size:13px;margin:20px 0 10px}
.hr{height:1px;background:var(--border);margin:14px 0}
.history-list a{display:block;color:var(--acc);text-decoration:none;margin:4px 0}
.controls{display:flex;gap:8px;align-items:center}
.btn{border:1px solid var(--border);background:var(--card);padding:6px 10px;border-radius:10px;cursor:pointer;color:var(--text)}
.btn:hover{border-color:var(--acc)}
</style>
<script>
(function() {
  const root = document.documentElement;
  function apply(t) {
    if (t==='dark') root.setAttribute('data-theme','dark');
    else if (t==='light') root.removeAttribute('data-theme');
    else {
      if (window.matchMedia && window.matchMedia('(prefers-color-scheme: dark)').matches)
        root.setAttribute('data-theme','dark');
      else root.removeAttribute('data-theme');
    }
  }
  let t = localStorage.getItem('theme') || 'light';
  if (!['light','dark','auto'].includes(t)) t='light';
  apply(t);
  window.__toggleTheme = function() {
    let cur = localStorage.getItem('theme') || 'light';
    if (cur==='light') cur='dark';
    else if (cur==='dark') cur='auto';
    else cur='light';
    localStorage.setItem('theme', cur);
    apply(cur);
    const el=document.getElementById('theme-label');
    if(el) el.textContent = cur.toUpperCase();
  }
  window.__expandAll = function(open) {
    document.querySelectorAll('details').forEach(d => d.open = !!open);
  }
})();
</script>
</head>
<body>
  <div class="container">
    <div class="header">
      <h1>arXiv 论文速递</h1>
      <div style="display:flex;gap:10px;align-items:center">
        
<div class="controls">
  <button class="btn" onclick="__toggleTheme()">Theme: <span id="theme-label" style="margin-left:6px">AUTO</span></button>
  <button class="btn" onclick="__expandAll(true)">Expand All</button>
  <button class="btn" onclick="__expandAll(false)">Collapse All</button>
</div>

        <span class="badge">2026-01-21 05:29</span>
      </div>
    </div>
    <div class="hr"></div>
    <div>Snapshot: 20260121_0529</div>
    <div class="row"><div class="card">
<div class="title">Building Production-Ready Probes For Gemini</div>
<div class="meta-line">Authors: János Kramár, Joshua Engels, Zheng Wang, Bilal Chughtai, Rohin Shah, Neel Nanda, Arthur Conmy</div>
<div class="meta-line">First: 2026-01-16T18:54:29+00:00 · Latest: 2026-01-16T18:54:29+00:00</div>
<div class="links" style="margin-top:8px"><a href="https://arxiv.org/abs/2601.11516v1">Abs</a> · <a href="https://arxiv.org/pdf/2601.11516v1">PDF</a> · <a href="https://huggingface.co/huggingface">Code1</a> · <a href="https://huggingface.co/docs/hub/spaces">Code2</a></div>
<details class="detail"><summary>Abstract</summary>
<div class="mono">Frontier language model capabilities are improving rapidly. We thus need stronger mitigations against bad actors misusing increasingly powerful systems. Prior work has shown that activation probes may be a promising misuse mitigation technique, but we identify a key remaining challenge: probes fail to generalize under important production distribution shifts. In particular, we find that the shift from short-context to long-context inputs is difficult for existing probe architectures. We propose several new probe architecture that handle this long-context distribution shift.
  We evaluate these probes in the cyber-offensive domain, testing their robustness against various production-relevant shifts, including multi-turn conversations, static jailbreaks, and adaptive red teaming. Our results demonstrate that while multimax addresses context length, a combination of architecture choice and training on diverse distributions is required for broad generalization. Additionally, we show that pairing probes with prompted classifiers achieves optimal accuracy at a low cost due to the computational efficiency of probes.
  These findings have informed the successful deployment of misuse mitigation probes in user-facing instances of Gemini, Google&#x27;s frontier language model. Finally, we find early positive results using AlphaEvolve to automate improvements in both probe architecture search and adaptive red teaming, showing that automating some AI safety research is already possible.</div></details>
<details class="detail"><summary>中文标题/摘要</summary>
<div class="mono"><b>标题：</b>为Gemini构建生产就绪的探针</div>
<div class="mono" style="margin-top:8px">前沿语言模型能力正快速提升，因此需要更强有力的措施来防止恶意行为者滥用日益强大的系统。先前研究表明，激活探针可能是一种有前景的滥用缓解技术，但我们发现一个关键挑战：探针在重要的生产分布变化下难以泛化。特别是，从短上下文到长上下文的输入转变对现有探针架构构成困难。我们提出了几种能处理这种长上下文分布变化的新探针架构。
  我们在网络攻击领域评估这些探针，测试其对多轮对话、静态越狱和自适应红队攻击等生产相关变化的鲁棒性。结果表明，虽然多最大值方法能应对上下文长度问题，但需结合架构选择与多样化分布训练才能实现广泛泛化。此外，探针的计算效率使其与提示分类器结合时，能以低成本达到最优准确率。
  这些发现已成功指导了Gemini（谷歌前沿语言模型）用户实例中滥用缓解探针的部署。最后，我们利用AlphaEvolve在探针架构搜索和自适应红队攻击自动化改进方面取得初步积极成果，表明部分AI安全研究已可实现自动化。</div>
</details>
<details class="detail"><summary>Summary / 总结</summary>
<div class="mono">As frontier language models become more capable, stronger mitigations are needed to prevent misuse by bad actors. This work addresses the challenge that existing activation probes fail to generalize under production distribution shifts, particularly from short to long contexts, by proposing new probe architectures. Evaluated in the cyber-offensive domain against shifts like multi-turn conversations and adaptive red teaming, the results show that robust generalization requires both architectural innovations like multimax for context length and training on diverse data, and that pairing probes with prompted classifiers achieves optimal accuracy efficiently. These findings have informed the deployment of probes in Gemini, and early results indicate automation via AlphaEvolve can improve both probe design and red teaming.</div>
<div class="mono" style="margin-top:8px">随着前沿语言模型能力快速提升，需要更强的缓解措施来防止恶意滥用。本研究针对现有激活探针在生产分布变化（特别是从短上下文到长上下文）下泛化失败的问题，提出了新的探针架构。在网络安全攻击领域进行评估，测试了多轮对话和自适应红队攻击等分布变化，结果表明，稳健的泛化需要结合针对上下文长度的架构创新（如multimax）和多样化数据训练，并且将探针与提示分类器结合能以低成本实现最优精度。这些发现已指导了Gemini模型中探针的部署，早期结果显示利用AlphaEvolve自动化改进探针架构搜索和红队攻击是可行的。</div>
</details>
</div>
<div class="card">
<div class="title">Predictive Modeling of Power Outages during Extreme Events: Integrating Weather and Socio-Economic Factors</div>
<div class="meta-line">Authors: Antar Kumar Biswas, Masoud H. Nazari</div>
<div class="meta-line">First: 2025-12-27T20:30:07+00:00 · Latest: 2026-01-16T18:53:25+00:00</div>
<div class="meta-line">Comments: This is a preprint of a manuscript currently under review at Electric Power Systems Research. The content may be subject to change following peer review</div>
<div class="links" style="margin-top:8px"><a href="https://arxiv.org/abs/2512.22699v2">Abs</a> · <a href="https://arxiv.org/pdf/2512.22699v2">PDF</a> · <a href="https://huggingface.co/huggingface">Code1</a> · <a href="https://huggingface.co/docs/hub/spaces">Code2</a></div>
<details class="detail"><summary>Abstract</summary>
<div class="mono">This paper presents a novel learning based framework for predicting power outages caused by extreme events. The proposed approach targets low probability high consequence outage scenarios and leverages a comprehensive set of features derived from publicly available data sources. We integrate EAGLE-I outage records from 2014 to 2024 with weather, socioeconomic, infrastructure, and seasonal event data. Incorporating social and demographic indicators reveals patterns of community vulnerability and improves understanding of outage risk during extreme conditions. Four machine learning models are evaluated including Random Forest (RF), Graph Neural Network (GNN), Adaptive Boosting (AdaBoost), and Long Short Term Memory (LSTM). Experimental validation is performed on a large scale dataset covering counties in the lower peninsula of Michigan. Among all models tested, the LSTM network achieves higher accuracy.</div></details>
<details class="detail"><summary>中文标题/摘要</summary>
<div class="mono"><b>标题：</b>极端事件下电力中断的预测建模：融合天气与社会经济因素</div>
<div class="mono" style="margin-top:8px">本文提出了一种基于学习的新型框架，用于预测极端事件引发的电力中断。该方法针对低概率高影响的停电场景，并利用从公开数据源提取的综合特征集。我们将2014年至2024年的EAGLE-I停电记录与天气、社会经济、基础设施及季节性事件数据相结合。纳入社会与人口指标揭示了社区脆弱性模式，并提升了对极端条件下停电风险的理解。评估了四种机器学习模型，包括随机森林（RF）、图神经网络（GNN）、自适应提升（AdaBoost）和长短期记忆网络（LSTM）。实验验证基于覆盖密歇根州下半岛各县的大规模数据集进行。在所有测试模型中，LSTM网络取得了更高的准确率。</div>
</details>
<details class="detail"><summary>Summary / 总结</summary>
<div class="mono">To address the challenge of predicting low-probability, high-consequence power outages during extreme events, this study develops a learning-based framework that integrates diverse data sources. The method combines EAGLE-I outage records from 2014-2024 with weather, socioeconomic, infrastructure, and seasonal event data, and evaluates four machine learning models: Random Forest, Graph Neural Network, Adaptive Boosting, and Long Short-Term Memory. Experimental validation on a large-scale dataset covering counties in Michigan&#x27;s lower peninsula shows that the LSTM network achieves the highest predictive accuracy.</div>
<div class="mono" style="margin-top:8px">本研究旨在通过整合多样化数据源，改进对极端事件期间低概率、高后果停电的预测。方法上，提出了一个基于学习的框架，该框架融合了EAGLE-I停电记录（2014-2024年）、天气、社会经济、基础设施和季节性事件数据，并评估了随机森林、图神经网络、自适应提升和长短期记忆（LSTM）四种机器学习模型。在覆盖密歇根州下半岛各县的大规模数据集上的实验验证表明，LSTM网络取得了最高的预测准确率。</div>
</details>
</div>
<div class="card">
<div class="title">ShapeR: Robust Conditional 3D Shape Generation from Casual Captures</div>
<div class="meta-line">Authors: Yawar Siddiqui, Duncan Frost, Samir Aroudj, Armen Avetisyan, Henry Howard-Jenkins, Daniel DeTone, Pierre Moulon, Qirui Wu, Zhengqin Li, Julian Straub, Richard Newcombe, Jakob Engel</div>
<div class="meta-line">Venue: www</div>
<div class="meta-line">First: 2026-01-16T18:51:24+00:00 · Latest: 2026-01-16T18:51:24+00:00</div>
<div class="meta-line">Comments: Project Page: http://facebookresearch.github.io/ShapeR Video: https://www.youtube.com/watch?v=EbY30KAA55I</div>
<div class="links" style="margin-top:8px"><a href="https://arxiv.org/abs/2601.11514v1">Abs</a> · <a href="https://arxiv.org/pdf/2601.11514v1">PDF</a> · <a href="https://huggingface.co/huggingface">Code1</a> · <a href="https://huggingface.co/docs/hub/spaces">Code2</a> · <a href="http://facebookresearch.github.io/ShapeR">Project1</a></div>
<details class="detail"><summary>Abstract</summary>
<div class="mono">Recent advances in 3D shape generation have achieved impressive results, but most existing methods rely on clean, unoccluded, and well-segmented inputs. Such conditions are rarely met in real-world scenarios. We present ShapeR, a novel approach for conditional 3D object shape generation from casually captured sequences. Given an image sequence, we leverage off-the-shelf visual-inertial SLAM, 3D detection algorithms, and vision-language models to extract, for each object, a set of sparse SLAM points, posed multi-view images, and machine-generated captions. A rectified flow transformer trained to effectively condition on these modalities then generates high-fidelity metric 3D shapes. To ensure robustness to the challenges of casually captured data, we employ a range of techniques including on-the-fly compositional augmentations, a curriculum training scheme spanning object- and scene-level datasets, and strategies to handle background clutter. Additionally, we introduce a new evaluation benchmark comprising 178 in-the-wild objects across 7 real-world scenes with geometry annotations. Experiments show that ShapeR significantly outperforms existing approaches in this challenging setting, achieving an improvement of 2.7x in Chamfer distance compared to state of the art.</div></details>
<details class="detail"><summary>中文标题/摘要</summary>
<div class="mono"><b>标题：</b>ShapeR：基于随意拍摄视频的鲁棒条件式三维形状生成</div>
<div class="mono" style="margin-top:8px">三维形状生成领域近期虽取得显著进展，但现有方法大多依赖干净、无遮挡且分割良好的输入数据，而现实场景很少能满足这些条件。本文提出ShapeR——一种从随意拍摄序列生成条件式三维物体形状的新方法。给定图像序列，我们利用现成的视觉-惯性SLAM、三维检测算法和视觉-语言模型，为每个物体提取稀疏SLAM点集、多视角位姿图像及机器生成描述。通过训练整流流变换器有效融合这些模态信息，最终生成高保真度度量三维形状。为提升对随意拍摄数据挑战的鲁棒性，我们采用动态组合增强、跨物体与场景级数据集的课程训练方案，以及背景干扰处理策略。此外，我们构建了包含7个真实场景中178个带几何标注野外物体的新评估基准。实验表明，ShapeR在此挑战性设定下显著优于现有方法，倒角距离指标较当前最优技术提升2.7倍。</div>
</details>
<details class="detail"><summary>Summary / 总结</summary>
<div class="mono">Motivated by the gap between clean input assumptions of existing 3D shape generation methods and the messy, occluded reality of casually captured real-world data, this work introduces ShapeR for robust conditional 3D object generation. The method first processes an image sequence using off-the-shelf tools—visual-inertial SLAM, 3D detection, and vision-language models—to extract sparse SLAM points, posed multi-view images, and machine-generated captions per object; a rectified flow transformer is then trained to condition on these modalities, enhanced by compositional augmentations and a curriculum from object- to scene-level data for robustness. Key experimental results, validated on a new benchmark of 178 in-the-wild objects across 7 scenes, show ShapeR significantly outperforms prior art, achieving a 2.7x improvement in Chamfer distance.</div>
<div class="mono" style="margin-top:8px">现有三维形状生成方法通常依赖干净、无遮挡的输入，这与现实世界中随意捕获的杂乱数据存在差距；为此，本文提出了ShapeR，一种从随意捕获序列中生成条件三维物体形状的鲁棒方法。该方法首先利用现成的视觉-惯性SLAM、三维检测和视觉-语言模型处理输入图像序列，为每个物体提取稀疏SLAM点、带姿态的多视角图像和机器生成的描述文本；随后训练一个修正流变换器，以这些多模态输入为条件生成高保真度量三维形状，并通过组合增强、从物体级到场景级数据的课程学习以及处理背景杂波的技术来确保鲁棒性。在一个包含178个标注真实物体的新评估基准上的实验表明，ShapeR显著优于现有方法，其倒角距离指标比之前的最优方法提升了2.7倍。</div>
</details>
</div>
<div class="card">
<div class="title">From Aggregation to Selection: User-Validated Distributed Social Recommendation</div>
<div class="meta-line">Authors: Jingyuan Huang, Dan Luo, Zihe Ye, Weixin Chen, Minghao Guo, Yongfeng Zhang</div>
<div class="meta-line">Venue: WWW 2026</div>
<div class="meta-line">First: 2025-05-27T16:17:06+00:00 · Latest: 2026-01-16T18:45:34+00:00</div>
<div class="meta-line">Comments: Accepted by HCRS@WWW 2026</div>
<div class="links" style="margin-top:8px"><a href="https://arxiv.org/abs/2505.21388v3">Abs</a> · <a href="https://arxiv.org/pdf/2505.21388v3">PDF</a> · <a href="https://github.com/agiresearch/DeSocial">Code1</a> · <a href="https://huggingface.co/huggingface">Code2</a> · <a href="https://huggingface.co/docs/hub/spaces">Code3</a></div>
<details class="detail"><summary>Abstract</summary>
<div class="mono">Social recommender systems facilitate social connections by identifying potential friends for users. Each user maintains a local social network centered around themselves, resulting in a naturally distributed social structure. Recent research on distributed modeling for social recommender systems has gained increasing attention, as it naturally aligns with the user-centric structure of user interactions. Current distributed social recommender systems rely on automatically combining predictions from multiple models, often overlooking the user&#x27;s active role in validating whether suggested connections are appropriate. Moreover, recommendation decisions are validated by individual users rather than derived from a single global ordering of candidates. As a result, standard ranking-based evaluation metrics make it difficult to evaluate whether a user-confirmed recommendation decision is actually correct. To address these limitations, we propose DeSocial, a distributed social recommendation framework with user-validation. DeSocial enables users to select recommendation algorithms to validate their potential connections, and the verification is processed through majority consensus among multiple independent user validators. To evaluate the distributed recommender system with user validator, we formulate this setting as a link prediction and verification task and introduce Acc@K, a consensus-based evaluation metric that measures whether user-approved recommendations are correct. Experiments on 4 real-world social networks shows that DeSocial improves decision correctness and robustness compared to single-point and distributed baselines. These findings highlight the potential of user-validated distributed recommender systems as a practical approach to social recommendation, with broader applicability to distributed and decentralized recommendations. Code: https://github.com/agiresearch/DeSocial.</div></details>
<details class="detail"><summary>中文标题/摘要</summary>
<div class="mono"><b>标题：</b>从聚合到选择：用户验证的分布式社交推荐</div>
<div class="mono" style="margin-top:8px">社交推荐系统通过为用户识别潜在好友来促进社交连接。每个用户维护以自身为中心的本地社交网络，形成天然的分布式社交结构。近期针对社交推荐系统的分布式建模研究日益受到关注，因其天然契合以用户为中心的交互结构。现有分布式社交推荐系统依赖自动聚合多模型预测，常忽视用户在验证推荐连接适宜性中的主动作用。且推荐决策由个体用户验证，而非基于全局候选排序。因此，基于排序的标准评估指标难以判断用户确认的推荐决策是否正确。为突破这些局限，我们提出DeSocial——融合用户验证的分布式社交推荐框架。该框架允许用户选择推荐算法验证潜在连接，并通过多独立验证者的多数共识完成验证。为评估含用户验证器的分布式推荐系统，我们将该场景构建为链接预测与验证任务，并提出Acc@K——基于共识的评估指标，用于衡量用户认可的推荐是否正确。在4个真实社交网络上的实验表明，DeSocial相比单点与分布式基线方法，提升了决策正确性与鲁棒性。这些发现凸显了用户验证的分布式推荐系统作为社交推荐实用方案的潜力，对分布式与去中心化推荐具有更广泛的适用性。代码：https://github.com/agiresearch/DeSocial。</div>
</details>
<details class="detail"><summary>Summary / 总结</summary>
<div class="mono">The research addresses limitations in distributed social recommender systems, which typically aggregate predictions automatically without involving users in validating suggested connections and rely on global ranking metrics that poorly reflect individual user decisions. The proposed DeSocial framework introduces user-validation by allowing users to select recommendation algorithms to verify potential connections through majority consensus among independent validators, and it employs a new consensus-based metric, Acc@K, to evaluate correctness of user-approved recommendations. Experiments on four real-world social networks demonstrate that DeSocial enhances decision correctness and robustness over single-point and distributed baselines, indicating the practical value of user-validated distributed approaches for social recommendation.</div>
<div class="mono" style="margin-top:8px">本研究针对分布式社交推荐系统的局限性，即现有方法通常自动聚合预测而忽视用户对推荐连接的主动验证，且依赖全局排序指标难以评估个体用户决策的正确性。提出的DeSocial框架引入用户验证机制，允许用户选择推荐算法并通过独立验证者的多数共识来确认潜在连接，同时采用新的基于共识的评估指标Acc@K来衡量用户批准推荐的正确性。在四个真实社交网络上的实验表明，DeSocial在决策正确性和鲁棒性上优于单点和分布式基线方法，凸显了用户验证的分布式推荐系统在社交推荐中的实用潜力。</div>
</details>
</div>
<div class="card">
<div class="title">MetaboNet: The Largest Publicly Available Consolidated Dataset for Type 1 Diabetes Management</div>
<div class="meta-line">Authors: Miriam K. Wolff, Peter Calhoun, Eleonora Maria Aiello, Yao Qin, Sam F. Royston</div>
<div class="meta-line">First: 2026-01-16T18:38:33+00:00 · Latest: 2026-01-16T18:38:33+00:00</div>
<div class="meta-line">Comments: 22 pages, 5 figures, 7 supplementary figures, submitted to JDST</div>
<div class="links" style="margin-top:8px"><a href="https://arxiv.org/abs/2601.11505v1">Abs</a> · <a href="https://arxiv.org/pdf/2601.11505v1">PDF</a> · <a href="https://huggingface.co/huggingface">Code1</a> · <a href="https://huggingface.co/docs/hub/spaces">Code2</a></div>
<details class="detail"><summary>Abstract</summary>
<div class="mono">Progress in Type 1 Diabetes (T1D) algorithm development is limited by the fragmentation and lack of standardization across existing T1D management datasets. Current datasets differ substantially in structure and are time-consuming to access and process, which impedes data integration and reduces the comparability and generalizability of algorithmic developments. This work aims to establish a unified and accessible data resource for T1D algorithm development. Multiple publicly available T1D datasets were consolidated into a unified resource, termed the MetaboNet dataset. Inclusion required the availability of both continuous glucose monitoring (CGM) data and corresponding insulin pump dosing records. Additionally, auxiliary information such as reported carbohydrate intake and physical activity was retained when present. The MetaboNet dataset comprises 3135 subjects and 1228 patient-years of overlapping CGM and insulin data, making it substantially larger than existing standalone benchmark datasets. The resource is distributed as a fully public subset available for immediate download at https://metabo-net.org/ , and with a Data Use Agreement (DUA)-restricted subset accessible through their respective application processes. For the datasets in the latter subset, processing pipelines are provided to automatically convert the data into the standardized MetaboNet format. A consolidated public dataset for T1D research is presented, and the access pathways for both its unrestricted and DUA-governed components are described. The resulting dataset covers a broad range of glycemic profiles and demographics and thus can yield more generalizable algorithmic performance than individual datasets.</div></details>
<details class="detail"><summary>中文标题/摘要</summary>
<div class="mono"><b>标题：</b>MetaboNet：用于1型糖尿病管理的最大公开整合数据集</div>
<div class="mono" style="margin-top:8px">1型糖尿病（T1D）算法开发进展受限于现有T1D管理数据集的碎片化及缺乏标准化。当前数据集结构差异显著，访问与处理耗时，阻碍了数据整合并降低了算法开发的可比性与泛化性。本研究旨在为T1D算法开发建立一个统一且可访问的数据资源。通过整合多个公开T1D数据集，构建了名为MetaboNet的统一资源。纳入标准要求同时具备连续血糖监测（CGM）数据及对应的胰岛素泵给药记录，并保留如碳水化合物摄入报告和体力活动等辅助信息（若存在）。MetaboNet数据集涵盖3135名受试者及1228患者年的重叠CGM与胰岛素数据，规模显著超过现有独立基准数据集。该资源分为完全公开子集（可通过https://metabo-net.org/直接下载）和需数据使用协议（DUA）限制的子集（需经相应申请流程访问）。对于后者，提供了数据处理流程以自动转换为标准化MetaboNet格式。本研究提出了一个整合的T1D研究公共数据集，并描述了其无限制组件与DUA管辖组件的访问路径。该数据集覆盖广泛的血糖谱与人口统计学特征，因此相比独立数据集能产生更具泛化性的算法性能。</div>
</details>
<details class="detail"><summary>Summary / 总结</summary>
<div class="mono">The research addresses the fragmentation and lack of standardization in existing Type 1 Diabetes (T1D) management datasets, which hinders algorithm development and comparability. To create a unified resource, the authors consolidated multiple public T1D datasets into MetaboNet, requiring continuous glucose monitoring (CGM) data paired with insulin pump records and retaining auxiliary information like carbohydrate intake and physical activity. The resulting dataset includes 3135 subjects and 1228 patient-years of overlapping CGM and insulin data, making it substantially larger than existing benchmarks, and it is designed to support more generalizable algorithmic performance across diverse glycemic profiles and demographics.</div>
<div class="mono" style="margin-top:8px">针对1型糖尿病（T1D）数据集分散且缺乏标准化、阻碍算法开发和泛化的问题，本研究将多个公开数据集整合为一个名为MetaboNet的统一资源。该方法要求整合同时包含连续血糖监测（CGM）和胰岛素泵数据的数据集，并保留碳水化合物摄入和身体活动等辅助信息，将其转换为标准化格式。最终数据集包含3135名受试者和1228患者年的重叠CGM与胰岛素数据，成为目前最大的此类整合资源，并通过完全公开子集和受限子集（附带处理流程）提供访问，从而支持更具泛化性的算法评估。</div>
</details>
</div>
<div class="card">
<div class="title">Beneficial Reasoning Behaviors in Agentic Search and Effective Post-training to Obtain Them</div>
<div class="meta-line">Authors: Jiahe Jin, Abhijay Paladugu, Chenyan Xiong</div>
<div class="meta-line">First: 2025-10-08T00:20:35+00:00 · Latest: 2026-01-16T18:30:29+00:00</div>
<div class="links" style="margin-top:8px"><a href="https://arxiv.org/abs/2510.06534v3">Abs</a> · <a href="https://arxiv.org/pdf/2510.06534v3">PDF</a> · <a href="https://github.com/cxcscmu/Behavior-Priming-for-Agentic-Search">Code1</a> · <a href="https://huggingface.co/huggingface">Code2</a> · <a href="https://huggingface.co/docs/hub/spaces">Code3</a></div>
<details class="detail"><summary>Abstract</summary>
<div class="mono">Agentic search requires large language models (LLMs) to perform multi-step search to solve complex information-seeking tasks, imposing unique challenges on their reasoning capabilities. However, what constitutes effective reasoning for agentic search and how it can be learned remains unclear. In this work, we first investigate the reasoning behaviors that enable success in agentic search. By comparing successful and failed trajectories via an LLM-based analysis pipeline, we identify four beneficial behaviors: Information Verification, Authority Evaluation, Adaptive Search, and Error Recovery. Building on this, we propose Behavior Priming, a training approach that equips agentic search models with these reasoning behaviors before reinforcement learning (RL). Specifically, it first performs supervised fine-tuning (SFT) on collected trajectories exhibiting the identified behaviors to cultivate these behaviors, and then applies standard RL to further improve task performance. Experiments on Qwen3-1.7B and Llama3.2-3B-Instruct show that Behavior Priming yields relative improvements over direct RL by 37.2\% on three web benchmarks and 6.2\% on seven multi-hop QA benchmarks, and outperforms the SFT-then-RL baseline using outcome-correct trajectories for fine-tuning. Crucially, we show that these reasoning behaviors matter more than outcome correctness in the priming stage prior to RL. Further analysis reveals that Behavior Priming enhances exploration (pass@8) and test-time scaling (search step number), providing a robust foundation for RL. Our code are avalible at https://github.com/cxcscmu/Behavior-Priming-for-Agentic-Search.</div></details>
<details class="detail"><summary>中文标题/摘要</summary>
<div class="mono"><b>标题：</b>智能体搜索中的有益推理行为及其有效后训练方法</div>
<div class="mono" style="margin-top:8px">智能体搜索要求大语言模型（LLM）执行多步搜索以解决复杂的信息获取任务，这对其推理能力提出了独特挑战。然而，何种推理对智能体搜索有效及其学习机制尚不明确。本研究首先探究了促成智能体搜索成功的推理行为：通过基于LLM的分析流程对比成功与失败轨迹，识别出四种有益行为——信息验证、权威性评估、自适应搜索和错误恢复。基于此，我们提出行为引导训练法，该方法在强化学习（RL）前为智能体搜索模型注入这些推理行为。具体流程包括：先对展现目标行为的轨迹进行监督微调（SFT）以培养行为模式，再通过标准RL提升任务性能。在Qwen3-1.7B和Llama3.2-3B-Instruct上的实验表明，行为引导训练在三个网页基准上相对直接RL提升37.2%，在七个多跳问答基准上提升6.2%，且优于使用结果正确轨迹进行微调的SFT-then-RL基线。关键发现表明，在RL前的引导阶段，这些推理行为比结果正确性更重要。进一步分析揭示，该方法能增强探索能力（pass@8）和测试时扩展性（搜索步数），为RL奠定坚实基础。代码已开源：https://github.com/cxcscmu/Behavior-Priming-for-Agentic-Search。</div>
</details>
<details class="detail"><summary>Summary / 总结</summary>
<div class="mono">This research addresses the unclear nature of effective reasoning for agentic search tasks, where large language models must perform multi-step information retrieval. The authors first analyze successful and failed search trajectories to identify four beneficial reasoning behaviors: Information Verification, Authority Evaluation, Adaptive Search, and Error Recovery. They then propose Behavior Priming, a two-stage training approach that first uses supervised fine-tuning on trajectories exhibiting these behaviors, followed by reinforcement learning. Experiments on Qwen3-1.7B and Llama3.2-3B-Instruct models show that this method yields substantial performance gains over direct reinforcement learning (37.2% on web benchmarks and 6.2% on multi-hop QA benchmarks), demonstrating that priming with these reasoning behaviors is more effective than using outcome-correct trajectories alone.</div>
<div class="mono" style="margin-top:8px">本研究旨在解决智能体搜索中有效推理行为不明确的问题，即大语言模型执行多步骤信息寻求任务时的推理机制。通过基于大语言模型的分析流程比较成功与失败的搜索轨迹，研究者识别出四种关键有益行为：信息验证、权威性评估、自适应搜索和错误恢复。基于此，他们提出了行为引导训练法，该方法采用两阶段训练策略：首先利用展现这些行为的轨迹进行监督微调，随后进行强化学习。在Qwen3-1.7B和Llama3.2-3B-Instruct模型上的实验表明，该方法相比直接强化学习在三个网页基准上取得37.2%的相对提升，在七个多跳问答基准上提升6.2%，同时增强了探索能力和测试时扩展性。</div>
</details>
</div>
<div class="card">
<div class="title">QUPID: A Partitioned Quantum Neural Network for Anomaly Detection in Smart Grid</div>
<div class="meta-line">Authors: Hoang M. Ngo, Tre&#x27; R. Jeter, Jung Taek Seo, My T. Thai</div>
<div class="meta-line">First: 2026-01-16T18:30:24+00:00 · Latest: 2026-01-16T18:30:24+00:00</div>
<div class="links" style="margin-top:8px"><a href="https://arxiv.org/abs/2601.11500v1">Abs</a> · <a href="https://arxiv.org/pdf/2601.11500v1">PDF</a> · <a href="https://huggingface.co/huggingface">Code1</a> · <a href="https://huggingface.co/docs/hub/spaces">Code2</a></div>
<details class="detail"><summary>Abstract</summary>
<div class="mono">Smart grid infrastructures have revolutionized energy distribution, but their day-to-day operations require robust anomaly detection methods to counter risks associated with cyber-physical threats and system faults potentially caused by natural disasters, equipment malfunctions, and cyber attacks. Conventional machine learning (ML) models are effective in several domains, yet they struggle to represent the complexities observed in smart grid systems. Furthermore, traditional ML models are highly susceptible to adversarial manipulations, making them increasingly unreliable for real-world deployment. Quantum ML (QML) provides a unique advantage, utilizing quantum-enhanced feature representations to model the intricacies of the high-dimensional nature of smart grid systems while demonstrating greater resilience to adversarial manipulation. In this work, we propose QUPID, a partitioned quantum neural network (PQNN) that outperforms traditional state-of-the-art ML models in anomaly detection. We extend our model to R-QUPID that even maintains its performance when including differential privacy (DP) for enhanced robustness. Moreover, our partitioning framework addresses a significant scalability problem in QML by efficiently distributing computational workloads, making quantum-enhanced anomaly detection practical in large-scale smart grid environments. Our experimental results across various scenarios exemplifies the efficacy of QUPID and R-QUPID to significantly improve anomaly detection capabilities and robustness compared to traditional ML approaches.</div></details>
<details class="detail"><summary>中文标题/摘要</summary>
<div class="mono"><b>标题：</b>QUPID：一种用于智能电网异常检测的分区量子神经网络</div>
<div class="mono" style="margin-top:8px">智能电网基础设施已彻底改变能源分配，但其日常运营需要稳健的异常检测方法，以应对网络物理威胁及自然灾害、设备故障和网络攻击可能引发的系统故障风险。传统机器学习模型在多个领域表现有效，但难以表征智能电网系统中观察到的复杂性。此外，传统模型极易受到对抗性操纵，在实际部署中可靠性日益降低。量子机器学习通过量子增强的特征表示，能有效建模智能电网系统高维特性，同时展现出更强的对抗性攻击鲁棒性。本文提出QUPID——一种分区量子神经网络，其在异常检测任务中优于传统先进机器学习模型。我们进一步扩展出R-QUPID模型，即使在引入差分隐私增强鲁棒性时仍保持性能。该分区框架通过高效分配计算负载，解决了量子机器学习中的关键可扩展性问题，使量子增强异常检测能实际应用于大规模智能电网环境。多场景实验表明，相较于传统机器学习方法，QUPID与R-QUPID能显著提升异常检测能力与系统鲁棒性。</div>
</details>
<details class="detail"><summary>Summary / 总结</summary>
<div class="mono">The research is motivated by the need for robust anomaly detection in smart grids to counter cyber-physical threats and system faults, where conventional machine learning models struggle with complexity and are vulnerable to adversarial attacks. The method introduces QUPID, a partitioned quantum neural network that uses quantum-enhanced feature representations, and extends it to R-QUPID with differential privacy for added robustness; the partitioning framework also addresses scalability by distributing computational workloads. Key experimental results show that QUPID and R-QUPID outperform traditional state-of-the-art models in anomaly detection and maintain performance with enhanced robustness, making them practical for large-scale smart grid environments.</div>
<div class="mono" style="margin-top:8px">本研究旨在解决智能电网系统中对鲁棒异常检测的需求，传统机器学习模型难以处理系统复杂性且易受对抗性攻击。作者提出了QUPID，一种利用量子增强特征表示来建模高维智能电网数据的分区量子神经网络，并将其扩展为具有差分隐私的R-QUPID以增强鲁棒性。实验结果表明，与传统最先进的机器学习模型相比，QUPID和R-QUPID在异常检测准确性和对抗性防御能力上均有显著提升，同时分区框架提高了可扩展性，使其适用于大规模实际部署。</div>
</details>
</div>
<div class="card">
<div class="title">Conditional Distribution Compression via the Kernel Conditional Mean Embedding</div>
<div class="meta-line">Authors: Dominic Broadbent, Nick Whiteley, Robert Allison, Tom Lovett</div>
<div class="meta-line">Venue: NeurIPS 2025</div>
<div class="meta-line">First: 2025-04-14T11:53:29+00:00 · Latest: 2026-01-16T18:26:41+00:00</div>
<div class="meta-line">Comments: 76 pages, 32 figures, accepted into NeurIPS 2025</div>
<div class="links" style="margin-top:8px"><a href="https://arxiv.org/abs/2504.10139v4">Abs</a> · <a href="https://arxiv.org/pdf/2504.10139v4">PDF</a> · <a href="https://huggingface.co/huggingface">Code1</a> · <a href="https://huggingface.co/docs/hub/spaces">Code2</a></div>
<details class="detail"><summary>Abstract</summary>
<div class="mono">Existing distribution compression methods, like Kernel Herding (KH), were originally developed for unlabelled data. However, no existing approach directly compresses the conditional distribution of \textit{labelled} data. To address this gap, we first introduce the Average Maximum Conditional Mean Discrepancy (AMCMD), a metric for comparing conditional distributions, and derive a closed form estimator. Next, we make a key observation: in the context of distribution compression, the cost of constructing a compressed set targeting the AMCMD can be reduced from cubic to linear. Leveraging this, we extend KH to propose Average Conditional Kernel Herding (ACKH), a linear-time greedy algorithm for constructing compressed sets that target the AMCMD. To better understand the advantages of directly compressing the conditional distribution rather than doing so via the joint distribution, we introduce Joint Kernel Herding (JKH), an adaptation of KH designed to compress the joint distribution of labelled data. While herding methods provide a simple and interpretable selection process, they rely on a greedy heuristic. To explore alternative optimisation strategies, we also propose Joint Kernel Inducing Points (JKIP) and Average Conditional Kernel Inducing Points (ACKIP), which jointly optimise the compressed set while maintaining linear complexity. Experiments show that directly preserving conditional distributions with ACKIP outperforms both joint distribution compression and the greedy selection used in ACKH. Moreover, we see that JKIP consistently outperforms JKH.</div></details>
<details class="detail"><summary>中文标题/摘要</summary>
<div class="mono"><b>标题：</b>基于核条件均值嵌入的条件分布压缩</div>
<div class="mono" style="margin-top:8px">现有分布压缩方法（如核牧群算法）最初是为无标签数据设计的，尚无方法能直接压缩带标签数据的条件分布。为此，本文首先提出平均最大条件均值差异作为条件分布比较指标，并推导出其闭式估计量。关键发现是：在分布压缩中，针对该指标的压缩集构建成本可从立方降至线性。基于此，我们将核牧群算法扩展为平均条件核牧群算法，这是一种线性时间贪心算法，用于构建针对该指标的压缩集。为比较条件分布直接压缩与通过联合分布间接压缩的差异，我们提出联合核牧群算法以压缩标签数据的联合分布。虽然牧群方法的选择过程简洁可解释，但其依赖贪心启发式策略。为此，我们进一步提出联合核诱导点与平均条件核诱导点方法，在保持线性复杂度的同时联合优化压缩集。实验表明：平均条件核诱导点通过直接保持条件分布，性能优于联合分布压缩及平均条件核牧群算法的贪心选择；且联合核诱导点始终优于联合核牧群算法。</div>
</details>
<details class="detail"><summary>Summary / 总结</summary>
<div class="mono">The research addresses the lack of methods for directly compressing the conditional distribution of labelled data, as existing techniques like Kernel Herding are designed for unlabelled data. The authors introduce the Average Maximum Conditional Mean Discrepancy (AMCMD) metric for comparing conditional distributions and propose a linear-time greedy algorithm, Average Conditional Kernel Herding (ACKH), for compression by exploiting a cost reduction from cubic to linear. They also develop Joint Kernel Herding (JKH) for joint distribution compression and alternative joint optimization methods, Joint Kernel Inducing Points (JKIP) and Average Conditional Kernel Inducing Points (ACKIP), with linear complexity. Experimental results demonstrate that directly compressing the conditional distribution using ACKIP outperforms joint distribution compression and the greedy ACKH, while JKIP consistently surpasses JKH.</div>
<div class="mono" style="margin-top:8px">本研究旨在解决现有分布压缩方法（如核赫丁）仅适用于无标签数据，而缺乏直接压缩带标签数据条件分布的问题。作者提出了用于比较条件分布的平均最大条件均值差异（AMCMD）度量，并通过利用从立方到线性的成本降低，开发了线性时间贪婪算法——平均条件核赫丁（ACKH）进行压缩。他们还提出了用于联合分布压缩的联合核赫丁（JKH），以及具有线性复杂度的替代联合优化方法——联合核诱导点（JKIP）和平均条件核诱导点（ACKIP）。实验结果表明，通过ACKIP直接保留条件分布优于联合分布压缩（JKH）和ACKH中的贪婪选择，同时JKIP始终优于JKH。</div>
</details>
</div>
<div class="card">
<div class="title">Meta-Learning Guided Pruning for Few-Shot Plant Pathology on Edge Devices</div>
<div class="meta-line">Authors: Shahnawaz Alam, Mohammed Mudassir Uddin, Mohammed Kaif Pasha</div>
<div class="meta-line">First: 2026-01-05T18:55:05+00:00 · Latest: 2026-01-16T18:26:08+00:00</div>
<div class="links" style="margin-top:8px"><a href="https://arxiv.org/abs/2601.02353v2">Abs</a> · <a href="https://arxiv.org/pdf/2601.02353v2">PDF</a> · <a href="https://huggingface.co/huggingface">Code1</a> · <a href="https://huggingface.co/docs/hub/spaces">Code2</a></div>
<details class="detail"><summary>Abstract</summary>
<div class="mono">A key challenge in agricultural AI is deploying disease detection systems in remote fields with limited access to laboratories or high-performance computing (HPC) resources. While deep learning (DL) models, specifically deep convolutional networks, achieve high accuracy in identifying plant pathologies from leaf imagery, their memory footprints and computational demands limit edge deployment on devices constrained by battery life, processing power, and connectivity, such as Raspberry Pi. Few-shot learning (FSL) paradigms offer a compelling solution to the data scarcity problem inherent in agricultural applications, where obtaining labeled samples for novel disease variants proves both costly and time-sensitive. This work introduces a framework combining pruning with meta-learning for agricultural disease classification, addressing the tension between generalization capability and deployment feasibility. The proposed approach combines a novel Disease-Aware Channel Importance Scoring (DACIS) mechanism with a three-stage Prune-then-Meta-Learn-then-Prune (PMP) pipeline. Experiments on PlantVillage and PlantDoc datasets demonstrate that the proposed approach reduces model size by 78\% while maintaining 92.3\% of the original accuracy. The compressed model achieves 7 frames per second (FPS) on a Raspberry Pi 4, enabling practical real-time field diagnosis for smallholder farmers.</div></details>
<details class="detail"><summary>中文标题/摘要</summary>
<div class="mono"><b>标题：</b>面向边缘设备少样本植物病理识别的元学习引导剪枝方法</div>
<div class="mono" style="margin-top:8px">农业人工智能面临的关键挑战是在缺乏实验室或高性能计算资源的偏远田间部署病害检测系统。虽然深度学习模型（特别是深度卷积网络）在叶片图像病理识别中具有高精度，但其内存占用和计算需求限制了在电池续航、处理能力和连接性受限的边缘设备（如树莓派）上的部署。少样本学习范式为农业应用中固有的数据稀缺问题提供了有效解决方案——获取新型病害变异的标注样本成本高昂且时效性强。本研究提出融合剪枝与元学习的农业病害分类框架，以解决泛化能力与部署可行性之间的矛盾。该方法结合新型病害感知通道重要性评分机制与三阶段&#x27;剪枝-元学习-再剪枝&#x27;流程。在PlantVillage和PlantDoc数据集上的实验表明，所提方法在保持原始精度92.3%的同时将模型体积缩减78%。压缩模型在树莓派4上达到每秒7帧的处理速度，为小农户实现了实用的实时田间诊断。</div>
</details>
<details class="detail"><summary>Summary / 总结</summary>
<div class="mono">To enable real-time plant disease detection on resource-constrained edge devices in remote agricultural settings, this research addresses the dual challenges of data scarcity and high computational demands of deep learning models. The method introduces a novel Disease-Aware Channel Importance Scoring (DACIS) mechanism integrated into a three-stage Prune-then-Meta-Learn-then-Prune (PMP) pipeline, which combines pruning with meta-learning to compress models while preserving their few-shot generalization capability. Experimental results on the PlantVillage and PlantDoc datasets show the framework reduces model size by 78% while retaining 92.3% of the original accuracy, and the compressed model runs at 7 frames per second on a Raspberry Pi 4, demonstrating practical feasibility for on-site diagnosis.</div>
<div class="mono" style="margin-top:8px">为实现资源受限的边缘设备在偏远农业场景中进行实时植物病害检测，本研究旨在解决深度学习模型数据稀缺和计算需求高的双重挑战。该方法提出了一个将剪枝与元学习相结合的框架，具体通过一种新颖的疾病感知通道重要性评分（DACIS）机制，在一个三阶段的“剪枝-元学习-再剪枝”（PMP）流程中压缩模型，以进行小样本学习。在PlantVillage和PlantDoc数据集上的实验结果表明，该方法将模型大小减少了78%，同时保持了原始精度的92.3%，压缩后的模型在树莓派4上达到每秒7帧的处理速度，证明了其田间部署的实用性。</div>
</details>
</div>
<div class="card">
<div class="title">On the Probability of First Success in Differential Evolution: Hazard Identities and Tail Bounds</div>
<div class="meta-line">Authors: Dimitar Nedanovski, Svetoslav Nenov, Dimitar Pilev</div>
<div class="meta-line">First: 2026-01-16T18:24:24+00:00 · Latest: 2026-01-16T18:24:24+00:00</div>
<div class="meta-line">Comments: All codes are publically available at https://github.com/snenovgmailcom/lshade_hazard_project</div>
<div class="links" style="margin-top:8px"><a href="https://arxiv.org/abs/2601.11499v1">Abs</a> · <a href="https://arxiv.org/pdf/2601.11499v1">PDF</a> · <a href="https://github.com/snenovgmailcom/lshade_hazard_project">Code1</a> · <a href="https://huggingface.co/huggingface">Code2</a> · <a href="https://huggingface.co/docs/hub/spaces">Code3</a></div>
<details class="detail"><summary>Abstract</summary>
<div class="mono">We study first-hitting times in Differential Evolution (DE) through a conditional hazard frame work. Instead of analyzing convergence via Markov-chain transition kernels or drift arguments, we ex press the survival probability of a measurable target set $A$ as a product of conditional first-hit probabilities (hazards) $p_t=\Prob(E_t\mid\mathcal F_{t-1})$. This yields distribution-free identities for survival and explicit tail bounds whenever deterministic lower bounds on the hazard hold on the survival event.
  For the L-SHADE algorithm with current-to-$p$best/1 mutation, we construct a checkable algorithmic witness event $\mathcal L_t$ under which the conditional hazard admits an explicit lower bound depending only on sampling rules, population size, and crossover statistics. This separates theoretical constants from empirical event frequencies and explains why worst-case constant-hazard bounds are typically conservative.
  We complement the theory with a Kaplan--Meier survival analysis on the CEC2017 benchmark suite . Across functions and budgets, we identify three distinct empirical regimes: (i) strongly clustered success, where hitting times concentrate in short bursts; (ii) approximately geometric tails, where a constant-hazard model is accurate; and (iii) intractable cases with no observed hits within the evaluation horizon. The results show that while constant-hazard bounds provide valid tail envelopes, the practical behavior of L-SHADE is governed by burst-like transitions rather than homogeneous per-generati on success probabilities.</div></details>
<details class="detail"><summary>中文标题/摘要</summary>
<div class="mono"><b>标题：</b>差分进化首次成功概率研究：风险恒等式与尾界</div>
<div class="mono" style="margin-top:8px">本研究通过条件风险框架分析差分进化算法的首次命中时间。不同于采用马尔可夫链转移核或漂移论证的收敛性分析方法，我们将可测目标集A的存活概率表达为条件首次命中概率（风险）$p_t=\Prob(E_t\mid\mathcal F_{t-1})$的乘积。当存活事件上存在风险的确切下界时，该方法可推导出与分布无关的存活恒等式及显式尾界。
针对采用current-to-$p$best/1变异的L-SHADE算法，我们构建了可检验的算法见证事件$\mathcal L_t$，使得条件风险存在仅取决于采样规则、种群规模和交叉统计量的显式下界。该方法将理论常数与经验事件频率分离，解释了为何最坏情况下的常数风险界通常趋于保守。
我们通过在CEC2017基准测试集上进行Kaplan-Meier存活分析来补充理论。跨函数与计算预算的实验识别出三种经验模式：（i）强聚类成功模式——命中时间集中分布于短时爆发区间；（ii）近似几何尾模式——常数风险模型具有准确性；（iii）难解案例——评估周期内未观测到命中事件。结果表明，虽然常数风险界能提供有效的尾包络，但L-SHADE的实际行为由爆发式跃迁主导，而非均匀的逐代成功概率。</div>
</details>
<details class="detail"><summary>Summary / 总结</summary>
<div class="mono">This research investigates the probability of first success in Differential Evolution (DE) to better understand its runtime behavior, moving beyond traditional Markov-chain or drift analyses. The method introduces a conditional hazard framework that expresses the survival probability of a target set as a product of conditional first-hit probabilities, yielding distribution-free identities and explicit tail bounds when deterministic lower bounds on the hazard exist. For the L-SHADE algorithm, the authors construct a checkable witness event that provides an explicit lower bound for the conditional hazard, separating theoretical constants from empirical frequencies. Experimental results from a Kaplan-Meier survival analysis on the CEC2017 benchmark reveal three empirical regimes: strongly clustered success with concentrated hitting times, approximately geometric tails where a constant-hazard model fits, and intractable cases with no observed hits, demonstrating that L-SHADE&#x27;s practical behavior is governed by burst-like transitions rather than homogeneous per-generation success probabilities.</div>
<div class="mono" style="margin-top:8px">本研究旨在通过超越传统的马尔可夫链或漂移分析，来理解差分进化算法中的首次命中时间。它引入了一个条件风险框架，将目标集的生存概率表示为条件首次命中概率的乘积，从而在存在风险的确定性下界时，导出了分布无关的恒等式和显式尾部边界。针对采用当前到p最佳/1变异的L-SHADE算法，该方法构建了一个可检查的算法见证事件，该事件给出了条件风险的显式下界，从而将理论常数与经验频率分离开来。在CEC2017基准测试上的实验分析揭示了三种经验模式：命中时间高度集中的强聚类成功、常数风险模型准确的近似几何尾部，以及无观测命中的难解情况，表明L-SHADE的实际行为以突发式跃迁为特征，而非均匀的每代成功概率。</div>
</details>
</div>
<div class="card">
<div class="title">A Distributed Generative AI Approach for Heterogeneous Multi-Domain Environments under Data Sharing constraints</div>
<div class="meta-line">Authors: Youssef Tawfilis, Hossam Amer, Minar El-Aasser, Tallal Elshabrawy</div>
<div class="meta-line">First: 2025-07-17T10:31:31+00:00 · Latest: 2026-01-16T18:20:30+00:00</div>
<div class="meta-line">Comments: Accepted and published in Transactions on Machine Learning Research (TMLR), 2026</div>
<div class="links" style="margin-top:8px"><a href="https://arxiv.org/abs/2507.12979v3">Abs</a> · <a href="https://arxiv.org/pdf/2507.12979v3">PDF</a> · <a href="https://huggingface.co/huggingface">Code1</a> · <a href="https://huggingface.co/docs/hub/spaces">Code2</a> · <a href="https://distributed-gen-ai.github.io/huscf-gan.github.io/">Project1</a></div>
<details class="detail"><summary>Abstract</summary>
<div class="mono">Federated Learning has gained attention for its ability to enable multiple nodes to collaboratively train machine learning models without sharing raw data. At the same time, Generative AI -- particularly Generative Adversarial Networks (GANs) -- have achieved remarkable success across a wide range of domains, such as healthcare, security, and Image Generation. However, training generative models typically requires large datasets and significant computational resources, which are often unavailable in real-world settings. Acquiring such resources can be costly and inefficient, especially when many underutilized devices -- such as IoT devices and edge devices -- with varying capabilities remain idle. Moreover, obtaining large datasets is challenging due to privacy concerns and copyright restrictions, as most devices are unwilling to share their data. To address these challenges, we propose a novel approach for decentralized GAN training that enables utilizing distributed data and underutilized, low-capability devices while not sharing data in its raw form. Our approach is designed to tackle key challenges in decentralized environments, combining KLD-weighted Clustered Federated Learning to address the issues of data heterogeneity and multi-domain datasets, with Heterogeneous U-Shaped split learning to tackle the challenge of device heterogeneity under strict data sharing constraints -- ensuring that no labels or raw data, whether real or synthetic, are ever shared between nodes. Experiments show that our approach demonstrates significant improvements across key metrics, where it achieves an average 10% boost in classification metrics (up to 60% in multi-domain non-IID settings), 1.1x -- 3x higher image generation scores for the MNIST family datasets, and 2x -- 70x lower FID scores for higher resolution datasets. Find our code at https://distributed-gen-ai.github.io/huscf-gan.github.io/.</div></details>
<details class="detail"><summary>中文标题/摘要</summary>
<div class="mono"><b>标题：</b>数据共享约束下异构多域环境的分布式生成式人工智能方法</div>
<div class="mono" style="margin-top:8px">联邦学习因其能使多个节点在不共享原始数据的情况下协作训练机器学习模型而受到关注。与此同时，生成式人工智能——特别是生成对抗网络——在医疗、安全和图像生成等多个领域取得了显著成功。然而，训练生成模型通常需要大规模数据集和大量计算资源，这在现实场景中往往难以满足。获取此类资源成本高昂且效率低下，尤其是在大量能力各异的未充分利用设备（如物联网设备和边缘设备）处于闲置状态时。此外，由于隐私担忧和版权限制，获取大规模数据集具有挑战性，因为大多数设备不愿共享其数据。为应对这些挑战，我们提出了一种去中心化GAN训练的新方法，能够在无需共享原始数据形式的前提下，利用分布式数据和未充分利用的低能力设备。该方法旨在解决去中心化环境中的关键挑战：结合KLD加权聚类联邦学习处理数据异构性和多域数据集问题，并采用异构U形分割学习应对严格数据共享约束下的设备异构性挑战——确保节点间从不共享任何标签或原始数据（无论是真实数据还是合成数据）。实验表明，该方法在关键指标上均有显著提升：分类指标平均提升10%（在多域非独立同分布设置中最高达60%），MNIST系列数据集的图像生成分数提高1.1-3倍，高分辨率数据集的FID分数降低2-70倍。代码详见：https://distributed-gen-ai.github.io/huscf-gan.github.io/。</div>
</details>
<details class="detail"><summary>Summary / 总结</summary>
<div class="mono">This research addresses the challenges of training generative models like GANs in real-world settings where large, centralized datasets and high computational power are scarce due to privacy concerns, copyright restrictions, and the prevalence of heterogeneous, underutilized devices. The proposed method combines KLD-weighted Clustered Federated Learning to manage data heterogeneity across multiple domains with Heterogeneous U-Shaped split learning to accommodate devices of varying capabilities, all while enforcing strict constraints that prevent the sharing of any raw or synthetic data and labels between nodes. Experimental results demonstrate that this decentralized approach yields substantial improvements, including an average 10% increase in classification metrics (up to 60% in multi-domain non-IID settings), a 1.1x to 3x enhancement in image generation scores for MNIST-family datasets, and a 2x to 70x reduction in FID scores for higher-resolution datasets.</div>
<div class="mono" style="margin-top:8px">本研究旨在解决在现实环境中训练生成对抗网络（GAN）等生成模型所面临的挑战，这些环境因隐私问题、版权限制以及异构、未充分利用设备的普遍存在，而缺乏大型集中式数据集和高计算资源。所提出的方法结合了KLD加权聚类联邦学习以处理多领域数据异构性，以及异构U型分割学习以适应不同能力的设备，同时强制执行严格约束，防止节点间共享任何原始或合成数据及标签。实验结果表明，这种去中心化方法带来了显著改进，包括分类指标平均提升10%（在多领域非独立同分布设置中最高达60%），MNIST系列数据集的图像生成分数提高1.1至3倍，以及高分辨率数据集的FID分数降低2至70倍。</div>
</details>
</div>
<div class="card">
<div class="title">Differentiable Cyclic Causal Discovery Under Unmeasured Confounders</div>
<div class="meta-line">Authors: Muralikrishnna G. Sethuraman, Faramarz Fekri</div>
<div class="meta-line">First: 2025-08-11T20:13:34+00:00 · Latest: 2026-01-16T18:16:17+00:00</div>
<div class="links" style="margin-top:8px"><a href="https://arxiv.org/abs/2508.08450v2">Abs</a> · <a href="https://arxiv.org/pdf/2508.08450v2">PDF</a> · <a href="https://huggingface.co/huggingface">Code1</a> · <a href="https://huggingface.co/docs/hub/spaces">Code2</a></div>
<details class="detail"><summary>Abstract</summary>
<div class="mono">Understanding causal relationships between variables is fundamental across scientific disciplines. Most causal discovery algorithms rely on two key assumptions: (i) all variables are observed, and (ii) the underlying causal graph is acyclic. While these assumptions simplify theoretical analysis, they are often violated in real-world systems, such as biological networks. Existing methods that account for confounders either assume linearity or struggle with scalability. To address these limitations, we propose DCCD-CONF, a novel framework for differentiable learning of nonlinear cyclic causal graphs in the presence of unmeasured confounders using interventional data. Our approach alternates between optimizing the graph structure and estimating the confounder distribution by maximizing the log-likelihood of the data. Through experiments on synthetic data and real-world gene perturbation datasets, we show that DCCD-CONF outperforms state-of-the-art methods in both causal graph recovery and confounder identification. Additionally, we also provide consistency guarantees for our framework, reinforcing its theoretical soundness.</div></details>
<details class="detail"><summary>中文标题/摘要</summary>
<div class="mono"><b>标题：</b>未测量混杂因素下的可微分循环因果发现</div>
<div class="mono" style="margin-top:8px">理解变量间的因果关系是科学领域的核心问题。多数因果发现算法依赖两个关键假设：(i) 所有变量均可观测，(ii) 基础因果图为无环结构。尽管这些假设简化了理论分析，但在生物网络等现实系统中常被违背。现有处理混杂因素的方法要么假设线性关系，要么面临可扩展性挑战。为突破这些局限，我们提出DCCD-CONF框架，利用干预数据实现未测量混杂因素下非线性循环因果图的可微分学习。该方法通过交替优化图结构与最大化数据对数似然来估计混杂因素分布。在合成数据和真实基因扰动数据集上的实验表明，DCCD-CONF在因果图还原和混杂因素识别方面均优于现有先进方法。此外，我们还为该框架提供了理论一致性保证，强化了其理论严谨性。</div>
</details>
<details class="detail"><summary>Summary / 总结</summary>
<div class="mono">Motivated by the frequent violation of the assumptions that all variables are observed and that causal graphs are acyclic in real-world systems like biological networks, this paper introduces DCCD-CONF, a differentiable framework for learning nonlinear cyclic causal graphs from interventional data in the presence of unmeasured confounders. The method alternates between optimizing the graph structure and estimating the confounder distribution by maximizing the data log-likelihood. Experimental results on synthetic data and real-world gene perturbation datasets demonstrate that DCCD-CONF outperforms existing state-of-the-art methods in recovering causal graphs and identifying confounders, and the framework is supported by consistency guarantees.</div>
<div class="mono" style="margin-top:8px">针对现实系统（如生物网络）中常违反所有变量可观测且因果图无环的假设，本文提出了DCCD-CONF，一个在未测量混杂因子存在下利用干预数据学习非线性循环因果图的可微框架。该方法通过最大化数据对数似然，交替优化图结构和估计混杂因子分布。在合成数据和真实基因扰动数据集上的实验表明，DCCD-CONF在因果图恢复和混杂因子识别方面优于现有先进方法，并得到了理论一致性保证的支持。</div>
</details>
</div>
<div class="card">
<div class="title">Extractive summarization on a CMOS Ising machine</div>
<div class="meta-line">Authors: Ziqing Zeng, Abhimanyu Kumar, Chris H. Kim, Ulya R. Karpuzcu, Sachin S. Sapatnekar</div>
<div class="meta-line">First: 2026-01-16T18:14:02+00:00 · Latest: 2026-01-16T18:14:02+00:00</div>
<div class="links" style="margin-top:8px"><a href="https://arxiv.org/abs/2601.11491v1">Abs</a> · <a href="https://arxiv.org/pdf/2601.11491v1">PDF</a> · <a href="https://huggingface.co/huggingface">Code1</a> · <a href="https://huggingface.co/docs/hub/spaces">Code2</a></div>
<details class="detail"><summary>Abstract</summary>
<div class="mono">Extractive summarization (ES) aims to generate a concise summary by selecting a subset of sentences from a document while maximizing relevance and minimizing redundancy. Although modern ES systems achieve high accuracy using powerful neural models, their deployment typically relies on CPU or GPU infrastructures that are energy-intensive and poorly suited for real-time inference in resource-constrained environments. In this work, we explore the feasibility of implementing McDonald-style extractive summarization on a low-power CMOS coupled oscillator-based Ising machine (COBI) that supports integer-valued, all-to-all spin couplings. We first propose a hardware-aware Ising formulation that reduces the scale imbalance between local fields and coupling terms, thereby improving robustness to coefficient quantization: this method can be applied to any problem formulation that requires k of n variables to be chosen. We then develop a complete ES pipeline including (i) stochastic rounding and iterative refinement to compensate for precision loss, and (ii) a decomposition strategy that partitions a large ES problem into smaller Ising subproblems that can be efficiently solved on COBI and later combined. Experimental results on the CNN/DailyMail dataset show that our pipeline can produce high-quality summaries using only integer-coupled Ising hardware with limited precision. COBI achieves 3-4.5x runtime speedups compared to a brute-force method, which is comparable to software Tabu search, and two to three orders of magnitude reductions in energy, while maintaining competitive summary quality. These results highlight the potential of deploying CMOS Ising solvers for real-time, low-energy text summarization on edge devices.</div></details>
<details class="detail"><summary>中文标题/摘要</summary>
<div class="mono"><b>标题：</b>基于CMOS伊辛机的抽取式文本摘要</div>
<div class="mono" style="margin-top:8px">抽取式摘要旨在通过从文档中选择句子子集来生成简洁摘要，同时最大化相关性和最小化冗余性。尽管现代抽取式摘要系统利用强大的神经模型实现了高精度，但其部署通常依赖能耗较高的CPU或GPU架构，难以适应资源受限环境中的实时推理需求。本研究探索了在支持整数值全连接自旋耦合的低功耗CMOS耦合振荡器伊辛机上实现McDonald式抽取式摘要的可行性。我们首先提出一种硬件感知的伊辛模型公式，通过减小局部场与耦合项间的尺度不平衡来提升系数量化鲁棒性——该方法可推广至任何需要从n个变量中选择k个的优化问题。随后开发了完整的抽取式摘要流程，包括：(i) 采用随机舍入与迭代优化补偿精度损失；(ii) 设计分解策略将大规模摘要问题拆分为可在CMOS耦合振荡器伊辛机上高效求解的伊辛子问题。在CNN/DailyMail数据集上的实验表明，该流程仅需有限精度的整数耦合伊辛硬件即可生成高质量摘要。相较于暴力求解法，CMOS耦合振荡器伊辛机实现了3-4.5倍的运行加速（与软件禁忌搜索算法相当），能耗降低2-3个数量级，同时保持具有竞争力的摘要质量。这些结果凸显了CMOS伊辛求解器在边缘设备上实现实时低能耗文本摘要的应用潜力。</div>
</details>
<details class="detail"><summary>Summary / 总结</summary>
<div class="mono">This work addresses the high energy consumption and computational demands of modern neural extractive summarization systems, which limit their deployment in resource-constrained environments. The authors propose implementing a McDonald-style extractive summarization model on a low-power CMOS coupled oscillator-based Ising machine (COBI) by developing a hardware-aware Ising formulation that improves robustness to coefficient quantization, alongside a complete pipeline featuring stochastic rounding, iterative refinement, and a decomposition strategy to handle large problems. Experiments on the CNN/DailyMail dataset demonstrate that the COBI-based pipeline achieves runtime speedups of 3-4.5x over a brute-force method, comparable to software Tabu search, while reducing energy consumption by two to three orders of magnitude and maintaining competitive summary quality.</div>
<div class="mono" style="margin-top:8px">本研究针对神经抽取式摘要系统的高能耗和高延迟问题，探索了一种基于CMOS耦合振荡器伊辛机（COBI）的硬件高效实现方法。该方法将摘要任务表述为伊辛问题，采用一种硬件感知的缩放技术以提高对量化的鲁棒性，并构建了一个包含随机舍入、迭代优化和问题分解的完整流程来应对有限精度。在CNN/DailyMail数据集上的实验结果表明，COBI实现相比暴力方法获得了3-4.5倍的运行加速，与软件禁忌搜索性能相当，同时能耗降低了二到三个数量级，且保持了有竞争力的摘要质量。</div>
</details>
</div>
<div class="card">
<div class="title">UCB-type Algorithm for Budget-Constrained Expert Learning</div>
<div class="meta-line">Authors: Ilgam Latypov, Alexandra Suvorikova, Alexey Kroshnin, Alexander Gasnikov, Yuriy Dorn</div>
<div class="meta-line">First: 2025-10-26T12:36:17+00:00 · Latest: 2026-01-16T17:59:33+00:00</div>
<div class="links" style="margin-top:8px"><a href="https://arxiv.org/abs/2510.22654v2">Abs</a> · <a href="https://arxiv.org/pdf/2510.22654v2">PDF</a> · <a href="https://huggingface.co/huggingface">Code1</a> · <a href="https://huggingface.co/docs/hub/spaces">Code2</a></div>
<details class="detail"><summary>Abstract</summary>
<div class="mono">In many modern applications, a system must dynamically choose between several adaptive learning algorithms that are trained online. Examples include model selection in streaming environments, switching between trading strategies in finance, and orchestrating multiple contextual bandit or reinforcement learning agents. At each round, a learner must select one predictor among $K$ adaptive experts to make a prediction, while being able to update at most $M \le K$ of them under a fixed training budget.
  We address this problem in the \emph{stochastic setting} and introduce \algname{M-LCB}, a computationally efficient UCB-style meta-algorithm that provides \emph{anytime regret guarantees}. Its confidence intervals are built directly from realized losses, require no additional optimization, and seamlessly reflect the convergence properties of the underlying experts. If each expert achieves internal regret $\tilde O(T^α)$, then \algname{M-LCB} ensures overall regret bounded by $\tilde O\!\Bigl(\sqrt{\tfrac{KT}{M}} \;+\; (K/M)^{1-α}\,T^α\Bigr)$.
  To our knowledge, this is the first result establishing regret guarantees when multiple adaptive experts are trained simultaneously under per-round budget constraints. We illustrate the framework with two representative cases: (i) parametric models trained online with stochastic losses, and (ii) experts that are themselves multi-armed bandit algorithms. These examples highlight how \algname{M-LCB} extends the classical bandit paradigm to the more realistic scenario of coordinating stateful, self-learning experts under limited resources.</div></details>
<details class="detail"><summary>中文标题/摘要</summary>
<div class="mono"><b>标题：</b>预算约束专家学习的UCB型算法</div>
<div class="mono" style="margin-top:8px">在许多现代应用中，系统必须动态选择在多个在线训练的自适应学习算法之间进行切换。典型场景包括流式环境中的模型选择、金融交易策略切换，以及协调多个上下文赌博机或强化学习智能体。在每轮决策中，学习者需从$K$个自适应专家中选择一个预测器进行预测，同时在固定训练预算下最多更新$M \le K$个专家。
  我们在\emph{随机环境}中研究该问题，提出计算高效的UCB风格元算法\algname{M-LCB}，该算法提供\emph{任意时段的遗憾保证}。其置信区间直接基于已实现损失构建，无需额外优化，并能自然反映底层专家的收敛特性。若每个专家实现内部遗憾$\tilde O(T^α)$，则\algname{M-LCB}确保整体遗憾上界为$\tilde O\!\Bigl(\sqrt{\tfrac{KT}{M}} \;+\; (K/M)^{1-α}\,T^α\Bigr)$。
  据我们所知，这是在每轮预算约束下同时训练多个自适应专家的首个遗憾保证理论结果。我们通过两个典型案例说明该框架：(i) 基于随机损失在线训练的参数模型；(ii) 本身为多臂赌博机算法的专家。这些案例展示了\algname{M-LCB}如何将经典赌博机范式扩展到有限资源下协调具有状态的自学习专家这一更现实的场景。</div>
</details>
<details class="detail"><summary>Summary / 总结</summary>
<div class="mono">The research addresses the challenge of dynamically selecting among multiple adaptive learning algorithms under a fixed per-round training budget, which arises in applications like streaming model selection and financial strategy switching. The authors propose M-LCB, a UCB-style meta-algorithm that efficiently allocates the budget by constructing confidence intervals directly from observed losses, without requiring additional optimization, and provides anytime regret guarantees. Experimental results show that if each expert achieves internal regret of order \(\tilde O(T^\alpha)\), M-LCB ensures overall regret bounded by \(\tilde O\!\Bigl(\sqrt{\tfrac{KT}{M}} + (K/M)^{1-\alpha}T^\alpha\Bigr)\), demonstrating its effectiveness in coordinating stateful experts, such as online parametric models or bandit algorithms, under resource constraints.</div>
<div class="mono" style="margin-top:8px">该研究针对在每轮固定训练预算下动态选择多个自适应学习算法的挑战，这在流式模型选择和金融策略切换等应用中常见。作者提出了M-LCB，一种基于UCB风格的元算法，通过直接根据已实现损失构建置信区间来高效分配预算，无需额外优化。实验结果表明，若每个专家实现内部遗憾为\(\tilde O(T^\alpha)\)，M-LCB能确保整体遗憾界为\(\tilde O\!\Bigl(\sqrt{\tfrac{KT}{M}} + (K/M)^{1-\alpha}T^\alpha\Bigr)\)，证明了其在资源有限条件下协调有状态专家的有效性。</div>
</details>
</div>
<div class="card">
<div class="title">A Probabilistic Approach to Trajectory-Based Optimal Experimental Design</div>
<div class="meta-line">Authors: Ahmed Attia</div>
<div class="meta-line">First: 2026-01-16T17:58:16+00:00 · Latest: 2026-01-16T17:58:16+00:00</div>
<div class="meta-line">Comments: 42 Figures, this version includes supplementary material as appendices</div>
<div class="links" style="margin-top:8px"><a href="https://arxiv.org/abs/2601.11473v1">Abs</a> · <a href="https://arxiv.org/pdf/2601.11473v1">PDF</a> · <a href="https://huggingface.co/huggingface">Code1</a> · <a href="https://huggingface.co/docs/hub/spaces">Code2</a></div>
<details class="detail"><summary>Abstract</summary>
<div class="mono">We present a novel probabilistic approach for optimal path experimental design. In this approach a discrete path optimization problem is defined on a static navigation mesh, and trajectories are modeled as random variables governed by a parametric Markov policy. The discrete path optimization problem is then replaced with an equivalent stochastic optimization problem over the policy parameters, resulting in an optimal probability model that samples estimates of the optimal discrete path. This approach enables exploration of the utility function&#x27;s distribution tail and treats the utility function of the design as a black box, making it applicable to linear and nonlinear inverse problems and beyond experimental design. Numerical verification and analysis are carried out by using a parameter identification problem widely used in model-based optimal experimental design.</div></details>
<details class="detail"><summary>中文标题/摘要</summary>
<div class="mono"><b>标题：</b>基于轨迹的最优实验设计概率方法</div>
<div class="mono" style="margin-top:8px">本文提出了一种用于最优路径实验设计的新型概率方法。该方法在静态导航网格上定义离散路径优化问题，并将轨迹建模为由参数化马尔可夫策略控制的随机变量。随后，离散路径优化问题被替换为策略参数上的等效随机优化问题，从而得到可采样最优离散路径估计的最优概率模型。该方法能够探索效用函数的分布尾部，并将设计效用函数视为黑箱，使其适用于线性和非线性反问题，并拓展至实验设计之外。通过基于模型的最优实验设计中广泛使用的参数识别问题，进行了数值验证与分析。</div>
</details>
<details class="detail"><summary>Summary / 总结</summary>
<div class="mono">The research aims to develop a flexible method for optimal experimental design based on trajectory optimization, applicable to both linear and nonlinear inverse problems. The method formulates the discrete path optimization as a stochastic optimization over parameters of a Markov policy, creating a probabilistic model that samples estimates of the optimal path while treating the utility function as a black box. Numerical experiments using a parameter identification problem demonstrate the approach&#x27;s capability to explore the tail of the utility distribution and verify its effectiveness.</div>
<div class="mono" style="margin-top:8px">该研究针对轨迹优化实验设计的需求，提出了一种概率方法，将离散路径优化问题转化为随机策略搜索。该方法在静态导航网格上将轨迹建模为服从参数化马尔可夫策略的随机变量，从而将路径优化等价为对策略参数的随机优化，得到一个能采样近似最优路径的概率模型。通过参数识别问题的数值验证表明，该方法能够探索效用函数的分布尾部，并将设计效用函数视为黑箱，适用于线性和非线性反问题以及更广泛的实验设计场景。</div>
</details>
</div>
<div class="card">
<div class="title">Low-Rank Key Value Attention</div>
<div class="meta-line">Authors: James O&#x27;Neill, Robert Clancy, Mariia Matskevichus, Fergal Reid</div>
<div class="meta-line">First: 2026-01-16T17:56:40+00:00 · Latest: 2026-01-16T17:56:40+00:00</div>
<div class="links" style="margin-top:8px"><a href="https://arxiv.org/abs/2601.11471v1">Abs</a> · <a href="https://arxiv.org/pdf/2601.11471v1">PDF</a> · <a href="https://huggingface.co/huggingface">Code1</a> · <a href="https://huggingface.co/docs/hub/spaces">Code2</a></div>
<details class="detail"><summary>Abstract</summary>
<div class="mono">Transformer pretraining is increasingly constrained by memory and compute requirements, with the key-value (KV) cache emerging as a dominant bottleneck during training and autoregressive decoding. We propose \textit{low-rank KV adaptation} (LRKV), a simple modification of multi-head attention that reduces KV cache memory by exploiting redundancy across attention heads while preserving full token-level resolution. Each layer uses a shared full-rank KV projection augmented with low-rank, head-specific residuals, yielding a continuous trade-off between complete sharing and fully independent attention.
  LRKV is a drop-in replacement for standard multi-head attention and directly subsumes query-sharing approaches such as multi-query and grouped-query attention, while remaining distinct from latent-compression methods such as multi-latent attention (MLA). Across large-scale pretraining experiments, LRKV consistently achieves faster loss reduction, lower validation perplexity, and stronger downstream task performance than standard attention, MQA/GQA, and MLA. At the 2.5B scale, LRKV outperforms standard attention while using roughly half the KV cache, and reaches equivalent model quality with up to \textbf{20-25\% less training compute} when measured in cumulative FLOPs. To explain these gains, we analyze attention head structure in operator space and show that LRKV preserves nearly all functional head diversity relative to standard attention, whereas more aggressive KV-sharing mechanisms rely on compensatory query specialization. Together, these results establish LRKV as a practical and effective attention mechanism for scaling Transformer pretraining under memory- and compute-constrained regimes.</div></details>
<details class="detail"><summary>中文标题/摘要</summary>
<div class="mono"><b>标题：</b>低秩键值注意力</div>
<div class="mono" style="margin-top:8px">Transformer预训练日益受到内存和计算需求的限制，其中键值（KV）缓存已成为训练和自回归解码过程中的主要瓶颈。我们提出\textit{低秩KV适配}（LRKV），这是对多头注意力的一个简单改进，通过利用注意力头之间的冗余性来减少KV缓存内存，同时保持完整的词元级分辨率。每一层使用共享的全秩KV投影，并辅以低秩、头特定的残差，从而在完全共享和完全独立注意力之间实现连续权衡。LRKV可直接替代标准多头注意力，并直接涵盖多查询和分组查询注意力等查询共享方法，同时区别于多潜在注意力（MLA）等潜在压缩方法。在大规模预训练实验中，与标准注意力、MQA/GQA和MLA相比，LRKV始终实现更快的损失下降、更低的验证困惑度和更强的下游任务性能。在25亿参数规模下，LRKV在使用约一半KV缓存的同时优于标准注意力，并在累积FLOPs衡量下，以\textbf{减少20-25%训练计算量}达到同等模型质量。为解释这些优势，我们在算子空间分析注意力头结构，表明LRKV相对于标准注意力保留了几乎全部功能性头多样性，而更激进的KV共享机制则依赖补偿性查询专门化。综上，这些结果确立了LRKV作为一种实用有效的注意力机制，适用于内存和计算受限场景下的Transformer预训练扩展。</div>
</details>
<details class="detail"><summary>Summary / 总结</summary>
<div class="mono">To address the memory and compute bottlenecks caused by the key-value (KV) cache in Transformer training and decoding, this paper proposes Low-Rank KV Adaptation (LRKV), a modified multi-head attention mechanism that reduces KV cache memory by using a shared full-rank KV projection with low-rank, head-specific residuals. This method offers a flexible trade-off between head sharing and independence, serving as a drop-in replacement that subsumes query-sharing approaches like multi-query and grouped-query attention. Experimental results from large-scale pretraining show that LRKV achieves faster loss reduction, lower validation perplexity, and better downstream task performance compared to standard attention and other methods, using roughly half the KV cache at the 2.5B scale and requiring 20-25% less training compute for equivalent model quality, while preserving functional head diversity.</div>
<div class="mono" style="margin-top:8px">为解决Transformer训练和自回归解码中键值（KV）缓存带来的内存与计算瓶颈，本研究提出了低秩键值适应（LRKV），这是一种改进的多头注意力机制，它通过采用共享的全秩KV投影和低秩的头部特定残差，利用注意力头之间的冗余来减少KV缓存内存，同时保持完整的词元级分辨率。该方法可直接替代标准注意力，并涵盖了多查询和分组查询注意力等查询共享方法。大规模预训练实验结果表明，与标准注意力及其他高效变体相比，LRKV实现了更快的损失下降、更低的验证困惑度和更强的下游任务性能；在25亿参数规模下，它仅使用约一半的KV缓存即可达到或超越标准注意力的模型质量，并将训练计算量减少20-25%。分析表明，LRKV比更激进的KV共享机制更好地保留了功能性的头部多样性，后者依赖于补偿性的查询专门化。</div>
</details>
</div>
<div class="card">
<div class="title">MHA2MLA-VLM: Enabling DeepSeek&#x27;s Economical Multi-Head Latent Attention across Vision-Language Models</div>
<div class="meta-line">Authors: Xiaoran Fan, Zhichao Sun, Tao Ji, Lixing Shen, Tao Gui</div>
<div class="meta-line">First: 2026-01-16T17:45:34+00:00 · Latest: 2026-01-16T17:45:34+00:00</div>
<div class="links" style="margin-top:8px"><a href="https://arxiv.org/abs/2601.11464v1">Abs</a> · <a href="https://arxiv.org/pdf/2601.11464v1">PDF</a> · <a href="https://huggingface.co/huggingface">Code1</a> · <a href="https://huggingface.co/docs/hub/spaces">Code2</a></div>
<details class="detail"><summary>Abstract</summary>
<div class="mono">As vision-language models (VLMs) tackle increasingly complex and multimodal tasks, the rapid growth of Key-Value (KV) cache imposes significant memory and computational bottlenecks during inference. While Multi-Head Latent Attention (MLA) offers an effective means to compress the KV cache and accelerate inference, adapting existing VLMs to the MLA architecture without costly pretraining remains largely unexplored. In this work, we present MHA2MLA-VLM, a parameter-efficient and multimodal-aware framework for converting off-the-shelf VLMs to MLA. Our approach features two core techniques: (1) a modality-adaptive partial-RoPE strategy that supports both traditional and multimodal settings by selectively masking nonessential dimensions, and (2) a modality-decoupled low-rank approximation method that independently compresses the visual and textual KV spaces. Furthermore, we introduce parameter-efficient fine-tuning to minimize adaptation cost and demonstrate that minimizing output activation error, rather than parameter distance, substantially reduces performance loss. Extensive experiments on three representative VLMs show that MHA2MLA-VLM restores original model performance with minimal supervised data, significantly reduces KV cache footprint, and integrates seamlessly with KV quantization.</div></details>
<details class="detail"><summary>中文标题/摘要</summary>
<div class="mono"><b>标题：</b>MHA2MLA-VLM：实现DeepSeek经济型多头部潜在注意力在视觉语言模型中的跨模态应用</div>
<div class="mono" style="margin-top:8px">随着视觉语言模型处理日益复杂的多模态任务，键值缓存快速增长导致推理过程面临显著的内存与计算瓶颈。虽然多头部潜在注意力为压缩键值缓存和加速推理提供了有效方案，但如何在不进行昂贵预训练的前提下将现有视觉语言模型适配至该架构仍属空白。本研究提出MHA2MLA-VLM——一种参数高效且具备多模态感知能力的框架，可将现成视觉语言模型转换为多头部潜在注意力架构。该框架包含两项核心技术：(1) 模态自适应部分旋转位置编码策略，通过选择性屏蔽非必要维度同时支持传统与多模态场景；(2) 模态解耦的低秩近似方法，独立压缩视觉与文本键值空间。此外，我们引入参数高效微调以最小化适配成本，并证明最小化输出激活误差（而非参数距离）能显著降低性能损失。在三个代表性视觉语言模型上的大量实验表明，MHA2MLA-VLM能以极少量监督数据恢复原始模型性能，显著降低键值缓存占用，并与键值量化技术无缝集成。</div>
</details>
<details class="detail"><summary>Summary / 总结</summary>
<div class="mono">The research addresses the memory and computational bottlenecks caused by the growing Key-Value (KV) cache in vision-language models (VLMs) during inference. To enable efficient adaptation of existing VLMs to a Multi-Head Latent Attention (MLA) architecture without full pretraining, the authors propose MHA2MLA-VLM, a parameter-efficient framework featuring a modality-adaptive partial-RoPE strategy and a modality-decoupled low-rank approximation method for compressing visual and textual KV spaces. Experimental results on three VLMs demonstrate that the method restores original model performance with minimal supervised data, significantly reduces KV cache size, and works effectively with KV quantization.</div>
<div class="mono" style="margin-top:8px">本研究旨在解决视觉语言模型推理过程中，因键值缓存快速增长导致的内存与计算瓶颈问题。为实现现有模型向多头潜在注意力架构的高效适配、避免昂贵的预训练，方法提出了MHA2MLA-VLM框架，其核心包括：支持传统与多模态场景的模态自适应部分RoPE策略，以及独立压缩视觉与文本键值空间的模态解耦低秩近似方法，并结合以最小化输出激活误差为目标的参数高效微调。在三个代表性视觉语言模型上的实验表明，该方法仅需少量监督数据即可恢复模型原始性能，显著降低了键值缓存占用，并能与键值量化技术无缝集成。</div>
</details>
</div>
<div class="card">
<div class="title">Learning Semantic-Geometric Task Graph-Representations from Human Demonstrations</div>
<div class="meta-line">Authors: Franziska Herbert, Vignesh Prasad, Han Liu, Dorothea Koert, Georgia Chalvatzaki</div>
<div class="meta-line">First: 2026-01-16T17:35:00+00:00 · Latest: 2026-01-16T17:35:00+00:00</div>
<div class="meta-line">Comments: 9 pages, 7 figures, preprint</div>
<div class="links" style="margin-top:8px"><a href="https://arxiv.org/abs/2601.11460v1">Abs</a> · <a href="https://arxiv.org/pdf/2601.11460v1">PDF</a> · <a href="https://huggingface.co/huggingface">Code1</a> · <a href="https://huggingface.co/docs/hub/spaces">Code2</a></div>
<details class="detail"><summary>Abstract</summary>
<div class="mono">Learning structured task representations from human demonstrations is essential for understanding long-horizon manipulation behaviors, particularly in bimanual settings where action ordering, object involvement, and interaction geometry can vary significantly. A key challenge lies in jointly capturing the discrete semantic structure of tasks and the temporal evolution of object-centric geometric relations in a form that supports reasoning over task progression. In this work, we introduce a semantic-geometric task graph-representation that encodes object identities, inter-object relations, and their temporal geometric evolution from human demonstrations. Building on this formulation, we propose a learning framework that combines a Message Passing Neural Network (MPNN) encoder with a Transformer-based decoder, decoupling scene representation learning from action-conditioned reasoning about task progression. The encoder operates solely on temporal scene graphs to learn structured representations, while the decoder conditions on action-context to predict future action sequences, associated objects, and object motions over extended time horizons. Through extensive evaluation on human demonstration datasets, we show that semantic-geometric task graph-representations are particularly beneficial for tasks with high action and object variability, where simpler sequence-based models struggle to capture task progression. Finally, we demonstrate that task graph representations can be transferred to a physical bimanual robot and used for online action selection, highlighting their potential as reusable task abstractions for downstream decision-making in manipulation systems.</div></details>
<details class="detail"><summary>中文标题/摘要</summary>
<div class="mono"><b>标题：</b>基于人类演示的语义-几何任务图表示学习</div>
<div class="mono" style="margin-top:8px">从人类演示中学习结构化任务表示对于理解长时程操作行为至关重要，尤其在双手操作场景中，动作顺序、对象参与和交互几何关系可能存在显著差异。核心挑战在于以支持任务进程推理的形式，同时捕捉任务的离散语义结构和以对象为中心的几何关系的时间演化。本研究提出一种语义-几何任务图表示方法，从人类演示中编码对象身份、对象间关系及其时间几何演化。基于此框架，我们提出结合消息传递神经网络编码器与基于Transformer解码器的学习框架，将场景表示学习与基于动作条件的任务进程推理解耦。编码器仅使用时序场景图学习结构化表示，而解码器基于动作上下文预测未来动作序列、关联对象及长时程对象运动。通过对人类演示数据集的广泛评估，我们证明语义-几何任务图表示对动作和对象高度可变的任务特别有效，而传统基于序列的模型难以捕捉此类任务进程。最后，我们演示了任务图表示可迁移至实体双手机器人并用于在线动作选择，凸显其作为可复用任务抽象在操作系统下游决策中的潜力。</div>
</details>
<details class="detail"><summary>Summary / 总结</summary>
<div class="mono">To understand long-horizon bimanual manipulation tasks where action order, object roles, and geometric interactions vary, this research aims to learn structured representations from human demonstrations. The method introduces a semantic-geometric task graph that encodes object identities and their evolving geometric relations, and proposes a learning framework using a Message Passing Neural Network encoder to learn from temporal scene graphs and a Transformer-based decoder to predict future actions, objects, and motions conditioned on action context. Experimental results on human demonstration datasets show that this graph representation outperforms simpler sequence models in tasks with high variability, and it is successfully transferred to a physical bimanual robot for online action selection, demonstrating its utility as a reusable abstraction for decision-making.</div>
<div class="mono" style="margin-top:8px">为从人类演示中理解复杂的长期双臂操作任务，本研究旨在解决如何同时捕捉离散的语义任务结构和以物体为中心的几何关系随时间演变的挑战。该方法引入了语义几何任务图表示和一个学习框架，该框架结合了消息传递神经网络编码器（从时序场景图中学习结构化表示）和基于Transformer的解码器（利用动作上下文预测未来的动作序列、相关物体及物体运动）。在人类演示数据集上的实验评估表明，这种基于图的表示对于动作和物体高度可变的任务特别有效，在捕捉任务进展方面优于简单的序列模型，并且学习到的表示已成功迁移到物理双臂机器人上用于在线动作选择。</div>
</details>
</div>
<div class="card">
<div class="title">PRISM-CAFO: Prior-conditioned Remote-sensing Infrastructure Segmentation and Mapping for CAFOs</div>
<div class="meta-line">Authors: Oishee Bintey Hoque, Nibir Chandra Mandal, Kyle Luong, Amanda Wilson, Samarth Swarup, Madhav Marathe, Abhijin Adiga</div>
<div class="meta-line">First: 2026-01-16T17:16:26+00:00 · Latest: 2026-01-16T17:16:26+00:00</div>
<div class="links" style="margin-top:8px"><a href="https://arxiv.org/abs/2601.11451v1">Abs</a> · <a href="https://arxiv.org/pdf/2601.11451v1">PDF</a> · <a href="https://huggingface.co/huggingface">Code1</a> · <a href="https://huggingface.co/docs/hub/spaces">Code2</a></div>
<details class="detail"><summary>Abstract</summary>
<div class="mono">Large-scale livestock operations pose significant risks to human health and the environment, while also being vulnerable to threats such as infectious diseases and extreme weather events. As the number of such operations continues to grow, accurate and scalable mapping has become increasingly important. In this work, we present an infrastructure-first, explainable pipeline for identifying and characterizing Concentrated Animal Feeding Operations (CAFOs) from aerial and satellite imagery. Our method (1) detects candidate infrastructure (e.g., barns, feedlots, manure lagoons, silos) with a domain-tuned YOLOv8 detector, then derives SAM2 masks from these boxes and filters component-specific criteria, (2) extracts structured descriptors (e.g., counts, areas, orientations, and spatial relations) and fuses them with deep visual features using a lightweight spatial cross-attention classifier, and (3) outputs both CAFO type predictions and mask-level attributions that link decisions to visible infrastructure. Through comprehensive evaluation, we show that our approach achieves state-of-the-art performance, with Swin-B+PRISM-CAFO surpassing the best performing baseline by up to 15\%. Beyond strong predictive performance across diverse U.S. regions, we run systematic gradient--activation analyses that quantify the impact of domain priors and show ho</div></details>
<details class="detail"><summary>中文标题/摘要</summary>
<div class="mono"><b>标题：</b>PRISM-CAFO：面向集中动物饲养场的先验条件遥感基础设施分割与制图方法</div>
<div class="mono" style="margin-top:8px">大规模畜牧养殖对人类健康和环境构成显著风险，同时也易受传染病和极端天气等威胁影响。随着此类养殖场数量持续增长，精准且可扩展的制图技术变得日益重要。本研究提出一种以基础设施为先导、可解释的技术流程，用于从航空与卫星影像中识别并表征集中动物饲养场。该方法：（1）通过领域调优的YOLOv8检测器识别候选基础设施（如畜舍、饲喂场、粪污池、筒仓），基于检测框生成SAM2掩码并筛选组件特定标准；（2）提取结构化描述符（如数量、面积、朝向及空间关系），并通过轻量级空间交叉注意力分类器将其与深度视觉特征融合；（3）同步输出CAFO类型预测结果及关联决策与可见基础设施的掩码级归因分析。综合评估表明，该方法达到业界最优性能，其中Swin-B+PRISM-CAFO较最佳基线模型提升达15%。除在美国多区域展现卓越预测性能外，系统化的梯度-激活分析量化了领域先验知识的影响，并揭示了</div>
</details>
<details class="detail"><summary>Summary / 总结</summary>
<div class="mono">The research is motivated by the need for accurate and scalable mapping of Concentrated Animal Feeding Operations (CAFOs) due to their significant environmental and health risks, as well as their vulnerability to threats like disease and extreme weather. The method introduces an infrastructure-first, explainable pipeline that first detects candidate infrastructure components (e.g., barns, lagoons) using a domain-tuned YOLOv8 detector and refines masks with SAM2, then extracts structured descriptors and fuses them with deep visual features via a lightweight spatial cross-attention classifier to predict CAFO types and provide mask-level attributions. Key experimental results demonstrate state-of-the-art performance, with the Swin-B+PRISM-CAFO model outperforming the best baseline by up to 15%, showing strong predictive accuracy across diverse U.S. regions and systematic analyses quantifying the impact of domain priors.</div>
<div class="mono" style="margin-top:8px">本研究旨在应对大规模畜牧养殖场（CAFOs）带来的重大环境与健康风险及其对疾病和极端天气等威胁的脆弱性，因此需要精确且可扩展的测绘方法。该方法提出了一种以基础设施为先、可解释的流程：首先使用领域调优的YOLOv8检测器识别候选基础设施组件（如畜舍、粪池），并通过SAM2细化掩码；然后提取结构化描述符，并通过轻量级空间交叉注意力分类器将其与深度视觉特征融合，以预测CAFO类型并提供掩码级归因。关键实验结果表明，该方法实现了最先进的性能，其中Swin-B+PRISM-CAFO模型比最佳基线高出15%，在不同美国地区均表现出强大的预测准确性，并通过系统分析量化了领域先验的影响。</div>
</details>
</div>
<div class="card">
<div class="title">IMS: Intelligent Hardware Monitoring System for Secure SoCs</div>
<div class="meta-line">Authors: Wadid Foudhaili, Aykut Rencber, Anouar Nechi, Rainer Buchty, Mladen Berekovic, Andres Gomez, Saleh Mulhem</div>
<div class="meta-line">First: 2026-01-16T17:10:17+00:00 · Latest: 2026-01-16T17:10:17+00:00</div>
<div class="meta-line">Comments: The final version is accepted for publication at the Design, Automation &amp; Test in Europe Conference (DATE) 2026</div>
<div class="links" style="margin-top:8px"><a href="https://arxiv.org/abs/2601.11447v1">Abs</a> · <a href="https://arxiv.org/pdf/2601.11447v1">PDF</a> · <a href="https://huggingface.co/huggingface">Code1</a> · <a href="https://huggingface.co/docs/hub/spaces">Code2</a></div>
<details class="detail"><summary>Abstract</summary>
<div class="mono">In the modern Systems-on-Chip (SoC), the Advanced eXtensible Interface (AXI) protocol exhibits security vulnerabilities, enabling partial or complete denial-of-service (DoS) through protocol-violation attacks. The recent countermeasures lack a dedicated real-time protocol semantic analysis and evade protocol compliance checks. This paper tackles this AXI vulnerability issue and presents an intelligent hardware monitoring system (IMS) for real-time detection of AXI protocol violations. IMS is a hardware module leveraging neural networks to achieve high detection accuracy. For model training, we perform DoS attacks through header-field manipulation and systematic malicious operations, while recording AXI transactions to build a training dataset. We then deploy a quantization-optimized neural network, achieving 98.7% detection accuracy with &lt;=3% latency overhead, and throughput of &gt;2.5 million inferences/s. We subsequently integrate this IMS into a RISC-V SoC as a memory-mapped IP core to monitor its AXI bus. For demonstration and initial assessment for later ASIC integration, we implemented this IMS on an AMD Zynq UltraScale+ MPSoC ZCU104 board, showing an overall small hardware footprint (9.04% look-up-tables (LUTs), 0.23% DSP slices, and 0.70% flip-flops) and negligible impact on the overall design&#x27;s achievable frequency. This demonstrates the feasibility of lightweight, security monitoring for resource-constrained edge environments.</div></details>
<details class="detail"><summary>中文标题/摘要</summary>
<div class="mono"><b>标题：</b>IMS：面向安全SoC的智能硬件监控系统</div>
<div class="mono" style="margin-top:8px">在现代片上系统（SoC）中，高级可扩展接口（AXI）协议存在安全漏洞，可通过违反协议的攻击导致部分或完全拒绝服务（DoS）。现有防护措施缺乏专用的实时协议语义分析，且规避协议合规性检查。本文针对AXI漏洞问题，提出一种用于实时检测AXI协议违规的智能硬件监控系统（IMS）。IMS是一种利用神经网络实现高检测精度的硬件模块。在模型训练阶段，我们通过头部字段篡改和系统性恶意操作实施DoS攻击，同时记录AXI事务以构建训练数据集。随后部署量化优化的神经网络，实现98.7%的检测准确率，延迟开销≤3%，推理吞吐量&gt;250万次/秒。我们将IMS集成至RISC-V SoC作为内存映射IP核，以监控其AXI总线。为演示并为后续ASIC集成提供初步评估，我们在AMD Zynq UltraScale+ MPSoC ZCU104开发板上实现了IMS，结果显示其硬件占用极小（查找表9.04%、DSP切片0.23%、触发器0.70%），且对整体设计可达频率的影响可忽略。这证明了在资源受限的边缘环境中实现轻量化安全监控的可行性。</div>
</details>
<details class="detail"><summary>Summary / 总结</summary>
<div class="mono">To address security vulnerabilities in the Advanced eXtensible Interface (AXI) protocol within modern Systems-on-Chip (SoCs), which are susceptible to denial-of-service (DoS) attacks through protocol violations, this paper proposes an Intelligent Hardware Monitoring System (IMS). The method involves designing a hardware module that employs a neural network trained on datasets generated from DoS attacks via header-field manipulation and malicious operations; the network is quantization-optimized for efficient deployment. Experimental results show that IMS achieves 98.7% detection accuracy with minimal latency overhead (≤3%) and high throughput (&gt;2.5 million inferences/s), and when integrated into a RISC-V SoC on an FPGA board, it demonstrates a small hardware footprint (e.g., 9.04% LUTs) and negligible impact on operating frequency, confirming its feasibility for resource-constrained edge environments.</div>
<div class="mono" style="margin-top:8px">针对现代片上系统中高级可扩展接口协议存在的安全漏洞，尤其是易受协议违规攻击导致的拒绝服务问题，本文提出了一种智能硬件监控系统。该方法设计了一个硬件模块，利用基于模拟攻击生成的训练数据集训练的神经网络，对AXI事务进行实时语义分析。实验结果表明，量化优化的神经网络实现了98.7%的检测准确率，延迟开销低（≤3%），吞吐量高（&gt;250万次推理/秒）；在FPGA上集成到RISC-V SoC中显示其硬件占用小，对系统频率影响可忽略，验证了其在资源受限边缘环境中的可行性。</div>
</details>
</div>
<div class="card">
<div class="title">When Are Two Scores Better Than One? Investigating Ensembles of Diffusion Models</div>
<div class="meta-line">Authors: Raphaël Razafindralambo, Rémy Sun, Frédéric Precioso, Damien Garreau, Pierre-Alexandre Mattei</div>
<div class="meta-line">First: 2026-01-16T17:07:25+00:00 · Latest: 2026-01-16T17:07:25+00:00</div>
<div class="meta-line">Comments: Accepted at TMLR. Code: https://github.com/rarazafin/score_diffusion_ensemble</div>
<div class="links" style="margin-top:8px"><a href="https://arxiv.org/abs/2601.11444v1">Abs</a> · <a href="https://arxiv.org/pdf/2601.11444v1">PDF</a> · <a href="https://github.com/rarazafin/score_diffusion_ensemble">Code1</a> · <a href="https://huggingface.co/huggingface">Code2</a> · <a href="https://huggingface.co/docs/hub/spaces">Code3</a></div>
<details class="detail"><summary>Abstract</summary>
<div class="mono">Diffusion models now generate high-quality, diverse samples, with an increasing focus on more powerful models. Although ensembling is a well-known way to improve supervised models, its application to unconditional score-based diffusion models remains largely unexplored. In this work we investigate whether it provides tangible benefits for generative modelling. We find that while ensembling the scores generally improves the score-matching loss and model likelihood, it fails to consistently enhance perceptual quality metrics such as FID on image datasets. We confirm this observation across a breadth of aggregation rules using Deep Ensembles, Monte Carlo Dropout, on CIFAR-10 and FFHQ. We attempt to explain this discrepancy by investigating possible explanations, such as the link between score estimation and image quality. We also look into tabular data through random forests, and find that one aggregation strategy outperforms the others. Finally, we provide theoretical insights into the summing of score models, which shed light not only on ensembling but also on several model composition techniques (e.g. guidance).</div></details>
<details class="detail"><summary>中文标题/摘要</summary>
<div class="mono"><b>标题：</b>何时双评分优于单评分？探究扩散模型的集成方法</div>
<div class="mono" style="margin-top:8px">扩散模型当前已能生成高质量、多样化的样本，研究重点正转向更强大的模型。尽管集成是提升监督模型的常用方法，但其在无条件基于评分的扩散模型中的应用仍鲜有探索。本研究旨在探究集成方法能否为生成建模带来实质性提升。我们发现：虽然集成评分通常能改善评分匹配损失和模型似然度，但未能持续提升图像数据集上的感知质量指标（如FID）。这一结论在CIFAR-10和FFHQ数据集上通过深度集成、蒙特卡洛Dropout等多种聚合规则得到验证。我们尝试通过探究评分估计与图像质量之间的关联等可能解释来说明这种差异。同时，通过随机森林方法对表格数据进行实验，发现某种聚合策略优于其他方法。最后，我们从理论角度分析了评分模型求和机制，这不仅阐明了集成方法，也揭示了包括引导技术在内的多种模型组合技术。</div>
</details>
<details class="detail"><summary>Summary / 总结</summary>
<div class="mono">This study investigates the application of ensembling techniques to unconditional score-based diffusion models, motivated by the established benefits of ensembling in supervised learning and the need to understand its potential for improving generative modeling. The method involves evaluating various aggregation rules, including Deep Ensembles and Monte Carlo Dropout, across image datasets like CIFAR-10 and FFHQ, as well as examining tabular data with random forests. Key experimental findings reveal that while ensembling scores generally improves the score-matching loss and model likelihood, it does not consistently enhance perceptual quality metrics such as FID; however, one aggregation strategy showed superior performance on tabular data, and theoretical insights were provided linking score model summation to broader composition techniques like guidance.</div>
<div class="mono" style="margin-top:8px">本研究探讨了将集成学习技术应用于无条件基于分数的扩散模型，其动机在于集成学习在监督学习中已证实的益处，以及理解其对改进生成模型潜力的需求。该方法通过评估包括深度集成和蒙特卡洛丢弃在内的多种聚合规则，在CIFAR-10和FFHQ等图像数据集上进行测试，并使用随机森林检查表格数据。主要实验结果表明，虽然集成分数通常能改善分数匹配损失和模型似然，但并未一致提升如FID等感知质量指标；然而，在表格数据上发现一种聚合策略优于其他方法，并为分数模型组合提供了理论见解。</div>
</details>
</div>
<div class="card">
<div class="title">Hierarchical Orthogonal Residual Spread for Precise Massive Editing in Large Language Models</div>
<div class="meta-line">Authors: Xiaojie Gu, Guangxu Chen, Yuheng Yang, Jingxin Han, Andi Zhang</div>
<div class="meta-line">Venue: ICASSP 2026</div>
<div class="meta-line">First: 2026-01-16T17:02:19+00:00 · Latest: 2026-01-16T17:02:19+00:00</div>
<div class="meta-line">Comments: ICASSP 2026</div>
<div class="links" style="margin-top:8px"><a href="https://arxiv.org/abs/2601.11441v1">Abs</a> · <a href="https://arxiv.org/pdf/2601.11441v1">PDF</a> · <a href="https://github.com/XiaojieGu/HORSE">Code1</a> · <a href="https://huggingface.co/huggingface">Code2</a> · <a href="https://huggingface.co/docs/hub/spaces">Code3</a></div>
<details class="detail"><summary>Abstract</summary>
<div class="mono">Large language models (LLMs) exhibit exceptional performance across various domains, yet they face critical safety concerns. Model editing has emerged as an effective approach to mitigate these issues. Existing model editing methods often focus on optimizing an information matrix that blends new and old knowledge. While effective, these approaches can be computationally expensive and may cause conflicts. In contrast, we shift our attention to Hierarchical Orthogonal Residual SprEad of the information matrix, which reduces noisy gradients and enables more stable edits from a different perspective. We demonstrate the effectiveness of our method HORSE through a clear theoretical comparison with several popular methods and extensive experiments conducted on two datasets across multiple LLMs. The results show that HORSE maintains precise massive editing across diverse scenarios. The code is available at https://github.com/XiaojieGu/HORSE</div></details>
<details class="detail"><summary>中文标题/摘要</summary>
<div class="mono"><b>标题：</b>分层正交残差扩散：实现大语言模型精准大规模编辑</div>
<div class="mono" style="margin-top:8px">大语言模型（LLMs）在各领域展现出卓越性能，但仍面临严峻的安全隐患。模型编辑已成为缓解这些问题的有效途径。现有方法通常聚焦于优化融合新旧知识的信息矩阵，虽有效但计算成本高昂且可能引发冲突。相比之下，我们将研究重点转向信息矩阵的分层正交残差扩散，该方法能减少噪声梯度，从不同视角实现更稳定的编辑。我们通过与多种主流方法的理论对比，以及在多个LLMs的两个数据集上的大量实验，证明了HORSE方法的有效性。结果表明，HORSE能在多样化场景中保持精准的大规模编辑能力。代码已开源：https://github.com/XiaojieGu/HORSE</div>
</details>
<details class="detail"><summary>Summary / 总结</summary>
<div class="mono">To address safety concerns in large language models (LLMs) where existing model editing methods are computationally expensive and prone to knowledge conflicts, this research proposes HORSE, a method based on Hierarchical Orthogonal Residual Spread of the information matrix. This approach reduces noisy gradients and enables more stable edits from a different perspective than prior techniques that blend new and old knowledge. Extensive experiments on two datasets across multiple LLMs demonstrate that HORSE maintains precise performance in massive editing scenarios, as validated through theoretical comparisons with popular methods.</div>
<div class="mono" style="margin-top:8px">针对大语言模型（LLMs）的安全性问题，现有模型编辑方法存在计算成本高且可能引发知识冲突的局限，本文提出了HORSE方法，该方法基于信息矩阵的分层正交残差展开，以减少噪声梯度并实现更稳定的编辑。该方法与主流方法进行了理论比较，并在多个LLMs的两个数据集上进行了广泛实验验证。结果表明，HORSE在多种场景下的大规模编辑中均能保持精确性能。</div>
</details>
</div>
<div class="card">
<div class="title">GenDA: Generative Data Assimilation on Complex Urban Areas via Classifier-Free Diffusion Guidance</div>
<div class="meta-line">Authors: Francisco Giral, Álvaro Manzano, Ignacio Gómez, Ricardo Vinuesa, Soledad Le Clainche</div>
<div class="meta-line">First: 2026-01-16T17:02:00+00:00 · Latest: 2026-01-16T17:02:00+00:00</div>
<div class="links" style="margin-top:8px"><a href="https://arxiv.org/abs/2601.11440v1">Abs</a> · <a href="https://arxiv.org/pdf/2601.11440v1">PDF</a> · <a href="https://huggingface.co/huggingface">Code1</a> · <a href="https://huggingface.co/docs/hub/spaces">Code2</a></div>
<details class="detail"><summary>Abstract</summary>
<div class="mono">Urban wind flow reconstruction is essential for assessing air quality, heat dispersion, and pedestrian comfort, yet remains challenging when only sparse sensor data are available. We propose GenDA, a generative data assimilation framework that reconstructs high-resolution wind fields on unstructured meshes from limited observations. The model employs a multiscale graph-based diffusion architecture trained on computational fluid dynamics (CFD) simulations and interprets classifier-free guidance as a learned posterior reconstruction mechanism: the unconditional branch learns a geometry-aware flow prior, while the sensor-conditioned branch injects observational constraints during sampling. This formulation enables obstacle-aware reconstruction and generalization across unseen geometries, wind directions, and mesh resolutions without retraining. We consider both sparse fixed sensors and trajectory-based observations using the same reconstruction procedure. When evaluated against supervised graph neural network (GNN) baselines and classical reduced-order data assimilation methods, GenDA reduces the relative root-mean-square error (RRMSE) by 25-57% and increases the structural similarity index (SSIM) by 23-33% across the tested meshes. Experiments are conducted on Reynolds-averaged Navier-Stokes (RANS) simulations of a real urban neighbourhood in Bristol, United Kingdom, at a characteristic Reynolds number of $\mathrm{Re}\approx2\times10^{7}$, featuring complex building geometry and irregular terrain. The proposed framework provides a scalable path toward generative, geometry-aware data assimilation for environmental monitoring in complex domains.</div></details>
<details class="detail"><summary>中文标题/摘要</summary>
<div class="mono"><b>标题：</b>GenDA：基于无分类器扩散引导的复杂城市区域生成式数据同化方法</div>
<div class="mono" style="margin-top:8px">城市风场重建对于评估空气质量、热量扩散和行人舒适度至关重要，但在仅有稀疏传感器数据时仍具挑战性。本文提出GenDA，一种生成式数据同化框架，能从有限观测数据中重建非结构化网格上的高分辨率风场。该模型采用基于多尺度图结构的扩散架构，通过计算流体力学（CFD）模拟进行训练，并将无分类器引导解释为一种学习的后验重建机制：无条件分支学习几何感知的流场先验，而传感器条件分支在采样过程中注入观测约束。该框架能够实现障碍物感知的重建，并泛化至未见过的几何结构、风向和网格分辨率，无需重新训练。我们使用相同的重建流程处理稀疏固定传感器和基于轨迹的观测数据。与监督式图神经网络（GNN）基线及经典降阶数据同化方法相比，GenDA在所有测试网格上将相对均方根误差（RRMSE）降低了25-57%，将结构相似性指数（SSIM）提高了23-33%。实验基于英国布里斯托尔真实城市街区的雷诺平均纳维-斯托克斯（RANS）模拟，特征雷诺数为$\mathrm{Re}\approx2\times10^{7}$，包含复杂建筑几何与不规则地形。该框架为复杂环境监测领域的生成式、几何感知数据同化提供了可扩展的路径。</div>
</details>
<details class="detail"><summary>Summary / 总结</summary>
<div class="mono">Accurate urban wind flow reconstruction from sparse sensor data is crucial for environmental assessments but remains difficult. To address this, the authors propose GenDA, a generative data assimilation framework that uses a multiscale graph-based diffusion model trained on CFD simulations; it employs classifier-free guidance to combine an unconditional, geometry-aware prior with observational constraints from sensor data. Experimental results on RANS simulations of a real urban area show that GenDA reduces relative root-mean-square error by 25-57% and increases structural similarity by 23-33% compared to supervised GNN and classical data assimilation baselines, demonstrating effective generalization to unseen geometries, wind directions, and mesh resolutions.</div>
<div class="mono" style="margin-top:8px">从稀疏传感器数据中准确重建城市风流对环境监测至关重要，但一直存在挑战。本研究提出了GenDA，一种生成式数据同化框架，它采用基于计算流体动力学模拟训练的多尺度图扩散模型，将无分类器引导解释为一种学习的后验机制：无条件分支学习几何感知的流场先验，而传感器条件分支在采样过程中注入观测约束。该方法能够实现障碍物感知的重建，并可泛化到未见过的几何形状、风向和网格分辨率，无需重新训练，同时处理固定传感器和基于轨迹的观测。在真实城区的雷诺平均Navier-Stokes模拟评估中，与监督图神经网络和经典降阶数据同化方法相比，GenDA将相对均方根误差降低了25-57%，并将结构相似性指数提高了23-33%。</div>
</details>
</div>
<div class="card">
<div class="title">Near-Optimal Decentralized Stochastic Nonconvex Optimization with Heavy-Tailed Noise</div>
<div class="meta-line">Authors: Menglian Wang, Zhuanghua Liu, Luo Luo</div>
<div class="meta-line">First: 2026-01-16T16:55:51+00:00 · Latest: 2026-01-16T16:55:51+00:00</div>
<div class="links" style="margin-top:8px"><a href="https://arxiv.org/abs/2601.11435v1">Abs</a> · <a href="https://arxiv.org/pdf/2601.11435v1">PDF</a> · <a href="https://huggingface.co/huggingface">Code1</a> · <a href="https://huggingface.co/docs/hub/spaces">Code2</a></div>
<details class="detail"><summary>Abstract</summary>
<div class="mono">This paper studies decentralized stochastic nonconvex optimization problem over row-stochastic networks. We consider the heavy-tailed gradient noise which is empirically observed in many popular real-world applications. Specifically, we propose a decentralized normalized stochastic gradient descent with Pull-Diag gradient tracking, which achieves approximate stationary points with the optimal sample complexity and the near-optimal communication complexity. We further follow our framework to study the setting of undirected networks, also achieving the nearly tight upper complexity bounds. Moreover, we conduct empirical studies to show the practical superiority of the proposed methods.</div></details>
<details class="detail"><summary>中文标题/摘要</summary>
<div class="mono"><b>标题：</b>重尾噪声下的近最优去中心化随机非凸优化</div>
<div class="mono" style="margin-top:8px">本文研究基于行随机网络的去中心化随机非凸优化问题，重点关注实际应用中常见的重尾梯度噪声。我们提出了一种采用Pull-Diag梯度追踪的去中心化归一化随机梯度下降法，该方法能以最优样本复杂度和近最优通信复杂度获得近似驻点。进一步将该框架拓展至无向网络场景，同样实现了近乎紧致的复杂度上界。实验验证了所提方法的实际优越性。</div>
</details>
<details class="detail"><summary>Summary / 总结</summary>
<div class="mono">This work addresses decentralized stochastic nonconvex optimization over row-stochastic networks, motivated by the empirical prevalence of heavy-tailed gradient noise in real-world applications. The method introduces a decentralized normalized stochastic gradient descent algorithm with Pull-Diag gradient tracking, designed to handle heavy-tailed noise. Experimental results demonstrate that the algorithm achieves approximate stationary points with optimal sample complexity and near-optimal communication complexity, and its extension to undirected networks also yields nearly tight upper complexity bounds, with empirical studies confirming its practical superiority.</div>
<div class="mono" style="margin-top:8px">本研究针对行随机网络上的去中心化随机非凸优化问题，其动机是现实应用中普遍存在的重尾梯度噪声。该方法提出了一种结合Pull-Diag梯度跟踪的去中心化归一化随机梯度下降算法，以处理重尾噪声。实验结果表明，该算法能以最优样本复杂度和接近最优的通信复杂度找到近似驻点，其在无向网络上的扩展也实现了近乎紧的上界复杂度，实证研究进一步验证了其实际优越性。</div>
</details>
</div>
<div class="card">
<div class="title">Inter-patient ECG Arrhythmia Classification with LGNs and LUTNs</div>
<div class="meta-line">Authors: Wout Mommen, Lars Keuninckx, Paul Detterer, Achiel Colpaert, Piet Wambacq</div>
<div class="meta-line">First: 2026-01-16T16:55:36+00:00 · Latest: 2026-01-16T16:55:36+00:00</div>
<div class="links" style="margin-top:8px"><a href="https://arxiv.org/abs/2601.11433v1">Abs</a> · <a href="https://arxiv.org/pdf/2601.11433v1">PDF</a> · <a href="https://huggingface.co/huggingface">Code1</a> · <a href="https://huggingface.co/docs/hub/spaces">Code2</a></div>
<details class="detail"><summary>Abstract</summary>
<div class="mono">Deep Differentiable Logic Gate Networks (LGNs) and Lookup Table Networks (LUTNs) are demonstrated to be suitable for the automatic classification of electrocardiograms (ECGs) using the inter-patient paradigm. The methods are benchmarked using the MIT-BIH arrhythmia data set, achieving up to 94.28% accuracy and a $jκ$ index of 0.683 on a four-class classification problem. Our models use between 2.89k and 6.17k FLOPs, including preprocessing and readout, which is three to six orders of magnitude less compared to SOTA methods. A novel preprocessing method is utilized that attains superior performance compared to existing methods for both the mixed-patient and inter-patient paradigms. In addition, a novel method for training the Lookup Tables (LUTs) in LUTNs is devised that uses the Boolean equation of a multiplexer (MUX). Additionally, rate coding was utilized for the first time in these LGNs and LUTNs, enhancing the performance of LGNs. Furthermore, it is the first time that LGNs and LUTNs have been benchmarked on the MIT-BIH arrhythmia dataset using the inter-patient paradigm. Using an Artix 7 FPGA, between 2000 and 2990 LUTs were needed, and between 5 to 7 mW (i.e. 50 pJ to 70 pJ per inference) was estimated for running these models. The performance in terms of both accuracy and $jκ$-index is significantly higher compared to previous LGN results. These positive results suggest that one can utilize LGNs and LUTNs for the detection of arrhythmias at extremely low power and high speeds in heart implants or wearable devices, even for patients not included in the training set.</div></details>
<details class="detail"><summary>中文标题/摘要</summary>
<div class="mono"><b>标题：</b>基于LGN与LUTN的跨患者心电图心律失常分类研究</div>
<div class="mono" style="margin-top:8px">研究证明，深度可微分逻辑门网络（LGN）和查找表网络（LUTN）适用于采用跨患者范式的自动心电图分类。方法在MIT-BIH心律失常数据集上进行基准测试，在四分类问题上达到94.28%的准确率和0.683的$jκ$指数。模型仅需2.89k至6.17k次浮点运算（含预处理与读出），比现有最优方法低三至六个数量级。提出的新型预处理方法在混合患者与跨患者范式中均优于现有方法，并创新性地采用多路复用器布尔方程训练LUTN中的查找表。首次在LGN与LUTN中应用脉冲编码，提升了LGN性能。本研究首次以跨患者范式在MIT-BIH数据集上对LGN与LUTN进行基准测试。在Artix 7 FPGA上实现需2000-2990个查找表，单次推理功耗约5-7 mW（即50-70 pJ）。准确率与$jκ$指数均显著优于先前LGN结果。这些积极成果表明，LGN与LUTN可用于心脏植入设备或可穿戴装置中实现超低功耗、高速心律失常检测，即使对训练集未涵盖的患者也具备适用性。</div>
</details>
<details class="detail"><summary>Summary / 总结</summary>
<div class="mono">This research aims to develop ultra-low-power models for classifying cardiac arrhythmias from ECG signals, specifically for the challenging inter-patient paradigm where the model must generalize to patients not seen during training. The method employs Deep Differentiable Logic Gate Networks (LGNs) and Lookup Table Networks (LUTNs), enhanced with a novel preprocessing technique and a novel training method for LUTs based on a multiplexer Boolean equation; rate coding is also introduced to these architectures for the first time. On the MIT-BIH arrhythmia dataset for a four-class problem, the models achieved up to 94.28% accuracy and a jκ index of 0.683 while requiring only 2.89k to 6.17k FLOPs—three to six orders of magnitude fewer than state-of-the-art methods—and were estimated to consume just 5 to 7 mW per inference on an FPGA, demonstrating significantly higher performance than prior LGN results.</div>
<div class="mono" style="margin-top:8px">本研究旨在开发低功耗、高速的心律失常心电图分类模型，尤其适用于对能效要求极高的心脏植入设备或可穿戴设备。该方法采用深度可微分逻辑门网络（LGNs）和查找表网络（LUTNs），结合了一种新颖的预处理技术以及基于多路复用器布尔方程的LUT训练方法，并首次引入速率编码以提升LGN性能。在MIT-BIH心律失常数据集上采用患者间范式进行实验，结果显示模型在四分类任务中达到了94.28%的准确率和0.683的jκ指数，仅需2.89k至6.17k FLOPs，比现有先进方法低三到六个数量级，在FPGA上每次推理的功耗估计为5至7 mW。</div>
</details>
</div>
<div class="card">
<div class="title">Entropy Production in Machine Learning Under Fokker-Planck Probability Flow</div>
<div class="meta-line">Authors: Lennon Shikhman</div>
<div class="meta-line">First: 2026-01-02T04:01:57+00:00 · Latest: 2026-01-16T16:53:45+00:00</div>
<div class="meta-line">Comments: 10 pages, 4 figures, 1 table</div>
<div class="links" style="margin-top:8px"><a href="https://arxiv.org/abs/2601.00554v3">Abs</a> · <a href="https://arxiv.org/pdf/2601.00554v3">PDF</a> · <a href="https://huggingface.co/huggingface">Code1</a> · <a href="https://huggingface.co/docs/hub/spaces">Code2</a></div>
<details class="detail"><summary>Abstract</summary>
<div class="mono">Machine learning models deployed in nonstationary environments inevitably experience performance degradation due to data drift. While numerous drift detection heuristics exist, most lack a dynamical interpretation and provide limited guidance on how retraining decisions should be balanced against operational cost. In this work, we propose an entropy-based retraining framework grounded in nonequilibrium statistical physics. Interpreting drift as probability flow governed by a Fokker-Planck equation, we quantify model-data mismatch using relative entropy and show that its time derivative admits an entropy-balance decomposition featuring a nonnegative entropy production term driven by probability currents. Guided by this theory, we implement an entropy-triggered retraining policy using an exponentially weighted moving-average (EWMA) control statistic applied to a streaming kernel density estimator of the Kullback-Leibler divergence. We evaluate this approach across multiple nonstationary data streams. In synthetic, financial, and web-traffic domains, entropy-based retraining achieves predictive performance comparable to frequent retraining while reducing retraining frequency by one to two orders of magnitude. However, in a challenging biomedical ECG setting, the entropy-based trigger underperforms the maximum-frequency baseline, highlighting limitations of feature-space entropy monitoring under complex label-conditional drift.</div></details>
<details class="detail"><summary>中文标题/摘要</summary>
<div class="mono"><b>标题：</b>福克-普朗克概率流下机器学习中的熵产生</div>
<div class="mono" style="margin-top:8px">在非平稳环境中部署的机器学习模型，由于数据漂移不可避免地会出现性能下降。尽管存在多种漂移检测启发式方法，但大多缺乏动力学解释，且对如何平衡重训练决策与操作成本的指导有限。本研究提出一种基于非平衡统计物理的熵驱动重训练框架。将漂移解释为受福克-普朗克方程支配的概率流，我们使用相对熵量化模型与数据间的失配，并证明其时间导数可通过概率流驱动的非负熵产生项进行熵平衡分解。基于该理论，我们采用指数加权移动平均控制统计量，对库尔贝克-莱布勒散度的流式核密度估计器实施熵触发重训练策略。通过在多个非平稳数据流上的评估，在合成、金融和网络流量场景中，基于熵的重训练在保持与频繁重训练相当预测性能的同时，将重训练频率降低了一到两个数量级。然而，在具有挑战性的生物医学心电图场景中，基于熵的触发器表现不及最高频率基线，这凸显了复杂标签条件漂移下特征空间熵监测的局限性。</div>
</details>
<details class="detail"><summary>Summary / 总结</summary>
<div class="mono">To address performance degradation in machine learning models under nonstationary data drift, this work proposes an entropy-based retraining framework grounded in nonequilibrium statistical physics. The method interprets drift as probability flow governed by a Fokker-Planck equation, quantifying model-data mismatch via relative entropy and deriving an entropy-balance decomposition with a nonnegative entropy production term. An entropy-triggered retraining policy is implemented using an exponentially weighted moving-average control statistic on a streaming kernel density estimator of the Kullback-Leibler divergence. Experimental evaluation on synthetic, financial, and web-traffic data streams shows the approach achieves predictive performance comparable to frequent retraining while reducing retraining frequency by one to two orders of magnitude, though it underperforms a maximum-frequency baseline in a complex biomedical ECG setting with label-conditional drift.</div>
<div class="mono" style="margin-top:8px">为解决非平稳数据漂移下机器学习模型的性能退化问题，本研究基于非平衡统计物理提出了一种熵驱动的重训练框架。该方法将数据漂移解释为受福克-普朗克方程支配的概率流，通过相对熵量化模型与数据的失配，并推导出包含非负熵产生项的熵平衡分解。通过使用指数加权移动平均控制统计量对KL散度的流式核密度估计器进行监控，实现了基于熵触发的重训练策略。在合成数据、金融和网络流量数据流上的实验表明，该方法在保持与频繁重训练相当预测性能的同时，将重训练频率降低了一到两个数量级；但在复杂的生物医学心电图场景中，由于特征空间熵监测在标签条件漂移下的局限性，该熵触发机制的表现不及最高频率基线。</div>
</details>
</div>
<div class="card">
<div class="title">Forcing and Diagnosing Failure Modes of Fourier Neural Operators Across Diverse PDE Families</div>
<div class="meta-line">Authors: Lennon Shikhman</div>
<div class="meta-line">First: 2026-01-16T16:47:44+00:00 · Latest: 2026-01-16T16:47:44+00:00</div>
<div class="meta-line">Comments: 17 pages, 8 figures</div>
<div class="links" style="margin-top:8px"><a href="https://arxiv.org/abs/2601.11428v1">Abs</a> · <a href="https://arxiv.org/pdf/2601.11428v1">PDF</a> · <a href="https://huggingface.co/huggingface">Code1</a> · <a href="https://huggingface.co/docs/hub/spaces">Code2</a></div>
<details class="detail"><summary>Abstract</summary>
<div class="mono">Fourier Neural Operators (FNOs) have shown strong performance in learning solution maps of partial differential equations (PDEs), but their robustness under distribution shifts, long-horizon rollouts, and structural perturbations remains poorly understood. We present a systematic stress-testing framework that probes failure modes of FNOs across five qualitatively different PDE families: dispersive, elliptic, multi-scale fluid, financial, and chaotic systems. Rather than optimizing in-distribution accuracy, we design controlled stress tests--including parameter shifts, boundary or terminal condition changes, resolution extrapolation with spectral analysis, and iterative rollouts--to expose vulnerabilities such as spectral bias, compounding integration errors, and overfitting to restricted boundary regimes. Our large-scale evaluation (1{,}000 trained models) reveals that distribution shifts in parameters or boundary conditions can inflate errors by more than an order of magnitude, while resolution changes primarily concentrate error in high-frequency modes. Input perturbations generally do not amplify error, though worst-case scenarios (e.g., localized Poisson perturbations) remain challenging. These findings provide a comparative failure-mode atlas and actionable insights for improving robustness in operator learning.</div></details>
<details class="detail"><summary>中文标题/摘要</summary>
<div class="mono"><b>标题：</b>傅里叶神经算子在多类偏微分方程族中的失效模式诱发与诊断</div>
<div class="mono" style="margin-top:8px">傅里叶神经算子在偏微分方程解映射的学习中表现出优异性能，但其在分布偏移、长时程推演和结构扰动下的鲁棒性仍不明确。本文提出系统性压力测试框架，针对五类性质各异的偏微分方程族（色散型、椭圆型、多尺度流体、金融模型、混沌系统）探究算子失效模式。通过设计受控压力测试——包括参数偏移、边界/终端条件变更、结合谱分析的分辨率外推及迭代推演——揭示谱偏差、积分误差累积及边界条件过拟合等脆弱性，而非优化分布内精度。大规模评估（1,000个训练模型）表明：参数或边界条件的分布偏移可使误差扩大超一个数量级；分辨率变化主要将误差集中于高频模态；输入扰动通常不会放大误差，但最坏情况（如局部泊松扰动）仍具挑战性。该研究为算子学习的鲁棒性提升提供了失效模式对比图谱与可行见解。</div>
</details>
<details class="detail"><summary>Summary / 总结</summary>
<div class="mono">This research systematically investigates the robustness limitations of Fourier Neural Operators (FNOs) in learning PDE solution maps, motivated by the need to understand their performance under realistic distribution shifts and perturbations beyond standard training conditions. The method involves a comprehensive stress-testing framework that subjects FNOs to controlled challenges—including parameter and boundary condition shifts, resolution extrapolation, and iterative rollouts—across five distinct PDE families (dispersive, elliptic, multi-scale fluid, financial, and chaotic systems). Key experimental findings from evaluating 1,000 models reveal that distribution shifts in parameters or boundary conditions can increase errors by over an order of magnitude, resolution changes mainly concentrate errors in high-frequency modes, and while input perturbations generally do not amplify error, certain worst-case scenarios like localized Poisson perturbations remain problematic.</div>
<div class="mono" style="margin-top:8px">本研究系统探究了傅里叶神经算子在偏微分方程求解中的鲁棒性，其动机在于对其在分布偏移和结构扰动下性能的理解不足。方法上，研究者构建了一个压力测试框架，通过参数偏移、边界条件改变和分辨率外推等受控测试，在五个不同性质的偏微分方程族上评估算子性能。基于1000个训练模型的大规模实验结果表明，参数或边界条件的分布偏移可使误差增加一个数量级以上，分辨率变化主要影响高频模态误差，而输入扰动通常不会放大误差，但局部泊松扰动等最坏情况仍具挑战性。</div>
</details>
</div>
<div class="card">
<div class="title">PubMed-OCR: PMC Open Access OCR Annotations</div>
<div class="meta-line">Authors: Hunter Heidenreich, Yosheb Getachew, Olivia Dinica, Ben Elliott</div>
<div class="meta-line">First: 2026-01-16T16:44:50+00:00 · Latest: 2026-01-16T16:44:50+00:00</div>
<div class="links" style="margin-top:8px"><a href="https://arxiv.org/abs/2601.11425v1">Abs</a> · <a href="https://arxiv.org/pdf/2601.11425v1">PDF</a> · <a href="https://huggingface.co/huggingface">Code1</a> · <a href="https://huggingface.co/docs/hub/spaces">Code2</a></div>
<details class="detail"><summary>Abstract</summary>
<div class="mono">PubMed-OCR is an OCR-centric corpus of scientific articles derived from PubMed Central Open Access PDFs. Each page image is annotated with Google Cloud Vision and released in a compact JSON schema with word-, line-, and paragraph-level bounding boxes. The corpus spans 209.5K articles (1.5M pages; ~1.3B words) and supports layout-aware modeling, coordinate-grounded QA, and evaluation of OCR-dependent pipelines. We analyze corpus characteristics (e.g., journal coverage and detected layout features) and discuss limitations, including reliance on a single OCR engine and heuristic line reconstruction. We release the data and schema to facilitate downstream research and invite extensions.</div></details>
<details class="detail"><summary>中文标题/摘要</summary>
<div class="mono"><b>标题：</b>PubMed-OCR：PMC开放获取OCR标注数据集</div>
<div class="mono" style="margin-top:8px">PubMed-OCR是一个基于OCR的科学文献语料库，源自PubMed Central开放获取PDF文件。每页图像均通过Google Cloud Vision进行标注，并以紧凑的JSON格式发布，包含单词、行和段落级别的边界框。该语料库涵盖20.95万篇文章（150万页；约13亿单词），支持布局感知建模、坐标锚定问答及OCR依赖流程的评估。我们分析了语料库特征（如期刊覆盖范围和检测到的布局特征），并讨论了其局限性，包括对单一OCR引擎的依赖和启发式行重建方法。我们公开数据和架构以促进下游研究，并欢迎扩展应用。</div>
</details>
<details class="detail"><summary>Summary / 总结</summary>
<div class="mono">To support research in layout-aware modeling and OCR-dependent tasks, this work introduces PubMed-OCR, a large-scale corpus created by applying Google Cloud Vision OCR to 1.5 million page images from PubMed Central Open Access PDFs. The method produces annotations with word-, line-, and paragraph-level bounding boxes in a compact JSON schema. The resulting dataset contains 209.5K articles and approximately 1.3 billion words, enabling tasks like coordinate-grounded QA, while analysis reveals its journal coverage and layout features, though limitations include dependence on a single OCR engine and heuristic line reconstruction.</div>
<div class="mono" style="margin-top:8px">为支持面向版式的建模、基于坐标的问答以及依赖OCR的流程评估等研究，本研究构建了PubMed-OCR数据集，该大规模语料源自PubMed Central开放获取的PDF文件。方法上，使用Google Cloud Vision OCR对150万页图像进行标注，生成包含单词、行和段落级边界框的紧凑JSON格式。最终数据集涵盖20.95万篇文章、约13亿单词，分析内容包括期刊覆盖范围和版面特征，同时指出了依赖单一OCR引擎和启发式行重建等局限性。</div>
</details>
</div>
<div class="card">
<div class="title">High-Dimensional Tail Index Regression</div>
<div class="meta-line">Authors: Yuya Sasaki, Jing Tao, Yulong Wang</div>
<div class="meta-line">First: 2024-03-02T21:37:40+00:00 · Latest: 2026-01-16T16:42:41+00:00</div>
<div class="links" style="margin-top:8px"><a href="https://arxiv.org/abs/2403.01318v3">Abs</a> · <a href="https://arxiv.org/pdf/2403.01318v3">PDF</a> · <a href="https://huggingface.co/huggingface">Code1</a> · <a href="https://huggingface.co/docs/hub/spaces">Code2</a></div>
<details class="detail"><summary>Abstract</summary>
<div class="mono">Motivated by the empirical observation of power-law distributions in the credits (e.g., ``likes&#x27;&#x27;) of viral posts in social media, we introduce a high-dimensional tail index regression model and propose methods for estimation and inference of its parameters. First, we propose a regularized estimator, establish its consistency, and derive its convergence rate. Second, we debias the regularized estimator to facilitate inference and prove its asymptotic normality. Simulation studies corroborate our theoretical findings. We apply these methods to the text analysis of viral posts on X (formerly Twitter).</div></details>
<details class="detail"><summary>中文标题/摘要</summary>
<div class="mono"><b>标题：</b>高维尾指数回归</div>
<div class="mono" style="margin-top:8px">受社交媒体中病毒式传播帖子的点赞数等信用指标呈现幂律分布的实证观察启发，我们提出了一种高维尾指数回归模型，并给出了其参数的估计与推断方法。首先，我们提出一种正则化估计量，证明其一致性并推导收敛速率。其次，我们对正则化估计量进行去偏处理以支持统计推断，并证明其渐近正态性。仿真研究验证了理论结果。我们将这些方法应用于X平台（原Twitter）病毒式传播帖子的文本分析。</div>
</details>
<details class="detail"><summary>Summary / 总结</summary>
<div class="mono">Motivated by the empirical observation of power-law distributions in social media metrics like post &#x27;likes&#x27;, this study introduces a high-dimensional tail index regression model to analyze such heavy-tailed phenomena. The method involves first proposing a regularized estimator, establishing its consistency and deriving its convergence rate, and then debiasing this estimator to enable statistical inference, with proven asymptotic normality. Simulation studies support the theoretical results, and the method is applied to analyze the text of viral posts on X (formerly Twitter).</div>
<div class="mono" style="margin-top:8px">本文的动机源于对社交媒体中病毒式帖子（如“点赞”数）呈现幂律分布的实证观察，为此引入了高维尾部指数回归模型来分析此类重尾现象。研究方法包括提出一种正则化估计量进行参数估计，确立其一致性和收敛速率，并对该估计量进行去偏处理以促进统计推断，同时证明了其渐近正态性。模拟研究验证了理论结果，该方法被应用于对X（原Twitter）上病毒式帖子的文本分析。</div>
</details>
</div>
<div class="card">
<div class="title">Statistical Robustness of Interval CVaR Based Regression Models under Perturbation and Contamination</div>
<div class="meta-line">Authors: Yulei You, Junyi Liu</div>
<div class="meta-line">First: 2026-01-16T16:41:57+00:00 · Latest: 2026-01-16T16:41:57+00:00</div>
<div class="links" style="margin-top:8px"><a href="https://arxiv.org/abs/2601.11420v1">Abs</a> · <a href="https://arxiv.org/pdf/2601.11420v1">PDF</a> · <a href="https://huggingface.co/huggingface">Code1</a> · <a href="https://huggingface.co/docs/hub/spaces">Code2</a></div>
<details class="detail"><summary>Abstract</summary>
<div class="mono">Robustness under perturbation and contamination is a prominent issue in statistical learning. We address the robust nonlinear regression based on the so-called interval conditional value-at-risk (In-CVaR), which is introduced to enhance robustness by trimming extreme losses. While recent literature shows that the In-CVaR based statistical learning exhibits superior robustness performance than classical robust regression models, its theoretical robustness analysis for nonlinear regression remains largely unexplored. We rigorously quantify robustness under contamination, with a unified study of distributional breakdown point for a broad class of regression models, including linear, piecewise affine and neural network models with $\ell_1$, $\ell_2$ and Huber losses. Moreover, we analyze the qualitative robustness of the In-CVaR based estimator under perturbation. We show that under several minor assumptions, the In-CVaR based estimator is qualitatively robust in terms of the Prokhorov metric if and only if the largest portion of losses is trimmed. Overall, this study analyzes robustness properties of In-CVaR based nonlinear regression models under both perturbation and contamination, which illustrates the advantages of In-CVaR risk measure over conditional value-at-risk and expectation for robust regression in both theory and numerical experiments.</div></details>
<details class="detail"><summary>中文标题/摘要</summary>
<div class="mono"><b>标题：</b>基于区间条件风险价值的回归模型在扰动与污染下的统计稳健性</div>
<div class="mono" style="margin-top:8px">扰动与污染下的稳健性是统计学习中的重要问题。本文研究基于区间条件风险价值（In-CVaR）的稳健非线性回归，该方法通过截断极端损失来增强稳健性。尽管近期文献表明基于In-CVaR的统计学习相比经典稳健回归模型具有更优的稳健性表现，但其在非线性回归中的理论稳健性分析尚未充分探索。我们严格量化了污染下的稳健性，通过分布崩溃点的统一研究覆盖了包括线性、分段仿射及采用ℓ₁、ℓ₂与Huber损失的神经网络模型在内的广泛回归模型。此外，我们分析了基于In-CVaR的估计量在扰动下的定性稳健性，证明在若干温和假设下，该估计量关于Prokhorov度量具有定性稳健性当且仅当最大比例的损失被截断。本研究系统分析了基于In-CVaR的非线性回归模型在扰动与污染下的稳健性，从理论与数值实验两方面阐明了In-CVaR风险度量相较于条件风险价值与期望在稳健回归中的优势。</div>
</details>
<details class="detail"><summary>Summary / 总结</summary>
<div class="mono">Motivated by the need for robust statistical learning under data perturbation and contamination, this study investigates nonlinear regression models based on interval conditional value-at-risk (In-CVaR), which trims extreme losses to enhance robustness. The method involves a rigorous theoretical analysis, quantifying robustness through distributional breakdown points for a broad class of models including linear, piecewise affine, and neural networks with various loss functions, and assessing qualitative robustness under perturbation using the Prokhorov metric. Key experimental findings demonstrate that the In-CVaR-based estimator exhibits superior robustness performance compared to classical models, with theoretical conditions showing it is qualitatively robust if and only if the largest portion of losses is trimmed, highlighting its advantages over CVaR and expectation-based methods in both theory and numerical experiments.</div>
<div class="mono" style="margin-top:8px">本研究针对数据扰动和污染下稳健统计学习的需求，深入分析了基于区间条件风险价值（In-CVaR）的非线性回归模型的稳健性，该风险度量通过修剪极端损失来增强鲁棒性。方法上，对包括线性、分段仿射和神经网络模型在内的广泛回归模型类别，在多种损失函数下进行了分布崩溃点的统一理论分析，并利用Prokhorov度量分析了扰动下的定性鲁棒性。主要实验结果表明，基于In-CVaR的估计器相比经典稳健回归模型表现出更优的鲁棒性能，理论条件证明仅当修剪最大部分的损失时该估计器才具有定性鲁棒性，这从理论和数值实验上阐明了In-CVaR相对于条件风险价值和期望在稳健回归中的优势。</div>
</details>
</div></div>
    <details style="margin-top:16px" class="detail"><summary>History</summary>
      <div class="history-list"><a href="archive/20260121_0450.html">20260121_0450</a>
<a href="archive/20260121_0423.html">20260121_0423</a>
<a href="archive/20260120_0626.html">20260120_0626</a>
<a href="archive/20260120_0528.html">20260120_0528</a>
<a href="archive/20260120_0443.html">20260120_0443</a>
<a href="archive/20260120_0330.html">20260120_0330</a>
<a href="archive/20260119_0624.html">20260119_0624</a>
<a href="archive/20260119_0525.html">20260119_0525</a>
<a href="archive/20260119_0440.html">20260119_0440</a>
<a href="archive/20260119_0325.html">20260119_0325</a>
<a href="archive/20260118_2225.html">20260118_2225</a>
<a href="archive/20260118_2159.html">20260118_2159</a>
<a href="archive/20260118_2135.html">20260118_2135</a>
<a href="archive/20260118_2040.html">20260118_2040</a>
<a href="archive/20260118_1953.html">20260118_1953</a>
<a href="archive/20260118_1907.html">20260118_1907</a>
<a href="archive/20260118_0327.html">20260118_0327</a>
<a href="archive/20260117_0332.html">20260117_0332</a>
<a href="archive/20260116_0339.html">20260116_0339</a>
<a href="archive/20260115_0334.html">20260115_0334</a>
<a href="archive/20260114_0333.html">20260114_0333</a>
<a href="archive/20260113_0334.html">20260113_0334</a>
<a href="archive/20260112_0331.html">20260112_0331</a>
<a href="archive/20260111_0329.html">20260111_0329</a>
<a href="archive/20260110_0333.html">20260110_0333</a>
<a href="archive/20260109_0334.html">20260109_0334</a>
<a href="archive/20260108_0335.html">20260108_0335</a>
<a href="archive/20260107_0330.html">20260107_0330</a>
<a href="archive/20260106_0336.html">20260106_0336</a>
<a href="archive/20260105_0328.html">20260105_0328</a>
<a href="archive/20260104_0328.html">20260104_0328</a>
<a href="archive/20260103_0325.html">20260103_0325</a>
<a href="archive/20260102_0339.html">20260102_0339</a>
<a href="archive/20260101_0329.html">20260101_0329</a>
<a href="archive/20251231_0333.html">20251231_0333</a>
<a href="archive/20251230_0332.html">20251230_0332</a>
<a href="archive/20251229_0329.html">20251229_0329</a>
<a href="archive/20251228_0332.html">20251228_0332</a>
<a href="archive/20251227_0329.html">20251227_0329</a>
<a href="archive/20251226_0330.html">20251226_0330</a>
<a href="archive/20251225_0329.html">20251225_0329</a>
<a href="archive/20251224_0331.html">20251224_0331</a>
<a href="archive/20251223_0332.html">20251223_0332</a>
<a href="archive/20251222_0328.html">20251222_0328</a>
<a href="archive/20251221_0329.html">20251221_0329</a>
<a href="archive/20251220_0330.html">20251220_0330</a>
<a href="archive/20251219_0330.html">20251219_0330</a>
<a href="archive/20251218_0345.html">20251218_0345</a>
<a href="archive/20251217_0332.html">20251217_0332</a>
<a href="archive/20251216_0333.html">20251216_0333</a>
<a href="archive/20251215_0333.html">20251215_0333</a>
<a href="archive/20251214_0327.html">20251214_0327</a>
<a href="archive/20251212_0333.html">20251212_0333</a>
<a href="archive/20251211_0331.html">20251211_0331</a>
<a href="archive/20251210_0332.html">20251210_0332</a>
<a href="archive/20251209_0331.html">20251209_0331</a>
<a href="archive/20251208_0328.html">20251208_0328</a>
<a href="archive/20251207_0327.html">20251207_0327</a>
<a href="archive/20251206_0330.html">20251206_0330</a>
<a href="archive/20251205_0331.html">20251205_0331</a>
<a href="archive/20251204_0331.html">20251204_0331</a>
<a href="archive/20251203_0333.html">20251203_0333</a>
<a href="archive/20251202_0335.html">20251202_0335</a>
<a href="archive/20251201_0328.html">20251201_0328</a>
<a href="archive/20251130_0327.html">20251130_0327</a>
<a href="archive/20251129_0328.html">20251129_0328</a>
<a href="archive/20251128_0327.html">20251128_0327</a>
<a href="archive/20251127_0327.html">20251127_0327</a>
<a href="archive/20251126_0329.html">20251126_0329</a>
<a href="archive/20251125_0327.html">20251125_0327</a>
<a href="archive/20251124_0327.html">20251124_0327</a>
<a href="archive/20251123_0326.html">20251123_0326</a>
<a href="archive/20251122_0328.html">20251122_0328</a>
<a href="archive/20251121_0328.html">20251121_0328</a>
<a href="archive/20251120_0329.html">20251120_0329</a>
<a href="archive/20251119_0328.html">20251119_0328</a>
<a href="archive/20251118_0328.html">20251118_0328</a>
<a href="archive/20251117_0326.html">20251117_0326</a>
<a href="archive/20251116_0325.html">20251116_0325</a>
<a href="archive/20251115_0327.html">20251115_0327</a>
<a href="archive/20251114_0328.html">20251114_0328</a>
<a href="archive/20251113_0330.html">20251113_0330</a>
<a href="archive/20251112_0329.html">20251112_0329</a>
<a href="archive/20251111_0328.html">20251111_0328</a>
<a href="archive/20251110_0325.html">20251110_0325</a>
<a href="archive/20251109_0326.html">20251109_0326</a>
<a href="archive/20251108_0328.html">20251108_0328</a>
<a href="archive/20251107_0328.html">20251107_0328</a>
<a href="archive/20251106_0329.html">20251106_0329</a>
<a href="archive/20251105_0326.html">20251105_0326</a>
<a href="archive/20251104_0327.html">20251104_0327</a>
<a href="archive/20251103_0324.html">20251103_0324</a>
<a href="archive/20251102_0326.html">20251102_0326</a>
<a href="archive/20251101_0324.html">20251101_0324</a>
<a href="archive/20251031_0328.html">20251031_0328</a>
<a href="archive/20251030_0330.html">20251030_0330</a>
<a href="archive/20251029_0329.html">20251029_0329</a>
<a href="archive/20251028_0329.html">20251028_0329</a>
<a href="archive/20251027_0322.html">20251027_0322</a>
<a href="archive/20251026_0327.html">20251026_0327</a></div>
    </details>
    <div class="footer">Generated by arxiv-tracker</div>
  </div>
</body></html>
